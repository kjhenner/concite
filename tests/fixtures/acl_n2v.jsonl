{"paper_id": "N12-1048", "abstract": "In a conventional telephone conversation between two speakers of the same language, the interaction is real-time and the speakers process the information stream incrementally. In this work, we address the problem of incremental speech-to-speech translation (S2S) that enables cross-lingual communication between two remote participants over a telephone. We investigate the problem in a novel real-time Session Initiation Protocol (SIP) based S2S framework. The speech translation is performed incrementally based on generation of partial hypotheses from speech recognition. We describe the statistical models comprising the S2S system and the SIP architecture for enabling real-time two-way cross-lingual dialog. We present dialog experiments performed in this framework and study the tradeoff in accuracy versus latency in incremental speech translation. Experimental results demonstrate that high quality translations can be generated with the incremental approach with approximately half the latency associated with nonincremental approach.", "title": "Real-time Incremental Speech-to-Speech Translation of Dialogs", "venue": "N", "graph_vector": [0.125098, 0.480843, 0.229536, 0.222365, 0.653658, -1.19315, 0.0124634, 0.15576, -1.33231, 0.246068, -0.123579, -0.590741, 0.460251, 0.397713, -0.0796341, -0.281036, 0.258627, -0.727439, 0.218483, 0.0603461, -0.383203, 0.636246, 0.390166, 0.270394, -0.511859, -0.251107, -0.00431533, 0.117586, -0.417964, -0.540696, -0.24143, 0.270124, -0.284199, -0.0340927, -0.208311, 0.273013, -0.278786, 0.749513, 0.217222, -0.417844, -0.0403301, -0.574581, -0.492015, 0.387932, 1.4002, -0.925445, -0.233266, 0.203208, -0.201505, -0.0213002, -0.0495792, -0.105481, 0.812265, 0.841613, -0.44453, 0.202133, 0.23349, 0.390498, 0.105252, -0.0167633, 0.00310336, -0.317088, 0.331828, -0.320586, 0.182974, 0.156197, -0.0599738, -0.0961462, -0.0589716, -0.0875468, 0.322352, 0.0842272, -0.0964686, 0.215097, 0.381328, 0.302268, -0.664523, -0.447111, -0.257419, -0.401835, -0.105269, 0.0705273, -0.377407, -0.418956, -0.0791064, -0.311179, 0.213812, -0.324002, 0.198423, 0.14494, 0.0912152, -0.0969431, -0.78948, -0.287532, -0.0496351, 0.241951, -0.27647, -0.0500544, -0.208937, 0.0470909, -0.173611, 0.0447822, -0.0329984, 0.344312, 0.114495, 0.0920097, 0.173714, 0.036945, 0.4675, 0.104321, 0.392125, 0.357749, 0.246987, 0.107861, -0.338435, 0.0597549, 0.0980967, 0.574062, 0.147811, -0.106757, 0.397994, -0.126438, 0.128953, -0.163617, 0.476223, 0.467374, -0.121263, 0.0711929], "internal": 1}
{"paper_id": "N13-3005", "abstract": "This paper presents a web application and a web service for the diagnostic evaluation of Machine Translation (MT). These web-based tools are built on top of DELiC4MT, an opensource software package that assesses the performance of MT systems over user-defined linguistic phenomena (lexical, morphological, syntactic and semantic). The advantage of the web-based scenario is clear; compared to the standalone tool, the user does not need to carry out any installation, configuration or maintenance of the tool.", "title": "A Web Application for the Diagnostic Evaluation of Machine Translation over Specific Linguistic Phenomena", "venue": "N", "graph_vector": [0.333472, 0.120822, -0.0748983, 0.036097, 0.605674, -0.589111, 0.00255181, -0.00368569, -1.65007, 0.370181, 0.336711, -0.679126, 0.899343, -0.109746, 0.259376, -0.209642, 0.419882, -0.518214, -0.0228003, 0.498603, -0.336177, 0.514375, 0.513284, 0.136573, -0.442842, -0.281873, -0.194004, 0.320289, -0.00100586, -0.369399, 0.0721651, -0.0949236, 0.12012, -0.0453385, -0.464259, 0.179968, -0.396534, 1.02953, -0.0589181, 0.0459338, -0.318328, -0.285813, -0.672862, 0.140921, 0.714476, -0.601083, -0.0594363, 0.358885, 0.0984207, -0.0335563, 0.212031, 0.204323, 0.605581, 0.61638, -0.170378, 0.598051, 0.528155, 0.221439, -0.0032318, -0.34613, -0.290706, 0.0902969, 0.145762, 0.283484, 0.0842984, 0.322738, 0.381082, -0.701912, 0.169577, -0.0539376, 0.0892959, 0.124191, 0.376012, 0.114421, 0.532383, 0.225403, -0.501733, -0.231997, 0.0812583, 0.00922223, 0.0824587, 0.0942523, 0.0705091, -0.0403879, 0.131924, -0.322876, 0.12077, -0.225977, 0.0609625, 0.033336, 0.010254, -0.35859, -1.15068, 0.0377639, -0.113692, -0.100836, -0.171992, 0.0219737, -0.0419629, -0.0900012, -0.496437, 0.163804, -0.132974, 0.368423, -0.280484, 0.00123196, -0.202521, 0.167808, 0.108667, -0.270983, 0.505835, 0.0477493, -0.212245, -0.0207654, -0.15161, -0.26703, 0.226507, 0.259411, 0.156391, 0.276205, 0.153282, -0.222267, -0.147468, 0.339656, 0.440037, 0.275035, -0.0407365, 0.36333], "internal": 1}
{"paper_id": "N13-3001", "abstract": "Automatic interpretation of documents is hampered by the fact that language contains terms which have multiple meanings. These ambiguities can still be found when language is restricted to a particular domain, such as biomedicine. Word Sense Disambiguation (WSD) systems attempt to resolve these ambiguities but are often only able to identify the meanings for a small set of ambiguous terms. DALE (Disambiguation using Automatically Labeled Examples) is a supervised WSD system that can disambiguate a wide range of ambiguities found in biomedical documents. DALE uses the UMLS Metathesaurus as both a sense inventory and as a source of information for automatically generating labeled training examples. DALE is able to disambiguate biomedical documents with the coverage of unsupervised approaches and accuracy of supervised methods.", "title": "DALE: A Word Sense Disambiguation System for Biomedical Documents Trained using Automatically Labeled Examples", "venue": "N", "graph_vector": [0.0305873, 0.329426, 0.450815, -0.0901532, 0.622076, -0.60545, 0.178767, -0.323464, -1.8557, 0.389639, -0.241218, -0.153732, 0.748446, 0.377286, 0.0191177, -0.246435, 0.901923, -0.806926, 0.293941, 0.256523, -0.129928, 0.205642, -0.277478, 0.000638746, -0.11803, 0.288164, -0.214139, 0.0196118, 0.0232115, 0.125302, 0.106988, 0.278318, -0.22119, -0.161157, -0.365731, -0.00382491, -0.456402, 0.722091, 0.22101, -0.206679, -0.262471, -0.259473, -0.25085, -0.058131, 1.06838, -0.784823, 0.601505, 0.0970251, -0.11433, -0.188072, 0.652541, 0.156953, 0.958969, 0.731058, -0.19773, 0.111297, 0.107563, 0.470793, -0.332844, 0.310308, -0.216853, -0.0703449, 0.135596, 0.129376, 0.0916219, -0.461139, 0.111264, -0.114357, -0.140484, -0.20589, 0.313725, 0.04551, 0.0274969, 0.0564127, -0.0145161, -0.0905536, -0.833155, -0.188146, 0.163708, -0.114639, -0.277959, -0.050256, 0.0935285, 0.36478, 0.078457, -0.504321, 0.208024, -0.131845, 0.210167, 0.100658, 0.444669, 0.0365569, -0.778038, -0.0688073, -0.122099, -0.079435, 0.0253824, -0.0469866, -0.140332, 0.409292, -0.46445, 0.121393, 0.183999, 0.212383, -0.126512, -0.34201, -0.413164, 0.0100552, -0.220856, -0.950241, -0.0533633, 0.177655, -0.501414, 0.161194, -0.262436, -0.116859, 0.436587, 0.299072, 0.205589, 0.211556, 0.0903932, -0.147762, -0.132485, -0.107423, 0.347574, -0.187472, -0.0325946, 0.0947153], "internal": 1}
{"paper_id": "N13-3004", "abstract": "Anafora is a newly-developed open source web-based text annotation tool built to be lightweight, flexible, easy to use and capable of annotating with a variety of schemas, simple and complex. Anafora allows secure web-based annotation of any plaintext file with both spanned (e.g. named entity or markable) and relation annotations, as well as adjudication for both types of annotation. Anafora offers automatic set assignment and progress-tracking, centralized and humaneditable XML annotation schemas, and filebased storage and organization of data in a human-readable single-file XML format.", "title": "Anafora: A Web-based General Purpose Annotation Tool", "venue": "N", "graph_vector": [-0.161939, 0.556682, 0.4048, 0.30189, 0.639702, -0.693487, -0.244341, 0.533594, -1.59263, 0.405136, -0.232866, -0.358289, 0.86727, -0.243028, -0.0426217, 0.0791103, 0.594098, -0.922589, 0.21223, 0.468591, -0.384293, 0.825632, 0.433429, 0.0113032, -0.350605, 0.0517608, 0.0921099, -0.0242704, -0.198057, -0.0137691, 0.145636, 0.195094, -0.0340751, -0.352841, -0.0435399, -0.091032, 0.00195727, 0.467248, -0.178696, -0.0157147, 0.190716, -0.253654, -0.415277, -0.0593514, 0.929047, -1.06012, 0.213073, 0.22552, 0.189169, 0.176255, 0.377887, 0.0140598, 0.711896, 0.802647, -0.0415096, 0.178036, 0.00917409, 0.106547, -0.0362512, -0.00488296, -0.385235, 0.137929, -0.0140593, -0.156071, 0.212482, -0.153314, 0.128084, -0.0466429, 0.425804, -0.143659, 0.292127, 0.126341, 0.14451, 0.242647, -0.176568, -0.171556, -0.605398, -0.422596, -0.240873, 0.423539, -0.209123, 0.0525821, 0.281391, -0.172124, 0.0526081, -0.281473, 0.157791, -0.207228, 0.260996, 0.0381286, -0.136838, 0.212391, -0.767901, 0.091663, -0.0198788, -0.252608, -0.0606041, -0.0842115, -0.234753, -0.0682312, -0.310578, -0.401445, 0.168465, 0.122636, -0.0648129, 0.0802416, 0.00317776, -0.0547608, -0.0271057, -0.551219, 0.0310062, 0.222299, 0.164132, -0.215792, -0.610901, -0.0982422, 0.618728, 0.224311, 0.130477, 0.297421, 0.509445, -0.081673, 0.0840036, -0.346074, 0.259275, 0.184515, -0.20257, -0.0647893], "internal": 1}
{"paper_id": "N13-2001", "abstract": "In this paper we revisit the task of quantitative evaluation of coreference resolution systems. We review the most commonly used metrics (MUC, B3, CEAF and BLANC) on the basis of their evaluation of coreference resolution in five texts from the OntoNotes corpus. We examine both the correlation between the metrics and the degree to which our human judgement of coreference resolution agrees with the metrics. In conclusion we claim that loss of information value is an essential factor, insufficiently adressed in current metrics, in human perception of the degree of success or failure of coreference resolution. We thus conjecture that including a layer of mention information weight could improve both the coreference resolution and its evaluation.", "title": "Critical Reflections on Evaluation Practices in Coreference Resolution", "venue": "N", "graph_vector": [0.0318512, 0.13185, -0.198625, 0.402401, 0.696802, -0.397147, 0.136625, -0.153502, -1.74734, 0.489159, 0.0443007, -0.167246, 0.696649, 0.344089, 0.412315, -0.140184, 0.386229, -0.759374, 0.163688, 0.404254, -0.855201, 0.337156, 0.058745, -0.168978, -0.38885, -0.0283194, 0.371026, 0.571194, -0.244277, -0.168792, 0.0116987, -0.0187564, 0.188589, -0.572933, -0.222566, 0.34412, -0.112999, 0.519111, -0.147323, -0.126693, 0.288731, -0.178874, -0.375292, 0.214569, 0.859226, -0.909979, 0.326473, 0.0246392, -0.214819, -0.0844252, -0.00838534, 0.00405335, 0.817087, 0.740573, 0.050798, 0.13921, -0.464992, 0.0901702, -0.218621, 0.151332, -0.237351, -0.344695, 0.0100587, -0.0997552, 0.00827883, -0.255619, 0.305641, -0.173203, 0.00510831, 0.0149295, 0.121061, 0.409935, -0.00444137, -0.097127, 0.12111, -0.146525, -0.39224, -0.143921, -0.297511, -0.247778, 0.169017, 0.107646, 0.0384998, -0.276049, 0.0235926, -0.315274, 0.130566, 0.0251412, 0.057661, 0.115561, 0.458813, 0.0271141, -0.576938, -0.117054, -0.239529, -0.184906, 0.146746, 0.0215783, -0.0302145, -0.0376009, 0.0254632, -0.294498, -0.0864786, 0.226454, -0.49606, 0.157469, -0.25055, 0.0998574, 0.063881, -0.246853, -0.12279, 0.0920977, -0.0932872, -0.0926803, 0.0109605, -0.335971, 0.465587, 0.0758049, 0.0365742, 0.364311, -0.0441247, 0.124196, -0.0332721, -0.241658, 0.395478, 0.27429, 0.119759, -0.23049], "internal": 1}
{"paper_id": "N09-2014", "abstract": "We investigate natural language understanding of partial speech recognition results to equip a dialogue system with incremental language processing capabilities for more realistic human-computer conversations. We show that relatively high accuracy can be achieved in understanding of spontaneous utterances before utterances are completed.", "title": "Towards Natural Language Understanding of Partial Speech Recognition Results in Dialogue Systems", "venue": "N", "graph_vector": [0.437112, -0.0659429, -0.349185, 0.0664161, 0.360241, -0.967163, 0.509795, -0.267708, -1.83792, 0.27359, -0.0901591, 0.0358707, 0.578567, -0.0429482, 0.119617, -0.141548, 0.568366, -0.239381, 0.0381973, 0.263526, -0.369495, 0.653238, 0.175874, -0.113096, -0.512407, 0.045633, -0.121349, -0.0989701, -0.217287, 0.243926, -0.393607, 0.0646336, -0.0822479, -0.9709, -0.0700689, 0.0163934, -0.271109, 0.722492, 0.599547, 0.424503, -0.0961988, -0.000633052, -0.478759, 0.130155, 0.907123, -1.09009, -0.0324114, -0.351038, 0.0203396, -0.328539, 0.325799, -0.405715, 0.536402, 0.783296, -0.272868, 0.220232, 0.357273, 0.217354, 0.32918, 0.0643624, 0.0332071, 0.29397, -0.049657, 0.152334, -0.412643, 0.187765, 0.191783, 0.0774011, -0.100006, 0.0635196, 0.271562, 0.393344, 0.273463, 0.278035, 0.0309718, -0.074612, -0.530536, -0.276203, -0.20096, 0.341728, -0.0227707, -0.400377, 0.12734, -0.0584057, 0.236215, 0.0225392, 0.0777701, 0.0190901, 0.186146, -0.17172, 0.561949, 0.0607868, -0.491887, -0.224884, -0.24159, 0.117683, -0.164726, 0.0923298, 0.459506, -0.177568, -0.159642, -0.432812, 0.369847, 0.411834, -0.320885, -0.0472919, 0.21981, -0.152384, 0.164834, -0.41597, -0.430555, -0.110091, -0.216273, 0.002456, 0.00182676, -0.227557, 0.190471, 0.0307567, -0.106537, -0.144216, 0.419738, 0.0951945, -0.210194, -0.241877, 0.328367, 0.0753045, -0.465716, -0.0711644], "internal": 1}
{"paper_id": "N03-1030", "abstract": "We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees. The models use syntactic and lexical features. A discourse parsing algorithm that implements these models derives discourse parse trees with an error reduction of 18.8% over a state-ofthe-art decision-based discourse parser. A set of empirical evaluations shows that our discourse parsing model is sophisticated enough to yield discourse trees at an accuracy level that matches near-human levels of performance.", "title": "Sentence Level Discourse Parsing using Syntactic and Lexical Information", "venue": "N", "graph_vector": [-0.0261667, 0.246105, 0.164945, 0.0880282, 0.2968, -0.678668, -0.0472365, -0.41394, -1.71016, 0.21315, -0.397468, -0.421572, 0.0623369, -0.0631454, -0.00248879, 0.151459, 0.311899, -0.589878, 0.374607, 0.312256, -0.239775, 0.595612, 0.0786003, -0.244345, -0.136571, 0.216195, -0.157366, -0.0280036, 0.141517, -0.37545, 0.0802257, -0.11688, 0.155411, -0.382336, -0.161117, 0.0191217, -0.477183, 0.835845, 0.340032, -0.0569027, -0.0581612, -0.210864, -0.162974, -0.197232, 0.887099, -0.398619, -0.155026, -0.124039, 0.166447, -0.0583709, 0.185042, 0.0453087, 1.06669, 0.655023, -0.200443, 0.215325, 0.213954, 0.207845, -0.00858189, 0.0127024, 0.120186, -0.0561144, -0.145313, -0.112114, -0.0927159, 0.105847, 0.162344, -0.0703262, 0.230059, -0.204848, 0.108534, -0.204576, 0.101123, -0.0864381, -0.00652624, -0.202432, -0.0823429, 0.140261, -0.129709, 0.155454, -0.216329, 0.211777, 0.0953691, 0.0845275, 0.00132185, -0.029076, -0.0250675, 0.139131, 0.243991, -0.0954888, 0.018359, 0.078034, -0.671342, -0.056641, -0.0529545, 0.10108, -0.332806, 0.21724, -0.057571, -0.154467, -0.210523, -0.276558, 0.00613879, 0.0713728, -0.110587, -0.240346, -0.178027, 0.0329299, -0.0916883, -0.216027, 0.139651, 0.196438, 0.0588096, -0.200479, 0.235606, 0.27621, 0.470317, -0.000829274, 0.097815, 0.117356, -0.152879, 0.0333427, -0.021364, -0.10261, -0.0624005, 0.159091, 0.120919, -0.737189], "internal": 1}
{"paper_id": "N03-1002", "abstract": "Named Entity (NE) extraction is an important subtask of document processing such as information extraction and question answering. A typical method used for NE extraction of Japanese texts is a cascade of morphological analysis, POS tagging and chunking. However, there are some cases where segmentation granularity contradicts the results of morphological analysis and the building units of NEs, so that extraction of some NEs are inherently impossible in this setting. To cope with the unit problem, we propose a character-based chunking method. Firstly, the input sentence is analyzed redundantly by a statistical morphological analyzer to produce multiple (n-best) answers. Then, each character is annotated with its character types and its possible POS tags of the top n-best answers. Finally, a support vector machine-based chunker picks up some portions of the input sentence as NEs. This method introduces richer information to the chunker than previous methods that base on a single morphological analysis result. We apply our method to IREX NE extraction task. The cross validation result of the F-measure being 87.2 shows the superiority and effectiveness of the method.", "title": "Japanese Named Entity Extraction with Redundant Morphological Analysis", "venue": "N", "graph_vector": [0.072419, -0.344789, 0.293087, 0.469448, 0.289753, -0.684766, -0.244513, 0.148427, -1.67906, 0.238574, 0.148479, -0.037085, 0.399851, 0.100953, -0.0814023, -0.152655, 0.136348, -0.566448, 0.428361, 0.40098, -0.405074, 0.681208, 0.421614, 0.331375, -0.691756, 0.135318, 0.108111, -0.0937147, -0.364998, -0.310181, 0.310586, 0.0451639, 0.390773, -0.374646, 0.246482, -0.135012, -0.410784, 0.710799, 0.308258, 0.0192965, -0.0628261, -0.360311, -0.293397, 0.653065, 1.29096, -0.527708, -0.172025, 0.274614, 0.0550162, 0.0996121, 0.685335, -0.366724, 0.474465, 0.663211, -0.396185, 0.251064, 0.0667461, 0.453518, -0.0473293, 0.0535186, -0.632297, -0.19575, 0.141304, 0.0196617, -0.362308, -0.305144, 0.202482, 0.0839392, 0.211627, 0.0690873, -0.0996831, 0.374762, -0.308401, -0.36955, 0.28394, -0.228815, -0.417481, -0.227879, 0.0721907, -0.00466215, 0.306982, -0.120226, 0.766912, 0.378783, 0.203636, -0.514315, 0.440955, -0.25599, -0.0027087, 0.185204, -0.0335465, -0.31488, -0.777931, -0.1041, -0.19599, -0.0163317, -0.350024, 0.0134766, -0.0591079, -0.237664, 0.0157489, -0.368192, 0.138288, -0.441746, 0.238335, -0.202369, 0.308285, 0.0430267, 0.145511, -0.255321, -0.274988, 0.487357, -0.180924, -0.0211248, 0.0631278, -0.32445, 0.630862, -0.050458, -0.118117, 0.327774, 0.037932, -0.113446, -0.143392, 0.0769867, 0.296583, -0.0270856, -0.00366342, 0.257247], "internal": 1}
{"paper_id": "N03-1006", "abstract": "We compute the coverage and accuracy of the system considering two estimation methods: type-based (all nouns are considered equally important and get a weight of one) and token-based (each prediction is weighted by the number of occurrences of the target noun in the corpus). For most languages, we had at least a main-POS annotated corpus, so that we could consider only the nominal instances of the words when computing the token coverage and accuracy. When such information is not available, one can approximate the token coverage and accuracy by considering all instances of the word forms from the noun list in the corpus, regardless their true POS.", "title": "", "venue": "N", "graph_vector": [-0.0290364, 0.385941, -0.434211, 0.320631, 0.602778, -0.733401, 0.107948, 0.206993, -1.32615, 0.100288, -0.385905, 0.0183233, 0.706224, 0.0618191, -0.101842, -0.1947, 0.164734, -0.378293, 0.0864714, 0.151939, -0.599048, 0.732037, -0.0339705, -0.314813, -0.49388, 0.272766, 0.119638, 0.261111, -0.416366, -0.37152, -0.141697, -0.250461, -0.0822258, -0.566836, 0.0119498, 0.362875, -0.0078455, 0.950415, 0.163104, -0.308921, 0.0870347, -0.584018, -0.23816, 0.468325, 0.924332, -0.941181, 0.274373, 0.130956, -0.292756, 0.181254, 0.264991, 0.367232, 0.897485, 0.619005, -0.145371, 0.0265107, -0.202125, -0.081452, -0.18333, 0.284745, -0.358326, -0.477522, 0.30206, -0.159977, -0.016725, -0.203224, 0.414655, 0.100575, 0.187414, 0.0248612, -0.235168, -0.311155, 0.134824, 0.251416, -0.0931015, 0.102719, 0.198983, -0.516633, 0.186091, 0.266741, 0.0463419, 0.040343, -0.0877806, -0.191742, 0.0648325, 0.047349, 0.198628, -0.0467004, 0.0347502, -0.104143, 0.0253047, -0.135042, -0.321911, 0.0174977, -0.0188313, -0.201706, 0.231329, -0.24178, 0.155124, -0.0643822, -0.118436, -0.156609, 0.19672, -0.217127, 0.200926, 0.0368307, 0.38306, -0.265325, -0.0240221, -0.0758778, -0.477504, 0.372655, -0.00366266, -0.18269, 0.171747, 0.121432, 0.274738, 0.244959, -0.198343, 0.341426, -0.338619, -0.487646, -0.201072, 0.323189, 0.784803, 0.498837, 0.0539732, 0.263967], "internal": 1}
{"paper_id": "N03-1011", "abstract": "The discovery of semantic relations from text becomes increasingly important for applications such as Question Answering, Information Extraction, Text Summarization, Text Understanding, and others. The semantic relations are detected by checking selectional constraints. This paper presents a method and its results for learning semantic constraints to detect part-whole relations. Twenty constraints were found. Their validity was tested on a 10,000 sentence corpus, and the targeted partwhole relations were detected with an accuracy of 83%.", "title": "the Automatic Discovery of Part-Whole Relations Main Papers , pp. 1-8 Edmonton, May-June 2003", "venue": "N", "graph_vector": [0.112611, 0.409342, -0.0489564, 0.0412289, 0.337918, -0.442521, -0.0448157, 0.126719, -1.86075, 0.348109, 0.0688109, -0.373311, 0.754926, -0.280345, -0.171636, -0.350332, 0.230709, -0.438896, 0.12795, 0.10491, -0.299532, 0.313236, 0.136234, 0.213665, -0.242018, 0.276847, 0.0718442, 0.645071, -0.193412, 0.130202, 0.358862, -0.0675415, -0.151955, -0.384911, 0.0403879, 0.334387, -0.389689, 0.543534, 0.185606, 0.101903, 0.141657, -0.357265, -0.0229337, 0.495747, 0.827977, -0.780636, 0.0694195, 0.295356, -0.141723, 0.118571, 0.124717, 0.210689, 0.502728, 0.59435, 0.0894693, 0.0745862, 0.0641465, 0.396187, -0.335115, 0.225423, -0.157297, -0.13429, -0.361522, 0.126608, -0.302572, -0.248359, 0.344162, -0.0585927, -0.0555501, -0.0669774, -0.065215, 0.0171181, 0.0374954, 0.227896, 0.00373191, -0.510165, -0.331576, -0.383894, 0.088587, 0.0341386, 0.216357, 0.12033, 0.411468, 0.0515909, -0.122197, 0.217955, 0.0140992, 0.521668, 0.215993, -0.0837544, 0.0864064, 0.347662, -0.729071, 0.0401412, -0.0560499, -0.0610962, -0.444549, 0.449904, 0.237179, -0.246195, -0.327263, -0.351214, 0.15621, 0.0104744, 0.4534, 0.0403487, -0.190396, 0.114495, -0.259653, -0.0958775, -0.415196, -0.0327708, -0.179263, 0.266991, 0.0623633, 0.0833985, 0.549831, 0.26936, 0.0358072, 0.0576323, 0.242989, -0.231383, -0.308394, 0.0223673, 0.129873, 0.36735, 0.0143792, 0.28649], "internal": 1}
{"paper_id": "N06-1024", "abstract": "We present a two stage parser that recovers Penn Treebank style syntactic analyses of new sentences including skeletal syntactic structure, and, for the first time, both function tags and empty categories. The accuracy of the first-stage parser on the standard Parseval metric matches that of the (Collins, 2003) parser on which it is based, despite the data fragmentation caused by the greatly enriched space of possible node labels. This first stage simultaneously achieves near state-of-theart performance on recovering function tags with minimal modifications to the underlying parser, modifying less than ten lines of code. The second stage achieves state-of-the-art performance on the recovery of empty categories by combining a linguistically-informed architecture and a rich feature set with the power of modern machine learning methods.", "title": "Fully Parsing the Penn Treebank", "venue": "N", "graph_vector": [-0.218606, 0.0650576, -0.0807978, 0.292605, 0.273839, -0.782178, -0.107649, -0.0698429, -1.46035, 0.460201, 0.0362123, -0.597557, 0.54927, 0.188058, -0.0423659, 0.00655739, 0.655081, -0.798132, -0.0974638, 0.595025, -0.272619, 0.548585, 0.268117, -0.00129414, -0.280042, 0.621449, 0.304518, -0.140506, -0.173265, -0.573459, -0.050928, 0.0650418, -0.121218, -0.647952, -0.0529597, 0.0846736, -0.0189549, 0.664946, 0.517358, -0.320902, 0.136573, 0.0863686, -0.560584, 0.182346, 0.793208, -0.721623, 0.244729, 0.140817, 0.239174, 0.25025, 0.116316, 0.02569, 0.58048, 0.372317, -0.399788, 0.359844, 0.144684, 0.221977, 0.0243561, 0.132153, -0.212012, -0.57591, -0.0791794, -0.0229158, -0.402461, 0.0107212, -0.172293, 0.0738248, 0.124763, 0.121006, 0.0548963, -0.0401261, 0.194447, -0.0725427, 0.0196309, -0.148631, -0.361243, -0.389867, -0.0118097, -0.215454, -0.231009, 0.106492, 0.0391813, 0.0469957, 0.0197272, -0.444601, 0.128929, -0.102452, 0.352761, 0.11572, 0.152789, -0.128138, -0.294382, -0.171913, -0.107766, 0.174625, -0.435394, 0.363054, 0.136848, -0.0994896, 0.366051, -0.382121, -0.0926936, 0.148853, -0.14547, 0.282354, -0.232789, -0.0575805, -0.113422, -0.136326, -0.0717367, -0.159557, 0.510818, -0.0351581, 0.155262, -0.296603, 0.514398, 0.209533, 0.477155, -0.0151321, -0.0523975, 0.0843795, -0.297014, -0.210267, 0.453688, 0.375419, -0.0786096, -0.229728], "internal": 1}
{"paper_id": "N07-2018", "abstract": "This paper presents an alternative algorithm based on the singular value decomposition (SVD) that creates vector representation for linguistic units with reduced dimensionality. The work was motivated by an application aimed to represent text segments for further processing in a multi-document summarization system. The algorithm tries to compensate for SVD’s bias towards dominant-topic documents. Our experiments on measuring document similarities have shown that the algorithm achieves higher average precision with lower number of dimensions than the baseline algorithms - the SVD and the vector space model.", "title": "Clustered Sub-matrix Singular Value Decomposition", "venue": "N", "graph_vector": [0.57635, 0.498627, 0.0511136, 0.324814, 0.0419539, -0.353128, -0.0937154, 0.352982, -2.3387, 0.239293, -0.157761, 0.0703445, 1.19878, 0.103787, -0.0642609, -0.315379, 0.525655, -1.03073, 0.204339, 0.374066, -0.267332, 0.470355, 0.392148, -0.339845, -0.707825, 0.288043, 0.255533, 0.226971, -0.188619, -0.307958, 0.030288, -0.240726, -0.0258099, -0.477366, -0.336068, 0.520272, 0.0183379, 0.805101, 0.561251, -0.486956, -0.232125, -0.643816, -0.330098, 0.622407, 1.02443, -0.659399, -0.188333, 0.152269, 0.108303, -0.0252861, 0.391114, -0.49552, 1.00162, 0.969643, -0.692361, -0.025056, 0.408485, 0.28911, 0.102107, 0.225707, -0.247805, 0.223035, -0.419556, -0.0211754, -0.212575, 0.238013, 0.0668987, 0.476523, -0.293748, 0.132818, -0.10242, 0.213756, 0.241156, -0.0729755, 0.102259, -0.539009, -0.61331, -0.288099, 0.0680617, 0.124989, 0.199411, 0.249557, 0.39302, -0.0230343, 0.0432684, -0.28582, 0.149838, -0.30169, 0.0746763, -0.253363, -0.109819, 0.228192, -0.951523, -0.149908, -0.276328, 0.613004, -0.38011, -0.141567, -0.154586, -0.0354536, -0.187335, -0.258682, 0.0777007, -0.030079, -0.141844, -0.120742, -0.12307, -0.16187, 0.233389, -0.387209, -0.196004, -0.0597877, -0.0879739, 0.209397, -0.0597101, -0.132112, 0.330729, 0.224274, -0.174977, 0.445106, -0.404986, -0.0335828, -0.116375, -0.217526, 0.539229, 0.336458, -0.106311, 0.0639979], "internal": 1}
{"paper_id": "N07-2036", "abstract": "Texts exhibit subtle yet identifiable modality about writers’ estimation of how true each statement is (e.g., definitely true or somewhat true). This study is an analysis of such explicit certainty and doubt markers in epistemically modalized statements for a written news discourse. The study systematically accounts for five levels of writer’s certainty (ABSOLUTE, HIGH, MODERATE, LOW CERTAINTY and UNCERTAINTY) in three news pragmatic contexts: perspective, focus, and time. The study concludes that independent coders’ perceptions of the boundaries between shades of certainty in epistemically modalized statements are highly subjective and present difficulties for manual annotation and consequent automation for opinion extraction and sentiment analysis. While stricter annotation instructions and longer coder training can improve intercoder agreement results, it is not entirely clear that a five-level distinction of certainty is preferable to a simplistic distinction between statements with certainty and statements with doubt.", "title": "Stating with Certainty or Stating with Doubt: Intercoder Reliability Results for Manual Annotation of Epistemically Modalized Statements", "venue": "N", "graph_vector": [-0.676643, 0.329093, 0.426547, -0.118903, 0.646016, -0.510731, -0.120172, -0.0966249, -1.81416, 0.10537, -0.191085, -0.473271, 0.404872, 0.227907, -0.0478012, 0.0886127, 0.611901, -0.401855, -0.133627, 0.484328, -0.336774, 0.556069, 0.241599, 0.314298, -0.501143, -0.184218, 0.274175, 0.100029, -1.00723, -0.318336, -0.135538, 0.081391, 0.10571, -0.441403, -0.253878, 0.0436776, -0.0630145, 0.824893, 0.054267, 0.352517, -0.664886, -0.178087, -0.41622, 0.0692858, 1.055, -0.805408, 0.110147, 0.27989, 0.0109849, 0.241486, 0.511709, -0.0976216, 0.574342, 0.755803, -0.0888764, 0.122063, 0.258382, 0.396637, 0.225154, 0.0532899, -0.0808903, -0.0179296, -0.0757947, -0.0379803, -0.0628594, -0.110016, 0.383846, 0.224173, -0.0850566, 0.313871, -0.0548168, -0.197106, 0.290453, 0.347289, 0.20226, -0.188158, -0.524868, -0.519332, -0.261487, 0.0740264, -0.0798566, -0.0685069, -0.0093415, -0.477466, -0.109032, -0.174594, 0.176744, 0.269301, -0.0524419, 0.162019, 0.107873, -0.313999, -0.591707, -0.224224, 0.112107, 0.0316288, 0.143429, -0.057237, 0.167642, 0.195502, -0.291442, -0.339212, -0.426906, -0.454651, -0.195316, -0.249998, 0.0016381, -0.240167, 0.0191001, -0.341719, -0.320471, 0.0935543, -0.419857, 0.138652, -0.418271, -0.150367, 0.797555, 0.268481, 0.305799, 0.385727, 0.221712, -0.337529, -0.0267332, 0.3221, 0.454542, -0.101333, 0.0114586, -0.428998], "internal": 1}
{"paper_id": "N07-4013", "abstract": "Traditional information extraction systems have focused on satisfying precise, narrow, pre-specified requests from small, homogeneous corpora. In contrast, the TEXTRUNNER system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input. (Banko et al., 2007) TEXTRUNNER is a fullyimplemented, highly scalable example of OIE. TEXTRUNNER's extractions are indexed, allowing a fast query mechanism. Our first public demonstration of the TEXTRUNNER system shows the results of performing OIE on a set of 117 million web pages. It demonstrates the power of TEXTRUNNER in terms of the raw number of facts it has extracted, as well as its precision using our novel assessment mechanism. And it shows the ability to automatically determine synonymous relations and objects using large sets of extractions. We have built a fast user interface for querying the results.", "title": "TEXTRUNNER: Open Information Extraction on the Web", "venue": "N", "graph_vector": [-0.131141, 0.123631, 0.10497, 0.0939536, 0.539964, -0.537692, 0.0833992, -0.0413201, -1.54496, 0.529159, 0.0729701, -0.620591, 0.699235, 0.402163, 0.0202359, 0.139326, 0.267295, -0.205683, 0.0732087, 0.329476, -0.0567319, 0.483108, 0.267883, 0.0438294, -0.409906, 0.200978, -0.356972, 0.218039, -0.0323815, -0.275271, 0.305066, -0.0215304, 0.123669, -0.944526, -0.121324, 0.246332, -0.596067, 0.478914, 0.100028, -0.144068, 0.0355757, -0.858416, -0.152556, 0.14522, 1.04272, -0.66076, -0.191474, 0.0642724, -0.0673316, -0.244804, 0.579491, -0.077497, 0.558029, 0.68007, 0.129602, -0.078934, -0.117692, 0.185533, -0.326207, 0.214395, -0.216939, -0.438762, -0.13285, 0.0802802, 0.0408808, -0.104196, 0.010243, -0.324847, 0.287209, 0.187506, 0.021601, -0.0183511, -0.188908, 0.104866, 0.666732, -0.229254, -0.308874, -0.255652, 0.033722, -0.0138926, -0.0432353, -0.118548, 0.14875, -0.151541, -0.0794046, -0.480362, -0.115392, 0.149727, 0.0851824, 0.263132, 0.052065, 0.143112, -0.901264, -0.0741174, -0.0774395, 0.0793744, -0.036974, -0.185877, -0.186994, -0.305204, -0.0828976, -0.155897, -0.156446, 0.333233, 0.0253385, 0.10616, -0.0659748, -0.0296185, 0.422558, -0.103637, -0.0308706, 0.0190192, 0.0919962, 0.276701, -0.138293, -0.0863205, 0.305984, 0.0977622, -0.307331, -0.115753, -0.376932, -0.154777, -0.123077, -0.120794, 0.365239, 0.0468971, 0.113087, 0.263266], "internal": 1}
{"paper_id": "E91-1032", "abstract": "This paper describes a computational model of human sentence processing based on the principles and parameters paradigm of current linguistic theory. The syntactic processing model posits four modules, recovering phrase structure, long-distance dependencies, coreference, and thematic structure. These four modules are implemented as meta-interpreters over their relevant components of the grammar, permitting variation in the deductive strategies employed by each module. These four interpreters are also `coroutined' via the freeze directive of constraint logic programming to achieve incremental interpretation across the modules.", "title": "Multiple Interpreters in a Principle-Based Model of Sentence Processing", "venue": "E", "graph_vector": [], "internal": 1}
{"paper_id": "E12-1029", "abstract": "Most event extraction systems are trained with supervised learning and rely on a collection of annotated documents. Due to the domain-specificity of this task, event extraction systems must be retrained with new annotated data for each domain. In this paper, we propose a bootstrapping solution for event role filler extraction that requires minimal human supervision. We aim to rapidly train a state-of-the-art event extraction system using a small set of “seed nouns” for each event role, a collection of relevant (in-domain) and irrelevant (outof-domain) texts, and a semantic dictionary. The experimental results show that the bootstrapped system outperforms previous weakly supervised event extraction systems on the MUC-4 data set, and achieves performance levels comparable to supervised training with 700 manually annotated documents.", "title": "Bootstrapped Training of Event Extraction Classifiers", "venue": "E", "graph_vector": [0.232707, 0.298702, 0.11862, 0.0291672, 0.435212, -0.54812, -0.159885, 0.0847165, -1.77364, 0.443863, 0.0239665, -0.470902, 0.405409, 0.360082, 0.0958626, -0.0643006, 0.35617, -0.265807, 0.459762, 0.292515, -0.179876, 0.411703, 0.352567, -0.181834, -0.230382, 0.150885, 0.437252, 0.314961, -0.220386, -0.156921, 0.422078, -0.237857, -0.297515, -0.663997, 0.172944, 0.195347, -0.139648, 0.432638, 0.092392, -0.224852, -0.0162385, -0.693393, -0.296512, 0.362465, 0.856137, -0.586762, -0.161971, 0.33288, -0.27162, 0.154135, 0.258496, 0.0644007, 0.782722, 0.905741, -0.012294, 0.0153684, 0.105721, 0.176462, 0.0241779, -0.055915, -0.312923, -0.118271, 0.322202, -0.422017, -0.154367, 0.0509573, 0.03225, -0.438523, 0.282934, 0.169437, -0.028621, 0.39323, 0.173683, -0.162565, 0.0270965, -0.238598, -0.104719, -0.385153, -0.195031, -0.324845, 0.110532, -0.0739055, -0.0862868, 0.0197804, -0.197505, -0.0993578, -0.0436036, -0.0542241, -0.221163, 0.146848, -0.272419, 0.0962677, -1.01692, 0.0217126, 0.0905811, -0.0285278, 0.0822467, -0.31996, -0.344176, -0.235003, -0.080971, 0.101655, -0.0182893, 0.0676254, 0.266306, 0.0765455, 0.0610698, -0.277932, 0.379708, 0.0402404, -0.0341982, -0.220862, -0.0338867, 0.190616, -0.0888802, -0.0551437, 0.665323, 0.031597, 0.195632, 0.117367, 0.0141408, -0.0986232, -0.256184, 0.139645, 0.18467, 0.302113, -0.0946263, 0.00123949], "internal": 1}
{"paper_id": "E14-1035", "abstract": "Translating text from diverse sources poses a challenge to current machine translation systems which are rarely adapted to structure beyond corpus level. We explore topic adaptation on a diverse data set and present a new bilingual variant of Latent Dirichlet Allocation to compute topic-adapted, probabilistic phrase translation features. We dynamically infer document-specific translation probabilities for test sets of unknown origin, thereby capturing the effects of document context on phrase translations. We show gains of up to 1.26 BLEU over the baseline and 1.04 over a domain adaptation benchmark. We further provide an analysis of the domain-specific data and show additive gains of our model in combination with other types of topic-adapted features.", "title": "Dynamic Topic Adaptation for Phrase-based MT", "venue": "E", "graph_vector": [-0.290495, 0.215648, 0.351102, 0.115619, 0.199688, -0.635628, 0.214745, -0.0256513, -1.46687, -0.0334496, -0.0724921, -0.547222, 0.659249, 0.0720483, 0.022919, -0.230887, 0.450704, -0.703933, 0.0120566, 0.338427, 0.0404582, 0.570783, 0.359434, 0.103782, -0.365225, 0.204333, 0.126293, -0.123462, -0.0105766, -0.137732, 0.0792917, 0.149624, 0.108054, -0.151946, -0.160433, 0.338833, -0.150528, 0.635257, 0.147909, -0.350721, -0.354387, -0.379584, -0.579667, 0.575255, 1.17341, -0.931177, 0.318968, -0.0831681, -0.250063, -0.0363014, 0.407982, 0.361378, 0.966785, 0.690489, -0.417705, 0.369558, 0.0259649, 0.201409, 0.240366, 0.260919, -0.00118078, -0.0517378, 0.0234584, 0.0696581, -0.114451, 0.0479677, -0.147683, -0.103758, -0.0373057, 0.103143, 0.128014, -0.128487, 0.168155, -0.515057, 0.618458, 0.185626, -0.889881, -0.0946084, -0.0193951, -0.00146581, -0.435527, 0.0230095, 0.132034, -0.515874, -0.0853794, 0.106748, 0.154247, 0.0932215, 0.0514371, -0.281362, 0.182891, -0.0329247, -0.348252, 0.168609, -0.0732086, 0.23627, 0.200095, -0.197072, -0.0182918, 0.135953, 0.0751516, -0.43426, 0.0520126, 0.406823, -0.359809, 0.019221, 0.0940472, -0.025986, 0.108667, 0.0947659, -0.100335, -0.00292564, 0.0131828, -0.024774, -0.445925, 0.333878, 0.348465, 0.0891761, 0.182626, -0.0993568, -0.171213, 0.0405424, -0.250241, 0.0281722, 0.339626, 0.175037, -0.189475, 0.0153355], "internal": 1}
{"paper_id": "E14-2004", "abstract": "Within the context of globalization, multilinguality and cross-linguality for information access have emerged as issues of major interest. In order to achieve the goal that users from all countries have access to the same information, there is an impending need for systems that can help in overcoming language barriers by facilitating multilingual and cross-lingual access to data. In this paper, we demonstrate such a toolkit, which supports both service-oriented and user-oriented interfaces for semantically annotating, analyzing and comparing multilingual texts across the boundaries of languages. We conducted an extensive user study that shows that our toolkit allows users to solve cross-lingual entity tracking and article matching tasks more efficiently and with higher accuracy compared to the baseline approach.", "title": "Semantic Annotation, Analysis and Comparison: A Multilingual and Cross-lingual Text Analytics Toolkit", "venue": "E", "graph_vector": [0.24943, 0.24077, 0.119095, -0.284227, 0.197324, -0.459721, 0.306206, -0.0411604, -1.37196, 0.205255, -0.3364, -0.465081, 0.713231, 0.150861, -0.0787664, 0.191087, 0.7151, -0.527614, -0.190685, 0.200989, -0.236913, 0.795136, 0.151886, 0.0943041, -0.268187, -0.0401597, -0.430364, 0.250846, -0.0264324, 0.024404, 0.192765, 0.205454, -0.0426243, -0.172089, -0.398411, 0.0195432, -0.478126, 0.391255, 0.282203, -0.192438, -0.00266108, -0.366099, -0.138941, 0.438543, 0.794543, -0.762382, 0.15119, 0.281515, -0.192429, -0.109279, 0.427859, 0.268433, 1.25322, 1.05612, -0.170432, 0.167389, -0.197635, 0.260021, 0.0315379, -0.34778, -0.13858, -0.361973, 0.0488196, -0.0435528, 0.183199, 0.178959, 0.297588, 0.389908, 0.0149567, 0.215202, 0.226489, 0.0682982, -0.313536, -0.191315, 0.106834, -0.274127, -0.732899, -0.200923, 0.0184002, -0.200927, -0.349678, -0.100807, 0.24101, -0.144928, 0.191661, -0.460822, -0.0718464, -0.0573804, -0.104058, -0.213379, -0.0325883, -0.178091, -0.999228, -0.214299, -0.420553, 0.1592, 0.018591, 0.0685822, 0.150912, -0.102529, 0.243335, 0.0330807, -0.508036, 0.154413, -0.257062, 0.212155, -0.103763, 0.0752351, -0.0306554, 0.0302028, -0.491115, -0.258716, -0.29871, -0.151855, 0.15587, -0.125881, 0.347232, 0.12286, -0.0600333, 0.100625, 0.0390665, 0.0190872, -0.2048, 0.0866302, 0.368539, 0.218119, 0.304138, 0.122691], "internal": 1}
{"paper_id": "E14-4037", "abstract": "Professional human translators usually do not employ the concept of word alignments, producing translations ‘sense-forsense’ instead of ‘word-for-word’. This suggests that unalignable words may be prevalent in the parallel text used for machine translation (MT). We analyze this phenomenon in-depth for Chinese-English translation. We further propose a simple and effective method to improve automatic word alignment by pre-removing unalignable words, and show improvements on hierarchical MT systems in both translation directions.", "title": "Analysis and Prediction of Unalignable Words in Parallel Text", "venue": "E", "graph_vector": [-0.118197, 0.520819, 0.382401, 0.265865, 0.265573, -0.815337, 0.310517, -0.29448, -1.63125, 0.111627, 0.179326, -0.0957494, 0.529357, 0.0499471, 0.145009, -0.182008, 0.270462, -0.619994, 0.179715, 0.073405, -0.175132, 0.245926, 0.57847, -0.117615, -0.435261, 0.00372938, 0.325111, -0.302443, -0.237009, 0.0592049, -0.16575, 0.31777, 0.233776, -0.384715, -0.0300676, 0.186819, -0.26847, 0.629586, 0.406363, 0.000851509, -0.0773461, -0.0862016, -0.71218, 0.44269, 1.36046, -0.892559, 0.408297, 0.0885177, -0.0727963, -0.0873761, 0.0793455, -0.35133, 0.300265, 0.697972, -0.460563, 0.0953403, -0.106037, 0.0899476, 0.112486, -0.225278, -0.092461, -0.143615, 0.123046, -0.0754659, -0.395852, -0.0961968, 0.0940437, -0.149462, 0.230775, -0.0647749, 0.0996187, -0.0967757, 0.312906, -0.212464, 0.182385, -0.111596, -0.434697, -0.0664152, 0.0471217, -0.0343281, -0.25842, 0.0805903, 0.169312, 0.273257, 0.16487, -0.383309, -0.0937959, 0.0340592, -0.120312, 0.0424517, -0.0823889, -0.107109, -0.449695, -0.0550054, -0.209206, -0.212103, -0.346809, -0.0121029, 0.0907775, -0.169137, -0.162157, -0.116697, -0.115786, 0.50059, -0.0704168, -0.216864, -0.0685465, -0.200501, 0.276698, 0.0696413, 0.150975, -0.0251828, -0.217133, -0.0157596, 0.0324097, -0.150027, 0.00105319, 0.0411066, 0.0805632, 0.376973, 0.0301576, -0.219787, -0.318354, -0.0204287, 0.27531, 0.448048, 0.0577804, 0.0854841], "internal": 1}
{"paper_id": "E14-3008", "abstract": "Animacy is the semantic property of nouns denoting whether an entity can act, or is perceived as acting, of its own will. This property is marked grammatically in various languages, albeit rarely in English. It has recently been highlighted as a relevant property for NLP applications such as parsing and anaphora resolution. In order for animacy to be used in conjunction with other semantic features for such applications, appropriate data is necessary. However, the few corpora which do contain animacy annotation, rarely contain much other semantic information. The addition of such an annotation layer to a corpus already containing deep semantic annotation should therefore be of particular interest. The work presented in this paper contains three main contributions. Firstly, we improve upon the state of the art in multiclass animacy classification. Secondly, we use this classifier to contribute to the annotation of an openly available corpus containing deep semantic annotation. Finally, we provide source code, as well as trained models and scripts needed to reproduce the results presented in this paper, or aid in annotation of other texts.1", "title": "Multi-class Animacy Classification with Semantic Features", "venue": "E", "graph_vector": [0.205474, -0.0594891, -0.0317261, 0.0250612, 0.29567, -0.77037, 0.0355552, -0.27361, -1.35728, 0.0852248, -0.0593258, -0.306335, 0.299924, -0.246861, 0.204459, -0.136295, 0.433074, -0.905852, 0.090484, 0.676702, -0.136207, 0.922505, 0.231159, -0.254658, -0.590195, 0.275828, 0.412063, 0.244071, -0.0523203, 0.111759, 0.0212428, -0.0589174, 0.422026, -0.568745, -0.269173, 0.343172, -0.2078, 0.92791, 0.143525, 0.126941, -0.0850479, -0.0670867, 0.104825, 0.314968, 0.662105, -1.05155, 0.0291666, 0.124247, -0.178381, -0.0887745, 0.0653216, 0.28277, 0.863765, 0.741872, 0.181361, 0.364377, -0.291308, -0.520711, -0.212762, 0.116526, -0.136974, 0.47425, 0.0458621, 0.216921, -0.153062, 0.127299, 0.158539, -0.133906, 0.175814, 0.250162, -0.157483, -0.069864, 0.151522, -0.346318, -0.0886076, 0.165093, -0.365778, -0.271326, -0.171927, 0.183568, 0.370708, -0.201289, -0.103452, -0.400409, -0.164161, -0.0814587, 0.0818366, -0.0128095, 0.346977, -0.271708, -0.269369, 0.137155, -0.788555, -0.34367, -0.631882, -0.274612, -0.204121, -0.0128898, -0.0458391, 0.313137, -0.199122, 0.0425044, 0.0892411, 0.126271, -0.0433781, 0.490853, 0.27396, -0.0141224, -0.0323961, 0.208645, 0.316902, 0.103721, 0.306146, -0.00787084, 0.449276, 0.298695, 0.470864, 0.309036, 0.0842768, 0.748747, -0.0232483, -0.240236, -0.189238, 0.000140913, 0.135139, 0.426088, -0.494068, -0.128916], "internal": 1}
{"paper_id": "E14-1005", "abstract": "We address the problem of automatically attributing quotations to speakers, which has great relevance in text mining and media monitoring applications. While current systems report high accuracies for this task, they either work at mentionlevel (getting credit for detecting uninformative mentions such as pronouns), or assume the coreferent mentions have been detected beforehand; the inaccuracies in this preprocessing step may lead to error propagation. In this paper, we introduce a joint model for entity-level quotation attribution and coreference resolution, exploiting correlations between the two tasks. We design an evaluation metric for attribution that captures all speakers’ mentions. We present results showing that both tasks benefit from being treated jointly.", "title": "A Joint Model for Quotation Attribution and Coreference Resolution Mariana S. C. Almeida*† Miguel B. Almeida*† Andr´e F. T. Martins*†", "venue": "E", "graph_vector": [0.155696, 0.127626, 0.185132, 0.495318, 0.350751, -0.874343, -0.170812, -0.100637, -1.67162, 0.544146, -0.459521, -0.493593, 0.665056, 0.0505663, 0.424532, -0.0282553, 0.183585, -0.6054, 0.33442, 0.22251, -0.782129, 0.458984, 0.234149, -0.363144, -0.147806, 0.381125, 0.000249427, 0.301441, -0.322397, -0.376019, 0.0335705, -0.0945793, 0.162955, -0.452376, -0.137907, 0.135589, -0.276878, 0.496722, -0.095426, 0.126151, 0.0634669, -0.243548, 0.0197479, 0.489872, 0.718306, -0.731173, 0.00590106, 0.0127595, 0.0790335, -0.192775, 0.14523, 0.0601428, 0.674161, 0.556704, 0.0805056, -0.0181264, 0.0223207, 0.0637913, -0.0828889, 0.224146, -0.335895, 0.0773111, -0.0904043, 0.19067, -0.158492, -0.334801, 0.254723, -0.0331875, -0.214589, 0.295459, 0.272899, 0.223008, 0.264381, -0.344171, 0.127637, -0.139554, -0.397561, -0.187501, -0.113526, -0.120057, 0.0498397, -0.0347136, 0.395182, -0.284764, -0.0173818, -0.506538, 0.12179, -0.0554894, -0.111714, -0.205605, 0.412181, -0.0314608, -0.490298, 0.12708, -0.0657298, -0.302278, 0.104195, -0.139434, 0.130074, 0.286345, -0.186351, -0.555008, 0.235708, 0.530195, -0.339886, 0.339743, -0.176086, 0.240609, 0.118653, -0.0760895, -0.0393486, -0.0684299, -0.0932086, 0.127537, 0.0455121, 0.0510416, 0.346201, 0.370278, -0.138103, 0.249888, 0.41539, 0.11576, 0.395993, -0.0507816, 0.627976, 0.0371564, -0.110758, -0.16452], "internal": 1}
{"paper_id": "E14-1033", "abstract": "Approaching temporal link labelling as a classification task has already been explored in several works. However, choosing the right feature vectors to build the classification model is still an open issue, especially for event-event classification, whose accuracy is still under 50%. We find that using a simple feature set results in a better performance than using more sophisticated features based on semantic role labelling and deep semantic parsing. We also investigate the impact of extracting new training instances using inverse relations and transitive closure, and gain insight into the impact of this bootstrapping methodology on classifying the full set of TempEval-3 relations.", "title": "Classifying Temporal Relations with Simple Features", "venue": "E", "graph_vector": [-0.297662, 0.117469, 0.318056, 0.286872, 0.397486, -0.574115, -0.196029, -0.10073, -1.68716, 0.258294, 0.00694751, -0.288284, 0.786938, 0.0326636, -0.156285, 0.203626, 0.280797, -0.695113, 0.323449, 0.567313, -0.43167, 0.372715, 0.321456, -0.252865, -0.414057, -0.0717625, 0.256353, -0.391972, -0.33544, -0.0194582, 0.134265, -0.133999, 0.0184088, -0.209014, 0.103492, -0.245996, -0.272932, 0.498297, -0.178176, 0.0208499, 0.0152043, -0.300935, -0.165434, 0.23074, 1.22543, -0.895173, -0.231246, 0.0899521, -0.194958, -0.128759, -0.0130143, -0.0481653, 0.905591, 0.592438, 0.157159, 0.461906, 0.0792725, 0.00279252, -0.368464, -0.070975, -0.401939, -0.33391, 0.0837545, 0.0897575, 0.00696096, -0.266097, 0.286401, -0.215508, 0.410624, 0.0404679, 0.427958, 0.0554575, 0.103867, -0.0917126, -0.198549, -0.309869, -0.403316, -0.284444, 0.0547557, 0.205792, -0.126088, 0.554329, 0.311806, -0.2777, -0.127016, -0.220243, 0.179733, -0.0535832, 0.72338, -0.136659, -0.127544, -0.00245411, -0.696464, -0.206068, -0.0215599, -0.0443769, -0.0222901, 0.242006, -0.165695, 0.0776382, 0.096183, 0.0716637, 0.410418, 0.335928, -0.149569, -0.198989, -0.15278, -0.12598, -0.325512, -0.416746, -0.141289, -0.107643, 0.244358, -0.0149254, -0.0796215, 0.0953449, 0.395273, 0.171644, 0.123243, 0.181754, 0.100642, 0.0423068, -0.0465521, -0.0348426, 0.215506, 0.555173, 0.0801696, -0.155916], "internal": 1}
{"paper_id": "E14-2006", "abstract": "Morfessor is a family of probabilistic machine learning methods for finding the morphological segmentation from raw text data. Recent developments include the development of semi-supervised methods for utilizing annotated data. Morfessor 2.0 is a rewrite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code.", "title": "Morfessor 2.0: Toolkit for statistical morphological segmentation", "venue": "E", "graph_vector": [-0.0739331, 0.142063, -0.198656, 0.586654, 0.477601, -0.834185, -0.129206, -0.147379, -1.70153, 0.601979, -0.129542, -0.143306, 0.592135, 0.0535908, 0.0335056, -0.415187, 0.540617, -0.606734, 0.0498916, 0.381651, -0.372586, 1.2159, 0.347008, 0.0654239, -0.433632, 0.0309983, -0.641561, -0.356963, -0.481172, -0.458438, 0.0166907, 0.306542, 0.179892, 0.0351402, -0.344593, 0.492242, -0.177227, 0.702109, -0.000833094, -0.0718875, -0.0860843, -0.730047, -0.520211, 0.608265, 1.18753, -0.925766, 0.235642, -0.210901, -0.130998, 0.26748, 0.288255, -0.248105, 0.958968, 0.418749, -0.691698, -0.0841189, 0.250471, -0.116774, 0.0282056, 0.198348, -0.059187, -0.310976, -0.176776, 0.0994247, -0.168455, -0.0956705, -0.0127881, -0.13149, 0.251726, -0.0667479, 0.299046, -0.179109, 0.117642, 0.0736251, 0.265285, -0.271521, -0.675743, -0.545542, 0.0574225, -0.140708, 0.166666, 0.169854, 0.23171, 0.0780058, -0.171636, -0.399115, -0.178364, -0.0553518, 0.158114, -0.213627, 0.119454, -0.081403, -0.362714, -0.373339, -0.0274677, -0.0449931, 0.0515322, -0.0357305, 0.278286, 0.128524, -0.325775, -0.354759, -0.0208116, -0.138968, 0.10736, -0.0471247, -0.0827045, 0.234316, 0.166498, -0.28984, -0.22942, 0.401571, -0.31596, -0.150073, 0.127451, -0.419001, 0.0512978, 0.125243, -0.000746812, 0.392576, 0.0535413, -0.202597, -0.247732, 0.277493, 0.707657, 0.26599, 0.0889291, -0.164357], "internal": 1}
{"paper_id": "E14-1024", "abstract": "Scripts represent knowledge of stereotypical event sequences that can aid text understanding. Initial statistical methods have been developed to learn probabilistic scripts from raw text corpora; however, they utilize a very impoverished representation of events, consisting of a verb and one dependent argument. We present a script learning approach that employs events with multiple arguments. Unlike previous work, we model the interactions between multiple entities in a script. Experiments on a large corpus using the task of inferring held-out events (the “narrative cloze evaluation”) demonstrate that modeling multi-argument events improves predictive accuracy.", "title": "Statistical Script Learning with Multi-Argument Events", "venue": "E", "graph_vector": [-0.189712, 0.345195, 0.164551, 0.611567, 0.621016, -0.645494, 0.0768049, -0.0736425, -1.69146, 0.241697, 0.0912247, 0.0794654, 0.52746, 0.608132, -0.000528155, 0.323271, 0.665494, -0.366582, 0.316394, 0.507028, -0.774573, 0.0594434, 0.139339, -0.13004, -0.621968, -0.0862739, -0.0420795, 0.218805, 0.184995, -0.49865, 0.54995, -0.223148, 0.283068, -0.736275, 0.0699593, 0.409896, -0.470496, 0.336357, 0.074591, 0.211533, -0.198887, -0.450794, -0.272151, 0.0243835, 1.13127, -0.822599, 0.139911, 0.0155995, -0.431903, 0.0551096, 0.0460772, 0.196414, 0.588319, 0.289121, 0.201148, 0.203928, -0.0389634, 0.172554, 0.156507, -0.166234, -0.383216, 0.174766, 0.234593, 0.080964, 0.159057, 0.189728, 0.19285, -0.0556034, 0.413631, 0.0412465, 0.269827, 0.420591, 0.0563157, -0.247169, 0.0289924, -0.522676, -0.22633, -0.297925, -0.325306, -0.112132, -0.178018, 0.125694, 0.0824168, -0.170105, -0.0617319, -0.436768, 0.0512778, -0.16326, 0.140041, 0.181357, -0.165463, -0.128713, -0.480671, -0.0778628, 0.0176898, 0.0537554, -0.0675361, -0.0073551, -0.136135, 0.0800076, -0.37842, -0.196165, -0.209763, 0.197454, 0.239102, 0.375729, 0.199474, 0.0741492, 0.219452, 0.0742555, -0.136501, -0.23214, 0.298808, -0.0574679, 0.0751167, -0.049123, 0.392853, 0.426656, -0.137735, -0.128678, -0.172913, 0.0186147, -0.106501, -0.0132937, 0.379444, 0.288756, 0.0569634, -0.0141797], "internal": 1}
{"paper_id": "E14-1043", "abstract": "The open structure of online social networks and their uncurated nature give rise to problems of user credibility and influence. In this paper, we address the task of predicting the impact of Twitter users based only on features under their direct control, such as usage statistics and the text posted in their tweets. We approach the problem as regression and apply linear as well as nonlinear learning methods to predict a user impact score, estimated by combining the numbers of the user’s followers, followees and listings. The experimental results point out that a strong prediction performance is achieved, especially for models based on the Gaussian Processes framework. Hence, we can interpret various modelling components, transforming them into indirect ‘suggestions’ for impact boosting.", "title": "Predicting and Characterising User Impact on Twitter", "venue": "E", "graph_vector": [-0.347863, 0.625508, 0.35467, 0.242809, 0.132131, -0.689731, -0.0294934, 0.123102, -1.50378, 0.116972, -0.257599, -0.0856317, 0.483018, -0.216949, -0.176089, -0.102085, -0.0322025, -0.649038, 0.0590181, 0.0831785, -0.140086, 0.568045, 0.270375, 0.138957, -0.354844, 0.0808465, 0.00192201, 0.318806, -0.6685, -0.393442, -0.107428, 0.215787, 0.699455, -0.652561, -0.381308, 0.117701, -0.667244, 0.879312, 0.215892, -0.146511, -0.00154778, -0.244189, -0.417928, 0.482517, 0.773562, -0.982793, -0.0833151, -0.209364, -0.294601, -0.0982697, 0.289304, -0.456006, 1.28052, 0.526068, -0.379606, 0.372934, -0.252457, 0.367495, -0.0325429, 0.362517, -0.359092, -0.303342, 0.192236, -0.271187, -0.40325, -0.233595, 0.265644, -0.250618, 0.152923, -0.0304541, 0.47503, -0.0234907, 0.138108, -0.375428, -0.0685545, 0.313616, -0.551622, 0.0411003, -0.220216, -0.155686, 0.18798, -0.596114, 0.112465, -0.1493, 0.175339, -0.358515, 0.212619, 0.202427, -0.130246, 0.32492, -0.193236, -0.15476, -0.373178, -0.40361, 0.509517, -0.236115, -0.159476, 0.0816581, 0.104017, -0.114955, -0.478754, 0.0685043, 0.0560194, -0.170307, -0.137889, 0.230739, -0.14094, -0.269844, 0.23828, -0.496165, -0.142953, 0.141635, 0.277431, 0.0936287, -0.308241, -0.704413, 0.0526515, 0.486248, -0.156206, 0.319348, -0.162158, 0.246035, -0.130735, 0.114305, 0.347979, -0.493453, 0.0815371, 0.0879031], "internal": 1}
{"paper_id": "E14-1011", "abstract": "We propose a Bayesian method of estimating a conditional distribution of data given metadata (e.g., the usage of a dialectal variant given a location) based on queries from a big data/social media source, such as Twitter. This distribution is structurally equivalent to those built from traditional experimental methods, despite lacking negative examples. Tests using Twitter to investigate the geographic distribution of dialectal forms show that this method can provide distributions that are tightly correlated with existing gold-standard studies at a fraction of the time, cost, and effort.", "title": "Mapping dialectal variation by querying social media", "venue": "E", "graph_vector": [-0.123696, 0.117659, -0.106111, 0.585766, 0.344119, -0.826157, -0.157206, -0.407522, -1.25594, 0.160706, 0.0260555, -0.318127, 0.769196, -0.3433, 0.401094, -0.243954, 0.699772, -0.646065, 0.19497, 0.299872, -0.181984, 0.92903, 0.516193, 0.099114, -0.216864, 0.250583, -0.0865682, -0.129975, -0.613232, -0.176806, 0.0423123, -0.0802987, 0.435749, -0.256167, -0.817264, 0.469082, 0.0518585, 0.55487, 0.398617, 0.0324313, 0.0927703, -0.567654, -0.438796, 0.851591, 1.10147, -0.803843, -0.18236, -0.273417, -0.364441, -0.0399316, 0.327672, -0.362667, 1.50262, 1.17415, 0.290643, -0.0336579, 0.162612, 0.171747, 0.15376, 0.108926, -0.337631, 0.0547297, 0.00134791, 0.314767, -0.0260371, -0.0602519, -0.286162, -0.149403, 0.45629, 0.115088, 0.0331145, 0.207654, 0.418585, 0.192159, -0.0648637, 0.125168, -0.493054, -0.17368, -0.0808172, 0.358981, -0.227361, -0.0789596, 0.657587, -0.0459894, -0.299048, -0.097551, 0.317902, -0.179989, 0.108375, -0.00896649, -0.190641, -0.0169269, -0.218024, -0.544997, -0.0749007, 0.0863898, -0.314126, -0.10276, 0.409352, -0.342505, 0.151547, -0.204981, 0.0396428, 0.0287289, 0.0787938, -0.132893, 0.300013, 0.100569, 0.165273, -0.0464006, -0.300553, -0.149411, 0.225452, 0.253761, 0.088523, -0.192718, -0.051407, 0.209537, -0.221774, 0.556149, 0.108707, -0.254279, 0.278249, 0.120415, 0.896914, 0.00643169, 0.218768, -0.207073], "internal": 1}
{"paper_id": "E14-1044", "abstract": "Current approaches to cross-language document retrieval and categorization are based on discriminative methods which represent documents in a low-dimensional vector space. In this paper we propose a shift from the supervised to the knowledge-based paradigm and provide a document similarity measure which draws on BabelNet, a large multilingual knowledge resource. Our experiments show state-of-the-art results in cross-lingual document retrieval and categorization.", "title": "A Knowledge-based Representation for Cross-Language Document Retrieval and Categorization", "venue": "E", "graph_vector": [0.381388, 0.245044, -0.214664, -0.101174, 0.23548, -0.708474, 0.273221, -0.128097, -1.29769, 0.320618, -0.243775, 0.159406, 0.775271, 0.315546, 0.00690031, -0.0035571, 0.644314, -0.587955, -0.613656, 0.506628, -0.0994732, 0.394684, 0.112945, -0.0417148, -0.173295, 0.260969, 0.0598677, -0.021622, -0.510484, -0.265754, 0.205066, -0.123599, 0.582124, -0.363841, -0.347568, 0.126674, -0.468711, 0.269269, 0.204791, 0.0307313, -0.249529, -0.512777, -0.195276, 0.609823, 1.07614, -0.762102, 0.017076, 0.170816, 0.0334651, 0.14299, 0.624573, -0.101071, 0.838834, 0.420342, -0.287341, 0.0899038, 0.257982, 0.353508, 0.114298, -0.169264, 0.0968492, 0.0114984, -0.235484, -0.00238327, 0.296019, 0.191698, 0.283544, 0.261693, -0.125214, -0.00595992, -0.0185809, 0.0294602, -0.073794, -0.478318, -0.100958, -0.46792, -0.698137, 0.0501743, 0.320681, -0.0185157, 0.112903, -0.1536, 0.0849343, 0.00221488, -0.041656, -0.368383, 0.0304291, -0.176992, 0.422462, -0.291767, 0.0750373, -0.327287, -1.0108, -0.301524, -0.386852, 0.0427374, -0.114207, -0.03071, 0.0160401, -0.225884, -0.145014, -0.22113, -0.126017, 0.191151, -0.0634126, 0.422197, -0.264286, 0.0416823, -0.520463, 0.0135128, -0.333516, 0.172262, -0.145239, 0.434257, -0.222881, -0.526649, 0.323211, -0.0813671, -0.131423, -0.0717582, -0.189343, 0.0154316, -0.0527336, 0.362322, 0.14163, 0.138615, -0.0412875, 0.303778], "internal": 1}
{"paper_id": "E14-4025", "abstract": "This paper is concerned with the discovery and aggregation of events that provoke a particular emotion in the person who experiences them, or emotion-provoking events. We first describe the creation of a small manually-constructed dictionary of events through a survey of 30 subjects. Next, we describe first attempts at automatically acquiring and aggregating these events from web data, with a baseline from previous work and some simple extensions using seed expansion and clustering. Finally, we propose several evaluation measures for evaluating the automatically acquired events, and perform an evaluation of the effectiveness of automatic event extraction.", "title": "Acquiring a Dictionary of Emotion-Provoking Events", "venue": "E", "graph_vector": [0.369367, 0.446446, 0.446377, -0.0473846, 0.617397, -0.719263, -0.303291, 0.142473, -1.66265, -0.0361954, -0.220229, 0.036797, 0.524734, 0.029436, 0.0875397, 0.407378, 0.172983, -0.569033, 0.00266156, 0.376784, -0.101095, 0.475205, -0.0301291, 0.241164, -0.671028, -0.0123507, 0.603886, 0.17158, 0.0835297, -0.583052, 0.0071724, 0.156006, -0.187056, -0.2204, 0.23842, 0.169805, -0.19033, 0.854732, 0.49982, -0.346481, 0.352804, -0.382956, -0.329742, 0.637788, 0.708401, -1.02453, -0.201384, 0.0074417, 0.125421, 0.46281, -0.00595232, -0.733417, 0.382419, 0.460671, 0.0992028, 0.0660396, 0.393259, 0.542593, 0.018141, 0.199795, -0.339438, -0.0348346, 0.396255, -0.0753911, -0.205087, -0.0578436, -0.0791496, -0.37045, -0.411431, 0.289557, -0.127005, 0.054849, -0.00702399, 0.0505212, 0.25852, -0.083116, -0.243507, -0.42429, 0.199988, 0.0585413, -0.131574, -0.232802, -0.11935, -0.196644, 0.220982, -0.171405, 0.185566, -0.00720705, 0.0289028, 0.0330012, 0.00249594, 0.28702, -0.85164, -0.242387, 0.237087, 0.184658, -0.207841, -0.268095, -0.0772339, -0.158571, -0.0586401, -0.214031, 0.0147692, -0.0290445, 0.402597, 0.0799654, -0.413879, 0.283205, 0.151976, -0.166883, 0.0875347, 0.205417, 0.0340962, 0.308986, -0.48151, -0.152499, 0.240487, 0.101695, -0.0328679, -0.289429, -0.432571, -0.246282, -0.237256, -0.130691, 0.516011, 0.261237, -0.18382, -0.0471091], "internal": 1}
{"paper_id": "E14-3006", "abstract": "We present a study of information status in scientific text as well as ongoing work on the resolution of coreferent and associative anaphora in two different scientific disciplines, namely computational linguistics and genetics. We present an annotated corpus of over 8000 definite descriptions in scientific articles. To adapt a state-of-the-art coreference resolver to the new domain, we develop features aimed at modelling technical terminology and integrate these into the coreference resolver. Our results indicate that this integration, combined with domain-dependent training data, can outperform the performance of an out-of-the-box coreference resolver. For the (much harder) task of resolving associative anaphora, our preliminary results show the need for and the effect of semantic features.", "title": "Resolving Coreferent and Associative Noun Phrases in Scientific Text", "venue": "E", "graph_vector": [-0.320655, 0.0478006, -0.140942, 0.703791, 0.65844, -0.580625, 0.0786936, -0.1841, -1.77276, 0.71278, 0.117782, -0.132889, 0.78278, 0.125602, 0.4591, 0.16341, 0.395285, -0.803829, 0.0313516, -0.0531495, -0.622785, 0.161899, -0.152082, 0.120008, -0.574199, 0.269041, 0.212657, 0.357611, -0.103303, 0.0734332, -0.100099, -0.0107349, -0.0975829, -0.606874, 0.061721, 0.091378, -0.237068, 0.433186, 0.419531, -0.332264, 0.0876587, -0.132484, -0.136538, 0.0883209, 0.79782, -0.772481, -0.107907, -0.167053, 0.265521, -0.167111, -0.159823, -0.0335392, 0.605179, 0.965558, -0.299359, 0.503093, 0.087503, 0.194586, 0.590864, 0.133559, -0.299826, 0.24724, 0.132644, 0.101811, -0.264038, -0.178412, 0.401885, -0.159975, 0.144215, -0.119916, 0.338796, 0.029254, -0.219559, -0.272249, -0.0186492, -0.0625617, -0.766701, -0.128216, -0.00882838, 0.250332, -0.0580579, 0.0552279, -0.18198, -0.197557, 0.0670955, -0.206286, -0.110399, -0.484426, 0.288616, 0.0803604, 0.13541, 0.0740429, -0.598678, -0.208163, -0.323435, -0.214943, 0.0778797, 0.0463811, -0.00893224, 0.0187723, 0.0798245, -0.295746, 0.0699358, -0.0976887, -0.537515, 0.388306, 0.177217, -0.0488085, -0.118469, -0.128372, -0.279472, -0.11737, 0.163306, -0.442556, -0.127186, -0.286745, 0.659375, 0.04161, -0.274665, 0.383916, 0.155288, -0.199608, 0.216455, 0.0628583, 0.193842, -0.0167583, 0.0908044, -0.176763], "internal": 1}
{"paper_id": "E97-1006", "abstract": "We propose a new method of classifying documents into categories. We define for each category a finite mixture model based on soft clustering of words. We treat the problem of classifying documents as that of conducting statistical hypothesis testing over finite mixture models, and employ the EM algorithm to efficiently estimate parameters in a finite mixture model. Experimental results indicate that our method outperforms existing methods.", "title": "Document Classification Using a Finite Mixture Model", "venue": "E", "graph_vector": [-0.126967, 0.212688, -0.208567, 0.434366, 0.428686, -0.830825, 0.156179, 0.561438, -1.39311, 0.100223, -0.110233, -0.557659, 0.644976, -0.0856003, 0.0886583, -0.225126, 0.239897, -0.478101, 0.224992, -0.312843, 0.0996843, 0.633739, -0.176308, -0.337208, -0.580606, -0.14681, 0.202008, 0.238633, -0.446408, -0.203321, 0.0690261, -0.40877, 0.125792, -0.508952, -0.471727, 0.148802, 0.128727, 0.493891, 0.345732, -0.0760816, -0.293826, -0.186568, -0.541154, 0.740109, 0.730997, -1.20394, -0.178617, 0.213127, -0.103453, -0.240239, 0.666533, -0.0861078, 0.997656, 0.530301, -0.330111, -0.167077, -0.115072, 0.0125743, 0.324611, 0.072798, -0.320881, 0.0611101, -0.210543, -0.0743271, -0.0371764, -0.214179, -0.208874, 0.351672, 0.201969, -0.293424, -0.0903216, -0.210748, -0.451452, -0.507159, 0.0152399, -0.377826, -0.427343, -0.419685, 0.529558, 0.197154, 0.110454, 0.126602, 0.151658, 0.200732, -0.0222421, -0.433432, -0.152336, 0.124875, -0.0892207, -0.10039, 0.0734297, 0.0641797, -0.537144, -0.302362, -0.109208, 0.0566905, -0.254303, 0.0839252, -0.496497, -0.0207764, -0.467225, -0.640387, -0.22193, 0.180265, 0.063055, 0.156747, -0.354386, 0.124288, 0.271839, 0.0737775, -0.282155, -0.307142, -0.290784, 0.169122, -0.0219217, -0.0454134, 0.25812, 0.130315, 0.140813, -0.0376043, 0.00591538, 0.327395, -0.133219, 0.431383, 0.237583, 0.0196511, -0.157959, -0.0940364], "internal": 1}
{"paper_id": "E97-1023", "abstract": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus.", "title": "Predicting the Semantic Orientation of Adjectives", "venue": "E", "graph_vector": [-0.15702, 0.179304, 0.191675, 0.755332, 0.431349, -1.18881, -0.241459, -0.165423, -1.74987, 0.0267148, -0.808841, -0.407984, 0.106336, 0.145621, 0.149022, 0.136596, 0.0504041, -0.334027, 0.679513, 0.225927, 0.01531, 0.74866, -0.160391, 0.0687245, -0.214272, -0.032616, 0.0723556, 0.338819, -0.409022, 0.116072, 0.156199, 0.0123063, -0.126305, -0.313218, 0.222982, 0.17181, -0.135865, 0.811039, 0.529024, 0.0115381, 0.256519, -0.190656, -0.228042, 0.437552, 1.17971, -0.70048, 0.00327074, 0.498843, -0.24944, 0.351072, 0.498601, -0.164077, 0.48019, 0.750498, -0.0593392, 0.292556, 0.05557, 0.210544, 0.264037, 0.164298, -0.436181, 0.0857132, -0.0977638, -0.199349, 0.33227, -0.315323, 0.457869, 0.15683, -0.187466, -0.187809, -0.141001, -0.0313205, 0.182037, -0.0674044, 0.0559216, 0.0740606, -0.0987154, -0.421503, 0.139512, 0.521387, -0.606608, -0.281823, 0.631485, -0.128666, 0.316379, -0.116363, -0.222715, -0.0966875, -0.130128, -0.00283395, 0.203166, -0.0446381, -0.442102, -0.795678, -0.017812, -0.0756392, 0.173789, 0.302132, -0.200448, 0.194097, -0.339862, -0.226494, -0.162914, 0.200096, 0.219958, 0.34337, 0.0802017, 0.14842, 0.290986, -0.197981, -0.0790835, 0.0731867, -0.0177043, 0.368022, 0.234298, 0.349308, 0.118853, 0.188263, 0.0715188, 0.296822, -0.371946, -0.148484, -0.138248, 0.134508, 0.490004, -0.129386, -0.195787, -0.0485876], "internal": 1}
{"paper_id": "A83-1005", "abstract": "Constructing natural language interfaces to computer systems often requires achievment of advanced reasoning and expert capabilities in addition to basic natural language understanding. In this paper the above issues are faced in the frame of an actual application concerning the design of a natural language interface for the access to online information retrieval systems. After a short discus sion of the peculiarities of this application, which requires both natural language understanding and reasoning capabilities, the general architecture and fundamental design criteria of a system presently being developed at the University of Udine are then presented. The system, named IR-NLI, is aimed at allowing non-technical users to directly access through natural language the services offered by online data bases. Attention is later focused on the basic functions of IR-NLI, namely, understanding and dialogue, strategy generation, and reasoning. Knowledge represenetation methods and Lagorithms adopted are also illustarted. A short example of interaction with IR-NLI is presented. Perspectives and directions for future research are also discussed.", "title": "Giovanni Guida , Carlo Tasso(C) Istituto di Matematica, Informatica e Sistemistica UniversitA di Udine", "venue": "A", "graph_vector": [0.294006, 0.365835, -0.289209, 0.375173, 0.875622, -0.859515, -0.0177687, 0.396262, -2.58978, 0.52547, -0.110085, -0.469092, 0.604537, -0.272743, 0.236516, 0.289482, 0.495486, -0.67069, -0.40544, 0.12113, 0.0424204, 0.029029, 0.0996236, -0.0795222, -0.305541, -0.135259, -0.263382, 0.112054, 0.028709, -0.565491, 0.116816, 0.357893, -0.0827401, -0.194661, -0.522511, 0.206221, -0.460196, 0.456335, 0.387883, -0.208432, 0.156725, -0.3109, -0.75128, 0.472967, 1.59133, -1.29058, -0.0865171, -0.164964, -0.14275, -0.00692676, 0.283731, -0.142499, 1.04001, 0.975826, -0.169754, 0.179077, -0.262929, 0.248541, -0.0293634, -0.173583, -0.122194, -0.16411, -0.866275, 0.311396, 0.0045209, 0.03488, -0.0945244, -0.304909, -0.368426, -0.154137, 0.0261599, 0.343314, -0.314385, -0.236988, 0.268362, -0.0906248, -0.630274, -0.628961, -0.411941, -0.126589, -0.0253258, 0.159258, 0.00584232, 0.268781, 0.27329, -0.333101, 0.493891, -0.527648, -0.2387, -0.0008473, 0.150692, -0.219689, -0.838058, -0.171417, 0.163278, -0.259045, -0.30703, -0.0707665, -0.0457278, -0.178666, -0.630422, -0.511861, 0.178976, 0.165151, 0.542927, -0.11818, 0.222321, -0.130109, 0.0334792, -0.397279, -0.0573497, 0.294066, -0.192559, 0.041205, 0.0092891, -0.136243, 1.3639, -0.099187, 0.101309, 0.239464, -0.262942, -0.186223, -0.282793, -0.0535181, 1.00406, 0.0967504, 0.0691447, 0.197369], "internal": 1}
{"paper_id": "A00-1000", "abstract": "", "title": "Rebecca Stone, Ralph Weischedel 316 Improving Testsuites via Instrumentation Norbert Broker 325 The Efficiency of Multimodal Interaction for a Map-Based Task", "venue": "A", "graph_vector": [], "internal": 1}
{"paper_id": "A88-1020", "abstract": "This paper describes an exploration of the implicit synonymy relationship expressed by synonym lists in an on-line thesaurus. A series of automatic steps was taken to properly constrain this relationship. The resulting groupings of semantically related word senses are believed to constitute a useful tool for natural language processing and for work in lexicography.", "title": "", "venue": "A", "graph_vector": [0.0456087, 0.300239, -0.235649, 0.56968, 0.387405, -0.927072, 0.528415, -0.349379, -1.75656, 0.675427, -0.67568, -0.76025, 0.540202, 0.467308, -0.448248, 0.027898, 0.898758, -0.787716, 0.00318287, 0.303487, -0.15102, 0.558086, 0.127221, 0.243211, -0.608313, 0.338201, 0.233234, -0.121103, 0.298737, -0.234199, 0.153353, 0.144675, -0.269396, -0.124214, -0.147186, -0.0497564, -0.838632, 0.775369, -0.402478, 0.575597, -0.444369, -0.464334, 0.0185679, 0.367603, 0.877079, -0.928883, 0.0647017, -0.157484, -0.0664789, -0.29525, 0.233969, 0.155095, 1.17364, 0.444287, -0.139777, -0.0706471, 0.121309, -0.0737253, -0.0267036, -0.111765, -0.116853, 0.0683899, -0.354669, -0.170529, -0.16404, -0.198607, 0.0604057, 0.539149, 0.126171, 0.131157, 0.345336, -0.581817, -0.0900479, 0.0399717, 0.188644, -0.142761, -0.606428, -0.758403, 0.216601, 0.190536, -0.215803, -0.361569, 0.256751, -0.00727535, 0.491343, -0.490945, 0.308539, -0.147761, 0.049497, -0.0308845, -0.090914, -0.247503, -0.402589, -0.327836, -0.0102808, 0.122749, -0.167047, -0.0464409, -0.0438745, 0.184046, -0.338183, -0.0744577, 0.171844, 0.283936, -0.175526, 0.391217, 0.0564785, -0.0791622, -0.0246685, -0.0129891, 0.335794, -0.147691, -0.165186, -0.201639, -0.141858, -0.610198, 0.381416, 0.441528, 0.348137, 0.512615, -0.462764, 0.0787514, -0.206193, -0.170839, 0.226782, 0.32928, -0.207535, 0.12318], "internal": 1}
{"paper_id": "K15-2006", "abstract": "We describe a minimalist approach to shallow discourse parsing in the context of the CoNLL 2015 Shared Task.1 Our parser integrates a rule-based component for argument identification and datadriven models for the classification of explicit and implicit relations. We place special emphasis on the evaluation of implicit sense labeling, we present different feature sets and show that (i) word embeddings are competitive with traditional word-level features, and (ii) that they can be used to considerably reduce the total number of features. Despite its simplicity, our parser is competitive with other systems in terms of sense recognition and thus provides a solid ground for further refinement.", "title": "A Minimalist Approach to Shallow Discourse Parsing and Implicit Relation Recognition", "venue": "K", "graph_vector": [0.265725, 0.227518, 0.219737, 0.208723, 0.226414, -0.69196, -0.112481, -0.397905, -1.7441, 0.0956652, -0.0762349, -0.538087, 0.277633, -0.0615221, 0.27896, 0.22504, 0.6031, -0.605125, 0.213505, 0.420293, -0.315793, 0.479669, 0.146878, -0.102936, -0.339768, 0.491577, 0.0191608, -0.213427, -0.47026, -0.0939779, -0.212243, -0.289409, 0.215244, -0.23884, -0.157086, 0.0626531, -0.517129, 0.600843, 0.0644006, 0.172001, -0.153146, -0.472423, -0.169628, 0.138693, 0.765543, -0.544493, 0.00224833, -0.0482215, -0.328086, 0.0195391, 0.0362272, -0.264616, 1.11872, 0.62595, -0.244997, 0.321823, -0.0457567, 0.16044, 0.0866504, 0.00171315, -0.407674, 0.181661, -0.204707, 0.016623, -0.0302528, -0.0153247, 0.165947, -0.0153806, 0.395949, -0.0765288, -0.134228, 0.138568, 0.0361011, -0.164533, -0.0605768, -0.114768, -0.0128725, 0.16542, 0.15308, -0.183784, -0.0826463, 0.33483, 0.100593, -0.08578, -0.39683, -0.256975, -0.0873496, -0.044697, 0.364202, 0.10351, -0.188801, 0.348369, -0.57346, -0.233988, -0.0453968, -0.120098, -0.0524397, 0.120083, -0.0558907, -0.153831, -0.256091, -0.044984, -0.0681143, -0.193173, -0.0675535, 0.0821899, -0.0674671, 0.154173, -0.492104, 0.204877, 0.369265, 0.0074889, 0.0628332, -0.312244, -0.293341, 0.0702718, 0.697777, 0.0910058, 0.0656012, 0.432837, -0.0752625, 0.314763, -0.129161, -0.0928128, 0.380636, 0.137566, 0.141289, -0.0426828], "internal": 1}
{"paper_id": "W15-3818", "abstract": "Identifying smoking status of patients is vital for assessing their risk for a disease. With the rapid adoption of electronic health records (EHRs), patient information is scattered across various systems in the form of structured and unstructured data. In this study, we aimed to develop a hybrid system using rule-based, unsupervised and supervised machine learning techniques to automatically identify the smoking status of patients in unstructured EHRs. In addition to traditional features, we used per-document topic model distribution weights as features in our system. We also discuss the performance of our hybrid system using different feature sets. Our preliminary results demonstrated that combining per-document topic model distribution weights with traditional features improve the overall performance of the system.", "title": "A preliminary study on automatic identification of patient smoking status in unstructured electronic health records", "venue": "W", "graph_vector": [0.0624402, 0.394199, 0.259146, -0.0134324, 0.845098, -0.807594, 0.26497, 0.477882, -1.99622, 0.369884, -0.0145002, -0.596765, 1.103, 0.111091, -0.160861, -0.00264214, 0.629159, -0.776464, 0.61791, 0.145666, -0.3624, 0.83189, 0.115415, 0.0985732, -0.262192, 0.152378, 0.261423, 0.205434, -0.120332, -0.114071, 0.636161, 0.12943, 0.437185, -0.298389, 0.103729, 0.233907, -0.350987, 0.486922, -0.0505663, -0.14234, -0.0571274, 0.0084662, -0.645584, -0.0552926, 1.13958, -1.05971, 0.329109, -0.161681, 0.141572, -0.232494, 0.549678, -0.147661, 0.800934, 0.838008, -0.224114, 0.268432, 0.130205, 0.000861628, -0.161271, 0.251123, 0.335476, -0.0522867, -0.219172, -0.00110673, -0.152848, 0.0575012, 0.072557, -0.357657, 0.568695, -0.0228808, -0.0390624, 0.504866, -0.363327, -0.138071, -0.00459559, -0.521014, -0.819457, -0.295555, -0.193353, 0.0985566, -0.580219, 0.110331, 0.616528, -0.137487, -0.0145867, -0.487429, 0.592669, -0.188009, 0.399693, -0.0382952, -0.00111094, -0.0366082, -0.404141, 0.169362, 0.0457088, 0.0077034, -0.17825, 0.1473, -0.0348565, -0.332443, -0.538573, -0.14292, -0.322412, 0.231888, 0.0668936, 0.393038, 0.532159, -0.320227, -0.0770684, -0.340533, 0.016131, 0.142249, -0.130403, -0.254595, -0.340146, -0.16137, 0.45835, -0.0183998, 0.0583633, 0.366263, 0.193942, 0.0365176, 0.160201, -0.17958, 0.142956, 0.106867, 0.401364, 0.218271], "internal": 1}
{"paper_id": "W15-1521", "abstract": "Recent work in learning bilingual representations tend to tailor towards achieving good performance on bilingual tasks, most often the crosslingual document classification (CLDC) evaluation, but to the detriment of preserving clustering structures of word representations monolingually. In this work, we propose a joint model to learn word representations from scratch that utilizes both the context coocurrence information through the monolingual component and the meaning equivalent signals from the bilingual constraint. Specifically, we extend the recently popular skipgram model to learn high quality bilingual representations efficiently. Our learned embeddings achieve a new state-of-the-art accuracy of 80.3 for the German to English CLDC task and a highly competitive performance of 90.7 for the other classification direction. At the same time, our models outperform best embeddings from past bilingual representation work by a large margin in the monolingual word similarity evaluation.1", "title": "Bilingual Word Representations with Monolingual Quality in Mind", "venue": "W", "graph_vector": [0.116853, 0.218986, -0.0111507, 0.346307, 0.512061, -0.773336, 0.107261, -0.328224, -1.43247, 0.0971628, -0.12846, -0.292393, 0.464948, -0.0923823, 0.338436, -0.0633497, 0.480636, -0.456579, 0.0703931, 0.340601, -0.15816, 0.817217, 0.0558644, 0.0487494, -0.392774, 0.138166, 0.186574, 0.0667337, -0.178567, -0.196146, -0.197493, -0.0905624, 0.286814, -0.500154, -0.133054, 0.380743, -0.129684, 0.353109, 0.154411, -0.228709, -0.245289, -0.323387, -0.466772, 0.426102, 1.07732, -0.801673, 0.141472, 0.0194276, -0.317913, -0.0704638, 0.0541841, -0.250826, 0.841613, 0.689352, -0.0340865, -0.00524512, 0.200735, 0.0855661, 0.150609, -0.373676, -0.108076, -0.081552, -0.297483, 0.142213, -0.124789, 0.267556, 0.197722, -0.582525, -0.218646, -0.282338, 0.190281, 0.367839, -0.188247, -0.30259, 0.242339, -0.255156, -0.347127, -0.30713, 0.00305265, -0.11415, -0.197081, -0.134914, 0.347395, 0.0629227, 0.277743, -0.260226, 0.304438, -0.220406, -0.0701693, -0.129532, 0.154621, 0.18108, -0.623018, -0.00176081, -0.241942, 0.0820808, -0.238323, 0.172211, 0.112376, 0.0477093, -0.0999625, -0.417875, -0.0926913, 0.106342, -0.17241, 0.0633886, -0.0344091, -0.306165, -0.163612, -0.280102, 0.0329236, -0.0711264, -0.519692, 0.184138, -0.325982, 0.161406, 0.322914, -0.0984754, -0.117115, -0.0772581, 0.00791844, -0.0842477, 0.0576568, 0.14677, 0.117917, 0.172124, 0.337534, 0.0706484], "internal": 1}
{"paper_id": "W15-0106", "abstract": "As part of our ongoing work on grounding in dialogue, we present a corpus-based investigation of intention-level clarification requests. We propose to refine existing theories of grounding by considering two distinct types of intention-related conversational problems: intention recognition and intention adoption. This distinction is backed-up by an annotation experiment conducted on a corpus assembled with a novel method for automatically retrieving potential requests for clarification.", "title": "Clarifying Intentions in Dialogue: A Corpus Study∗", "venue": "W", "graph_vector": [0.134414, -0.0743259, -0.281299, 0.255168, 0.27016, -0.95525, -0.0615081, -0.397523, -1.7399, 0.645957, -0.144781, -0.175762, 0.58818, 0.0797647, -0.0231806, -0.0606356, 0.233059, -0.904224, -0.255557, 0.574879, -0.310082, 0.576557, 0.53563, -0.190777, -0.748101, -0.307645, 0.235705, 0.0658404, -0.0871917, -0.124005, -0.483732, 0.282528, 0.199636, -0.555228, 0.0668749, 0.0424083, -0.404397, 1.16804, 0.14703, 0.157545, -0.184897, -0.582125, 0.147857, 0.159571, 0.815188, -0.780666, 0.0766715, -0.137933, -0.290642, -0.209134, 0.367235, -0.267775, 0.856769, 0.350637, -0.01886, 0.176053, 0.400493, 0.106401, -0.148768, -0.383041, 0.200053, -0.0810939, -0.355383, -0.177874, 0.0314497, -0.141899, 0.261779, -0.207018, -0.356964, -0.0638346, 0.297877, -0.163455, -0.0945097, -0.304067, -0.291604, -0.0704364, -0.192713, -0.348366, -0.312878, 0.326674, -0.243663, -0.0330864, -0.121104, -0.0833755, 0.0725652, -0.406055, 0.140216, -0.128448, 0.122796, 0.139998, -0.115213, 0.190743, -0.48709, -0.251454, -0.24078, 0.610878, -0.112548, -0.14971, 0.338575, -0.190316, -0.230284, -0.242307, -0.135798, -0.0519398, 0.0730004, -0.189572, -0.0777217, 0.145584, -0.062523, -0.0276978, -0.155133, 0.114997, -0.167497, 0.256822, -0.1499, -0.0118996, 0.101713, 0.479088, -0.222738, 0.529757, -0.101193, 0.3901, 0.109331, -0.0396047, 0.352235, 0.494155, -0.418339, -0.0714778], "internal": 1}
{"paper_id": "W15-4105", "abstract": "There are two primary approaches to the use bilingual dictionary in statistical machine translation: (i) the passive approach of appending the parallel training data with a bilingual dictionary and (ii) the pervasive approach of enforcing translation as per the dictionary entries when decoding. Previous studies have shown that both approaches provide external lexical knowledge to statistical machine translation thus improving translation quality. We empirically investigate the effects of both approaches on the same dataset and provide further insights on how lexical information can be reinforced in statistical machine translation.", "title": "Passive and Pervasive Use of a Bilingual Dictionary in Statistical Machine Translation", "venue": "W", "graph_vector": [0.200686, 0.23381, 0.0666856, 0.245465, 0.584636, -0.67809, -0.0889861, -0.281019, -1.60954, 0.129333, 0.0111274, -0.522844, 0.59228, 0.202411, -0.0123291, -0.146699, 0.368882, -0.56007, 0.301057, 0.616648, -0.233307, 0.539722, 0.252635, 0.388865, -0.439717, -0.0687922, -0.0437661, 0.316281, -0.21754, -0.274676, 0.367048, 0.146144, 0.156743, -0.187293, -0.220671, 0.314739, -0.230364, 0.53389, 0.578762, -0.162344, -0.381279, -0.172193, -0.724987, 0.384197, 1.37019, -1.08239, 0.122754, -0.102665, -0.503093, -0.319469, 0.474443, -0.213718, 0.633069, 0.777104, -0.202362, 0.385416, 0.137371, 0.278857, -0.161973, -0.403638, -0.162323, -0.282511, 0.107452, 0.151167, -0.0117567, -0.19307, 0.460406, 0.0970251, -0.216836, 0.104136, 0.0472277, -0.0489674, -0.049774, -0.389706, 0.291198, 0.112944, -0.636556, -0.380306, 0.16346, 0.0724278, -0.152666, 0.0600481, 0.0290901, 0.143305, 0.0846337, -0.458594, 0.11339, -0.327162, -0.264046, 0.0908357, -0.258263, -0.0643207, -0.330206, 0.149471, 0.11585, -0.104177, -0.0749718, -0.121696, -0.259024, 0.018108, -0.193609, -0.406588, -0.0816357, 0.167322, 6.94902e-05, 0.110011, 0.0405947, -0.423615, 0.241989, 0.0799663, 0.043656, 0.329976, 0.0777637, -0.0302762, -0.388719, 0.042147, 0.26863, 0.268857, 0.318909, -0.0834863, -0.0375865, 0.00844857, 0.0207221, 0.0682295, 0.327439, 0.394342, 0.0625408, -0.0141899], "internal": 1}
{"paper_id": "W15-0110", "abstract": "Following earlier work in multimodal distributional semantics, we present the first results of our efforts to build a perceptually grounded semantic model. Rather than using images, our models are built on sound data collected from freesound.org. We compare three models: one bag-of-words model based on user-provided tags, a model based on audio features, using a ‘bag-of-audio-words’ approach and a model that combines the two. Our results show that the models are able to capture semantic relatedness, with the tag-based model scoring higher than the sound-based model and the combined model. However, capturing semantic relatedness is biased towards language-based models. Future work will focus on improving the sound-based model, finding ways to combine linguistic and acoustic information, and creating more reliable evaluation data.", "title": "Sound-based distributional models", "venue": "W", "graph_vector": [0.456459, 0.486051, 0.194365, 0.765307, 0.315022, -0.783264, 0.39001, -0.481783, -1.59508, -0.0985816, 0.062693, -0.161115, 0.188199, -0.186801, -0.0497163, -0.303913, 0.381153, -0.736866, 0.119372, 0.385792, -0.17694, 0.163231, 0.259899, -0.217857, -0.50944, 0.124296, -0.0669407, -0.196321, -0.129357, -0.0376734, 0.159249, -0.329346, 0.31829, -0.183469, -0.516382, 0.316996, -0.444189, 1.31196, 0.326429, -0.0609011, -0.22199, -0.536295, -0.0608849, 0.785805, 1.21002, -0.77369, 0.163242, -0.0843868, -0.161171, 0.0335564, 0.507055, -0.135033, 1.00626, 0.496958, 0.260252, -0.215039, 0.2146, 0.279237, -0.255988, -0.248746, -0.0804652, -0.130464, -0.0923504, 0.349953, 0.102765, -0.100673, 0.295727, -0.248512, -0.263888, 0.171046, -0.181145, 0.116583, 0.459358, -0.0242309, 0.175129, 0.0695922, -0.462531, -0.424511, -0.493879, -0.522401, 0.185986, 0.217, 0.349188, -0.229023, 0.175683, -0.23845, 0.0300686, -0.206551, 0.357965, 0.32661, -0.0743469, -0.205333, -0.689021, -0.614781, -0.173746, -0.204555, 0.357462, 0.068698, 0.230223, -0.113103, -0.475678, -0.429227, 0.00159695, -0.155466, 0.081642, 0.00485125, 0.0856725, -0.247167, 0.345124, 0.0625862, -0.240045, -0.233235, -0.00523068, 0.171445, -0.465224, -0.144582, 0.480036, 0.223416, -0.41506, 0.35098, -0.19247, -0.0431749, -0.317158, 0.0406284, 0.0467971, -0.155157, 0.0608647, -0.0438317], "internal": 1}
{"paper_id": "W15-1605", "abstract": "Understanding the structure of scientific discourse is of paramount importance for the development of appropriate Natural Language Processing tools able to extract and summarize information from research articles. In this paper we present an annotated corpus of scientific discourse in the domain of Computer Graphics. We describe the way we built our corpus by designing an annotation schema and relying on three annotators for manually classifying all sentences into the defined categories. Our corpus constitutes a semantically rich resource for scientific text mining. In this respect, we also present the results of our initial experiments of automatic classification of sentences into the 5 main categories in our corpus.", "title": "On the Discoursive Structure of Computer Graphics Research Papers", "venue": "W", "graph_vector": [-0.349002, 0.363697, 0.267748, 0.536299, 0.723919, -0.410086, 0.0921015, 0.0545653, -1.62995, 0.280803, -0.140537, -0.0705969, 0.863326, 0.112108, -0.0340819, -0.1502, 0.779812, -0.349231, 0.278964, 0.270067, -0.255987, 0.711171, 0.159509, -0.0402401, -0.688692, 0.0481707, 0.336423, -0.0170344, -0.298947, -0.328881, -0.11603, 0.0209825, 0.18894, -0.627829, 0.0677874, -0.0749785, -0.213617, 0.630866, 0.286248, 0.0594101, -0.0736952, -0.234806, -0.320381, 0.0332032, 1.16126, -0.782462, -0.150775, -0.404518, -0.342654, -0.110684, 0.214475, -0.132256, 0.632729, 0.564314, -0.477918, 0.263643, 0.170933, -0.0554137, 0.0785643, 0.0881916, -0.107652, -0.129958, -0.138127, 0.198553, -0.357554, -0.0167424, 0.117149, -0.0946958, 0.266413, -0.0252241, -0.120476, -0.107669, -0.0852635, 0.130601, -0.0121396, 0.0211844, -1.00115, -0.237025, -0.179211, 0.376647, -0.33566, -0.273156, -0.101825, 0.00420889, -0.067912, 0.0507606, -0.0438234, -0.206008, 0.123484, -0.00477781, -0.100623, 0.111608, -0.704161, 0.0650972, 0.00590953, -0.220715, 0.140119, -0.448324, -0.0431907, 0.360506, -0.457586, -0.460161, -0.00792794, -0.075245, 0.13832, 0.220117, 0.245516, 0.0109269, -0.462666, -0.0503722, -0.0606793, 0.0489881, -0.145496, -0.257984, -0.287739, -0.0939506, 0.801427, -0.187109, -0.265778, 0.102742, 0.068781, -0.444204, 0.392291, 0.201263, 0.276936, -0.19095, -0.0955258, -0.195716], "internal": 1}
{"paper_id": "W15-1512", "abstract": "We propose a novel approach to learning distributed representations of variable-length text sequences in multiple languages simultaneously. Unlike previous work which often derive representations of multi-word sequences as weighted sums of individual word vectors, our model learns distributed representations for phrases and sentences as a whole. Our work is similar in spirit to the recent paragraph vector approach but extends to the bilingual context so as to efficiently encode meaning-equivalent text sequences of multiple languages in the same semantic space. Our learned embeddings achieve state-of-theart performance in the often used crosslingual document classification task (CLDC) with an accuracy of 92.7 for English to German and 91.5 for German to English. By learning text sequence representations as a whole, our model performs equally well in both classification directions in the CLDC task in which past work did not achieve.", "title": "Learning Distributed Representations for Multilingual Text Sequences", "venue": "W", "graph_vector": [0.177843, 0.374805, 0.0292441, 0.208681, 0.444066, -0.645309, 0.351701, -0.370941, -1.26905, 0.322029, -0.141033, -0.304162, 0.466012, -0.00937528, 0.231401, -0.0088811, 0.373204, -0.352283, -0.000418954, 0.104197, -0.271372, 0.879237, 0.342199, -0.101931, -0.0969018, 0.301819, 0.0696999, 0.262107, 0.0435895, -0.218531, -0.350243, -0.102031, 0.171795, -0.475908, -0.341331, 0.191724, -0.219981, 0.536827, 0.223137, -0.0433727, -0.13159, -0.270625, -0.419311, 0.338393, 1.13844, -0.896807, -0.00673245, -0.0399284, -0.445734, -0.158433, 0.051784, -0.100481, 0.82795, 0.579138, -0.0175277, -0.0474324, 0.19601, 0.401738, -0.118862, -0.222932, -0.0807935, 0.189325, -0.126065, 0.105767, -0.00137519, 0.11185, 0.197181, -0.164644, -0.000152204, -0.0663351, 0.487559, 0.192124, 0.0186534, -0.117483, 0.2525, -0.0939822, -0.582542, -0.264208, -0.10059, -0.0874247, 0.00619973, 0.190818, 0.144645, 0.00336428, 0.241022, -0.559345, 0.20173, -0.183029, 0.0742787, -0.125778, 0.176709, 0.125155, -0.779942, -0.191244, 0.0486624, 0.0869688, 0.0478863, 0.180761, 0.022268, 0.0834015, 0.144821, -0.289266, -0.0754317, -0.13891, -0.00650308, 0.248978, 0.116031, -0.16996, -0.114553, -0.186702, -0.0695911, 0.105681, -0.232058, 0.490799, -0.263824, 0.2064, 0.46835, -0.0375708, -0.0300767, -0.0306875, -0.233178, -0.0434678, 0.296373, -0.0225151, 0.121249, 0.28504, 0.432447, -0.067917], "internal": 1}
{"paper_id": "W15-0403", "abstract": "Software requirements describe functional and non-functional aspects of a software system and form the basis for the development process. Accordingly, requirements of existing systems can provide insights regarding the re-usability of already implemented software artifacts. To facilitate direct comparison between requirements of existing and to be developed systems, we propose to automatically map requirements in natural language text to structured semantic representations. For this task, we adapt techniques from semantic role labeling to a high-level ontology that defines concepts and relations for describing static software functionalities. The proposed method achieves a precision and recall of 77.9% and 74.5%, respectively, on an annotated software requirements dataset and significantly outperforms two baselines that are based on lexical and syntactic patterns.", "title": "Parsing Software Requirements with an Ontology-based Semantic Role Labeler", "venue": "W", "graph_vector": [-0.0619804, -0.0268681, -0.0290549, 0.168931, 0.582448, -1.03679, -0.161151, -0.444303, -1.8325, -0.334725, 0.274313, -0.578748, 0.409804, 0.254971, 0.732758, -0.151115, 0.37674, -1.02288, 0.244447, 0.607484, -0.247524, 0.737938, 0.180919, -0.239269, -0.401967, 0.245706, -0.103317, 0.0759519, -0.379971, -0.33401, 0.0150962, -0.148556, -0.0591906, -0.690861, -0.272663, 0.0610915, -0.183739, 0.795114, -0.0790682, 0.159495, 0.1297, -0.304217, -0.445638, 0.34732, 0.845902, -1.01427, 0.0267332, 0.0869053, 0.0632437, 0.0191422, -0.160274, -0.293038, 0.778086, 0.734646, -0.124102, 0.100504, -0.339255, 0.598473, -0.083233, -0.113922, 0.291272, -0.493301, -0.0991718, 0.0500217, 0.361328, 0.0902984, 0.426569, 0.0949935, 0.0827488, 0.124308, -0.161279, -0.0904376, -0.397894, -0.0681457, 0.0835729, -0.017184, -0.638404, -0.728315, 0.0854246, 0.0446935, 0.159911, -0.103497, 0.250351, -0.0329296, 0.00541854, -0.363121, -0.0527228, -0.440795, 0.20033, -0.110335, 0.0211744, 0.238535, -0.733611, -0.369683, 0.433393, 0.187541, -0.0148968, -0.275128, -0.207572, 0.0779085, 0.0348553, -0.447043, 0.0770034, 0.0588208, 0.243783, -0.109347, -0.136726, -0.395569, 0.138373, -0.140507, 0.238853, -0.116587, -0.0100642, 0.425118, -0.254029, 0.228212, 0.526721, -0.262459, -0.0292155, 0.182611, -0.579615, 0.264948, -0.0643887, -0.297519, 0.398045, 0.302745, 0.178156, 0.273584], "internal": 1}
{"paper_id": "W15-0125", "abstract": "Truly interactive dialogue systems need to construct meaning on at least a word-by-word basis. We propose desiderata for incremental semantics for dialogue models and systems, a task not heretofore attempted thoroughly. After laying out the desirable properties we illustrate how they are met by current approaches, comparing two incremental semantic processing frameworks: Dynamic Syntax enriched with Type Theory with Records (DS-TTR) and Robust Minimal Recursion Semantics with incremental processing (RMRS-IP). We conclude these approaches are not significantly different with regards to their semantic representation construction, however their purported role within semantic models and dialogue models is where they diverge.", "title": "Incremental Semantics for Dialogue Processing: Requirements, and a Comparison of Two Approaches", "venue": "W", "graph_vector": [-0.0939375, 0.327044, -0.576755, 0.172944, 0.514352, -1.14262, -0.0181687, -0.437017, -2.07307, 0.286088, 0.137906, -0.508065, 0.455459, 0.231904, -0.0381483, -0.296077, 0.17649, -0.637343, 0.101153, 0.42012, 0.00537376, 0.608945, -0.0427507, 0.116668, -0.474567, -0.17185, -0.0634148, -0.218068, -0.211743, 0.0350102, -0.239863, 0.121958, 0.451877, -0.734896, -0.131524, -0.00685717, -0.119205, 0.770269, -0.105054, -0.0780723, -0.22208, -0.527977, -0.658624, 0.52676, 0.695519, -0.949254, -0.0202833, -0.0106708, -0.0405952, -0.237853, 0.442702, -0.163949, 0.75763, 0.288007, -0.00759916, -0.116032, 0.257545, -0.157856, -0.0162289, -0.261787, 0.02675, -0.0768876, -0.151568, 0.0353266, -0.208625, 0.300553, -0.23049, 0.117651, -0.25723, 0.241379, 0.0272141, 0.295705, -0.0644853, 0.0735469, 0.00786747, 0.0303383, 0.0117134, -0.140485, -0.317235, 0.276064, -0.622938, 0.323717, -0.0182371, -0.0856174, 0.0390164, -0.139717, -0.171902, -0.161809, 0.415778, -0.132654, 0.146802, 0.426247, -0.418125, -0.562626, 0.236292, 0.259242, -0.363708, -0.300031, 0.173703, -0.248913, -0.195963, -0.143105, 0.278724, -0.0757006, -0.00835832, -0.0427186, -0.00997314, -0.446449, 0.3191, -0.346761, -0.400786, 0.10127, -0.219008, 0.100198, 0.123709, 0.0649117, 0.501308, 0.385758, -0.120467, 0.161214, 0.312979, -0.125575, -0.302606, -0.274675, 0.214558, -0.0661916, -0.208174, -0.111331], "internal": 1}
{"paper_id": "W15-1506", "abstract": "Up to now, relation extraction systems have made extensive use of features generated by linguistic analysis modules. Errors in these features lead to errors of relation detection and classification. In this work, we depart from these traditional approaches with complicated feature engineering by introducing a convolutional neural network for relation extraction that automatically learns features from sentences and minimizes the dependence on external toolkits and resources. Our model takes advantages of multiple window sizes for filters and pre-trained word embeddings as an initializer on a non-static architecture to improve the performance. We emphasize the relation extraction problem with an unbalanced corpus. The experimental results show that our system significantly outperforms not only the best baseline systems for relation extraction but also the state-of-the-art systems for relation classification.", "title": "Relation Extraction: Perspective from Convolutional Neural Networks", "venue": "W", "graph_vector": [0.0831122, 0.0987791, 0.341957, 0.213292, 0.449362, -0.737162, 0.117813, -0.118697, -1.47959, 0.318825, 0.186681, -0.145077, 0.340379, 0.182405, 0.259822, 0.0626267, 0.243015, -0.338071, -0.0763487, -0.00382711, -0.306839, 0.662393, 0.324815, -0.123931, -0.419569, 0.120174, -0.265013, 0.0576104, -0.189978, -0.136042, -0.23719, -0.182835, 0.246544, -0.709765, -0.192516, 0.0317841, -0.260642, 0.516787, 0.250677, 0.0141654, -0.0868169, -0.752448, -0.333775, 0.493507, 0.925719, -0.728898, 0.148882, 0.157269, -0.190385, -0.0600597, 0.248404, -0.153894, 1.07022, 0.573577, -0.00597919, -0.00979022, -0.0115737, 0.142811, -0.149265, 0.124529, -0.235372, -0.194786, -0.420407, 0.142147, 0.225284, -0.299221, 0.00799844, -0.288423, 0.0429578, 0.0634279, 0.0021391, -0.122715, 0.0132907, -0.122853, 0.188221, -0.212825, -0.51832, -0.403981, 0.0822285, -0.0827633, -0.246356, 0.114491, 0.411446, -0.177152, 0.387253, -0.293433, 0.0892823, -0.0900338, -0.0219881, -0.178761, 0.308161, 0.30797, -0.727567, 0.258724, -0.0643926, 0.100585, -0.199424, -0.27031, -0.33985, 0.0335647, 0.143107, 0.0738606, 0.0652941, -0.117436, -0.018133, 0.181655, 0.223863, 0.0386051, 0.274646, -0.120226, 0.0515946, -0.0906302, -0.18281, 0.116194, -0.354182, -0.0753536, 0.252059, -0.0760895, 0.2089, 0.193014, -0.0348775, -0.0432993, 0.0754947, -0.0369096, 0.638492, -0.0382427, 0.0626049, 0.206323], "internal": 1}
{"paper_id": "W15-1518", "abstract": "We replicate the syntactic experiments of Mikolov et al. (2013b) on English, and expand them to include morphologically complex languages. We learn vector representations for Dutch, French, German, and Spanish with the WORD2VEC tool, and investigate to what extent inflectional information is preserved across vectors. We observe that the accuracy of vectors on a set of syntactic analogies is inversely correlated with the morphological complexity of the language.", "title": "Morpho-syntactic Regularities in Continuous Word Representations: A Multilingual Study", "venue": "W", "graph_vector": [-0.117997, 0.340405, -0.0461665, 0.321723, 0.43242, -0.758053, 0.255473, -0.40524, -1.18667, 0.124375, 0.299177, -0.45881, 0.850512, -0.212973, 0.0997245, -0.250246, 0.353742, -0.508021, 0.17468, 0.208183, -0.236662, 0.697512, 0.0844357, 0.194933, -0.318275, 0.0653128, -0.377367, 0.0707484, -0.24467, -0.369972, -0.0158905, -0.0151186, 0.247122, 0.0296369, -0.335093, 0.407608, -0.0797755, 0.604407, 0.253877, 0.166503, -0.131151, -0.404083, -0.468508, 0.436631, 0.912042, -0.724663, 0.0192983, 0.18477, -0.0620932, 0.244235, 0.526242, -0.104102, 1.12398, 0.0384354, 0.184396, -0.235645, 0.226854, 0.398996, -0.139554, 0.271325, -0.103403, 0.00727236, -0.00146961, 0.144939, 0.0316517, 0.0495621, 0.28389, -0.40918, -0.204934, -0.302272, 0.145993, 0.37359, 0.0665327, -0.0632667, 0.0035487, -0.0853857, -0.72344, -0.0948934, 0.149223, -0.0433666, -0.161883, 0.342286, 0.167618, -0.0224027, 0.185638, -0.470865, -0.0148811, 0.0531998, 0.00120184, -0.34613, 0.250628, 0.181966, -0.618717, -0.28215, -0.128912, -0.191109, 0.0823119, -0.0764771, -0.0491293, -0.0627697, -0.230317, -0.0190012, -0.409164, 0.0891359, -0.100332, 0.152754, 0.097504, -0.184942, -0.177599, 0.0389631, 0.0552194, 0.105851, -0.0663329, -0.0408098, -0.318093, 0.0560411, 0.290558, 0.14537, 0.102036, 0.162385, -0.295751, 0.0310595, -0.0472827, -0.0821467, 0.358224, 0.0418927, 0.334985, -0.455101], "internal": 1}
{"paper_id": "W15-1006", "abstract": "We present an initial experiment in integrating a disambiguation step in MT evaluation. We show that accounting for sense distinctions helps METEOR establish better sense correspondences and improves its correlation with human judgments of translation quality.", "title": "METEOR-WSD: Improved Sense Matching in MT Evaluation", "venue": "W", "graph_vector": [-0.0614782, 0.255137, -0.123088, -0.287554, 0.392251, -0.698244, 0.330283, 0.233284, -1.43655, 0.297243, -0.481264, -0.35509, 0.69619, -0.015094, -0.173979, 0.00711546, 0.385506, -0.811098, -0.436783, 0.575891, -0.208554, 0.346858, 0.351245, -0.0240954, -0.493199, 0.039948, -0.00809243, 0.534259, -0.287767, -0.207478, -0.14139, 0.0209559, -0.0325735, -0.275949, -0.567834, 0.0672385, -0.568409, 0.493983, 0.157806, -0.172843, 0.0135055, -0.490935, -0.369906, 0.360335, 0.935409, -0.499481, 0.391073, 0.181966, 0.0556659, -0.0749751, 0.420012, 0.0936099, 0.909426, 0.830368, 0.013926, 0.317272, 0.277836, 0.0810685, -0.444175, -0.240753, -0.506342, -0.0780216, 0.186538, 0.228686, 0.199078, 0.0346704, 0.425573, -0.186254, 0.0481873, -0.0411097, -0.0025128, 0.0245083, -0.413259, -0.260734, 0.252582, 0.0166891, -0.394612, -0.159092, -0.16986, 0.0653574, 0.223871, 0.194891, 0.0909514, -0.374034, 0.150107, -0.388905, -0.0313795, -0.200798, -0.0845636, -0.10941, 0.0677347, -0.230717, -0.788798, -0.363436, 0.180214, -0.156479, 0.0757799, -0.0444954, 0.269831, -0.0281295, -0.227738, 0.138784, -0.0242921, 0.0857786, -0.223785, -0.0633031, -0.140439, 0.0642734, -0.0360628, -0.100522, -0.085354, 0.0477011, -0.143281, 0.130651, -0.201308, -0.261542, 0.431778, 0.425214, 0.029565, 0.203751, -0.054986, -0.0725913, -0.242907, 0.448737, 0.491652, 0.225127, -0.0226823, 0.187748], "internal": 1}
{"paper_id": "W15-3807", "abstract": "The goal of our research is to extract medical concepts from clinical notes containing patient information. Our research explores stacked generalization as a metalearning technique to exploit a diverse set of concept extraction models. First, we create multiple models for concept extraction using a variety of information extraction techniques, including knowledgebased, rule-based, and machine learning models. Next, we train a meta-classifier using stacked generalization with a feature set generated from the outputs of the individual classifiers. The meta-classifier learns to predict concepts based on information about the predictions of the component classifiers. Our results show that the stacked generalization learner performs better than the individual models and achieves state-of-the-art performance on the 2010 i2b2 data set.", "title": "Stacked Generalization for Medical Concept Extraction from Clinical Notes", "venue": "W", "graph_vector": [-0.0983315, 0.156207, 0.209349, 0.254481, 0.423915, -0.957829, 0.330366, 0.253483, -1.47476, 0.0386001, 0.290665, -0.472143, 0.473267, 0.239748, 0.0600045, -0.228927, 0.227904, -0.643673, 0.65093, 0.131456, -0.239062, 0.714734, 0.505523, 0.213495, -0.413316, 0.408168, 0.137784, 0.103577, 0.0464807, -0.575994, 0.583072, 0.177209, 0.0222925, 0.176202, -0.0284566, -0.000148299, -0.32331, 0.701918, 0.120785, -0.326247, -0.12645, -0.50878, -0.142141, 0.447201, 0.481837, -0.904519, -0.0732083, 0.431794, 0.393886, -0.313094, 0.367033, 0.0207842, 0.828027, 0.647088, -0.455609, -0.114092, 0.114575, 0.223276, -0.118691, 0.312773, -0.193431, -0.249581, -0.122574, 0.323451, -0.258768, 0.0257358, 0.179672, 0.0358175, 0.121547, 0.0170215, 0.312413, 0.536583, 0.0668316, 0.223496, 0.206525, -0.0494409, -0.613518, -0.146357, 0.233373, 0.0618923, -0.271339, 0.07077, 0.574692, 0.246086, -0.149709, -0.54871, 0.136355, 0.0711907, 0.206863, 0.102655, 0.212891, 0.086594, -0.632968, 0.222888, 0.346074, -0.407234, -0.188111, -0.128551, -0.376459, 0.218774, -0.106084, -0.257575, 0.221095, -0.167969, -0.0316733, 0.0419657, 0.112061, 0.0323793, 0.225327, -0.545665, 0.0849069, -0.0574965, 0.0783577, -0.336297, -0.120667, -0.0204281, 0.327458, 0.192882, -0.0365784, 0.468547, 0.361445, -0.15169, 0.0300602, -0.502079, 0.317946, 0.365004, -0.309624, 0.142477], "internal": 1}
{"paper_id": "W03-0407", "abstract": "This paper investigates booststrapping part-ofspeech taggers using co-training, in which two taggers are iteratively re-trained on each other’s output. Since the output of the taggers is noisy, there is a question of which newly labelled examples to add to the training set. We investigate selecting examples by directly maximising tagger agreement on unlabelled data, a method which has been theoretically and empirically motivated in the co-training literature. Our results show that agreement-based co-training can significantly improve tagging performance for small seed datasets. Further results show that this form of co-training considerably outperforms self-training. However, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results to agreement-based co-training, with only a fraction of the computational cost.", "title": "Bootstrapping POS taggers using Unlabelled Data", "venue": "W", "graph_vector": [-0.0619968, 0.173541, 0.00134159, 0.2187, 0.810564, -0.823373, -0.0594552, -0.00637822, -1.32842, 0.416439, -0.356999, -0.281673, 0.813426, 0.122239, 0.0287234, -0.069035, 0.370086, -0.65318, 0.00238688, 0.457924, -0.401965, 0.470061, 0.03164, 0.274906, -0.183994, 0.1807, -0.0897862, -0.141834, -0.0707511, -0.0967584, 0.125681, -0.159179, 0.308857, -0.74052, -0.379402, -0.0808821, 0.0740189, 0.748742, 0.0140758, -0.286553, -0.0385843, -0.340128, -0.125927, 0.391848, 0.71101, -0.617771, 0.131528, 0.162259, 0.19548, 0.148798, 0.52605, -0.301724, 0.760366, 0.631595, -0.253954, 0.0511026, 0.296444, -0.0599483, 0.0813526, 0.0830935, -0.0672257, -0.0755534, 0.00558792, -0.257322, -0.122541, -0.0645928, 0.152602, -0.139428, -0.286249, -0.0153523, -0.0673031, 0.144215, 0.112943, 0.022476, -0.199409, -0.0934302, -0.527248, -0.320552, -0.158975, -0.168967, -0.240999, 0.421564, 0.0821198, 0.0699801, 0.493898, 0.320614, -0.0784754, -0.289981, -0.0976038, -0.238164, -0.0618188, -0.293119, -0.281843, 0.107106, 0.0389428, -0.308032, -0.162487, -0.139941, 0.0439859, 0.407367, -0.0295724, -0.181493, -0.184475, 0.0304495, 0.179125, 0.23201, -0.188394, -0.0306748, -0.264727, -0.166372, 5.39079e-05, -0.0817073, -0.354108, -0.0805292, 0.0796074, -0.004461, 0.475333, -0.0686442, 0.226157, -0.0145037, 0.0958266, -0.283678, -0.0489221, 0.320522, 0.58786, 0.418602, -0.324149, 0.0667627], "internal": 1}
{"paper_id": "W03-1307", "abstract": "In this paper, we explore how to adapt a general Hidden Markov Model-based named entity recognizer effectively to biomedical domain. We integrate various features, including simple deterministic features, morphological features, POS features and semantic trigger features, to capture various evidences especially for biomedical named entity and evaluate their contributions. We also present a simple algorithm to solve the abbreviation problem and a rule-based method to deal with the cascaded phenomena in biomedical domain. Our experiments on GENIA V3.0 and GENIA V1.1 achieve the 66.1 and 62.5 F-measure respectively, which outperform the previous best published results by 8.1 F-measure when using the same training and testing data.", "title": "Effective Adaptation of a Hidden Markov Model-based Named Entity Recognizer for Biomedical Domain", "venue": "W", "graph_vector": [-0.341186, 0.102419, 0.572941, 0.465112, 0.551545, -0.663526, 0.201561, 0.00911055, -1.81969, 0.530687, 0.107146, -0.101433, 0.28735, 0.095214, 0.328215, -0.34288, 0.495842, -0.108053, 0.25049, 0.407071, -0.258536, 0.691534, 0.143101, 0.135051, -0.360478, 0.252855, 0.0439457, 0.187046, -0.0936803, -0.102574, 0.415344, 0.116593, -0.0608554, -0.533693, -0.0123352, -0.146806, -0.107062, 0.554946, 0.38834, -0.203157, -0.134401, -0.865814, -0.204984, 0.202531, 0.851636, -0.923831, -0.293913, 0.152509, 0.234476, 0.239208, 0.280508, 0.0164105, 0.765441, 0.6152, -1.0291, 0.484694, 0.580997, 0.167978, 0.337673, -0.261653, -0.0131874, -0.0434054, 0.0810054, 0.274806, -0.240853, -0.410598, 0.38115, 0.204225, -0.0668445, 0.02805, -0.165824, 0.0659438, -0.318148, -0.117418, 0.337633, 0.176296, -0.438113, -0.342733, 0.101205, 0.0106786, -0.160128, -0.123635, 0.273944, 0.240191, 0.437817, -0.152966, 0.313063, 0.185498, 0.0371167, 0.122482, -0.0261346, 0.0308991, -0.960635, 0.161876, 0.0236432, -0.15142, -0.0784696, 0.00446575, -0.249304, 0.0849648, -0.39705, -0.229152, -0.0113311, 0.0852471, -0.0166583, -0.202309, 0.0944238, 0.156494, 0.448591, -0.671139, -0.20633, 0.326124, -0.246064, 0.203992, -0.062884, -0.118966, 0.277971, 0.0698372, 0.0251445, 0.221181, 0.053272, 0.108936, -0.215849, -0.259814, 0.0913312, 0.420922, 0.120134, -0.170097], "internal": 1}
{"paper_id": "W03-2120", "abstract": "Annotation of discourse phenomena is a notoriously difficult task which cannot be carried out without the help of annotation tools. In this paper we present a Perspicuous and Adjustable Links Annotator (PALinkA), a tool successfully used in several of our projects. We also briefly describe three types of discourse annotations applied using the tool.", "title": "PALinkA: A highly customisable tool for discourse annotation", "venue": "W", "graph_vector": [-0.111324, 0.400733, -0.0190881, 0.137336, 0.424183, -0.523637, -0.232191, -0.250448, -1.84616, 0.458031, 0.0771616, -0.259552, 0.893936, 0.177751, 0.261139, -0.286914, 0.406735, -0.530987, 0.513656, 0.0310371, -0.58226, 0.536437, -0.00247628, -0.00772332, -0.125644, 0.525009, 0.514713, 0.439521, -0.18215, 0.138126, 0.29995, 0.30074, 0.0491609, -0.0196401, -0.136198, 0.183816, -0.120105, 1.10719, 0.261606, -0.302288, 0.141803, -0.0555514, -0.0913445, 0.219495, 1.06134, -0.610556, 0.312746, -0.00270036, -0.496565, 0.0241831, 0.232193, -0.0645012, 0.619285, 0.570006, -0.335665, 0.291945, 0.385537, 0.151697, -0.020091, -0.154779, -0.0806638, -0.594924, -0.0567792, -0.0563084, 0.105425, -0.394053, 0.325474, -0.304587, 0.0149308, 0.17479, -0.464871, 0.184946, -0.229375, -0.253367, 0.196671, 0.0729259, -0.118988, 0.00033, -0.459142, 0.291712, 0.0677945, 0.223173, 0.0155246, -0.221108, 0.0932204, -0.279266, -0.121106, -0.148234, 0.0690635, 0.0433626, 0.497386, -0.199228, -0.68511, 0.386876, -0.406784, -0.24682, -0.267876, -0.345915, -0.0325098, -0.301377, -0.171998, -0.155111, -0.172334, -0.168389, -0.0738497, 0.348714, -0.221088, 0.0209871, 0.312214, -0.142582, -0.354154, 0.248729, 0.170484, -0.360781, 0.112715, -0.0424175, 0.43306, 0.131879, -0.151357, 0.208207, -0.0504802, 0.0184606, 0.187499, 0.0240337, 0.317837, 0.0211281, -0.145029, 0.0083132], "internal": 1}
{"paper_id": "W04-1221", "abstract": "As the wealth of biomedical knowledge in the form of literature increases, there is a rising need for effective natural language processing tools to assist in organizing, curating, and retrieving this information. To that end, named entity recognition (the task of identifying words and phrases in free text that belong to certain classes of interest) is an important first step for many of these larger information management goals. In recent years, much attention has been focused on the problem of recognizing gene and protein mentions in biomedical abstracts. This paper presents a framework for simultaneously recognizing occurrences of PROTEIN, DNA, RNA, CELL-LINE, and CELL-TYPE entity classes using Conditional Random Fields with a variety of traditional and novel features. I show that this approach can achieve an overall F1 measure around 70, which seems to be the current state of the art. The system described here was developed as part of the BioNLP/NLPBA 2004 shared task. Experiments were conducted on a training and evaluation set provided by the task organizers.", "title": "Biomedical Named Entity Recognition Using Conditional Random Fields and Rich Feature Sets", "venue": "W", "graph_vector": [-0.145331, 0.00169186, 0.514173, 0.247501, 0.121222, -0.766767, -0.170304, 0.149158, -1.40434, 0.456945, 0.0892294, -0.579045, 0.525654, 0.085758, 0.167072, -0.251572, 0.514219, -0.510442, 0.383825, 0.563448, -0.25689, 0.725978, 0.392376, 0.149475, -0.0536398, 0.046694, -0.0411146, -0.0719154, 0.0729984, -0.170895, -0.0897984, 0.198976, 0.156088, -0.291233, -0.100917, -0.02861, -0.199264, 0.632331, 0.250213, -0.181709, 0.174087, -0.689075, -0.287975, 0.252808, 0.673442, -0.599901, 0.105897, 0.214548, 0.0959303, -0.0456735, 0.243853, 0.0142365, 0.844385, 0.768066, -0.631568, 0.0236747, 0.0586662, 0.162324, 0.126455, 0.0730404, -0.0575739, -0.0451129, 0.0366608, -0.154634, -0.0455023, 0.187451, 0.182328, 0.031279, -0.0481021, 0.0868927, -0.238522, 0.293834, -0.25663, 0.0252735, 0.0432596, -0.161053, -0.326487, -0.42211, 0.0947357, -0.320508, -0.530293, 0.211637, 0.598704, 0.179469, 0.313096, -0.226106, 0.0905481, -0.387438, 0.154256, 0.0969298, -0.00986541, -0.183694, -0.582223, -0.064915, 0.11381, 0.0348243, -0.326066, 0.035508, 0.260372, 0.352826, -0.150677, -0.490807, 0.211964, -0.0961757, -0.0721365, 0.300179, 0.287189, -0.00110244, 0.0538334, -0.317843, -0.159264, 0.291135, -0.334776, -0.215268, -0.153563, 0.0475226, 0.488662, -0.206142, 0.105994, -0.204341, 0.167735, 0.0911216, -0.229345, -0.332951, 0.299425, 0.374777, -0.222564, 0.0450368], "internal": 1}
{"paper_id": "W04-0836", "abstract": "In this paper we describe the Catalan Lexical Sample task. This task was initially devised for evaluating the role of unlabeled examples in supervised and semi-supervised learning systems for WSD and it is the counterpart of the Spanish Lexical Sample task. It was coordinated also with other lexical sample tasks (Basque, English, Italian, Rumanian, and Spanish) in order to share part of the target words. Firstly, we describe the methodology followed for developing the specific linguistic resources necessary for the task: the MiniDir-Cat lexicon and the MiniCors-Cat corpus. Secondly, we briefly describe the seven participant systems, the results obtained, and a comparative evaluation between them. All participant teams applied only pure supervised learning algorithms.", "title": "Senseval-3: The Catalan Lexical Sample Task", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W04-2008", "abstract": "This paper describes an algorithm for open text shallow semantic parsing. The algorithm relies on a frame dataset (FrameNet) and a semantic network (WordNet), to identify semantic relations between words in open text, as well as shallow semantic features associated with concepts in the text. Parsing semantic structures allows semantic units and constituents to be accessed and processed in a more meaningful way than syntactic parsing, moving the automation of understanding natural language text to a higher level.", "title": "An Algorithm for Open Text Semantic Parsing", "venue": "W", "graph_vector": [0.0169832, 0.304738, 0.0400465, 0.0949518, 0.182238, -0.704735, 0.111966, -0.490315, -1.53966, 0.292757, -0.154889, -0.505416, 1.03401, 0.14196, -0.201916, -0.143145, 0.365303, -0.27504, 0.291588, 0.489268, -0.626602, 0.0919078, 0.0540372, 0.00190229, -0.321688, 0.179166, -0.0559805, 0.0931958, 0.0206347, 0.0363841, 0.109812, -0.180538, 0.223184, -0.706386, -0.234511, 0.295753, -0.258396, 0.915758, 0.124887, 0.00574595, 0.0812961, -0.274468, -0.325721, 0.442139, 0.518623, -0.578527, -0.24902, -0.00949831, 0.101164, 0.145865, 0.183957, -0.341906, 1.01991, 0.49672, -0.163201, -0.0953448, 0.233874, 0.479931, 0.0345548, 0.0550057, -0.174911, 0.0332411, -0.0175353, 0.287488, -0.0632313, -0.064596, -0.0706106, -0.0319462, 0.285765, -0.00587513, 0.431525, -0.275926, -0.0672828, -0.0859608, 0.429497, -0.167621, -0.395302, 0.00665383, 0.202418, 0.257348, 0.148464, -0.291743, 0.0398772, 0.238173, -0.315939, -0.0304991, 0.247777, -0.10803, 0.168145, -0.130052, 0.0893919, -0.250213, -0.805166, -0.714355, -0.07755, -0.181575, -0.0210305, 0.137881, -0.0541127, -0.182982, -0.280229, -0.115604, -0.159199, 0.329815, 0.0376816, 0.00907053, -0.0219964, -0.0156833, 0.156349, -0.0321344, 0.276186, -0.271339, -0.19527, 0.00335047, 0.190084, 0.0614826, 0.228989, 0.0278491, 0.468707, -0.0327092, -0.068348, 0.0244174, 0.189521, -0.117624, 0.440417, 0.292169, 0.19788, -0.100756], "internal": 1}
{"paper_id": "W04-2307", "abstract": "In this paper, we look into extending standard dialogue move taxonomies for the genre of tutorial dialogues. We suggest a way of investigating tutorial dialogue phenomena robustly. We keep a view towards reusable general dialogue management and the easy reconfigurable genre and domain dependent phenomena.", "title": "A View on Dialogue Move Taxonomies for Tutorial Dialogues", "venue": "W", "graph_vector": [-0.177753, 0.362561, 0.561975, 0.237918, 0.246263, -1.76942, 0.623696, 0.0957491, -2.0626, 0.0746487, -0.0852769, -0.144613, 1.0905, 0.279985, -0.0104503, -0.0192287, 0.75992, 0.0109293, 0.538677, 0.63874, -0.675043, 0.998009, 0.295857, 0.101285, -0.700332, -0.123165, -0.130315, -0.063214, 0.264194, -0.103175, -0.0134484, 0.0343911, 0.29705, -0.917169, -0.262708, 0.0635013, -0.625262, 1.22706, -0.12449, -0.0875188, -0.384086, 0.160189, -0.0704317, 0.273405, 1.39838, -1.06703, -0.379847, 0.248605, 0.119816, -0.0139754, 0.447545, 0.121791, 1.22286, 0.867638, -0.34567, 0.215163, 0.286176, 0.245452, -0.0797294, -0.404846, 0.108414, -0.395699, -0.266677, 0.258258, -0.173322, 0.0456591, -0.46098, 0.474158, -0.17389, 0.105912, 0.0003072, 0.0496734, 0.265974, -0.475333, 0.539016, -0.294338, -0.359434, -0.403277, -0.645145, 0.689044, -0.370781, 0.263595, -0.0805448, -0.329993, 0.0120074, -0.304281, 0.0263246, -0.493935, 0.0118054, 0.136327, 0.365861, 0.0691698, -0.599676, -0.29849, 0.191573, 0.473001, 0.00670278, 0.0634063, 0.213916, -0.0711132, -0.0197962, -0.66492, -0.133898, 0.454116, 0.248277, 0.241221, -0.00555948, -0.211851, 0.148591, 0.230709, -0.0569912, -0.427679, -0.38666, -0.265521, -0.097469, 0.034038, 0.671514, 0.1778, -0.239081, 0.154007, 0.00469346, 0.157057, -0.133926, 0.106662, 0.406003, 0.297779, 0.446782, -0.235418], "internal": 1}
{"paper_id": "W04-0855", "abstract": "It is known that whenever a system’s actions depend on the meaning of the text being processed, disambiguation is beneficial or even necessary. The contest Senseval is an international frame where the research in this important field is validated in an hierarchical manner. In this paper we present our system participating for the first time at Senseval 3 contest on WSD, contest developed in March-April 2004. We present also our intentions on improving our system, intentions occurred from the study of results.", "title": "", "venue": "W", "graph_vector": [0.345297, 0.43584, 0.144883, 0.378759, 0.821601, -0.883214, 0.158653, 0.131243, -1.6082, 0.513469, -0.103557, 0.00338162, 0.877884, 0.163446, 0.464342, -0.138364, 0.537423, -0.903927, 0.216263, 0.689101, -0.683605, 0.614154, 0.198198, 0.193142, 0.250049, 0.451031, -0.0962829, 0.523383, -0.349403, -0.245382, 0.113841, -0.0108589, -0.365731, -0.262716, -0.237945, 0.0414848, -0.223273, 1.12232, -0.374539, -0.0511275, -0.427095, 0.0302562, -0.334722, 0.331612, 0.845794, -0.828478, -0.232519, -0.111945, 0.156506, -0.10816, -0.0139495, -0.259488, 0.60541, 0.233985, -0.180304, -0.180048, -0.423451, -0.140153, 0.038043, -0.0357908, 0.299723, 0.0968596, 0.0915352, 0.15851, 0.0199555, -0.417777, 0.664302, -0.0335181, -0.0825045, -0.317505, 0.0730683, 0.119761, 0.382478, -0.377598, 0.278425, -0.07672, -0.537457, -0.543339, 0.0843274, 0.470478, 0.119098, 0.293478, 0.423894, -0.0123898, 0.216573, -0.371182, -0.257877, 0.0883128, 0.292134, -0.250214, -0.0467135, 0.0502117, -0.906399, -0.417314, -0.0967563, 0.130734, -0.156184, -0.10656, -0.27186, 0.305734, -0.148313, -0.361106, 0.0571819, -0.0168861, -0.0776115, 0.176343, 0.0930894, -0.420725, 0.17358, -0.0253743, -0.178228, 0.0780673, 0.0332154, 0.194459, -0.0271336, -0.0898757, -0.173286, 0.336653, 0.121409, -0.0601252, 0.0293921, -0.0397684, -0.466205, -0.0859211, 0.222118, 0.992706, 0.233638, 0.0677033], "internal": 1}
{"paper_id": "W91-0220", "abstract": "Explaining how the meaning of words relate to the meaning of the utterance in which they are used is of utmost importance. The most common approaches view the meaning of an utterance as a composition of the meanings of it parts, which of course include the words used to construct the utterance. This approach is successful for entailments. However, similar approaches to explain the presuppositional behaviour of utterances have for the most part failed. In this paper we describe the application of Default Logic to the representation and the generation of natural language presuppositions. The view is taken that the presuppositions of an utterance are conjectures made by the hearer based upon the assumption that the speaker is following Grice's maxims of cooperative conversation. These conjectures represent information implicitly contained in the utterance which cannot be generated by classical techniques. The compositional framework is maintained. The difference is that functional units rather than predetermined semantic units are inherited by the meaning structure. The function's meaning changes depending on the contents of the meaning structure. Hence, we view the study of these functional units as lexical pragmatics rather than lexical semantics. Default Logic is one formal method for performing default reasoning in the area of Artificial Intelligence called Knowledge Representation. Default reasoning attempts to fill with conjectures the gaps left by classical forms of reasoning. We suggest that the use of non-classical inferencing techniques such as default reasoning will prove fruitful in the realm of lexical reasoning.", "title": "Presuppositions and Default Reasoning: A Study in Lexical Pragmatics", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W02-1607", "abstract": "The most difficult task in machine translation is the elimination of ambiguity in human languages. A certain word in English as well as Vietnamese often has different meanings which depend on their syntactical position in the sentence and the actual context. In order to solve this ambiguation, formerly, people used to resort to many hand-coded rules. Nevertheless, manually building these rules is a time-consuming and exhausting task. So, we suggest an automatic method to solve the above-mentioned problem by using semantically tagged corpus. In this paper, we mainly present building a semantically tagged bilingual corpus to word sense disambiguation (WSD) in English texts. To assign semantic tags, we have taken advantage of bilingual texts via word alignments with semantic class names of LLOCE (Longman Lexicon of Contemporary English). So far, we have built 5,000,000-word bilingual corpus in which 1,000,000 words have been semantically annotated with the accuracy of 70%. We have evaluated our result of semantic tagging by comparing with SEMCOR on SUSANNE part of our corpus. This semantically annotated corpus will be used to extract disambiguation rules automatically by TBL (Transformationbased Learning) method. These rules will be manually revised before being applied to the WSD module in the English-to-Vietnamese Translation (EVT) system.", "title": "Building a training corpus for word sense disambiguation in English-to-Vietnamese Machine Translation", "venue": "W", "graph_vector": [-0.266877, 0.211118, 0.0352743, 0.0676012, 0.528316, -0.464044, 0.520139, -0.24082, -1.6502, 0.321119, -0.460657, -0.200682, 0.562995, -0.0729518, -0.251066, 0.0726649, 0.11377, -0.483655, 0.657353, 0.0953241, 0.0685205, 0.478756, 0.188982, -0.399497, -0.478718, 0.34428, -0.262523, 0.134323, -0.0370802, 0.116162, 0.0827813, -0.046232, 0.220408, -0.636025, -0.506384, 0.309548, -0.496789, 0.42897, 0.11927, -0.0829617, 0.247026, -0.124195, -0.322948, 0.137233, 1.17746, -0.895366, 0.265794, 0.478363, -0.135882, -0.0684001, 0.603162, 0.259856, 0.73356, 1.12129, 0.020759, -0.0375115, 0.377829, 0.0914148, 0.337273, -0.313894, -0.424563, -0.482901, 0.274208, -0.376633, 0.229902, -0.163498, 0.138885, 0.315365, -0.234529, 0.764195, -0.00494938, 0.125541, 0.244397, 0.217043, -0.293251, 0.0642443, -0.284454, -0.263038, 0.0615735, 0.276507, -0.484253, -0.159615, 0.0847338, -0.346016, 0.592534, -0.440755, -0.291416, -0.0657768, 0.0312543, -0.756517, -0.212688, -0.437512, -0.252204, -0.396917, 0.152199, -0.192068, -0.0355547, -0.0787225, -0.20997, -0.208989, -0.22442, 0.0185947, -0.317251, 0.436819, -0.0639693, 0.354196, 0.143933, -0.384388, 0.125198, -0.368757, 0.063719, 0.256207, 0.210546, 0.0214212, -0.210247, -0.123558, 0.547652, -0.0299028, -0.0950759, 0.110462, -0.395589, 0.379299, 0.428635, 0.209721, 0.219676, 0.428013, -0.338843, 0.138042], "internal": 1}
{"paper_id": "W02-1011", "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.", "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques", "venue": "W", "graph_vector": [0.134298, 0.0202945, 0.143098, 0.40466, 0.304471, -0.83738, 0.0288427, 0.179238, -1.41758, 0.0316604, -0.342251, -0.219746, 0.630233, -0.142315, -0.0635871, 0.0907712, 0.250243, -0.450357, 0.0920853, 0.190907, 0.0489243, 0.452763, 0.215978, 0.0549142, -0.113462, 0.491401, 0.0785612, 0.0575141, -0.195444, -0.111091, -0.0457674, 0.233029, 0.170739, -0.443883, -0.092402, 0.257528, -0.357796, 0.651425, 0.228013, -0.105566, 0.0569325, -0.412541, -0.358179, 0.442069, 0.829751, -0.851906, -0.0364785, -0.132876, 0.134097, -0.0530024, 0.133368, -0.316, 0.757011, 0.611513, 0.0856536, -0.110527, 0.244285, 0.0217777, -0.0251109, 0.155411, 0.0193263, -0.0691036, -0.122468, -0.080026, -0.0574411, 0.0344702, 0.287609, -0.0644891, 0.325329, 0.0853877, -0.156695, 0.105889, 0.110603, -0.0961511, -0.316569, -0.363095, -0.294521, -0.248702, -0.195093, 0.0686147, -0.235644, 0.0671227, 0.25599, -0.120004, -0.00508611, -0.185762, 0.263093, -0.00827513, -0.203192, 0.00962343, -0.176252, 0.0349343, -0.784191, 0.013696, -0.106812, -0.25704, 0.272265, -0.0459596, -0.00753833, 0.100032, -0.215597, -0.255846, 0.0868169, 0.00805685, 0.141233, -0.0246465, -0.229548, -0.0206462, 0.138321, -0.310058, -0.0449786, 0.227845, 0.0253322, 0.252078, 0.0482017, -0.0857397, 0.331695, -0.276338, 0.262349, -0.058001, -0.206129, -0.215472, -0.0242007, 0.189876, 0.259507, 0.272208, 0.136524, -0.0174243], "internal": 1}
{"paper_id": "W02-2007", "abstract": "This paper investigates the use of a language independent model for named entity recognition based on iterative learning in a co-training fashion, using word-internal and contextual information as independent evidence sources. Its bootstrapping process begins with only seed entities and seed contexts extracted from the provided annotated corpus. F-measure exceeds 77 in Spanish and 72 in Dutch.", "title": "Language Independent NER using a Unified Model of Internal and Contextual Evidence", "venue": "W", "graph_vector": [0.0472109, -0.0777215, 0.127654, -0.0069388, 0.597244, -0.733424, 0.00576607, 0.178102, -1.43712, 0.304558, 0.0233256, -0.45551, 0.247627, -0.229696, -0.393321, -0.252772, 0.463476, -0.631975, 0.603685, 0.347875, -0.399338, 0.913358, 0.333382, 0.182036, -0.318534, 0.350125, 0.0967882, 0.275736, -0.0363189, -0.222777, 0.237558, -0.00875387, 0.155169, -0.0894964, 0.0532473, -0.156196, -0.0853048, 0.957922, 0.180634, -0.0732495, -0.206379, -0.661876, 0.0818905, 0.490088, 1.46182, -0.48514, 0.322472, -0.0917358, -0.096358, -0.144169, 0.402703, -0.0379909, 0.753608, 0.839381, -0.575974, 0.248164, 0.148578, -0.062337, 0.0394727, 0.0937234, -0.341129, -0.160341, 0.11799, -0.101039, -0.384993, -0.0996461, 0.346344, -0.18973, 0.00234605, 0.456499, 0.357966, 0.199671, -0.336289, -0.477432, 0.483402, 0.193552, -0.191089, -0.38375, 0.187276, 0.119376, -0.219276, 0.043275, 0.00637553, -0.0322566, 0.0325565, 0.337406, -0.516427, 0.0245428, 0.129172, -0.0266423, 0.391599, 0.100041, -0.469936, 0.308085, -0.289708, -0.255475, 0.0240628, -0.299192, -0.0370877, 0.0111918, -0.139542, -0.281155, -0.0340073, -0.190641, 0.00942672, -0.0281137, 0.0512928, 0.116135, 0.288009, -0.35872, -0.355819, -0.176625, -0.461545, -0.359724, -0.09858, -0.191854, 0.34321, 0.393166, 0.0179451, 0.278577, -0.196869, -0.106338, -0.240895, -0.0344751, 0.528437, 0.316856, -0.0788102, 0.189902], "internal": 1}
{"paper_id": "W02-2006", "abstract": "This paper presents a method for bootstrapping a fine-grained, broad-coverage part-of-speech (POS) tagger in a new language using only one personday of data acquisition effort. It requires only three resources, which are currently readily available in 60-100 world languages: (1) an online or hard-copy pocket-sized bilingual dictionary, (2) a basic library reference grammar, and (3) access to an existing monolingual text corpus in the language. The algorithm begins by inducing initial lexical POS distributions from English translations in a bilingual dictionary without POS tags. It handles irregular, regular and semi-regular morphology through a robust generative model using weighted Levenshtein alignments. Unsupervised induction of grammatical gender is performed via global modeling of contextwindow feature agreement. Using a combination of these and other evidence sources, interactive training of context and lexical prior models are accomplished for fine-grained POS tag spaces. Experiments show high accuracy, fine-grained tag resolution with minimal new human effort.", "title": "Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day", "venue": "W", "graph_vector": [0.0775278, 0.0946752, 0.0636476, 0.186139, 0.606213, -0.863595, -0.310506, -0.229577, -1.44938, 0.458726, 0.290648, -0.0352551, 0.682693, 0.0740084, -0.137148, -0.244464, 0.391662, -0.752693, 0.328522, 0.682623, -0.0664208, 0.968082, 0.178605, 0.336014, -0.307466, -0.0652777, -0.357548, 0.184608, 0.0813148, -0.350364, 0.0492516, 0.222079, 0.134641, -0.200276, -0.545109, 0.216394, 0.0344249, 0.48754, 0.0409459, -0.061672, -0.126707, -0.602522, -0.1849, 0.545904, 1.0043, -0.698695, -0.0228646, 0.030736, 0.0128438, 0.113142, 0.596949, -0.361888, 0.580939, 0.42023, -0.255407, 0.249426, 0.00390554, -0.203876, -0.115236, -0.0502554, -0.29139, -0.251046, -0.0579601, -0.30363, -0.104513, -0.142758, 0.136084, -0.176586, -0.179165, -0.0859177, 0.374962, 0.0951044, 0.230273, 0.0265178, 0.348386, -0.171837, -0.416504, -0.554693, 0.226306, -0.157525, 0.308787, 0.0801719, -0.0261025, 0.321791, 0.332539, 0.302867, -0.0603871, -0.0731702, -0.150742, -0.250875, 0.276453, -0.359134, -0.496971, -0.331899, -0.450196, -0.154756, 0.0241945, -0.18824, -0.00555826, 0.00767585, -0.339519, -0.241989, -0.208501, -0.0796964, 0.156144, -0.0986555, 0.0418664, 0.0100484, -0.0639899, -0.263573, -0.281887, 0.133435, -0.331241, -0.177609, -0.0164313, 0.11124, 0.525464, 0.123692, -0.142914, 0.237103, 0.117, -0.206384, -0.347756, 0.272262, 0.635452, 0.436007, -0.0679802, -0.268653], "internal": 1}
{"paper_id": "W02-2035", "abstract": "This paper presents a system that applies boosting to the task of named-entity identification. The CoNLL-2002 shared task, for which the system is designed, is language-independent named-entity recognition. Using a set of features which are easily obtainable for almost any language, the presented system uses boosting to combine a set of weak classifiers into a final system that performs significantly better than that of an off-the-shelf maximum entropy classifier.", "title": "", "venue": "W", "graph_vector": [-0.288447, -0.363706, -0.36919, 0.314817, 0.201141, -0.6383, -0.11447, -0.157201, -1.45649, 0.386151, -0.0814266, -0.303562, 0.495104, -0.184501, -0.219517, -0.223016, 0.461896, -0.439439, 0.692792, 0.337212, -0.0493472, 0.882949, 0.282489, 0.142231, -0.542222, 0.615158, -0.208811, -0.0217171, -0.127725, -0.381513, 0.0645843, 0.192463, 0.369568, -0.329746, -0.0104497, -0.15616, 0.24238, 1.25443, 0.0670691, -0.231648, -0.0124774, -0.518509, 0.0229077, 0.433132, 1.01109, -0.525733, 0.177604, 0.0788386, 0.197291, 0.425895, 0.421854, -0.28875, 0.883658, 0.600361, -0.283296, 0.344729, 0.199098, 0.440335, -0.144779, 0.00724475, -0.193914, 0.0143272, 0.059385, 0.0382857, -0.414908, 0.0926423, 0.541656, -0.000763989, 0.000819991, -0.0243102, 0.570174, 0.588522, 0.107438, -0.214681, 0.387727, 0.285684, -0.662251, -0.819258, 0.335373, 0.067036, -0.137223, 0.276339, -0.0286721, 0.17391, -0.0940845, 0.193526, -0.488615, 0.0936271, 0.165588, -0.391338, -0.117285, 0.0163662, -0.314218, 0.20462, -0.147391, -0.0394695, 0.0129275, -0.303903, -0.230813, 0.00825002, -0.0644093, -0.284898, -0.128248, 0.240846, 0.143151, 0.0360446, -0.0771344, 0.16523, 0.206235, -0.0857599, -0.0794014, -0.103913, -0.405866, -0.149818, -0.0220511, -0.109751, 0.28733, -0.176262, 0.0416353, 0.0743984, -0.321373, -0.133872, -0.295627, 0.381584, 0.476648, 0.449871, 0.0717089, 0.318279], "internal": 1}
{"paper_id": "W06-0121", "abstract": "This paper presents the Chinese word segmentation systems developed by Speech and Hearing Research Group of National Laboratory on Machine Perception (NLMP) at Peking University, which were evaluated in the third International Chinese Word Segmentation Bakeoff held by SIGHAN. The Chinese character-based maximum entropy model, which switches the word segmentation task to a classification task, is adopted in system developing. To integrate more linguistics information, an n-gram language model as well as several post processing strategies are also employed. Both the closed and open tracks regarding to all four corpora MSRA, UPUC, CITYU, CKIP are involved in our systems’ evaluation, and good performance are achieved. Especially, in the closed track on MSRA, our system ranks 1st.", "title": "Chinese Word Segmentation with Maximum Entropy and N-gram Language Model", "venue": "W", "graph_vector": [-0.0742229, 0.279024, -0.078159, 0.488573, 0.610787, -1.00547, -0.0510717, -0.0951405, -1.52537, 0.10743, -0.0739163, -0.481852, 0.523936, 0.330066, -0.0883006, -0.359131, 0.607621, -0.911898, -0.0882412, 0.683888, -0.111491, 0.662963, 0.302669, -0.0129775, -0.0454186, 0.0982367, 0.0921076, -0.0756067, -0.123671, -0.416524, -0.11324, 0.0358134, 0.49466, -0.525791, -0.314282, 0.156142, -0.236041, 0.661521, 0.25538, -0.208918, 0.259349, -0.290137, -0.00218345, 0.278873, 0.996557, -0.5709, -0.157236, -0.0630867, -0.212322, 0.185021, 0.206835, -0.356384, 0.814566, 0.812147, -0.534825, -0.0689937, 0.395788, 0.27762, -0.0349979, 0.268578, -0.421548, 0.0874208, 0.179353, -0.13467, -0.353451, -0.0744812, 0.147958, -0.0645153, -0.305193, -0.0724363, 0.0891682, 0.227272, 0.246977, -0.159979, 0.136317, -0.332449, -0.45666, -0.138707, -0.227701, -0.0728221, -0.232406, 0.295571, 0.507354, 0.0292501, 0.201492, -0.399915, 0.0693281, -0.0195836, -0.0638861, -0.23812, 0.301438, 0.449201, -0.673254, -0.187204, 0.27117, -0.0841551, -0.116036, -0.100397, 0.095532, -0.0679795, 0.0403567, -0.312077, 0.0447205, 0.0461905, -0.0976826, 0.20235, 0.113485, -0.0131801, 0.311572, -0.272411, -0.0790383, -0.190904, -0.344969, 0.0329901, 0.218128, -0.121574, 0.237639, 0.047856, 0.0508714, 0.421484, -0.0341947, -0.0361135, 0.0207765, -0.024339, 0.21777, 0.373363, -0.107636, -0.0731319], "internal": 1}
{"paper_id": "W06-3903", "abstract": "This paper discusses a planner of the semantics of utterances, whose essential design is an epistemic theorem prover. The planner was designed for the purpose of planning communicative actions, whose effects are famously unknowable and unobservable by the doer/speaker, and depend on the beliefs of and inferences made by the recipient/hearer. The fully implemented model can achieve goals that do not match action effects, but that are rather entailed by them, which it does by reasoning about how to act: state-space planning is interwoven with theorem proving in such a way that a theorem prover uses the effects of actions as hypotheses. The planner is able to model problematic conversational situations, including felicitous and infelicitous instances of bluffing, lying, sarcasm, and stating the obvious.1", "title": "How to change a person’s mind: Understanding the difference between the effects and consequences of speech acts", "venue": "W", "graph_vector": [-0.14856, 0.175841, 0.218052, 0.255236, 0.437378, -0.762813, 0.397351, -0.0834648, -1.91934, 0.0214487, 0.0161289, -0.40036, 0.716806, 0.71207, -0.741266, 0.0443691, 0.518153, -0.726584, 0.176397, 0.233217, -0.365637, 0.543667, -0.264533, 0.101496, -0.453657, -0.000155202, 0.111722, -0.217239, -0.180679, -0.493231, -0.347006, -0.0869782, -0.509002, -0.884404, -0.809558, 0.639971, -0.323436, 1.15121, 0.428319, -0.228131, -0.0653156, 0.105557, -0.141852, -0.0895725, 1.03385, -0.391768, -0.120467, 0.0107517, 0.131956, 0.0555779, 0.0178367, -0.415474, 0.724937, 0.493572, -0.0721531, -0.160968, -0.143018, -0.0048101, -0.031109, -0.184235, -0.297559, -0.328743, -0.0205997, 0.209312, -0.327246, 0.0603225, 0.306428, -0.312239, 0.341064, 0.174752, 0.115834, -0.1184, -0.00602965, 0.1223, -0.325888, -0.159807, -0.187577, -0.577541, 0.0073377, 0.133292, 0.0628809, -0.123427, -0.000696663, -0.275983, -0.158298, -0.258149, -0.416896, 0.0773151, 0.316711, -0.0146904, -0.0972217, -0.121718, -0.693937, -0.339378, -0.301351, 0.589325, 0.257324, 0.115259, -0.141844, -0.297264, -0.474577, -0.364938, -0.314304, 0.00484238, -0.0377166, 0.158288, 0.173051, 0.258235, 0.347142, -0.403654, 0.110534, -0.0207231, -0.531673, -0.0632979, 0.343831, -0.112937, 0.0965441, 0.437356, -0.177236, -0.153527, -0.147096, 0.02213, 0.0829853, -0.347613, 0.50357, 0.515502, 0.0607397, -0.163014], "internal": 1}
{"paper_id": "W06-2702", "abstract": "Publishers of biomedical journals increasingly use XML as the underlying document format. We present a modular text-processing pipeline that inserts XML markup into such documents in every processing step, leading to multi-dimensional markup. The markup introduced is used to identify and disambiguate named entities of several semantic types (protein/gene, Gene Ontology terms, drugs and species) and to communicate data from one module to the next. Each module independently adds, changes or removes markup, which allows for modularization and a flexible setup of the processing pipeline. We also describe how the cascaded approach is embedded in a large-scale XML-based application (EBIMed) used for on-line access to biomedical literature. We discuss the lessons learnt so far, as well as the open problems that need to be resolved. In particular, we argue that the pragmatic and tailored solutions allow for reduction in the need for overlapping annotations — although not completely without cost.", "title": "Annotation and Disambiguation of Semantic Types in Biomedical Text: a Cascaded Approach to Named Entity Recognition", "venue": "W", "graph_vector": [0.0787951, 0.353896, 0.715932, 0.175625, 0.586926, -0.880536, -0.0039537, 0.137191, -1.84097, 0.674772, -0.05965, 0.0661262, 0.830288, -0.00148139, 0.218018, -0.639032, 0.592025, -0.58024, 0.0728287, 0.259121, -0.0636944, 0.593558, 0.130023, 0.550183, -0.493422, 0.449343, -0.036768, -0.26106, 0.00484966, -0.297107, 0.230502, 0.0856615, -0.0589973, -0.443039, -0.274382, -0.441076, -0.113397, 0.562062, 0.666147, -0.106597, -0.0628622, -0.860763, -0.282056, 0.127994, 0.834908, -0.855433, 0.406143, -0.150634, 0.0152718, 0.287566, 0.131361, 0.0976624, 1.26554, 0.595985, -0.386952, 0.247679, 0.265144, -0.236931, 0.00124451, -0.302146, -0.217404, 0.0196642, 0.278134, -0.00665273, 0.164543, -0.605803, 0.274477, 0.203036, -0.253418, 0.149727, 0.114282, 0.279389, -0.261301, 0.0557591, 0.104659, -0.0440655, -0.577706, -0.485404, -0.122831, -0.319709, -0.0983458, -0.161631, -0.120083, 0.401295, 0.523982, -0.0430586, 0.205888, -0.169074, -0.12113, -0.104123, -0.0677915, 0.234248, -0.737732, -0.0797858, 0.0318909, 0.141007, -0.0381083, -0.354037, -0.559728, 0.202467, -0.407595, -0.299501, 0.219107, -0.132934, -0.242525, 0.0515583, -0.0415492, 0.0294901, 0.116314, -0.34173, -0.0431264, 0.139903, -0.347909, 0.139121, -0.199151, -0.144511, 0.572023, 0.173787, -0.192423, 0.209989, 0.126493, 0.0815625, -0.242859, -0.371848, 0.61623, -0.0934476, -0.102164, -0.0906419], "internal": 1}
{"paper_id": "W06-1306", "abstract": "In this paper we present an approach to dialogue management that supports the generation of multifunctional utterances. It is based on the multidimensional dialogue act taxonomy and associated context model as developed in Dynamic Interpretation Theory (DIT). The multidimensional organisation of the taxonomy reflects that there are various aspects that dialogue participants have to deal with simultaneously during a dialogue. Besides performing some underlying task, a participant also has to pay attention to various aspects of the communication process itself, including social conventions. Therefore, a multi-agent approach is proposed, in which for each of the dimensions in the taxonomy a specialised dialogue act agent is designed, dedicated to the generation of dialogue acts from that particular dimension. These dialogue act agents operate in parallel on the information state of the system. For a simplified version of the taxonomy, a dialogue manager has been implemented and integrated into an interactive QA system.", "title": "Multidimensional Dialogue Management", "venue": "W", "graph_vector": [-0.0340524, 0.585501, -0.090364, 0.322938, 0.601643, -1.29414, 0.502627, -0.157286, -1.69501, 0.421474, -0.206812, -0.439029, 0.936177, -0.115997, -0.199641, -0.263597, 0.3737, -0.852375, 0.543168, 0.128772, -0.172179, 0.551586, 0.251468, -0.363339, -0.361985, -0.288952, -0.544378, -0.137235, -0.321009, -0.387094, -0.414841, 0.0778975, -0.52638, -0.903283, -0.51579, 0.265981, -0.503853, 0.818728, 0.115921, 0.417186, -0.311128, 0.102857, -0.283314, 0.179613, 1.23309, -0.831598, -0.0890825, -0.098491, -0.399425, 0.146913, 0.390568, -0.539243, 0.781504, 0.950299, -0.297942, -0.349144, 0.0751089, -0.0310769, -0.330677, -0.463476, -0.431022, -0.0411867, 0.0412874, 0.172129, -0.0283346, -0.0232844, -0.039614, -0.132471, 0.240581, 0.144065, 0.0365293, -0.0401762, 0.058127, -0.0157127, -0.30935, -0.171822, -0.0871, -0.488738, -0.199252, 0.410773, -0.201892, 0.127594, 0.0530121, 0.00564824, 0.0388056, -0.093899, -0.302318, -0.139992, 0.0686853, -0.161705, 0.000758885, -0.123764, -0.994753, -0.522944, -0.178587, 0.508625, 0.44689, -0.368593, 0.0964201, -0.318246, -0.421019, -0.27104, 0.0638504, -0.16672, -0.255239, 0.00825101, 0.226015, 0.0595922, -0.44462, 0.118779, -0.132644, 0.442563, -0.484138, -0.0953443, -0.217465, -0.541177, 0.428555, 0.392507, -0.00802343, 0.51764, 0.224246, -0.175353, 0.0745423, -0.0734048, 0.0190417, 0.635798, -0.0621881, -0.298017], "internal": 1}
{"paper_id": "W06-2001", "abstract": "This paper presents the automatic extension to other languages of TERSEO, a knowledge-based system for the recognition and normalization of temporal expressions originally developed for Spanish1. TERSEO was first extended to English through the automatic translation of the temporal expressions. Then, an improved porting process was applied to Italian, where the automatic translation of the temporal expressions from English and from Spanish was combined with the extraction of new expressions from an Italian annotated corpus. Experimental results demonstrate how, while still adhering to the rule-based paradigm, the development of automatic rule translation procedures allowed us to minimize the effort required for porting to new languages. Relying on such procedures, and without any manual effort or previous knowledge of the target language, TERSEO recognizes and normalizes temporal expressions in Italian with good results (72% precision and 83% recall for recognition).", "title": "Multilingual Extension of a Temporal Expression Normalizer using Annotated Corpora E. Saquete P. Martinez-Barco R. Mu˜noz", "venue": "W", "graph_vector": [0.12306, 0.456097, -0.188163, 0.505557, 0.478854, -0.601533, -0.0814462, 0.0789867, -2.00875, 0.616072, 0.0443077, -0.461205, 0.301152, 0.131706, 0.104699, -0.0588334, 0.340555, -0.664178, 0.10231, 0.684224, -0.390965, 0.92153, -0.160099, -0.301095, -0.363388, -0.339468, 0.231019, 0.239752, -0.370085, 0.0165769, 0.031966, -0.163506, 0.237668, -1.1378, 0.0312538, 0.479628, 0.369144, 0.360874, -0.288337, 0.0145828, 0.150575, -0.00293022, -0.50333, 0.368189, 1.1383, -1.05756, -0.390528, 0.559572, 0.0227776, -0.166816, 0.558371, 0.035513, 1.57356, 0.817002, -0.0822223, 0.338369, 0.193618, 0.175379, -0.150759, -0.165995, -0.882489, -0.204546, -0.1052, 0.185617, 0.306704, -0.643296, -0.0534545, -0.511777, 0.359012, 0.000951682, 0.369826, 0.176125, 0.147297, -0.0876922, -0.0512908, -0.338102, -0.448407, -0.10698, -0.66222, 0.0813253, -0.175397, 0.194496, 0.437966, -0.238945, 0.0996538, -0.237648, 0.198739, 0.0619959, 0.382178, -0.295422, 0.387799, -0.0907669, -0.844093, -0.0386579, -0.320578, 0.289324, -0.133786, 0.0475226, -0.356717, -0.201065, -0.578056, 0.0800534, 0.0434759, -0.108851, 0.173699, -0.0765453, -0.431637, -0.04994, 0.25312, -0.665842, -0.166087, -0.0119581, -0.0451299, -0.0757991, -0.123624, -0.072006, 0.296619, -0.177731, -0.0667067, -0.198226, -0.0442292, 0.105766, 0.24375, 0.0669718, 0.38097, 0.515962, -0.236575, 0.0496826], "internal": 1}
{"paper_id": "W00-1801", "abstract": "Finite-state morphology in the general tradition of the Two-Level and Xerox implementations has proved very successful in the production of robust morphological analyzer-generators, including many large-scale commercial systems. However, it has long been recognized that these implementations have serious limitations in handling non-concatenative phenomena. We describe a new technique for constructing finitestate transducers that involves reapplying the regular-expression compiler to its own output. Implemented in an algorithm called compilereplace, this technique has proved useful for handling non-concatenative phenomena; and we demonstrate it on Malay full-stem reduplication and Arabic stem interdigitation.", "title": "", "venue": "W", "graph_vector": [-0.373656, 0.351299, -0.188189, 0.514824, 0.561808, -0.753623, 0.0547913, -0.273266, -2.27507, 0.284423, 0.360451, -0.366474, 0.628404, -0.00610956, -0.123762, -0.426765, 0.430531, -0.652179, 0.624351, 0.287356, -0.487167, 0.675704, 0.125287, 0.087304, -0.260717, 0.197171, -0.104773, -0.00521549, -0.383712, -0.117487, -0.106415, 0.425378, -0.218302, -0.164062, -0.338378, 0.33312, -0.116462, 0.378084, 0.243466, -0.0533858, -0.116859, -0.299971, -0.723592, 0.556428, 1.1627, -0.44264, -0.1032, 0.187925, 0.110513, -0.00152773, 0.438548, -0.175679, 0.705512, 0.616217, -0.387537, 0.149011, 0.0390889, 0.103136, 0.0666748, 0.170873, -0.308574, 0.113089, -0.274495, -0.205345, 0.141263, 0.152833, -0.0960992, -0.138403, -0.384613, 0.521583, -0.140758, 0.0514333, -0.203085, 0.0892277, 0.127653, 0.0552789, -0.790226, -0.430788, -0.204612, 0.0390276, 0.0725474, 0.174064, 0.492148, -0.0310138, 0.246199, 0.13276, 0.00729663, -0.0695131, 0.429191, 0.0917273, 0.361623, 0.0237568, -0.572703, -0.390242, 0.112078, 0.170024, -0.206294, -0.0560062, -0.120598, 0.113613, 0.0404938, -0.176998, -0.092232, 0.142712, 0.0182026, 0.032227, -0.18881, -0.421023, 0.290156, -0.319135, -0.202582, 0.0880134, -0.162167, -0.248243, 0.476323, -0.125608, 0.156889, 0.562429, 0.153637, 0.76446, -0.46439, 0.221794, -0.0808077, 0.114451, 0.362074, 0.300612, 0.267467, 0.0264077], "internal": 1}
{"paper_id": "W97-1002", "abstract": "Information extraction systems process natural language documents and locate a specific set of relevant items. Given the recent success of empirical or corpusbased approaches in other areas of natural language processing, machine learning has the potential to significantly aid the development of these knowledge-intensive systems. This paper presents a system, RAPIER, that takes pairs of documents and filled templates and induces pattern-match rules that directly extract fillers for the slots in the template. The learning algorithm incorporates techniques from several inductive logic programming systems and learns unbounded patterns that include constraints on the words and partof-speech tags surrounding the filler. Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc. jobs. offered.", "title": "Relational Learning of Pattern-Match Rules for Information Extraction", "venue": "W", "graph_vector": [0.201339, 0.468189, -0.0501039, 0.515191, 0.202597, -0.907345, 0.513198, 0.0795751, -1.98336, 0.490455, -0.177185, -0.618543, 0.0284248, 0.326121, 0.184328, 0.0774318, 0.165028, -0.121061, 0.561063, 0.386305, 0.0198914, 0.547856, 0.120206, -0.298261, -0.0847283, 0.277086, -0.152077, 0.230028, -0.499397, -0.236383, 0.297724, -0.00123767, -0.0845928, -0.397691, 0.131671, 0.31334, -0.173017, 0.700568, 0.213886, 0.0404354, 0.289, -0.228014, -0.451324, 0.369385, 0.740458, -0.952097, -0.226018, 0.110208, 0.13854, 0.302674, 0.614072, 0.303343, 0.76985, 0.676196, -0.051353, 0.139871, -0.231842, 0.0481806, 0.28007, -0.00145655, -0.099307, -0.489348, 0.697178, -0.190051, -0.253793, 0.221801, 0.409882, -0.473897, -0.325174, 0.0817917, 0.184705, 0.202328, 0.310334, 0.246918, 0.188762, -0.181449, -0.107576, -0.55607, 0.137964, -0.0161252, 0.275822, 0.0156599, 0.204227, 0.00258686, -0.152672, 0.148868, -0.155169, -0.122734, -0.155792, 0.320885, -0.283081, 0.0721841, -0.928266, -0.137733, 0.0339382, -0.00326925, -0.0298184, -0.173216, -0.421874, 0.0804851, 0.0134826, -0.0739542, 0.386069, 0.35463, 0.232673, 0.298077, 0.00208133, 0.185327, 0.551815, 0.0383869, 0.11716, 0.0116063, 0.0688113, 0.394418, 0.132325, -0.00235284, 0.584038, 0.273002, -0.184457, 0.358238, -0.047332, 0.207318, -0.227359, 0.183568, 0.0361362, 0.124957, -0.228366, -0.108864], "internal": 1}
{"paper_id": "W05-0631", "abstract": "We describe a system for the CoNLL2005 shared task of Semantic Role Labeling. The system implements a two-layer architecture to first identify the arguments and then to label them for each predicate. The components are implemented as SVM classifiers using libSVM. Features were adapted and tuned for the system, including a reduced set for the identifier classifier. Experiments were conducted to find kernel parameters for the Radial Basis Function (RBF) kernel. An algorithm was defined to combine the results of the argument labeling classifier according to the constraints of the argument labeling problem.", "title": "Semantic Role Labeling using libSVM", "venue": "W", "graph_vector": [-0.0517934, 0.0598754, 0.0262359, 0.0709252, 0.15915, -0.615469, 0.141526, -0.417281, -1.58418, 0.173663, -0.0244109, -0.444829, 0.613321, 0.117177, 0.107424, -0.0548044, 0.642808, -0.514682, 0.0277678, 0.326371, -0.457942, 0.665758, 0.263804, 0.093209, -0.343049, 0.18622, 0.15051, -0.137749, -0.441418, -0.169319, 0.190432, 0.0418883, -0.0945647, -0.549122, 0.0149105, 0.245142, -0.27132, 0.663665, 0.0720062, 0.223829, 0.26257, -0.455232, -0.20389, 0.128166, 0.581266, -0.727478, 0.0168842, 0.150512, 0.186197, -0.0495616, 0.119548, -0.0513738, 0.624049, 0.696067, -0.141991, -0.105, 0.250441, 0.347071, -0.115914, 0.0282695, -0.332531, 0.0284884, 0.0631549, 0.000434504, -0.134759, -0.269355, -0.0469453, 0.0543652, 0.194238, -0.0689271, 0.0318787, -0.243623, -0.0250488, -0.178894, -0.028197, -0.00922909, -0.211582, -0.371358, 0.0282494, 0.0354564, 0.410296, 0.0402236, -0.0359796, -0.0220309, 0.00723138, -0.315898, 0.351697, -0.111968, 0.37968, 0.0700635, -0.116462, -0.0168538, -0.576543, -0.327591, -0.0655932, -0.0575173, -0.157398, -0.0160104, -0.131521, 0.0525883, -0.123523, -0.265918, 0.0986268, 0.1185, -0.141334, 0.0121408, -0.0195539, -0.0588259, 0.188147, -0.228572, -0.0479613, -0.140041, 0.00320986, 0.0833902, -0.0300272, 0.0660829, 0.448423, 0.0230457, 0.289298, 0.00515564, 0.0371981, 0.0282206, -0.0726062, -0.207781, 0.61908, 0.214472, 0.172818, -0.10266], "internal": 1}
{"paper_id": "W11-0411", "abstract": "Within the framework of the construction of a fact database, we defined guidelines to extract named entities, using a taxonomy based on an extension of the usual named entities definition. We thus defined new types of entities with broader coverage including substantivebased expressions. These extended named entities are hierarchical (with types and components) and compositional (with recursive type inclusion and metonymy annotation). Human annotators used these guidelines to annotate a 1.3M word broadcast news corpus in French. This article presents the definition and novelty of extended named entity annotation guidelines, the human annotation of a global corpus and of a mini reference corpus, and the evaluation of annotations through the computation of inter-annotator agreements. Finally, we discuss our approach and the computed results, and outline further work.", "title": "Proposal for an Extension of Traditional Named Entities: From Guidelines to Evaluation, an Overview", "venue": "W", "graph_vector": [-0.229089, 0.768174, 0.288519, 0.0658685, 0.899798, -0.685211, -0.341492, 0.506869, -1.46248, 0.307694, -0.168033, 0.260323, 0.330341, -0.0853946, 0.412125, 0.200428, 0.790484, -0.887767, 0.406368, 0.382521, -0.80408, 0.838048, 0.135107, 0.220182, -0.0991616, 0.0644368, -0.0938983, 0.222824, 0.0860739, 0.133037, -0.248407, -0.410731, 0.11773, -0.613291, -0.217642, -0.0592957, -0.362742, 0.602501, -0.1028, -0.297976, 0.0318008, -0.0512246, -0.27855, 0.307781, 1.25099, -0.73393, -0.0156812, 0.328073, -0.129225, 0.323494, 0.306796, -0.22301, 0.696576, 1.19276, 0.00567061, -0.0821852, 0.199637, -0.24254, 0.292723, -0.0416217, -0.524775, -0.0322977, 0.293959, -0.201119, -0.12302, -0.298064, 0.505194, -0.0148916, -0.523074, 0.334375, -0.103667, -0.170787, -0.33887, 0.138306, 0.174751, -0.0915509, -0.323332, -0.0433881, 0.02524, 0.127395, 0.0735036, 0.0808379, 0.0331831, 0.0293161, 0.15363, -0.338571, 0.00964974, -0.381179, 0.140652, 0.0595074, 0.0921174, 0.241639, -0.935943, -0.0586359, -0.382236, 0.255701, -0.49519, -0.169611, 0.297093, -0.205165, -0.250153, -0.426827, 0.0631266, 0.2472, -0.102011, -0.135447, 0.0014694, 0.194117, -0.122206, -0.216355, -0.251105, 0.272908, 0.0350227, 0.0404691, -0.39167, -0.357839, 0.622015, 0.2252, 0.194605, -0.076461, 0.317107, -0.173975, -0.0947188, -0.0393574, -0.0377187, 0.0887701, -0.122477, 0.0218043], "internal": 1}
{"paper_id": "W11-4114", "abstract": "The amount of digitized legacy documents has been rising dramatically over the last years due mainly to the increasing number of on-line digital libraries publishing this kind of documents. The vast majority of them remain waiting to be transcribed into a textual electronic format (such as ASCII or PDF) that would provide historians and other researchers new ways of indexing, consulting and querying them. In this work, the state-of-the-art Handwritten Text Recognition techniques are applied for the automatic transcription of these historical documents. We report results for several ancient documents.", "title": "Handwritten Text Recognition for Historical Documents", "venue": "W", "graph_vector": [0.0137497, 0.0322162, 0.236166, 0.47128, 0.97383, -0.84638, 0.333111, 0.290174, -1.77461, -0.180247, -0.0311907, -0.225196, 0.50205, 0.500513, -0.576876, -0.33478, 0.5578, -0.623434, 0.167026, 0.190879, -0.467091, 0.665981, 0.518911, 0.174299, -0.673613, -0.122315, -0.0844468, 0.436457, -0.432359, -0.132565, 0.179455, -0.480657, 0.216072, -0.743719, -0.332857, 0.441572, -0.314924, 1.10687, 0.156438, 0.113467, 0.000479522, -0.353996, -0.2148, 0.61725, 0.992364, -1.09061, -0.00890277, 0.0573129, -0.310387, -0.436864, 0.162992, -0.0867641, 1.11591, 0.868285, -0.280681, 0.508485, 0.556176, 0.0636191, -0.0243178, -0.0297981, -0.223827, -0.141073, -0.235789, -0.344576, -0.0977103, -0.647039, 0.198282, -0.401829, -0.0379686, 0.478019, 0.290751, 0.0855473, -0.440461, -0.0196102, 0.021804, 0.0521164, -0.606796, -0.507451, 0.177723, 0.0302322, -0.368285, 0.138737, 0.169106, -0.118654, 0.306566, -0.297973, -0.0072853, -0.45955, -0.165138, 0.233436, 0.595121, 0.163216, -0.492735, -0.236495, 0.0388323, 0.168047, 0.0109187, -0.25409, -0.0895307, -0.291837, -0.306147, -0.083723, -0.000951516, -0.0551686, 0.175644, 0.0605321, 0.027457, -0.291573, 0.292332, 0.178028, 0.0178833, 0.119847, 0.113249, 0.197412, 0.119347, -0.259448, 0.312506, 0.0924481, 0.305364, 0.118307, -0.214892, -0.0946127, -0.32554, 0.00437196, 0.344428, 0.411705, 0.36173, -0.127444], "internal": 1}
{"paper_id": "W11-4006", "abstract": "This paper discusses a system for automatic clustering of urban-legend texts. Urban legend (UL) is a short story set in the present day, believed by its tellers to be true and spreading spontaneously from person to person. A corpus of Polish UL texts was collected from message boards and blogs. Each text was manually assigned to one story type. The aim of the presented system is to reconstruct the manual grouping of texts. It turned out that automatic clustering of UL texts is feasible but it requires techniques different from the ones used for clustering e.g. news articles.", "title": "How to Distinguish a Kidney Theft from a Death Car? Experiments in Clustering Urban-Legend Texts", "venue": "W", "graph_vector": [-0.111129, -0.199844, 0.151152, 0.703687, 0.538401, -0.836105, -0.275439, -0.298927, -1.73309, 0.936097, -0.40984, -0.23325, 0.878337, -0.41733, -0.331575, 0.193033, 0.878722, -0.159203, -0.167976, 0.270653, -0.0804545, 0.639509, 0.187686, -0.103211, -1.08461, 0.142677, 0.343597, 0.529212, -0.739625, -0.475003, -0.175436, 0.03029, -0.274094, -0.568925, -0.320068, 0.115961, -0.0319973, 0.23851, -0.325524, -0.297107, 0.250399, -0.524923, -0.369662, 0.51982, 0.728265, -0.68373, 1.02636, 0.243899, -0.204434, 0.252624, 0.441561, 0.21207, 1.25905, 1.10513, -0.238421, 0.448286, 0.172679, -0.0814803, -0.0571404, 0.404343, -0.360791, -0.0164854, -0.0526212, 0.124925, -0.156971, -0.307718, -0.309307, 0.372653, 0.35749, -0.277219, -0.0912567, 0.541323, -0.0583459, 0.296746, 0.461642, -0.00929599, -0.578841, -0.456934, -0.114131, -0.292278, 0.158505, 0.271034, 0.122034, -0.24314, -0.230297, -0.8668, 0.00514294, -0.228342, -0.0811357, -0.343895, -0.344655, -0.00620529, -0.648831, -0.352824, 0.0800979, 0.332569, -0.202337, 0.171974, -0.161382, 0.0450929, -0.229933, -0.175457, -0.303151, -0.286165, -0.127046, -0.418016, 0.0591872, 0.0944859, -0.228741, 0.227256, -0.179901, 0.296849, -0.554521, 0.371943, -0.0804768, -0.565877, 0.455792, 0.107648, -0.199212, 0.460238, -0.620474, 0.0230458, -0.430102, 0.200569, 0.829819, 0.0285787, -0.0553775, -0.00969589], "internal": 1}
{"paper_id": "W11-1413", "abstract": "Learning a vocabulary word requires seeing it in multiple informative contexts. We describe a system to generate such contexts for a given word sense. Rather than attempt to do word sense disambiguation on example contexts already generated or selected from a corpus, we compile information about the word sense into the context generation process. To evaluate the sense-appropriateness of the generated contexts compared to WordNet examples, three human judges chose which word sense(s) fit each example, blind to its source and intended sense. On average, one judge rated the generated examples as sense-appropriate, compared to two judges for the WordNet examples. Although the system’s precision was only half of WordNet’s, its recall was actually higher than WordNet’s, thanks to covering many senses for which WordNet lacks examples.", "title": "Generating Example Contexts to Illustrate a Target Word Sense", "venue": "W", "graph_vector": [0.237301, 0.573003, -0.108119, -0.19977, 0.59674, -0.86288, 0.264034, -0.064019, -1.87026, 0.0902329, -0.422588, -0.200257, 0.830325, 0.108775, -0.297743, -0.0290628, 0.817703, -0.414366, -0.115627, -0.0532347, -0.319575, 0.487452, -0.315334, 0.218978, -0.144363, 0.459647, 0.182337, 0.169751, -0.155308, 0.0132225, 0.131243, -0.236925, 0.334751, -0.103857, -0.31003, 0.483876, -0.54677, 0.729729, -0.173863, 0.278485, -0.106746, -0.610215, -0.3897, -0.152984, 1.02779, -1.13025, 0.473962, -0.044633, -0.312983, -0.116998, 0.541511, -0.625395, 0.834289, 1.40119, -0.537616, 0.0854176, 0.0656964, 0.0149042, -0.663256, 0.154098, -0.0387596, -0.226048, 0.18567, 0.203599, 0.0737326, 0.176065, -0.0696426, -0.0454961, 0.0511957, 0.384962, -0.221696, -0.0602525, -0.0217462, 0.12043, 0.14388, -0.377938, -0.510235, -0.488334, 0.104962, -0.467469, -0.0558984, -0.0524775, 0.384627, -0.0223572, 0.266776, 0.139168, 0.214961, -0.269938, 0.186032, 0.0535465, -0.148484, -0.235832, -0.604377, 0.315402, -0.0975529, 0.319555, -0.26073, -0.189845, -0.051953, 0.0109935, -0.363101, -0.335677, 0.151367, 0.281271, -0.157491, 0.180224, -0.505787, -0.225091, -0.129697, -0.0510391, -0.269913, -0.112573, 0.069626, -0.0523721, -0.0788959, -0.262473, 0.441573, -0.326375, 0.225825, 0.112099, -0.348768, 0.0930746, -0.361543, 0.288768, 0.281268, 0.319589, 0.0366565, -0.0791423], "internal": 1}
{"paper_id": "W11-0703", "abstract": "Political blogs as a form of social media allow for an uniquely interactive form of political discourse. This is especially evident in focused blogs with a strong ideological identity. We investigate techniques to identify topics within the context of the community, which when discussed in a blog post evoke a discernible positive or negative collective opinion from readers who respond to posts in comments. This is done by using computational methods to assign sentiment polarity to blog comments and learning community specific models that summarize issues tackled by blogs and predict the polarity based on the topics discussed in a blog post.", "title": "What pushes their buttons? Predicting comment polarity from the content of political blog posts", "venue": "W", "graph_vector": [0.0712013, 0.270578, 0.373358, -0.124775, 0.730682, -0.824534, -0.101671, 0.124407, -1.79661, 0.0713025, -0.072413, -0.449067, 0.795131, -0.0870961, 0.220715, 0.163209, 0.416683, -0.550148, 0.0382773, -0.00621291, -0.237624, 0.765908, 0.214771, 0.0612156, -0.504839, -0.151545, 0.22303, -0.141479, -0.00341035, -0.269916, -0.164543, 0.254826, 0.169376, -0.418748, -0.071826, 0.345373, -0.470892, 0.69122, 0.157886, -0.319283, -0.19496, -0.568276, -0.628737, 0.372008, 0.76424, -1.18625, 0.120117, -0.199988, -0.0469298, 0.101745, 0.237057, -0.191963, 1.11296, 0.804132, -0.129974, 0.440516, 0.0303642, 0.0316742, 0.0959525, -0.433708, 0.0475231, -0.234445, 0.375015, -0.241887, -0.358071, 0.196483, 0.0998249, -0.0186052, -0.00392064, 0.00137966, -0.0186028, -0.237397, 0.0301452, -0.429525, 0.243068, 0.020327, -0.367088, -0.264588, 0.0677198, 0.0431952, -0.622843, -0.579475, 0.0572198, -0.191023, 0.235802, 0.222929, 0.368723, 0.0647317, -0.00020743, 0.243241, -0.270149, 0.215165, -0.607972, -0.343621, 0.0773362, 0.0634426, 0.245123, 0.0832818, 0.255522, -0.125409, -0.268218, -0.397299, -0.0640377, 0.0665997, -0.145774, -0.0113244, -0.112815, 0.122233, 0.29721, -0.324869, -0.322934, -0.02661, 0.202216, 0.207723, -0.0948161, -0.527419, 0.203084, 0.0168747, -0.0191119, 0.0336876, 0.0691171, -0.143544, -0.0907848, -0.208529, 0.614291, 0.57239, 0.029945, -0.0593756], "internal": 1}
{"paper_id": "W11-0131", "abstract": "Distributed semantic representations like Latent Semantic Analysis (Deerwester et al., 1990), probabilistic LSA (Hofmann, 2001), Latent Dirichlet Allocation (Blei et al., 2003), or relational clustering (Taskar et al., 2001) have garnered widespread interest because of their ability to quantitatively capture ‘gist’ semantic content. Two modeling assumptions underlie most of these models. First, the typical assumption is that words in the same document are an unstructured bag of words. This means that word order and syntactic structure are ignored in the resulting vectorial representations of meaning, and the only relevant relationship between words is the ‘same-document’ relationship. Second, these semantic models are not compositional in and of themselves. They require some external process to aggregate the meaning representations of words to form phrasal or sentential meaning; at best, they can jointly represent whole strings of words without the internal relationships. This paper introduces structured vectorial semantics (SVS) as a principled response to these weaknesses of vector space models. In this framework, the syntax–semantics interface is fully interactive: semantic vectors exist in syntactic context, and any composition of semantic vectors necessarily produces a hypothetical syntactic parse. Since semantic information is used in syntactic disambiguation (MacDonald et al., 1994), we would expect practical improvements in parsing accuracy by accounting for the interactive interpretation process. Others have incorporated syntactic information with vector-space semantics, challenging the bagof-words assumption. Syntax and semantics may be jointly generated with Bayesian methods (Griffiths et al., 2005); syntactic structure may be coupled to the basis elements of a semantic space (Pad´o and Lapata, 2007); clustered semantics may be used as a pre-processing step (Koo et al., 2008); or, semantics may be learned in some defined syntactic context (Lin, 1998). These techniques are interactive, but their semantic models are not syntactically compositional (Frege, 1892). SVS is a generative model of sentences that uses a variant of the last strategy to incorporate syntax at preterminal tree nodes, but is inherently compositional. Mitchell and Lapata (2008) provide a general framework for semantic vector composition:", "title": "Structured Composition of Semantic Vectors", "venue": "W", "graph_vector": [-0.268239, -0.0184266, 0.0396775, 0.303062, 0.94796, -0.82678, 0.147707, -0.0418784, -1.45613, 0.114932, -0.301022, -0.588397, 0.711178, 0.136482, 0.173178, -0.173786, 0.744188, -0.529892, 0.286483, -0.202603, -0.273783, 0.518775, 0.24884, 0.149276, -0.0762423, 0.0622551, -0.198336, 0.215572, -0.0616699, -0.0264472, -0.0264838, -0.0513057, 0.194411, -0.113889, 0.174755, 0.392884, -0.325175, 0.491657, 0.0988374, -0.220921, -0.195777, -0.268929, -0.711741, 0.0937621, 0.592165, -1.07297, -0.218807, 0.240605, -0.0693784, 0.052686, 0.555288, -0.025244, 0.746478, 0.419983, -0.232116, 0.107714, 0.335923, 0.142811, 0.125663, -0.0813855, -0.203739, -0.37737, -0.0476614, 0.0109522, -0.244797, 0.282167, 0.0254228, -0.036691, -0.1314, -0.000894081, 0.00448051, 0.172765, 0.268059, -0.326047, -0.0470149, -0.241159, -0.403263, -0.681779, 0.139118, -0.302166, -0.00537277, -0.26297, -0.0183798, -0.187823, 0.171313, -0.212706, -0.320683, -0.249347, 0.116399, -0.120383, -0.530648, 0.190949, -0.258298, -0.0944738, -0.139201, 0.134181, -0.284516, 0.44376, 0.205071, 0.00565368, 0.347564, -0.00423038, 0.10072, -0.0298401, -0.0385393, -0.0135738, -0.348033, -0.422265, -0.162108, -0.295214, -0.196383, 0.0373743, -0.0373599, 0.314525, 0.0208045, -0.291877, 0.18584, -0.0913788, 0.108095, -0.0955208, -0.194794, 0.104048, 0.00422162, -0.0885044, 0.485615, 0.409361, -0.0179021, -0.197982], "internal": 1}
{"paper_id": "W11-0146", "abstract": "The MultiModal Interface Language formalism (MMIL) has been selected as the High Level Semantic (HLS) formalism for annotating the French MEDIA dialogue corpus. This corpus is composed of human-machine dialogues in the domain of hotel reservation and tourist information. Utterances in dialogues have been previously annotated with a concept-value flat semantics for studying and evaluating spoken language understanding modules in dialogue systems. We are now interested in investigating the use of more complex representations to improve the understanding capability. The MMIL intermediate language is a high level semantic formalism that bears relevant linguistic information, from syntax up to discourse. This representation should increase the expressivity of the current annotation though at the expense of the annotation process complexity. In this paper we present our first attempt in defining the annotation guidelines for the HLS annotation of the MEDIA corpus and its effect on the annotation process itself, revealed by annotators’ disagreements due to the different levels of hierarchy and the granularity of the features defined in MMIL.", "title": "Using MMIL for the High Level Semantic Annotation of the French MEDIA Dialogue Corpus.∗", "venue": "W", "graph_vector": [-0.0110686, 0.254565, -0.00169087, 0.359136, 0.230487, -1.28008, 0.0473478, -0.0902898, -1.52037, -0.0376682, 0.0695846, 0.154123, 0.655997, 0.555825, -0.0165161, -0.0876743, 0.459449, -0.583164, 0.218512, 0.199393, -0.445163, 0.695808, 0.140728, 0.217628, -0.416841, -0.189214, -0.147872, -0.141374, -0.418357, 0.191627, 0.367467, -0.0190818, 0.141617, -0.792764, 0.0423388, 0.304559, -0.0722019, 0.823704, -0.0480197, 0.118143, 0.278053, -0.304221, -0.499412, 0.149406, 0.574429, -0.742406, 0.103784, -7.14856e-06, 0.428032, -0.365077, 0.564913, -0.24412, 0.616143, 0.781124, -0.107889, -0.222358, 0.309091, 0.242883, 0.310279, -0.0956316, -0.313428, -0.379426, 0.301305, 0.0975691, 0.109243, -0.115356, 0.170956, 0.000270232, 0.172384, -0.0532392, 0.0364589, -0.476807, 0.130235, -0.235425, 0.0808144, -0.371481, -0.608532, -0.186951, 0.0340941, 0.429214, 0.318345, -0.285387, -0.228164, 0.301871, 0.108654, -0.0835768, 0.368805, -0.472629, 0.490622, -0.25677, -0.121592, -0.0182782, -0.47647, -0.228102, -0.126001, 0.444283, 0.00520938, 0.115793, -0.134248, 0.0703927, -0.330883, -0.607903, -0.237908, -0.090009, -0.00483724, -0.239232, -0.137621, 0.141107, 0.178159, 0.114013, 0.0619807, -0.166027, -0.0759853, -0.260517, -0.260058, -0.146028, 0.344328, 0.141572, -0.111788, -0.162406, -0.023013, -0.0203965, 0.226476, -0.0597818, 0.312269, -0.0745853, -0.0566509, 0.0156083], "internal": 1}
{"paper_id": "W09-1109", "abstract": "Vector space models of word meaning typically represent the meaning of a word as a vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task.", "title": "Representing words as regions in vector space", "venue": "W", "graph_vector": [-0.0233166, 0.0808528, -0.251223, 0.268312, 0.607103, -0.490791, -0.078725, -0.255651, -1.5765, 0.42751, -0.254743, -0.510841, 0.638152, -0.0179419, 0.117753, -0.327734, 0.248981, -0.503649, 0.123768, 0.699599, -0.231763, 0.671536, -0.135404, 0.262948, -0.513291, 0.0087731, 0.104186, 0.116638, -0.1324, 0.19623, 0.175354, -0.293989, 0.0775291, -0.35024, 0.242246, -0.0187773, -0.411467, 0.509706, 0.290368, -0.409859, 0.247013, -0.285492, -0.238607, 0.386669, 0.801882, -0.761672, -0.0665817, 0.399567, -0.246139, 0.252827, 0.314791, -0.200366, 0.894286, 0.842137, 0.0627041, -0.0924639, 0.414315, 0.0421386, 0.0685817, -0.0141536, 0.0994127, -0.0819952, -0.00275747, 0.331678, -0.107414, -0.0269144, -0.0289808, 0.0287548, 0.136511, -0.077403, 0.091603, -0.186868, 0.330794, -0.481645, 0.260224, -0.154927, -0.80113, -0.353601, 0.251455, 0.18371, 0.291534, -0.111415, 0.0976824, -0.12018, 0.191784, -0.178569, -0.171931, -0.137219, 0.0171103, -0.0844976, -0.0717787, 0.0410863, -0.165904, -0.0344626, -0.256051, 0.185304, -0.0653448, -0.237289, 0.0716815, -0.624297, -0.279051, -0.395575, 0.308318, -0.0191753, 0.0850468, -0.12534, -0.176774, -0.209683, 0.0696661, -0.06954, -0.0197291, 0.0749794, -0.0816667, 0.40458, 0.0809328, -0.353545, 0.651648, 0.224073, 0.10854, 0.363294, -0.294218, 0.0777371, -0.0607362, -0.277189, 0.204822, 0.133653, 0.101601, 0.135405], "internal": 1}
{"paper_id": "W09-3212", "abstract": "The first task of statistical computational linguistics, or any other type of datadriven processing of language, is the extraction of counts and distributions of phenomena. This is much more difficult for the type of complex structured data found in treebanks and in corpora with sophisticated annotation than for tokenized texts. Recent developments in data mining, particularly in the extraction of frequent subtrees from treebanks, offer some solutions. We have applied a modified version of the TreeMiner algorithm to a small treebank and present some promising results.", "title": "Quantitative analysis of treebanks using frequent subtree mining methods", "venue": "W", "graph_vector": [0.209158, -0.0827065, 0.22219, -0.242191, 0.452701, -0.647611, 0.0313054, 0.020893, -1.95768, -0.0255278, -0.105142, -0.450971, 0.859929, 0.616693, 0.0124373, -0.0412584, 0.343625, -0.538211, 0.459261, -0.117381, -0.229112, 0.602332, 0.570411, 0.39227, -0.24405, 0.648573, 0.131367, 0.390516, -0.456891, -0.199245, 0.159315, -0.0121412, -0.135311, -0.195136, -0.0309326, 0.455887, -0.133696, 0.180556, 0.333601, -0.253138, 0.200639, -0.243524, -0.73452, 0.027224, 1.24697, -0.685451, 0.00491268, 0.321827, 0.0354124, -0.0229983, 0.327083, -0.269013, 0.983251, 0.417852, 0.090446, 0.370785, -0.168971, 0.104953, 0.127161, 0.327802, -0.094869, -0.125891, -0.146023, -0.0831586, 0.113481, -0.197234, 0.20032, -0.26103, -0.560352, 0.216146, 0.719514, 0.175766, -0.0117545, -0.425133, 0.358105, -0.239789, -0.0592956, -0.449731, -0.0351537, -0.207547, 0.235014, 0.277585, 0.539059, 0.247775, 0.801007, 0.175175, -0.0717087, 0.232055, 0.219557, 0.464358, -0.179546, 0.15062, -0.610049, -0.195986, -0.0591277, 0.406167, 0.0835269, -0.217341, -0.308497, -0.374232, -0.404614, -0.498515, -0.125437, 0.20948, -0.020189, -0.0676411, 0.391506, 0.0439716, 0.259499, 0.194459, -0.0465715, 0.370598, 0.28304, -0.136775, -0.316761, -0.0776365, 0.233286, 0.190895, -0.343687, 0.272241, -0.000418235, 0.108708, -0.424343, -0.0840877, 0.271873, 0.670387, 0.38478, 0.190831], "internal": 1}
{"paper_id": "W09-1117", "abstract": "This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses. We introduce a dependency-based context model that incorporates long-range dependencies, variable context sizes, and reordering. It provides a 16% relative improvement over the baseline approach that uses a fixed context window of adjacent words. Its Top 10 accuracy for noun translation is higher than that of a statistical translation model trained on a Spanish-English parallel corpus containing 100,000 sentence pairs. We generalize the evaluation to other word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equivalencies during translation.", "title": "Improving Translation Lexicon Induction from Monolingual Corpora via Dependency Contexts and Part-of-Speech Equivalences", "venue": "W", "graph_vector": [-0.0174219, 0.296671, -0.0651, 0.160838, 0.318889, -0.725779, 0.0801321, -0.197636, -1.50871, 0.0896633, 0.00265491, -0.229361, 0.788997, -0.180564, -0.419577, -0.0197649, 0.421038, -0.405477, 0.210167, 0.23585, -0.350124, 0.700057, 0.575943, -0.137327, -0.348924, 0.437565, 0.332517, 0.19418, -0.5036, 0.28998, -0.0796866, -0.413146, -0.219077, -0.207602, -0.256742, 0.109232, -0.268153, 0.11364, 0.291436, -0.229966, 0.0805836, -0.0699152, -0.156915, 0.662947, 0.995394, -0.990329, 0.259649, 0.113981, -0.20326, 0.222785, -0.126531, -0.129684, 0.844594, 0.303098, 0.138818, 0.0424645, 0.506264, 0.213096, -0.0113489, -0.156157, 0.0571187, 0.0263137, -0.0851913, -0.0819239, -0.0938566, -0.147537, -0.000489712, -0.00705731, -0.0311428, 0.418866, 0.157136, -0.378789, 0.0153802, -0.464838, 0.229632, -0.243831, -0.578072, -0.740042, 0.105929, 0.240967, -0.32331, 0.0838044, 0.0998126, -0.28234, -0.130392, 0.0395006, 0.0477258, 0.0727679, 0.315157, 0.370111, 0.00159587, 0.0236666, -0.364048, -0.177312, -0.000533918, -0.369878, -0.105414, -0.232578, -0.0809154, -0.108117, 0.0568418, -0.397343, -0.0754457, 0.557713, 0.251842, 0.0590365, -0.0173823, -0.11389, 0.055527, -0.0581333, -0.236884, 0.0401243, 0.0116595, 0.0613726, -0.128088, -0.0938926, 0.203165, 0.10937, -0.0473149, 0.0571836, 0.187576, -0.219116, -0.0515695, -0.00057447, 0.191649, 0.441103, -0.0220276, -0.178826], "internal": 1}
{"paper_id": "W09-3013", "abstract": "The goal of the presented project is to assign a structure of clauses to Czech sentences from the Prague Dependency Treebank (PDT) as a new layer of syntactic annotation, a layer of clause structure. The annotation is based on the concept of segments, linguistically motivated and easily automatically detectable units. The task of the annotators is to identify relations among segments, especially relations of super/subordination, coordination, apposition and parenthesis. Then they identify individual clauses forming complex sentences. In the pilot phase of the annotation, 2,699 sentences from PDT were annotated with respect to their sentence structure.", "title": "Annotation of Sentence Structure; Capturing the Relationship among Clauses in Czech Sentences", "venue": "W", "graph_vector": [-0.0640883, 0.0476291, -0.187421, 0.464358, 0.508513, -1.0815, 0.246444, 0.0144707, -1.54497, 0.12707, 0.346434, -0.99857, 0.69601, -0.0504409, -0.0937292, -0.507288, 0.309642, -0.498328, 0.167972, 0.0925603, -0.116834, 0.813682, 0.166566, 0.185728, -0.616983, 0.293776, -0.449753, 0.201585, -0.285617, 0.0210604, 0.478502, -0.0593734, 0.0729221, -0.349433, -0.00559818, 0.0815107, -0.597106, 0.850349, 0.355933, 0.431274, 0.571295, 0.0216063, -0.0841332, 0.0441179, 0.908473, -0.770782, -0.0586333, 0.389063, 0.0446925, -0.189342, 0.240709, -0.177563, 0.309118, 0.946817, 0.208556, 0.376222, 0.162384, 0.414266, -0.147812, 0.222459, -0.369775, -0.0607414, -0.151609, 0.0977602, -0.239062, -0.283778, 0.1294, -0.0261409, 0.160262, 0.562914, 0.0883573, -0.0998043, -0.195021, 0.0515923, 0.321105, -0.247578, -0.0699995, 0.19958, -0.437101, -0.403236, -0.00181998, -0.349055, 0.272218, 0.137599, 0.23438, 0.24026, 0.0635126, -0.343, -0.0139373, -0.153697, 0.0727684, -0.276823, -0.560215, -0.128454, 0.078934, -0.0591061, -0.221311, -0.012193, 0.179772, 0.168383, -0.051931, -0.301149, -0.0735428, -0.0632997, -0.0114885, -0.535017, -0.267449, -0.237575, 0.164263, -0.0869344, -0.181937, 0.2589, 0.208464, -0.0603024, -0.0139892, -0.0464525, -0.00956421, 0.145203, -0.17498, 0.378055, -0.0701653, 0.17063, -0.402893, -0.135597, 0.488267, 0.660768, 0.288459, 0.106835], "internal": 1}
{"paper_id": "W93-0233", "abstract": "", "title": "and in press. K. Sparck Jones 'What. might he in a. summary?',", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W07-0405", "abstract": "Binarization is essential for achieving polynomial time complexities in parsing and syntax-based machine translation. This paper presents a new binarization scheme, target-side binarization, and compares it with source-side and synchronous binarizations on both stringbased and tree-based systems using synchronous grammars. In particular, we demonstrate the effectiveness of targetside binarization on a large-scale tree-tostring translation system.", "title": "Binarization, Synchronous Binarization, and Target-side Binarization∗", "venue": "W", "graph_vector": [-0.00831316, 0.0756452, 0.0464084, 0.185604, 0.623647, -0.717636, 0.119036, -0.147706, -1.93566, -0.0431803, -0.123232, -0.365594, 0.396712, 0.0427184, -0.247271, -0.159937, 0.894194, -0.463308, -0.0989832, -0.0426172, -0.204585, 0.438199, 0.377397, -0.0719747, -0.236094, 0.300317, 0.040165, 0.136282, -0.37204, -0.355955, 0.0178297, 0.0366516, 0.127541, -0.199414, -0.406784, 0.463683, -0.276623, 0.547551, 0.353781, -0.341505, 0.185999, -0.400307, -0.311021, 0.461393, 0.958731, -0.498777, 0.267052, 0.317965, 0.0478255, 0.0362727, 0.230006, 0.183845, 0.685075, 0.623944, -0.213893, 0.295078, 0.178034, 0.225497, 0.242716, -0.273192, -0.301355, -0.259995, -0.274601, 0.128177, -0.529852, 0.0180133, 0.14656, 0.167315, -0.00416453, -0.0345199, -0.136203, -0.353051, 0.273074, -0.198807, 0.14701, -0.111013, -0.475062, -0.414677, -0.312476, 0.233432, -0.132294, 0.173306, 0.0881914, 0.012236, 0.14793, -0.202441, -0.0330355, -0.0331624, 0.0108065, -0.162937, 0.0837186, -0.00456823, -0.361056, -0.0716796, -0.314021, 0.0790277, -0.208991, -0.259543, -0.0585961, -0.25376, -0.519765, -0.150892, -0.0789161, 0.270369, -0.166655, 0.328222, -0.243147, -0.496021, 0.38236, -0.167047, -0.0403162, -0.0535039, -0.458249, 0.0878369, 0.15231, 0.0905371, 0.442743, 0.182884, 0.0975712, 0.0682134, 1.45763e-05, 0.000831545, -0.125107, 0.209938, 0.369251, 0.411257, 0.295343, -0.0537638], "internal": 1}
{"paper_id": "W01-0519", "abstract": "The aim of this study is a systematic evaluation and comparison of four state-of-the-art datadriven learning algorithms applied to part of speech tagging of Swedish. The algorithms included in this study are Hidden Markov Model, Maximum Entropy, Memory-Based Learning, and Transformation-Based Learning. The systems are evaluated from several aspects. Both the effects of tag set and the effects of the size of training data are examined. The accuracy is calculated as well as the error rate for known and unknown tokens. The results show differences between the approaches due to the different linguistic information built into the systems.", "title": "Comparing Data-Driven Learning Algorithms for PoS Tagging of Swedish", "venue": "W", "graph_vector": [0.0884696, 0.261601, 0.0136592, 0.128117, 0.826136, -0.801234, 0.205197, 0.0607649, -1.41353, 0.476981, -0.331721, -0.0688681, 0.655373, 0.0954242, -0.0570722, -0.671295, 0.465539, -0.150903, 0.354441, 0.587485, -0.293812, 0.48584, 0.032563, 0.171022, -0.220116, 0.221836, 0.202462, 0.403701, 0.0691911, -0.144514, -0.376612, -0.0954142, -0.0377369, -0.350727, -0.606542, 0.0376221, -0.169515, 0.529117, -0.0125721, 0.171298, 0.157325, -0.26826, 0.017393, 0.0887094, 1.10126, -0.697411, 0.20421, 0.202432, 0.198284, -0.32258, 0.259142, -0.374035, 0.804471, 0.912181, -0.199219, -0.00993983, 0.104996, 0.0115142, 0.122913, -0.245495, 0.0685201, -0.0376415, -0.146118, -0.397467, -0.4562, 0.248578, 0.244144, -0.234353, -0.157349, -0.470524, -0.216401, 0.16209, 0.175582, -0.212697, 0.593452, -0.178551, -0.558695, -0.303058, 0.14247, -0.0227254, 0.0221991, -0.0335623, -0.137785, 0.350874, 0.393432, 0.117633, 0.0439623, 0.523808, 0.0528104, -0.394117, 0.00651404, 0.270314, -0.651038, -0.0594026, 0.0353185, -0.0634027, -0.245849, 0.177861, -0.280203, -0.0413872, -0.501257, -0.469646, 0.0832477, -0.0169966, 0.316784, -0.148931, 0.0584123, 0.239962, 0.370436, -0.0533205, 0.295818, 0.211827, -0.148087, -0.111408, -0.151389, -0.315827, 0.453444, 0.177227, -0.0687859, 0.287311, -0.187416, 0.281764, -0.218775, -0.119356, 0.186996, 0.524899, -0.0160283, -0.260353], "internal": 1}
{"paper_id": "W01-1515", "abstract": "Annotation graphs provide an efficient and expressive data model for linguistic annotations of time-series data. This paper reports progress on a complete open-source software infrastructure supporting the rapid development of tools for transcribing and annotating time-series data. This generalpurpose infrastructure uses annotation graphs as the underlying model, and allows developers to quickly create special-purpose annotation tools using common components. An application programming interface, an I/O library, and graphical user interfaces are described. Our experience has shown us that it is a straightforward task to create new special-purpose annotation tools based on this general-purpose infrastructure.", "title": "Annotation Tools Based on the Annotation Graph API", "venue": "W", "graph_vector": [0.226532, 0.426725, -0.129336, -0.204056, 0.511896, -0.764019, -0.179902, 0.0162586, -1.62071, 0.342734, -0.174999, -0.0567245, 0.977118, -0.0783356, -0.212692, 0.235274, 0.194447, -0.488586, -0.19185, -0.0202094, -0.718018, 0.829322, 0.596388, 0.28998, -0.31107, -0.0650396, -0.16154, 0.0180334, 0.0318701, -0.458455, 0.138208, 0.1498, 0.063497, -0.679137, -0.363055, -0.164546, -0.2422, 0.893541, -0.0481965, -0.100444, 0.248662, -0.253648, 0.068998, 0.24056, 1.20271, -0.49243, 0.199513, -0.335, 0.28894, -0.15203, 0.672591, -0.200959, 1.29517, 0.468438, -0.200699, 0.0395621, 0.881837, 0.336492, 0.135401, 0.0512964, -0.0374182, -0.649409, -0.0725878, -0.231643, 0.36694, -0.510202, 0.0973889, -0.0918829, 0.441736, 0.579169, 0.127778, 0.0300419, -0.0393407, -0.056622, 0.143478, -0.196597, -0.465982, -0.405905, -0.734968, 0.118912, -0.117497, 0.00646967, -0.289183, 0.180292, 0.267778, -0.00192184, -0.0314445, -0.0911511, -0.194766, 0.130673, -0.249922, -0.307966, -0.819337, -0.203977, 0.00268094, 0.103348, -0.394639, -0.307724, -0.625715, -0.317374, -0.292894, -0.480232, -0.0065215, 0.118057, -0.343355, 0.336234, 0.304841, 0.0272898, 0.275476, 0.296158, -0.304753, 0.402557, 0.0385762, 0.405704, -0.0732432, -0.456795, 0.162635, -0.0113894, 0.689881, 0.391042, 0.152185, 0.0492978, 0.216066, 0.160402, 0.363271, 0.271757, -0.366578, 0.163143], "internal": 1}
{"paper_id": "W13-4027", "abstract": "While natural language as an interaction modality is increasingly being accepted by users, remaining technological challenges still hinder its widespread employment. Tools that better support the design, development and improvement of these types of applications are required. This demo presents a prototyping framework for Spoken Dialog System (SDS) design which combines existing language technology components for Automatic Speech Recognition (ASR), Dialog Management (DM), and Text-to-Speech Synthesis (TTS) with a multi-step component for Natural Language Understanding (NLU).", "title": "Multi-step Natural Language Understanding", "venue": "W", "graph_vector": [0.0234604, 0.200103, -0.083609, 0.494849, 0.475246, -0.855459, 0.0817274, -0.138334, -1.4325, 0.306487, -6.69145e-05, -0.185005, 0.497744, 0.398148, -0.169843, -0.287982, 0.534132, -0.440479, 0.333769, 0.601719, -0.123055, 0.575486, 0.0841802, -0.0372128, -0.106152, 0.163173, 0.282412, 0.0437011, -0.162812, -0.034696, 0.119418, 0.232209, -0.0101259, -0.570529, -0.365439, 0.194021, -0.289573, 0.81115, 0.336565, 0.144355, 0.252463, -0.240641, 0.00394162, 0.047502, 1.17016, -0.59765, -0.0767015, 0.051007, -0.0973261, 0.0648527, 0.34469, -0.304581, 0.609101, 0.790668, -0.258889, 0.113388, 0.325867, 0.309042, 0.171397, 0.398351, -0.124803, -0.0971434, -0.0764973, -0.104192, -0.220829, -0.0100283, -0.0666778, 0.140145, -0.169794, 0.17364, 0.114502, -0.0705585, 0.0160828, -0.228932, 0.402875, -0.250153, -0.153928, -0.201041, 0.256516, 0.113671, -0.169868, 0.0120246, 0.135306, 0.310284, 0.456769, 0.289414, -0.275362, 0.0507887, 0.253315, 0.314161, 0.222187, -0.165737, -0.831602, -0.195704, -0.229153, -0.12102, -0.267609, -0.11737, -0.252329, 0.0679941, -0.0873834, -0.446673, 0.0331754, -0.011643, 0.0599503, -0.199133, -0.0418554, 0.167587, 0.172375, -0.0646774, -0.115227, 0.131487, 0.0423741, -0.127156, -0.211666, 0.0733215, 0.203806, 0.297985, 0.138286, 0.571123, -0.372668, 0.368413, -0.121516, 0.131972, 0.253454, 0.379424, -0.0586053, -0.017195], "internal": 1}
{"paper_id": "W13-3105", "abstract": "This report provides a description of the methods applied in CIST system participating ACL MultiLing 2013. Summarization is based on sentence extraction. hLDA topic model is adopted for multilingual multi-document modeling. Various features are combined to evaluate and extract candidate summary sentences.", "title": "CIST System Report for ACL MultiLing 2013 -- Track 1: Multilingual Multi-document Summarization", "venue": "W", "graph_vector": [-0.159178, 0.350179, 0.17022, 0.216952, 0.420672, -1.08503, -0.592434, 0.00366945, -2.22702, 0.00120342, -0.205975, -0.391574, 0.628306, 0.340777, 0.32019, -0.361594, 0.504399, -0.227807, -0.112196, 0.531749, 0.167043, 0.624232, 0.467194, -0.201466, -0.326493, 0.165056, 0.206385, 0.286297, -0.0345989, 0.133375, 0.119366, -0.0651199, 0.631614, -0.353027, -0.0570822, 0.817337, -0.608492, 1.00246, 0.327972, -0.398975, -0.35978, -0.0583817, -0.495759, 0.749817, 0.936596, -1.24261, 0.0180609, 0.190451, 0.131697, 0.0952123, 0.488345, 0.140197, 1.36939, 0.864927, -0.457258, 0.328617, -0.108534, 0.125422, -0.33575, 0.177091, 0.0513129, -0.378364, -0.200979, 0.105192, -0.646601, 0.0878088, 0.200697, -0.46853, 0.536741, -0.172393, -0.146253, 0.237854, 0.241926, -0.538082, 0.542962, -0.408369, -1.00457, -0.452342, -0.17804, 0.055919, -0.207695, 0.0470601, -0.376021, 0.22487, 0.29616, -0.325397, -0.133512, -0.235174, 0.0784727, -0.0509407, -0.0305254, -0.0547269, -0.769047, -0.0597323, -0.3948, 0.272996, 0.109916, -0.203667, 0.0714347, 0.175627, -0.13048, -0.121068, -0.187686, 0.91868, 0.244582, -0.0127247, -0.466889, -0.136383, -0.233901, -0.501973, -0.395555, 0.12229, -0.0983936, 0.29204, 0.48342, 0.137891, 0.220219, 0.183681, 0.0359921, -0.0222974, -0.334539, -0.115068, -0.10648, -0.0226731, 0.428647, 0.0931815, -0.073325, -0.238893], "internal": 1}
{"paper_id": "W13-2604", "abstract": "We use a set of enriched n-gram models to track grammaticality judgements for different sorts of passive sentences in English. We construct these models by specifying scoring functions to map the log probabilities (logprobs) of an n-gram model for a test set of sentences onto scores which depend on properties of the string related to the parameters of the model. We test our models on classification tasks for different kinds of passive sentences. Our experiments indicate that our n-gram models achieve high accuracy in identifying ill-formed passives in which ill-formedness depends on local relations within the n-gram frame, but they are far less successful in detecting non-local relations that produce unacceptability in other types of passive construction. We take these results to indicate some of the strengths and the limitations of word and lexical class n-gram models as candidate representations of speakers’ grammatical knowledge.", "title": "Statistical Representation of Grammaticality Judgements: the Limits of N-Gram Models", "venue": "W", "graph_vector": [-0.284256, 0.168856, -0.384731, -0.0745669, 0.561834, -0.863584, 0.249031, -0.275387, -1.38463, 0.0105767, -0.190152, -0.34906, 0.765303, 0.121709, -0.191664, -0.38228, 0.480376, -0.752868, 0.351612, 0.149564, -0.714103, 0.908989, 0.164954, -0.0245244, -0.277333, 0.212786, 0.282629, 0.103947, -0.136121, -0.305667, 0.442309, 0.459472, 1.10137, -0.605135, -0.539274, 0.519508, -0.397704, 0.814417, -0.101084, -0.183113, -0.0119654, -0.0106582, -0.617868, 0.0806323, 1.2337, -0.813858, 0.0319508, -0.199503, 0.0976337, -0.473741, 0.0660621, -0.273984, 1.07182, 0.365315, 0.0829639, 0.48856, -0.194089, -0.0717019, -0.619432, 0.245856, -0.271074, 0.111045, -0.169046, -0.0771415, -0.270203, 0.0248165, 0.0787538, 0.000693104, -0.0244745, -0.320751, 0.261891, 0.167844, -0.138766, -0.0716005, -0.101467, -0.0979188, -0.221308, -0.456251, -0.418026, 0.0131806, -0.468988, 0.199375, 0.177432, 0.250997, 0.15302, -0.370076, -0.0796724, -0.552079, 0.403791, -0.0501462, 0.100804, 0.312998, -0.359587, -0.285268, 0.310254, 0.436002, 0.0862185, -0.193147, -0.0940699, -0.220343, -0.519101, -0.310321, 0.0755145, -0.168207, 0.0964735, 0.261243, 0.0323129, -0.451334, 0.296325, -0.526851, -0.327723, 0.442505, 0.214596, 0.570345, 0.113711, -0.0724427, -0.0392671, -0.461547, -0.100656, 0.149414, 0.158138, 0.123569, -0.152171, 0.421502, 0.558907, -0.00122068, 0.44162, 0.0417544], "internal": 1}
{"paper_id": "W13-3802", "abstract": "", "title": "The Groningen Meaning Bank", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W13-3209", "abstract": "With the increasing empirical success of distributional models of compositional semantics, it is timely to consider the types of textual logic that such models are capable of capturing. In this paper, we address shortcomings in the ability of current models to capture logical operations such as negation. As a solution we propose a tripartite formulation for a continuous vector space representation of semantics and subsequently use this representation to develop a formal compositional notion of negation within such models.", "title": "“Not not bad” is not “bad”: A distributional account of negation", "venue": "W", "graph_vector": [-0.0619454, -0.31214, 0.153688, 0.0492481, 0.542893, -0.772386, 0.179624, -0.220826, -1.55087, 0.1411, 0.0213045, -0.468412, 0.681226, -0.131411, 0.149455, 0.114188, 0.447838, -0.467074, 0.130351, 0.511814, -0.114256, 0.543932, -0.0377307, -0.162315, -0.700594, 0.118704, 0.0657761, 0.126797, -0.230535, 0.125912, -0.00534521, -0.197253, 0.119434, -0.252137, -0.10105, 0.0974974, -0.185119, 0.822579, -0.0421836, -0.0139438, -0.229996, -0.493907, -0.167646, 0.373188, 1.04825, -0.501236, 0.0921829, 0.0613467, 0.0159128, 0.27836, 0.381726, -0.245514, 0.822532, 0.362687, 0.132644, -0.0958073, 0.354772, 0.0732444, -0.10991, -0.162405, 0.128502, -0.231039, -0.192076, 0.0265023, -0.207909, 0.1892, 0.00327435, 0.219859, -0.148837, -0.0370571, 0.0439981, -0.0515147, 0.31358, -0.145075, -0.334068, -0.263461, -0.694967, -0.438574, -0.175337, 0.0419771, 0.101957, 0.223645, 0.0577756, -0.599278, 0.380666, -0.308204, -0.304619, -0.0631474, 0.0276667, -0.170889, -0.0308976, 0.179141, -0.635112, 0.0880764, -0.169087, 0.133411, -0.0114114, -0.0479689, -0.172981, -0.105184, -0.0228469, -0.376754, -0.032612, -0.0559043, -0.137308, 0.0297748, 0.165123, -0.411121, -0.0325985, -0.229724, -0.0468014, 0.0610581, -0.192665, 0.0536958, -0.050812, -0.0264882, 0.367371, 0.367428, -0.187746, 0.368342, -0.323323, 0.141168, 0.0597918, -0.164792, 0.288261, -0.214433, -0.0134118, 0.452272], "internal": 1}
{"paper_id": "W13-1011", "abstract": "This paper presents an algorithm that allows the user to issue a query pattern, collects multi-word expressions (MWEs) that match the pattern, and then ranks them in a uniform fashion. This is achieved by quantifying the strength of all possible relations between the tokens and their features in the MWEs. The algorithm collects the frequency of morphological categories of the given pattern on a unified scale in order to choose the stable categories and their values. For every part of speech, and for all of its categories, we calculate a normalized Kullback-Leibler divergence between the category’s distribution in the pattern and its distribution in the corpus overall. Categories with the largest divergence are considered to be the most significant. The particular values of the categories are sorted according to a frequency ratio. As a result, we obtain morphosyntactic profiles of a given pattern, which includes the most stable category of the pattern, and their values.", "title": "Automatic Detection of Stable Grammatical Features in N-Grams", "venue": "W", "graph_vector": [-0.0626507, 0.217393, 0.507519, 0.136729, 1.05338, -0.651575, -0.112718, -0.173041, -1.42132, 0.398778, 0.15829, -0.623265, 0.745658, 0.373572, -0.0497189, 0.118943, -0.122366, -0.771861, 0.176971, 0.378239, -0.254145, 0.598104, 0.208678, 0.201582, -0.2535, 0.20142, 0.21843, 0.253073, -0.572205, -0.143763, 0.473392, -0.00317846, -0.00225412, -0.403869, -0.103647, 0.104528, -0.17484, 0.348278, 0.0773349, -0.131117, 0.043286, -0.129177, -0.380185, 0.224202, 1.18094, -0.757914, 0.00472365, -0.232284, -0.82525, -0.220069, 0.111434, -0.446531, 0.560371, 0.578604, -0.51009, 0.632497, 0.223388, 0.226696, -0.330852, -0.0339546, -0.138058, -0.257455, 0.36364, 0.0201159, -0.0132983, -0.349258, -0.0904071, -0.0298879, -0.421196, -0.0792118, 0.371353, 0.0852313, 0.171749, -0.150964, 0.208391, -0.0626877, -0.327838, 0.082042, -0.202707, -0.0304178, 0.214018, 0.0928283, 0.210192, -0.337188, 0.281368, 0.284235, 0.198598, -0.418547, -0.22671, -0.0933395, 0.0807608, 0.0323962, -0.632426, -0.100699, -0.260263, 0.191719, 0.33695, 0.216655, -0.206995, -0.421332, -0.581217, -0.526169, -0.497415, -0.0883957, 0.290773, 0.36897, 0.063734, 0.198343, 0.353374, -0.60778, 0.124994, 0.00231303, -0.271332, -0.105371, 0.00546051, -0.254449, 0.174655, 0.0474359, 0.00850517, -0.043563, -0.31406, -0.0208132, 0.265009, -0.157814, 0.575254, 0.15239, 0.170915, 0.118411], "internal": 1}
{"paper_id": "W13-2611", "abstract": "We describe a method for learning an incremental semantic grammar from data in which utterances are paired with logical forms representing their meaning. Working in an inherently incremental framework, Dynamic Syntax, we show how words can be associated with probabilistic procedures for the incremental projection of meaning, providing a grammar which can be used directly in incremental probabilistic parsing and generation. We test this on child-directed utterances from the CHILDES corpus, and show that it results in good coverage and semantic accuracy, without requiring annotation at the word level or any independent notion of syntax.", "title": "Incremental Grammar Induction from Child-Directed Dialogue Utterances∗", "venue": "W", "graph_vector": [-0.080199, 0.229072, -0.56908, 0.0655761, 0.685407, -1.15599, 0.0314715, -0.375052, -1.83358, 0.0574849, 0.131101, -0.3167, 0.657196, 0.335579, -0.0521373, -0.352918, -0.0210179, -0.305954, -0.203212, 0.541053, -0.195363, 0.894393, 0.102303, -0.0998523, -0.356643, 0.110345, 0.163279, -0.0996851, -0.237052, -0.319002, -0.327489, 0.0244122, 0.315346, -0.644011, -0.179352, 0.145557, -0.379844, 0.71238, -0.0265949, 0.146885, -0.182898, -0.273044, -0.558854, 0.232847, 0.803819, -0.819302, -0.0132787, -0.159385, -0.0335899, -0.211214, 0.554471, -0.15468, 0.880126, 0.270465, -0.340102, -0.277093, 0.0134216, -0.10348, 0.181918, -0.150652, -0.128707, -0.284432, 0.00457259, -0.106875, -0.0170904, -0.0446314, -0.437949, 0.193605, 0.0452151, 0.164859, 0.377041, 0.348763, -0.184035, 0.166844, -0.335117, 0.0123532, -0.272994, 0.0768368, -0.0497839, 0.405304, -0.276808, 0.666071, 0.478293, -0.144266, -0.0422167, -0.0514981, 0.125943, 0.0229439, 0.429727, 0.210689, -0.409639, 0.190684, -0.47648, -0.375326, -0.149759, 0.099083, -0.0129389, -0.407621, -0.116449, -0.243091, -0.148603, -0.249202, 0.331189, 0.161939, 0.0402502, 0.241701, 0.0823895, -0.248192, 0.231171, -0.0962254, -0.304592, 0.185516, -0.130965, 0.28382, 0.129326, -0.237976, 0.0679982, -0.0390329, -0.314801, 0.390506, 0.170973, -0.114192, -0.256641, 0.195526, 0.41945, 0.145224, -0.160287, -0.0846665], "internal": 1}
{"paper_id": "W13-4073", "abstract": "While belief tracking is known to be important in allowing statistical dialog systems to manage dialogs in a highly robust manner, until recently little attention has been given to analysing the behaviour of belief tracking techniques. The Dialogue State Tracking Challenge has allowed for such an analysis, comparing multiple belief tracking approaches on a shared task. Recent success in using deep learning for speech research motivates the Deep Neural Network approach presented here. The model parameters can be learnt by directly maximising the likelihood of the training data. The paper explores some aspects of the training, and the resulting tracker is found to perform competitively, particularly on a corpus of dialogs from a system not found in the training.", "title": "Deep Neural Network Approach for the Dialog State Tracking Challenge", "venue": "W", "graph_vector": [0.196816, 0.181081, 0.0838296, 0.210937, 0.13733, -0.753735, 0.15341, -0.216732, -1.67221, 0.217529, 0.0388831, 0.038392, 0.461138, -0.230862, -0.262536, -0.305488, 0.682524, -0.503906, -0.0892832, 0.386727, -0.340042, 0.541751, 0.521323, -0.204328, -0.430425, 0.349565, 0.0274365, -0.252051, -0.440399, -0.301784, 0.00189462, -0.0156693, 0.292165, -0.815057, -0.363139, 0.180826, 0.166259, 1.57352, -0.211006, -0.255629, -0.113168, -0.386452, -0.326104, 0.721916, 1.25877, -0.886874, -0.0102835, -0.358456, 0.198439, 0.114157, 0.322625, -0.263354, 0.842616, 0.80634, 0.234134, 0.300901, -0.00439412, 0.733971, 0.124018, -0.119629, -0.061444, -0.300416, 0.080023, 0.579712, 0.131966, -0.270748, 0.36335, -0.310887, -0.0587765, 0.0515923, -0.0924785, -0.291308, 0.140835, 0.000364084, 0.57876, 0.0493035, -0.421783, -0.565159, -0.342979, -0.168915, -0.165988, 0.29463, 0.4866, -0.141011, 0.342265, -0.862397, 0.131312, 0.046745, -0.378101, 0.0814472, 0.0504735, 0.197452, -0.703633, -0.523741, -0.0327132, 0.0513288, 0.178115, -0.092137, 0.0565618, -0.296202, 0.0132124, -0.698527, 0.149249, -0.0584183, -0.0245637, -0.00756751, -0.365253, -0.0316492, 0.0782364, -0.0805584, -0.425997, -0.391549, -0.491486, -0.101801, -0.116569, 0.0794031, 0.0847144, -0.0117792, -0.336355, 0.269017, -0.128122, 0.104441, -0.312751, -0.121926, -0.0485172, 0.277107, -0.133375, -0.405639], "internal": 1}
{"paper_id": "W13-2610", "abstract": "Discourse connectives play an important role in making a text coherent and helping humans to infer relations between spans of text. Using the Penn Discourse Treebank, we investigate what information relevant to inferring discourse relations is conveyed by discourse connectives, and whether the specificity of discourse relations reflects general cognitive biases for establishing coherence. We also propose an approach to measure the effect of a discourse marker on sense identification according to the different levels of a relation sense hierarchy. This will open a way to the computational modeling of discourse processing.", "title": "On the Information Conveyed by Discourse Markers", "venue": "W", "graph_vector": [0.203458, 0.090709, -0.0544443, 0.217346, 0.546511, -0.470966, -0.170754, -0.337383, -1.78606, 0.400864, -0.286502, -0.584816, 0.214817, -0.0927213, 0.0479211, 0.0510395, 0.608656, -0.461707, 0.295222, 0.29195, -0.441944, 0.797069, -0.191657, 0.0101138, -0.0442497, 0.0826665, 0.276161, 0.079866, -0.832233, -0.379624, 0.0279686, -0.133788, 0.165426, -0.296353, -0.0998949, 0.0640222, -0.546131, 0.482047, -0.0747682, 0.131182, -0.294147, -0.174916, -0.16435, 0.668576, 1.01024, -0.986525, -0.345276, 0.0388332, -0.6497, -0.0105908, 0.570365, 0.407757, 0.871301, 0.561907, -0.0947305, 0.0635976, 0.332768, -0.179039, 0.103745, 0.339844, -0.0589886, -0.406664, -0.111703, -0.103333, -0.0527251, 0.213929, 0.228791, -0.216371, 0.29041, 0.141166, -0.10214, -0.110734, -0.0634317, -0.312491, -0.499652, -0.153544, -0.366322, -0.106315, -0.208848, 0.274416, -0.0299743, 0.0987613, -0.0470121, -0.138285, 0.0787039, -0.335564, -0.170759, 0.295935, 0.0442053, 0.16112, -0.294968, 0.267136, -0.354488, -0.0600252, 0.161366, 0.223517, -0.24519, 0.00574429, 0.159159, -0.040625, 0.0679599, -0.528365, 0.296884, -0.181324, -0.00590129, 0.186633, -0.3105, 0.0687993, 0.038988, -0.0693824, 0.0408502, 0.363846, 0.0785294, -0.355764, -0.305204, 0.172265, 0.323937, 0.218207, -0.529506, 0.295647, 0.262263, 0.00152437, -0.11012, -0.321202, 0.444978, 0.201448, 0.250718, -0.315066], "internal": 1}
{"paper_id": "W13-3728", "abstract": "In this work, we present a data-driven method to enhance syntax trees with additional dependencies as defined in the wellknown Stanford Dependencies scheme, so as to give more information about the structure of the sentence. This hybrid method utilizes both machine learning and a rule-based approach, and achieves a performance of 93.1% in F1-score, as evaluated using an existing treebank of Finnish. The resulting tool will be integrated into an existing Finnish parser and made publicly available at the address http://bionlp.utu.fi/.", "title": "Predicting conjunct propagation and other extended Stanford Dependencies", "venue": "W", "graph_vector": [-0.207816, 0.164732, 0.297425, 0.336299, 0.510575, -1.0317, -0.185131, -0.10249, -1.66745, 0.407532, 0.232391, -0.252925, 0.975515, -0.0316908, 0.128525, -0.241528, 0.590208, -0.776269, 0.0814688, 0.317995, -0.590806, 0.565548, 0.357568, -0.209158, -0.180893, 0.619915, 0.106535, -0.0863875, 0.15078, -0.0957554, -0.368653, -0.287633, -0.180596, -0.507919, -0.270014, -0.160142, -0.270606, 0.53692, 0.315082, 0.019066, 0.229412, -0.0407766, -0.14717, 0.0274396, 0.469994, -0.74246, 0.301195, -0.216778, 0.140751, 0.282644, -0.168648, -0.132483, 0.922476, 0.449215, 0.139092, 0.434173, -0.0886672, 0.374562, 0.17185, -0.434491, -0.0246654, -0.54141, 0.177842, -0.200225, -0.166265, 0.360034, 0.00924783, 0.296858, -0.130839, -0.108107, -0.154772, -0.29907, -0.400391, -0.00864812, 0.227891, -0.104766, -0.2808, -0.336169, -0.0778505, -0.389354, 0.411349, -0.0432131, 0.100572, 0.131301, -0.0270019, -0.169642, 0.282273, -0.0749785, 0.49456, 0.0669538, 0.106389, -0.023204, -0.601099, -0.162335, 0.315589, -0.0657706, 0.12495, 0.0234041, 0.151222, -0.0983128, 0.129661, -0.461214, -0.0823276, 0.118828, 0.186019, -0.128458, -0.13999, 0.0707499, 0.242668, -0.211594, 0.205561, -0.168414, -0.116258, 0.391485, 0.39113, -0.0276791, 0.262175, 0.120347, 0.074768, -0.0873055, 0.0635995, -0.2797, -0.141134, 0.264346, 0.631351, 0.200278, -0.00756922, 0.175838], "internal": 1}
{"paper_id": "W13-3517", "abstract": "Coreference resolution systems can benefit greatly from inclusion of global context, and a number of recent approaches have demonstrated improvements when precomputing an alignment to external knowledge sources. However, since alignment itself is a challenging task and is often noisy, existing systems either align conservatively, resulting in very few links, or combine the attributes of multiple candidates, leading to a conflation of entities. Our approach instead performs joint inference between within-document coreference and entity linking, maintaining ranked lists of candidate entities that are dynamically merged and reranked during inference. Further, we incorporate a large set of surface string variations for each entity by using anchor texts from the web that link to the entity. These forms of global context enables our system to improve classifier-based coreference by 1.09 B3 F1 points, and improve over the previous state-of-art by 0.41 points, thus introducing a new state-of-art result on the ACE 2004 data.", "title": "Dynamic Knowledge-Base Alignment for Coreference Resolution", "venue": "W", "graph_vector": [0.177477, 0.216794, 0.0272515, 0.590469, 0.500131, -0.433551, 0.0840508, 0.208527, -1.56291, 0.573507, 0.171051, -0.188004, 0.601222, 0.54861, 0.218589, 0.236288, 0.518181, -0.660982, -0.151954, 0.177447, -0.723006, 0.682077, 0.0223341, 0.012797, -0.206804, 0.223007, 0.163686, 0.235721, -0.00582039, -0.0105155, 0.189746, -0.123434, 0.120453, -0.519701, -0.248979, 0.086181, -0.221141, 0.727331, 0.184439, -0.149047, 0.172747, -0.488063, -0.262375, 0.410297, 0.831363, -0.740476, 0.250822, 0.216288, 0.0200249, -0.217331, 0.411186, 0.0215024, 0.836158, 0.881611, 0.00524599, 0.0137838, -0.293375, -0.139236, -0.0690125, 0.0715782, -0.0428999, -0.0853423, -0.0236921, -0.0900861, -0.0925946, -0.0193447, 0.328306, -0.0261716, -0.159814, 0.201004, 0.360214, 0.136698, -0.132834, -0.311186, 0.0181492, -0.392854, -0.253856, 0.160193, 0.0166569, -0.025358, 0.337453, -0.102648, 0.0240497, -0.34975, 0.0358421, -0.595793, -0.0438958, -0.27875, 0.0531148, 0.0293772, 0.119359, 0.117172, -0.609047, -0.0329745, -0.198803, -0.0456417, -0.0348378, 0.199364, 0.174447, -0.141164, 0.154566, -0.0101959, -0.0873079, 0.278605, -0.472664, 0.294002, -0.198418, 0.182402, 0.0821794, -0.123652, -0.108721, -0.0261305, -0.174235, 0.0922114, -0.0268188, -0.0647295, 0.434461, 0.474712, -0.0399644, 0.219025, 0.0452949, -0.0821003, 0.205354, -0.0349204, 0.405191, 0.227075, 0.106632, -0.274877], "internal": 1}
{"paper_id": "W13-2607", "abstract": "We augment an existing TAG-based incremental syntactic formalism, PLTAG, with a semantic component designed to support the simultaneous modeling effects of thematic fit as well as syntactic and semantic predictions. PLTAG is a psycholinguistically-motivated formalism which extends the standard TAG operations with a prediction and verification mechanism and has experimental support as a model of syntactic processing difficulty. We focus on the problem of formally modelling semantic role prediction in the context of an incremental parse and describe a flexible neo-Davidsonian formalism and composition procedure to accompany a PLTAG parse. To this end, we also provide a means of augmenting the PLTAG lexicon with semantic annotation. To illustrate this, we run through an experimentally-relevant model case, wherein the resolution of semantic role ambiguities influences the resolution of syntactic ambiguities and vice versa.", "title": "The semantic augmentation of a psycholinguistically-motivated syntactic formalism", "venue": "W", "graph_vector": [0.0140215, -0.0620545, -0.02364, 0.607548, 0.503952, -1.21491, -0.235042, -0.317786, -1.70866, 0.432134, -0.0125379, -0.698435, 0.616519, 0.0180256, 0.0639362, -0.0942977, 0.513944, -0.827365, -0.223054, 0.452167, -0.558815, 0.639589, -0.00238172, -0.101332, -0.337807, 0.0108256, -0.0200045, 0.410031, -0.203186, -0.0197933, 0.215654, -0.231296, 0.21031, -0.637807, -0.755752, 0.423489, -0.555176, 0.543943, 0.21348, 0.416681, -0.204556, -0.128386, -0.35784, 0.411205, 0.661175, -1.21158, 0.0444403, 0.171293, 0.00834539, -0.0447377, 0.371857, -0.225888, 0.471014, 0.376206, -0.426462, 0.213634, 0.127824, -0.0992369, -0.178272, 0.192347, -0.293687, -0.147259, -0.285463, 0.117326, 0.306805, 0.0425806, -0.015965, 0.236302, 0.28165, -0.0411612, 0.271234, 0.282441, -0.397366, -0.266512, -0.902419, 0.14386, -0.529486, -0.0189918, -0.0295637, 0.143927, 0.169862, 0.0683292, -0.123751, -0.465239, 0.323314, 0.119086, 0.145859, 0.063374, 0.369137, -0.303255, 0.161776, 0.0111181, -0.50463, -0.287646, 0.410831, 0.0660994, -0.116705, 0.0790504, -0.137852, 0.0464938, -0.109996, -0.165455, 0.261641, -0.0312199, 0.0925563, 0.0626, -0.103492, -0.202251, 0.346526, -0.210596, -0.138792, -0.059161, -0.0532843, 0.410282, 0.147719, -0.0390086, 0.300086, 0.451557, 0.115777, 0.156911, 0.186497, -0.405644, -0.45817, -0.156637, 0.467251, 0.0513368, -0.0147468, 0.120044], "internal": 1}
{"paper_id": "W13-1103", "abstract": "Although the ideal length of summaries differs greatly from topic to topic on Twitter, previous work has only generated summaries of a pre-fixed length. In this paper, we propose an event-graph based method using information extraction techniques that is able to create summaries of variable length for different topics. In particular, we extend the Pageranklike ranking algorithm from previous work to partition event graphs and thereby detect finegrained aspects of the event to be summarized. Our preliminary results show that summaries created by our method are more concise and news-worthy than SumBasic according to human judges. We also provide a brief survey of datasets and evaluation design used in previous work to highlight the need of developing a standard evaluation for automatic tweet summarization task.", "title": "A Preliminary Study of Tweet Summarization using Information Extraction", "venue": "W", "graph_vector": [-0.0742499, 0.421166, -0.0537888, 0.205265, 0.307399, -0.513041, -0.325458, 0.0778972, -1.62619, 0.289077, -0.0424117, 0.121958, 0.723969, -0.0865492, 0.00263175, -0.0568078, 0.300323, -0.487501, -0.256438, 0.799778, -0.474622, 0.960993, -0.110071, -0.365624, -0.22781, -0.117718, -0.107424, 0.0405023, 0.019536, -0.114834, 0.209228, -0.000417471, 0.0878204, -0.513797, -0.263733, 0.22607, -0.525063, 0.0655192, 0.457704, 0.364179, 0.406631, -0.0334337, -0.311355, 0.520092, 1.05547, -0.628228, 0.0018169, 0.0930597, 0.103642, -0.136003, 0.0732655, 0.140375, 1.01613, 0.865534, -0.251963, -0.0431805, -0.0320589, 0.631218, -0.164753, -0.253369, -0.648698, -0.10801, 0.149358, 0.201524, -0.143773, -0.106519, 0.16417, -0.436128, 0.080447, -0.158119, 0.246935, 0.0559513, 0.269484, -0.225849, -0.271848, 0.0378177, 0.0256231, -0.311395, 0.0738904, -0.259976, -0.0582795, -0.0967832, 0.271238, -0.0423472, -0.124583, 0.025842, -0.00867485, -0.0926047, 0.0538789, 0.0416898, 0.0391264, 0.406975, -0.830012, -0.149181, -0.00349508, 0.524913, 0.101953, -0.489674, -0.0325925, 0.161126, -0.315186, -0.297782, 0.0533165, -0.0652686, -0.0758695, -0.215755, -0.125439, -0.270923, 0.113646, -0.523258, 0.235714, 0.0215048, -0.0673868, 0.179859, -0.460195, -0.10519, -0.0639502, -0.153134, -0.109339, 0.124059, -0.26398, 0.0461851, -0.0820509, -0.0911764, 0.80517, -0.240513, 0.158397, -0.0845116], "internal": 1}
{"paper_id": "W13-3915", "abstract": "This paper presents a dialogue act classification for a spoken dialogue system that delivers necessary information to elderly subjects with mild dementia. Lexical features have been shown to be effective for classification, but the automatic transcription of spontaneous speech demands expensive language modeling. Therefore, this paper proposes a classifier that does not require language modeling and that uses sub-lexical features instead of lexical features. This classifier operates on sequences of phonemes obtained by a phoneme recognizer and exhaustively analyzes the saliency of all possible sub-sequences using a support vector machine with a string kernel. An empirical study of a dialogue corpus containing elderly speech showed that the sub-lexical classifier was robust against the poor modeling of language and it performed better than a lexical classifier that used hidden Markov models of words. Index Terms: dialogue acts, support vector machines, string kernels, spontaneous speech, elderly speech, dementia", "title": "Sub-lexical Dialogue Act Classification in a Spoken Dialogue System Support for the Elderly with Cognitive Disabilities", "venue": "W", "graph_vector": [-0.198789, 0.26654, 0.0673889, 0.323488, 0.731755, -0.693951, 0.168939, 0.0668252, -1.6854, 0.0708822, -0.142233, -0.103629, 0.505248, 0.638713, 0.425868, -0.0635255, 0.55515, -0.443267, 0.0145348, 0.0528367, -0.495776, 0.163689, 0.270689, 0.291571, -1.14513, -0.268778, -0.280333, -0.474248, -0.101314, -0.789151, -0.06819, -0.0519625, 0.518913, -0.99482, -0.32739, 0.411161, -0.122035, 0.866062, -0.288783, 0.220182, 0.100268, -0.230627, -0.234448, 0.165911, 1.36227, -0.526358, 0.3505, 0.414112, -0.264612, -0.0600888, 0.681336, -0.291796, 1.25802, 0.715698, -0.335853, 0.130742, 0.17274, 0.355435, 0.354938, 0.157184, 0.299766, -0.344636, 0.00913189, -0.0278567, -0.270643, -0.312211, -0.0661234, -0.0954438, -0.346108, -0.353998, -0.13549, 0.0214287, -0.100184, -0.273582, -0.364267, -0.392642, -0.223568, -0.880576, -0.202983, 0.0393725, -0.121759, -0.199428, -0.0247889, 0.086209, -0.0259165, -0.259014, 0.372392, -0.134398, 0.153691, 0.258555, 0.0395616, -0.0542728, -0.811914, -0.453559, -0.156508, -0.0163413, -0.429886, 0.0500266, -0.251841, -0.616825, 0.329914, -0.0838219, 0.0543515, -0.0986108, -0.444156, 0.0555626, 0.025897, -0.0624504, 0.266052, -0.36688, 0.169857, 0.886777, 0.313755, 0.24384, -0.0761087, -0.638992, 0.153359, -0.0588893, -0.201071, 0.270147, -0.230546, 0.290985, -0.369322, -0.536492, 0.419218, 0.169341, 0.178882, 0.180753], "internal": 1}
{"paper_id": "W13-3520", "abstract": "Distributed word representations (word embeddings) have recently contributed to competitive performance in language modeling and several NLP tasks. In this work, we train word embeddings for more than 100 languages using their corresponding Wikipedias. We quantitatively demonstrate the utility of our word embeddings by using them as the sole features for training a part of speech tagger for a subset of these languages. We find their performance to be competitive with near state-of-art methods in English, Danish and Swedish. Moreover, we investigate the semantic features captured by these embeddings through the proximity of word groupings. We will release these embeddings publicly to help researchers in the development and enhancement of multilingual applications.", "title": "Polyglot: Distributed Word Representations for Multilingual NLP", "venue": "W", "graph_vector": [0.183724, 0.236943, 0.0569953, 0.249637, 0.392284, -0.566614, 0.282696, -0.303501, -1.28218, -0.000718782, 0.0395536, -0.407873, 0.484937, -0.238205, 0.0915029, 0.0455464, 0.293, -0.543271, -0.0175766, 0.31617, -0.226251, 0.686192, 0.141288, -0.0360719, -0.498946, 0.27957, -0.187577, 0.19252, -0.248665, -0.137808, -0.0609249, -0.316088, 0.180636, -0.469517, -0.517248, 0.285911, 0.0246546, 0.896344, -0.0503732, -0.105558, -0.0156305, -0.373584, -0.16493, 0.650706, 1.03735, -0.68506, 0.195295, -0.00729127, 0.0836528, -0.0531415, 0.380055, -0.306918, 0.985019, 0.470658, 0.185539, -0.0198734, -0.237299, 0.214301, 0.10075, 0.0106416, -0.0288473, 0.295138, 0.101105, 0.182539, 0.154062, 0.0336014, 0.495497, -0.269275, 0.13969, -0.10247, 0.280046, 0.273301, 0.104943, -0.220772, 0.026325, -0.0795793, -0.722687, -0.417653, -0.0202031, -0.190236, -0.181747, 0.175633, 0.108229, 0.16232, 0.322868, -0.372062, 0.199885, 0.19675, -0.0722939, -0.228318, 0.199456, 0.232548, -0.418394, -0.259126, -0.0311822, -0.23617, -0.209304, 0.00421201, 0.0668661, -0.0985761, 0.128661, -0.206607, -0.143247, -0.0859171, -0.105078, 0.340374, -0.186187, 0.0873694, -0.14255, -0.241345, 0.00321401, 0.0289535, -0.0652752, 0.0596486, -0.28609, 0.218422, 0.30111, 0.033836, -0.00397746, -0.0190237, -0.132712, 0.162761, -0.0999174, -0.149255, 0.52585, -0.258626, 0.110498, -0.347079], "internal": 1}
{"paper_id": "W13-3214", "abstract": "The compositionality of meaning extends beyond the single sentence. Just as words combine to form the meaning of sentences, so do sentences combine to form the meaning of paragraphs, dialogues and general discourse. We introduce both a sentence model and a discourse model corresponding to the two levels of compositionality. The sentence model adopts convolution as the central operation for composing semantic vectors and is based on a novel hierarchical convolutional neural network. The discourse model extends the sentence model and is based on a recurrent neural network that is conditioned in a novel way both on the current sentence and on the current speaker. The discourse model is able to capture both the sequentiality of sentences and the interaction between different speakers. Without feature engineering or pretraining and with simple greedy decoding, the discourse model coupled to the sentence model obtains state of the art performance on a dialogue act classification experiment.", "title": "Recurrent Convolutional Neural Networks for Discourse Compositionality", "venue": "W", "graph_vector": [0.0372139, 0.151288, 0.110862, 0.254874, 0.688304, -0.633635, 0.424401, -0.261501, -1.46483, 0.217082, 0.0546343, -0.226928, 0.287292, 0.262066, -0.121166, -0.0482983, 0.308564, -0.377037, 0.126278, 0.32863, 0.0184445, 0.692268, 0.387913, -0.252862, -0.4507, 0.204316, -0.122429, 0.141045, 0.0143457, -0.335313, -0.267284, -0.339544, 0.192093, -0.416091, -0.0543448, 0.397131, -0.209735, 0.803937, -0.191592, -0.176051, -0.230716, -0.321796, 0.0157865, 0.441277, 1.0562, -0.759202, 0.149785, 0.00544442, -0.244692, 0.0714068, -0.00386111, -0.0581288, 0.976767, 0.451248, 0.0488157, -0.174936, 0.380058, 0.279226, 0.222373, -0.454199, 0.0400283, -0.167377, 0.077561, 0.0302972, 0.236271, -0.159075, 0.103741, 0.0617007, 0.221017, -0.126272, -0.0944017, 0.0692874, 0.27843, -0.158, -0.08465, -0.174947, -0.468633, -0.536621, -0.245371, -0.0530978, -0.217888, -0.0265734, 0.24426, -0.284446, 0.198667, -0.225656, -0.100366, -0.0573084, 0.0156482, -0.108171, 0.148247, 0.488067, -0.509485, 0.0452889, -0.124216, 0.0794701, 0.047942, -0.0669034, -0.189574, -0.476926, 0.325898, -0.151986, -0.122662, 0.1387, -0.141262, 0.209699, 0.185253, -0.249007, -0.0225306, -0.192282, -0.0469684, -0.0618508, 0.0607665, 0.302673, -0.179285, 0.0761949, 0.333394, 0.165885, -0.148129, 0.367186, -0.239377, 0.197234, 0.0748743, -0.212068, 0.288675, 0.134066, 0.166516, 0.539644], "internal": 1}
{"paper_id": "W13-2320", "abstract": "In this paper, we discuss our efforts to annotate nominals in the Hindi Treebank with the semantic property of animacy. Although the treebank already encodes lexical information at a number of levels such as morph and part of speech, the addition of animacy information seems promising given its relevance to varied linguistic phenomena. The suggestion is based on the theoretical and computational analysis of the property of animacy in the context of anaphora resolution, syntactic parsing, verb classification and argument differentiation.", "title": "Animacy Annotation in the Hindi Treebank", "venue": "W", "graph_vector": [0.196208, -0.101849, 0.208933, 0.0526636, 0.2388, -1.26407, -0.42164, 0.494579, -1.39245, 0.310989, 0.217215, -0.721017, 0.544458, -0.485485, 0.120801, -0.153723, 0.557447, -0.850987, 0.442803, 0.648178, -0.483241, 0.952112, 0.570894, 0.0554154, -0.494753, 0.166891, 0.159234, 0.513777, -0.507071, 0.0701929, -0.386928, 0.199682, 0.204175, -0.464784, -0.258371, 0.28292, -0.399163, 1.0825, 0.0785809, 0.273431, -0.040109, 0.0491015, 0.00930197, 0.15119, 0.750413, -1.1434, -0.00744686, 0.196942, -0.210009, 0.00276132, 0.296366, 0.118166, 0.437331, 0.610026, 0.166819, 0.320408, -0.193005, 0.326639, 0.381606, 0.139712, -0.152992, -0.105181, -0.0615473, 0.00108458, -0.225531, -0.159418, 0.0896559, -0.0389437, -0.144349, -0.0619704, 0.367658, -0.158585, -0.0423282, 0.0785171, 0.0912586, -0.494739, -0.688906, -0.337295, -0.244711, 0.173516, 0.410782, 0.000881641, 0.279419, -0.518558, -0.0778936, 0.106655, -0.12727, -0.245708, 0.379079, -0.173589, -0.435418, 0.263605, -0.626809, -0.552383, -0.360815, -0.249528, 0.147998, 0.07705, 0.106077, 0.117262, -0.00465998, -0.400015, -0.0278926, 0.252782, 0.198312, 0.102157, 0.0601352, -0.291185, 0.182674, 0.0669225, 0.221413, -0.185859, 0.015403, 0.194138, 0.826691, -0.0469855, 0.372419, 0.063199, 0.497401, 0.537405, -0.0956692, -0.137211, -0.256421, -0.159395, 0.349095, 0.35379, -0.470708, -0.437154], "internal": 1}
{"paper_id": "W13-3201", "abstract": "We present vector space semantic parsing (VSSP), a framework for learning compositional models of vector space semantics. Our framework uses Combinatory Categorial Grammar (CCG) to define a correspondence between syntactic categories and semantic representations, which are vectors and functions on vectors. The complete correspondence is a direct consequence of minimal assumptions about the semantic representations of basic syntactic categories (e.g., nouns are vectors), and CCG’s tight coupling of syntax and semantics. Furthermore, this correspondence permits nonuniform semantic representations and more expressive composition operations than previous work. VSSP builds a CCG semantic parser respecting this correspondence; this semantic parser parses text into lambda calculus formulas that evaluate to vector space representations. In these formulas, the meanings of words are represented by parameters that can be trained in a task-specific fashion. We present experiments using noun-verbnoun and adverb-adjective-noun phrases which demonstrate that VSSP can learn composition operations that RNN (Socher et al., 2011) and MV-RNN (Socher et al., 2012) cannot.", "title": "Vector Space Semantic Parsing: A Framework for Compositional Vector Space Models", "venue": "W", "graph_vector": [-0.0127974, 0.191222, 0.19354, 0.282509, 0.817188, -0.78512, 0.0283588, -0.15959, -1.54765, 0.364108, 0.266438, -0.331542, 0.485395, 0.0133532, 0.0924993, -0.0141216, 0.616601, -0.330338, 0.0504909, 0.0586559, -0.160656, 0.490984, 0.249559, -0.0749138, -0.593297, -0.0888199, -0.149211, 0.105965, 0.0216019, -0.282611, -0.0808076, -0.16618, -0.0248048, -0.209348, -0.0374912, -0.0333486, -0.164199, 0.613969, -0.0622934, -0.0276512, 0.043153, -0.32461, -0.401489, 0.451887, 1.0341, -0.831648, -0.12932, -0.00205921, 0.177671, 0.261292, 0.0518265, -0.496763, 0.891234, 0.51652, -0.161606, -0.0424617, 0.0147518, -0.144619, -0.0708542, -0.113575, 0.374823, -0.274016, -0.0256439, -0.147345, 0.0584947, 0.114272, 0.141675, 0.0779358, -0.347674, -0.150673, 0.239828, 0.148343, 0.211913, -0.184253, -0.205325, -0.213656, -0.450878, -0.373074, 0.0474081, -0.243324, -0.029536, 0.21916, 0.306209, -0.403808, 0.144874, 0.0978784, -0.0425472, -0.124749, 0.142957, -0.297071, -0.178739, 0.215073, -0.584724, -0.282501, -0.0253143, 0.196973, -0.286493, -0.197837, 0.0179111, -0.127277, 0.180822, -0.175598, 0.388596, 0.0065883, -0.0113775, 0.200943, 0.153282, -0.282391, 0.284885, -0.289664, -0.0387566, 0.0201444, 0.00265368, 0.208828, 0.125104, 0.0100982, 0.400768, -0.0323876, -0.131802, 0.211913, -0.209056, 0.087828, -0.232547, -0.219648, 0.0543835, -0.0409293, 0.0316443, 0.128438], "internal": 1}
{"paper_id": "W13-3825", "abstract": "Recent studies refocus on usage of the Naïve Bayes model in unsupervised word sense disambiguation (WSD). They discuss the issue of feature selection for this statistical model, when used as clustering technique, and comment (Hristea, 2012) that it still holds a promise for unsupervised WSD. Within the various investigated types of feature selection, this ongoing research concentrates on syntactic dependency-based features, introduced in (Hristea and Colhon, 2012) with respect to adjectives only. We hereby extend the mentioned approach to the case of nouns and recommend the further investigation of this promising feature selection method.", "title": "On a Dependency-based Semantic Space for Unsupervised Noun Sense Disambiguation with an Underlying Naïve Bayes Model", "venue": "W", "graph_vector": [0.359433, -0.315686, -0.245102, 0.280372, 0.552222, -0.764492, 0.282642, -0.0781356, -1.64328, 0.244003, 0.0904299, -0.610098, 0.978931, 0.16335, -0.089807, -0.190992, 0.306704, -0.335298, 0.174328, 0.566257, -0.0371542, 0.600297, -0.12134, -0.309687, -0.33313, 0.385214, 0.142894, 0.285335, 0.0373021, -0.573801, -0.306759, 0.0156775, 0.0971176, -0.21673, -0.0979386, 0.263102, -0.319379, 0.420328, -0.241553, -0.18771, -0.282139, -0.112485, -0.310067, 0.0448298, 1.0984, -0.312048, 0.63503, 0.394261, -0.222217, 0.100884, 0.789515, -0.124627, 1.20678, 0.928157, 0.140217, -0.135264, 0.171844, -0.293479, -0.109096, 0.107575, -0.4579, -0.220295, 0.108444, -0.265666, 0.0894974, -0.312278, -0.292919, -0.177453, 0.243645, 0.169127, 0.105211, -0.0787112, -0.0879366, -0.0652674, 0.0480444, -0.153458, -0.439264, -0.173277, 0.176289, 0.255007, 0.0466523, -0.0595695, 0.244984, 0.0773788, -0.191478, 0.234314, -0.0774967, 0.12901, -0.367488, -0.0207007, -0.231775, 0.0149661, -0.444318, -0.307251, -0.324921, 0.0154446, -0.171682, 0.162443, 0.0386528, -0.204477, -0.168204, -0.420805, -0.0623423, 0.568232, -0.144238, 0.0552452, -0.520977, 0.0629041, -0.0306764, -0.262639, -0.0418446, -0.310945, -0.178961, 0.536561, -0.408696, 0.066741, 0.135093, 0.0143796, -0.185336, -0.0474216, -0.0379188, 0.227286, -0.378682, 0.263761, 0.609763, 0.261407, 0.285528, 0.111949], "internal": 1}
{"paper_id": "W13-4601", "abstract": "This paper describes a method to extract medical information from texts. The method targets to extract complaints and diagnoses from electronic health record texts. Complaints and diagnoses are fundamental information and can be used for more complex medical tasks. The method utilizes several medical knowledge resources to enhance the performance of extraction. With an evaluation using NTCIR10 MedNLP data, our method marked 86.53 in F1 score with a cross validation. The score is comparable to top scoring teams in NTCIR-10 MedNLP task. The approach taken to incorporate knowledge resources has a high generality. It is not restricted to the resources presented in this paper and can be applied to various other resources.", "title": "Incorporating Knowledge Resources to Enhance Medical Information Extraction", "venue": "W", "graph_vector": [0.377966, -0.0765779, -0.12528, 0.502479, 0.205874, -0.397398, -0.217377, -0.263959, -1.48371, 0.276946, -0.114073, -0.168827, 0.490645, 0.0935558, -0.296099, -0.153985, 0.287177, -0.432555, 0.228275, 0.579731, -0.566795, 0.819108, 0.236379, 0.311761, -0.698696, 0.0121374, -0.234527, 0.0101631, -0.365203, -0.0115881, 0.297853, 0.148702, 0.0846071, -0.418651, -0.0337501, -0.178167, -0.644036, 0.548502, 0.280438, 0.0133743, -0.247191, -0.609191, -0.376359, 0.662486, 1.13865, -1.0903, 0.206583, 0.33444, 0.244397, 0.0867947, 0.353252, 0.0530688, 0.43263, 0.543614, -0.466197, -0.202396, -0.0711111, 0.549012, -0.341799, -0.0507031, -0.584621, -0.349701, -0.0796998, -0.25107, -0.196463, -0.10888, 0.527488, 0.0108772, 0.0157757, 0.567017, -0.0587034, 0.229191, -0.375215, -0.145622, 0.207793, -0.0763233, -0.247422, -0.325388, 0.0639389, -0.218928, 0.167526, 0.0574326, 0.246141, -0.0446982, 0.0259823, -0.147989, 0.279766, -0.197748, -0.106998, 0.177584, 0.159061, -0.100888, -0.529121, -0.110786, 0.176579, -0.0209823, -0.504627, -0.33985, 0.358688, 0.126372, 0.0635088, -0.433375, 0.487049, -0.52087, 0.0174058, -0.269617, -0.0891972, 0.189709, 0.00892386, -0.347405, -0.257, 0.299797, -0.34273, 0.0784013, -0.178555, -0.376863, 0.823084, -0.0415687, 0.0516062, 0.13695, -0.0501601, 0.0837589, 0.0854124, -0.300265, 0.4551, 0.2059, 0.0353505, 0.234469], "internal": 1}
{"paper_id": "W13-5004", "abstract": "Distance metric learning from high (thousands or more) dimensional data with hundreds or thousands of classes is intractable but in NLP and IR, high dimensionality is usually required to represent data points, such as in modeling semantic similarity. This paper presents algorithms to scale up learning of a Mahalanobis distance metric from a large data graph in a high dimensional space. Our novel contributions include random projection that reduces dimensionality and a new objective function that regularizes intra-class and inter-class distances to handle a large number of classes. We show that the new objective function is convex and can be efficiently optimized by a stochastic-batch subgradient descent method. We applied our algorithm to two different domains; semantic similarity of documents collected from the Web, and phenotype descriptions in genomic data. Experiments show that our algorithm can handle the high-dimensional big data and outperform competing approximations in both domains.", "title": "Reconstructing Big Semantic Similarity Networks", "venue": "W", "graph_vector": [0.0204677, 0.478072, 0.150571, 0.739963, 0.393598, -0.848768, -0.158179, 0.250649, -1.82422, 0.0879254, 0.00628173, -0.313164, 0.793633, -0.17935, -0.422948, -0.398434, 0.316483, -0.866928, 0.115532, 0.183241, -0.21099, 1.1442, 0.776658, -0.256711, -0.513572, 0.0236965, 0.30368, 0.835614, -0.358524, 0.00147452, -0.467334, -0.32862, -0.147082, -0.805155, 0.0629622, -0.283431, -0.657458, 0.364925, -0.0078146, -0.257022, -0.0253154, -0.323958, -0.403201, 0.646165, 1.3726, -1.07705, 0.286727, 0.018386, -0.0108977, 0.0834952, 0.249748, -0.516504, 1.33394, 0.712747, -0.521106, -0.105583, 0.15808, 0.0314856, 0.389453, 0.0164532, -0.0870883, -0.0238861, -0.25442, -0.0181561, -0.566788, 0.124137, 0.494175, -0.416748, -0.0478178, 0.269849, 0.105423, 0.00651012, 0.0240711, -0.0512296, 0.168416, -0.250304, -0.483019, -0.578316, -0.366051, -0.224768, -0.0188492, 0.346018, 0.0994407, -0.18444, 0.0339353, -0.430036, 0.357418, -0.734164, -0.206335, -0.17279, -0.0294699, 0.0380372, -0.543188, 0.319609, -0.325843, -0.189262, 0.13221, -0.222652, -0.456194, -0.354004, -0.000818342, -0.564995, 0.569455, 0.0958547, 0.152262, 0.520549, -0.147741, -0.0815449, -0.142638, -0.285074, -0.724125, 0.0110892, -0.325109, 0.25499, -0.566395, -0.0170333, 0.348311, 0.261723, 0.0315792, 0.30212, -0.35409, -0.298291, -0.0762634, -0.479953, 0.284621, 0.283498, -0.202077, -0.0380228], "internal": 1}
{"paper_id": "W13-2510", "abstract": "This paper presents a comparable translation corpus created to investigate translation variation phenomena in terms of contrasts between languages, text types and translation methods (machine vs. computer-aided vs. human). These phenomena are reflected in linguistic features of translated texts belonging to different registers and produced with different translation methods. For their analysis, we combine methods derived from translation studies, language variation and machine translation, concentrating especially on textual and lexico-grammatical variation. To our knowledge, none of the existing corpora can provide comparable resources for a comprehensive analysis of variation across text types and translation methods. Therefore, the corpus resources created, as well as our analysis results will find application in different research areas, such as translation studies, machine translation, and others.", "title": "VARTRA: A Comparable Corpus for Analysis of Translation Variation", "venue": "W", "graph_vector": [-0.276746, 0.285453, 0.166598, 0.0231932, 0.872693, -0.827578, -0.0957968, -0.182235, -1.6769, -0.1744, 0.0922629, -0.455795, 0.376819, 0.0821023, -0.272651, -0.619149, 0.51726, -0.741964, 0.183585, 0.156001, -0.165561, 0.473991, 0.00443356, 0.147964, 0.123377, 0.432929, 0.517222, 0.370046, -0.61226, -0.093154, -0.261461, 0.0946138, 0.0554886, 0.260044, -0.564442, 0.0270378, 0.0275086, 0.793912, 0.113762, 0.0779951, 0.128591, -0.249738, -0.479414, 0.482162, 1.01844, -0.601022, -0.266092, 0.398673, -0.212181, -0.162182, 0.306097, -0.0366019, 1.16698, 0.622586, -0.539774, -0.122313, -0.227393, -0.0521653, -0.0579913, -0.054188, 0.161805, -0.396303, 0.191346, 0.226048, 0.252283, -0.321927, 0.443513, 0.100576, 0.118095, -0.119786, 0.455261, 0.109479, -0.249811, -0.232627, 0.0678441, -0.0963227, -0.429592, -0.508009, -0.0995225, 0.252148, -0.0807974, -0.210861, 0.0914753, -0.0931489, -0.311615, -0.0704806, -0.0267166, -0.274677, 0.191987, -0.235613, -0.181391, 0.0498579, -0.595609, 0.0456394, -0.082293, 0.0307662, 0.405104, -0.190225, -0.116975, -0.15748, -0.110809, 0.0134009, 0.175649, -0.0576832, 0.048493, -0.14676, -0.231796, 0.224389, 0.539908, -0.158784, 0.302801, 0.272726, 0.318872, 0.0703659, -0.500718, 0.157952, 0.164342, -0.150195, -0.190481, 0.0343157, 0.0291963, 0.0114811, 0.0922072, -0.335282, 0.581531, 0.160889, 0.0918461, -0.0775372], "internal": 1}
{"paper_id": "W13-1614", "abstract": "We describe TWITA, the first corpus of Italian tweets, which is created via a completely automatic procedure, portable to any other language. We experiment with sentiment analysis on two datasets from TWITA: a generic collection and a topic-specific collection. The only resource we use is a polarity lexicon, which we obtain by automatically matching three existing resources thereby creating the first polarity database for Italian. We observe that albeit shallow, our simple system captures polarity distinctions matching reasonably well the classification done by human judges, with differences in performance across polarity values and on the two sets.", "title": "Sentiment analysis on Italian tweets", "venue": "W", "graph_vector": [0.167581, 0.31755, 0.385172, 0.10819, 0.747246, -0.467901, -0.19355, -0.203281, -1.78151, 0.241341, -0.00117256, -0.220142, 0.369633, -0.204587, 0.357896, 0.0580988, 0.665186, -0.337373, -0.064309, 0.314303, -0.123823, 0.335881, 0.235317, 0.00744246, -0.449348, -0.182795, 0.16303, 0.221915, 0.0483376, -0.476086, -0.231517, 0.054455, -0.0105379, -0.0412672, -0.184387, -0.275261, -0.141474, 0.669436, -0.0166384, -0.0419849, 0.168052, -0.0515575, -0.301775, 0.722018, 0.997606, -0.815264, -0.000302675, 0.265104, -0.0706642, -0.0582394, 0.576861, -0.357208, 1.04547, 0.499779, 0.0195088, 0.00838299, 0.104095, 0.00239675, -0.0359072, 0.0696737, 0.219846, 0.0723842, 0.0947656, 0.274788, 0.0271904, -0.188865, 0.403092, 0.122268, 0.21065, -0.100753, 0.0711033, 0.232863, 0.194866, -0.11266, -0.318443, 0.0386956, -0.63571, -0.444048, 0.0571513, 0.275672, -0.198303, -0.15258, 0.180909, -0.0739366, -0.0344473, 0.0261362, 0.251531, 0.0985684, 0.16225, 0.0967143, 0.430645, 0.015195, -0.513618, -0.0898112, -0.0842967, -0.112113, -0.280357, 0.0692549, -0.109484, 0.194018, -0.287764, -0.262989, -0.268377, 0.144669, 0.0462591, -0.122813, -0.412702, -0.219945, 0.432302, 0.0567714, 0.238984, -0.0865847, 0.385883, -0.092285, -0.0257891, -0.167436, 0.363485, -0.311841, 0.0686263, -0.00725785, -0.528294, 0.0317012, -0.144383, 0.0403728, 0.483263, 0.126583, 0.208738, 0.22639], "internal": 1}
{"paper_id": "W13-1727", "abstract": "In this paper, we describe our approach to native language identification and discuss the results we submitted as participants to the First NLI Shared Task. By resorting to a wide set of general–purpose features qualifying the lexical and grammatical structure of a text, rather than to ad hoc features specifically selected for the NLI task, we achieved encouraging results, which show that the proposed approach is general–purpose and portable across different tasks, domains and languages.", "title": "Linguistic Profiling based on General–purpose Features and Native Language Identification", "venue": "W", "graph_vector": [0.31302, 0.0741491, 0.00987738, 0.306003, 1.01967, -0.807308, 0.0485247, -0.30228, -1.48726, 0.167986, -0.550279, -0.32095, 0.732894, -0.353606, -0.0660104, -0.30976, 0.376878, -0.452347, -0.250712, 0.149607, -0.367923, 0.548185, -0.192272, -0.288225, -0.298799, 0.262755, 0.55393, -0.221266, -0.759051, 0.528869, 0.136982, 0.25744, 0.431029, -0.161218, -0.172217, 0.000524958, -0.193738, 0.623381, 0.597369, -0.0147835, 0.202949, -0.8137, -0.510378, 0.437275, 0.983561, -1.11662, -0.088789, -0.00483156, 0.0504674, -0.249875, 0.0746908, 0.0119448, 0.577881, 0.764013, -0.115547, 0.0351853, -0.12808, -0.282864, 0.254438, 0.189977, -0.0598613, 0.0408769, -0.129645, 0.290873, -0.324973, -0.0926627, -0.271061, -0.185403, 0.134112, 0.0233205, -0.0920602, 0.0235086, -0.285937, -0.0589248, 0.0479016, -0.150872, -0.301689, -0.197514, 0.0815539, 0.319388, -0.0803881, 0.166475, 0.0503676, -0.397183, -0.149658, -0.364904, -0.0449541, -0.20279, -0.0560905, 0.669961, 0.0495355, -0.247716, -0.608565, -0.134239, -0.372838, -0.33949, 0.0119265, -0.554771, -0.169558, -0.293969, -0.306841, -0.34029, 0.338557, -0.216088, -0.315225, 0.0345766, 0.0517467, -0.354535, -0.243429, -0.131739, 0.315127, -0.0296497, 0.165497, 0.0685755, 0.18643, 0.15855, 0.237951, -0.666931, -0.0256713, 0.158092, -0.169073, -0.0905037, -0.255639, -0.283401, 0.984748, 0.297233, -0.0617246, 0.250346], "internal": 1}
{"paper_id": "W13-5002", "abstract": "We introduce an interactive visualization component for the JoBimText project. JoBimText is an open source platform for large-scale distributional semantics based on graph representations. First we describe the underlying technology for computing a distributional thesaurus on words using bipartite graphs of words and context features, and contextualizing the list of semantically similar words towards a given sentential context using graphbased ranking. Then we demonstrate the capabilities of this contextualized text expansion technology in an interactive visualization. The visualization can be used as a semantic parser providing contextualized expansions of words in text as well as disambiguation to word senses induced by graph clustering, and is provided as an open source tool.", "title": "JoBimText Visualizer: A Graph-based Approach to Contextualizing Distributional Similarity", "venue": "W", "graph_vector": [-0.0332934, 0.386158, -0.0247157, -0.111911, 0.784191, -0.403329, 0.230426, 0.115472, -1.25194, 0.415976, 0.27252, -0.358608, 0.877263, 0.111923, 0.264402, -0.349598, 0.355293, -0.896411, -0.340474, 0.199995, -0.157569, 0.487739, -0.31642, -0.0145081, -0.431958, 0.0868503, 0.0167568, 0.361022, -0.127016, -0.155436, 0.295363, 0.150418, 0.0571346, -0.126908, 0.0371064, -0.0159174, -0.516696, 0.581071, -0.102912, -0.159083, -0.213976, -0.284224, -0.658898, 0.0271871, 0.922366, -0.537744, -0.0894191, 0.147603, 0.32204, -0.213704, 0.0399728, -0.346421, 0.811353, 0.437734, -0.741781, 0.21934, 0.290529, 0.263692, -0.154065, -0.131129, -0.0562116, -0.335758, 0.0226346, -0.0628025, -0.0407072, 0.0873007, 0.00745615, 0.030595, 0.0682769, -0.511951, -0.186516, 0.124862, -0.235078, -0.101294, 0.124029, -0.460557, -0.364762, -0.206641, -0.0668068, -0.0264112, 0.135371, -0.0300893, 0.188063, -0.211275, -0.172223, -0.084927, 0.169435, -0.204695, 0.00474252, -0.0610126, 0.332054, 0.108067, -0.770089, -0.144852, -0.100037, 0.283244, -0.406759, 0.272568, 0.150555, 0.195276, -0.233051, -0.216965, 0.106042, 0.214864, 0.307732, 0.528998, 0.111158, 0.0870686, 0.171974, -0.207842, -0.316389, 0.199469, 0.165545, 0.372987, 0.390938, -0.0665531, 0.15012, 0.0912698, -0.525104, 0.390002, -0.0589384, -0.024475, 0.0365077, -0.146785, 0.215054, 0.138044, 0.0302728, 0.0360197], "internal": 1}
{"paper_id": "W13-2414", "abstract": "In the paper we discuss the problem of low recall for the named entity (NE) recognition task for Polish. We discuss to what extent the recall of NE recognition can be improved by reducing the space of NE categories. We also present several extensions to the binary model which give an improvement of the recall. The extensions include: new features, application of external knowledge and post-processing. For the partial evaluation the final model obtained 90.02% recall with 91.30% precision on the corpus of economic news.", "title": "Recognition of Named Entities Boundaries in Polish Texts", "venue": "W", "graph_vector": [0.27706, 0.297243, -0.0035726, 0.0330605, 0.564823, -0.816942, 0.189174, -0.0338878, -1.52368, 0.335341, -0.0119469, -0.428863, 0.405429, 0.0273673, 0.0619366, 0.209791, 0.630892, -0.191554, 0.558984, 0.154197, -0.624164, 0.840392, -0.0437239, -0.48338, -0.384309, 0.326332, 0.605173, 0.670438, -0.395439, -0.201805, 0.0740865, -0.467871, -0.0553306, -0.453613, 0.473693, 0.187133, 0.00535663, 0.569776, 0.230719, 0.215425, 0.0954887, -0.285334, -0.323873, 0.51309, 0.900096, -0.611556, 0.233287, -0.059459, 0.0813202, -0.111591, 0.159912, 0.0965198, 1.08708, 0.866522, -0.346943, -0.694717, 0.0462191, 0.0284632, 0.01872, 0.143747, -0.555488, -0.0368632, -0.332352, -0.182289, -0.181831, 0.230544, 0.592893, 0.0749209, 0.011747, 0.240136, 0.322058, 0.340142, -0.142541, -0.0207806, 0.425821, 0.344453, -0.829046, 0.0200515, -0.303144, -0.0227325, -0.105596, -0.162645, 0.119551, -0.397038, 0.0983032, -0.0557533, 0.204823, 0.0746238, 0.0515611, -0.209342, 0.198515, 0.567842, -0.503196, -0.0701109, -0.447484, -0.307167, 0.0968943, -0.11604, 0.321847, 0.341321, -0.175847, -0.513931, -0.3041, 0.261948, -0.015528, 0.198723, 0.177101, -0.309653, 0.00782475, -0.219438, -0.23767, -0.393318, -0.229399, 0.059203, 0.134403, -0.291813, 0.296782, -0.00498851, 0.10261, 0.564092, 0.314434, 0.364889, 0.0697926, 0.194662, 0.47952, 0.393012, -0.0412416, -0.355534], "internal": 1}
{"paper_id": "W13-1910", "abstract": "Interpreting the rapidly increasing amount of experimental data requires the availability and representation of biological knowledge in a computable form. The Biological expression language (BEL) encodes the data in form of causal relationships, which describe the association between biological events. BEL can successfully be applied to large data and support causal reasoning and hypothesis generation. With the rapid growth of biomedical literature, automated methods are a crucial prerequisite for handling and encoding the available knowledge. The BioNLP shared tasks support the development of such tools and provide a linguistically motivated format for the annotation of relations. On the other hand, BEL statements and the corresponding evidence sentences might be a valuable resource for future BioNLP shared task training data generation. In this paper, we briefly introduce BEL and investigate how far BioNLP-shared task annotations could be converted to BEL statements and in such a way directly support BEL statement generation. We present the first results of the automatic BEL statement generation and emphasize the need for more training data that captures the underlying biological meaning.", "title": "BEL networks derived from qualitative translations of BioNLP Shared Task annotations", "venue": "W", "graph_vector": [0.334303, 1.09618, -0.257602, 0.82728, 0.764129, -0.996075, -0.0540949, -0.0877294, -2.54093, 0.200424, -0.319109, -0.0126969, 0.777848, -0.0568694, -0.501461, 0.329351, 0.940898, -0.613314, 0.0595072, 0.236267, -0.508256, 1.18769, 0.433217, -0.20057, -0.150512, 0.146951, 0.377298, -0.133328, -0.500045, -0.435373, 0.407871, -0.0844193, 0.124913, -0.701089, -0.525351, 0.0572862, -0.251732, 1.03829, 0.487363, -0.27541, 0.132807, -0.400365, -0.285245, 0.667524, 1.6523, -1.42024, 0.081877, -0.0164046, 0.317572, -0.198347, 0.476348, -0.153997, 1.00968, 0.95383, -0.0896938, 0.301512, 0.3967, 0.0457628, -0.0310364, 0.268341, -0.257088, -0.310336, -0.0600889, 0.30683, -0.0384295, -0.354669, 0.339952, 0.15073, -0.230597, 0.0170182, -0.369931, -0.100501, 0.167141, -0.545069, 0.409707, -0.313446, -0.997056, -0.6809, -0.345877, -0.127297, 0.241466, 0.17454, 0.118268, 0.33685, -0.0907495, -0.368534, 0.0261719, -0.53794, -0.278611, 0.0670942, 0.198041, 0.00351614, -1.11344, -0.403135, -0.399053, 0.0818034, 0.0950722, -0.0723062, 0.326991, -0.581649, -0.407958, -0.127554, -0.00252416, -0.223543, -0.109533, 0.526664, -0.219148, -0.481094, 0.165849, -0.10335, -0.147376, 0.0782582, -0.135245, -0.533133, -0.49736, -0.136992, 0.671271, 0.0645066, 0.0601197, 0.475619, -0.151589, -0.434287, -0.375797, 0.420712, 0.888239, 0.385694, -0.442557, 0.269636], "internal": 1}
{"paper_id": "W13-0404", "abstract": "Abstract – Because of privacy concerns and the expense involved in creating an annotated corpus, the existing small annotated corpora might not have sufficient number of examples for statistically learning to extract all the named-entities precisely. In this work, we evaluate what value may lie in automatically generated features based on distributional semantics when using machine-learning named entity recognition (NER). The features we generated and experimented with include n-nearest words, support vector machine (SVM)-regions, and term clustering, all of which are considered semantic (or distributional semantic) features. The addition of n-nearest words feature resulted in a greater increase in F-score than adding a manually constructed lexicon to a baseline system that extracts medical concepts from clinical notes. Although the need for relatively small annotated corpora for retraining is not obviated, lexicons empirically derived from unannotated text can not only supplement manually created lexicons, but replace them. This phenomenon is observed in extracting concepts both from biomedical literature and clinical notes. Background One of the most time-consuming tasks faced by a Natural Language Processing (NLP) researcher or practitioner trying to adapt a machine-learning–based NER system to a different domain is the creation, compilation, and customization of the needed lexicons. Lexical resources, such as lexicons of concept classes are considered necessary to improve the performance of NER. It is typical for medical informatics researchers to implement modularized systems that cannot be generalized (Stanfill et al. 2010). As the work of constructing or customizing lexical resources needed for these highly specific systems is human-intensive, automatic generation is a desirable alternative. It might be possible that empirically created lexical resources might incorporate domain knowledge into a machine-learning NER engine and increase its accuracy. Although many machine learning–based NER techniques require annotated data, semi-supervised and unsupervised techniques for NER have been long been explored due to their value in domain robustness and minimizing labor costs. Some attempts at automatic knowledgebase construction included automatic thesaurus discovery efforts (Grefenstette 1994), which sought to build lists of similar words without human intervention to aid in query expansion or automatic dictionary construction (Riloff 1996). More recently, the use of empirically derived semantics for NER is used by Finkel and Manning (Finkel and Manning 2009a), Turian et al. (Turian et al. 2010), and Jonnalagadda et al. (Siddhartha Jonnalagadda et al. 2010). Finkel’s NER tool uses clusters of terms built apriori from the British National corpus (Aston and Burnard 1998) and English gigaword corpus (Graff et al. 2003) for extracting concepts from newswire text and PubMed abstracts for extracting gene mentions from biomedical literature. Turian et al. (Turian et al. 2010) also showed that statistically created word clusters (P. F. Brown et al. 1992; Clark 2000) could be used to improve named entity recognition. However, only a single feature (cluster membership) can be derived from the clusters. Semantic vector representations of terms had not been previously used for NER or sequential tagging classification tasks before (Turian et al. 2010). Although Jonnalagadda et al. (Siddhartha Jonnalagadda et al. 2010) use empirically derived vector representation for extracting concepts defined in the GENIA (Kim, Ohta, and Tsujii 2008) ontology from biomedical literature using rule-based methods, it was not clear whether such methods could be ported to extract other concepts or incrementally improve the performance of an existing system . This work not only demonstrates how such vector representation could improve state-of-the-art NER, but also that they are more useful than statistical clustering in this context.", "title": "Evaluating the Use of Empirically Constructed Lexical Resources for Named Entity Recognition", "venue": "W", "graph_vector": [-0.0467047, 0.382933, 0.11024, -0.00355201, 0.280848, -0.474893, 0.131323, 0.0784679, -1.67344, 0.450776, -0.0627685, -0.319073, 0.69643, -0.0394455, 0.401416, -0.365853, 0.0496335, -0.677988, 0.708858, 0.514195, -0.517094, 0.632026, 0.236894, 0.568975, -0.354693, 0.626902, 0.0452174, -0.297183, -0.0587715, -0.48845, 0.128225, 0.215431, -0.699828, -0.306175, -0.16167, 0.354974, -0.500697, 1.02581, -0.0487914, -0.344646, 0.143198, -0.252587, -0.0530713, -0.0441778, 0.881552, -0.890742, 0.212243, 0.185121, 0.207896, 0.375359, 0.125004, 0.388932, 0.716334, 0.48593, -0.349155, -0.354192, -0.20342, 0.209873, 0.0954113, 0.0232884, -0.275741, -0.399731, 0.269743, -0.193784, -0.361651, 0.251992, 0.0368554, 0.0171495, 0.17002, -0.527881, 0.30405, 0.272404, -0.0816258, -0.235875, 0.362644, -0.325359, -0.270274, -0.619198, -0.164484, -0.284224, -0.575907, 0.544641, 0.17009, -0.232472, 0.162663, -0.359767, 0.0688111, -0.145158, 0.285131, -0.0599849, -0.216245, -0.216951, -0.368588, -0.228536, -0.195892, 0.126953, -0.366909, -0.099721, 0.280852, 0.25534, -0.692252, -0.330385, 0.139756, -0.309754, -0.15585, 0.251697, 0.216138, -0.229961, 0.139014, -0.459166, 0.123868, -0.0749155, -0.251647, -0.108713, 0.0124971, -0.323417, 0.566686, -0.11078, 0.298353, -0.192369, 0.0622628, 0.359862, -0.00502237, -0.0135397, 0.419622, -0.0311796, 0.241547, 0.274184], "internal": 1}
{"paper_id": "W13-4028", "abstract": "The Wizard of Oz (WOZ) method has been used for a variety of purposes in early-stage development of dialogue systems and language technology applications, from data collection, to experimentation, prototyping and evaluation. However, software to support WOZ experimentation is often developed ad hoc for specific application scenarios. In this demo we present WebWOZ, a web-based WOZ prototyping platform that aims at supporting a variety of experimental settings and combinations of different language technology components. We argue that a generic and distributed platform such as WebWOZ can increase the usefulness of the WOZ method.", "title": "WebWOZ: A Platform for Designing and Conducting Web-based Wizard of Oz Experiments", "venue": "W", "graph_vector": [-0.241905, 0.302105, -0.0409201, 0.475364, 0.266677, -0.75747, 0.12962, -0.345475, -1.80196, 0.334517, -0.381634, -0.355016, 1.09124, 0.146362, -0.0524994, -0.0339496, 0.311458, -0.358523, -0.180782, 0.160369, -0.104953, 0.573991, 0.267524, 0.189796, -0.213627, 0.0371623, -0.1272, 0.274237, -0.244003, -0.22493, -0.163981, 0.305691, -0.00682509, -0.751973, -0.126639, 0.0575872, -0.371536, 0.957255, 0.148058, 0.0225026, -0.0213518, -0.311572, -0.560573, 0.677001, 0.901818, -0.79261, -0.067648, 0.0935597, -0.101294, 0.0668926, 0.375773, -0.269592, 1.11174, 0.964029, -0.105167, 0.038322, 0.067081, 0.296242, -0.210548, 0.0644889, -0.205285, -0.0290295, 0.00327481, 0.148716, 0.0686216, -0.189094, 0.403226, 0.0472639, 0.291681, 0.107546, 0.111676, 0.331683, -0.0652768, -0.231149, 0.203967, 0.111895, -0.407798, -0.0409656, -0.613341, 0.157427, 0.0621768, 0.201138, -0.0160483, -0.416422, 0.160476, -0.574317, 0.131804, -0.238877, 0.0761269, -0.476118, 0.0226121, 0.0428174, -0.774954, -0.323902, 0.148961, 0.108836, -0.0524872, -0.374867, 0.062938, -0.32545, 0.0258965, -0.166436, 0.298562, 0.0163089, 0.0636398, 0.147113, -0.08521, -0.218639, 0.352042, -0.15384, -0.295934, 0.1139, -0.430383, -0.247064, 0.0962763, -0.403767, -0.190111, 0.274346, -0.0205984, 0.228493, 0.0567517, 0.0482047, -0.103595, -0.380322, 0.285661, 0.104398, -0.115333, 0.275847], "internal": 1}
{"paper_id": "W13-0112", "abstract": "We present a model for compositional distributional semantics related to the framework of Coecke et al. (2010), and emulating formal semantics by representing functions as tensors and arguments as vectors. We introduce a new learning method for tensors, generalising the approach of Baroni and Zamparelli (2010). We evaluate it on two benchmark data sets, and find it to outperform existing leading methods. We argue in our analysis that the nature of this learning method also renders it suitable for solving more subtle problems compositional distributional models might face.", "title": "Multi-Step Regression Learning for Compositional Distributional Semantics", "venue": "W", "graph_vector": [-0.024952, 0.243265, 0.174722, 0.249175, 0.724583, -0.578074, 0.347528, 0.0288587, -1.59078, 0.25943, 0.295597, -0.360728, 0.570864, 0.183952, 0.278981, -0.316941, 0.243278, -0.596416, 0.152976, 0.442596, -0.143344, 0.620296, 0.0799957, -0.0574373, -0.73339, 0.0030125, -0.0658918, 0.210948, -0.164265, -0.313833, -0.0530931, -0.346868, 0.130534, -0.0158158, -0.202749, 0.0978347, -0.518879, 0.48936, 0.047559, 0.160491, -0.0676766, -0.282139, -0.251579, 0.537641, 1.04312, -0.807107, -0.114839, 0.0510725, -0.234775, 0.298862, 0.381998, -0.186318, 0.856371, 0.574996, -0.156819, -0.380858, 0.593311, 0.384922, -0.0995291, -0.170654, 0.0198774, -0.268763, -0.041789, 0.268764, 0.115982, 0.0789064, -0.0684871, -0.0376526, -0.0512475, 0.0814488, 0.162552, 0.0369557, 0.557116, -0.262286, -0.187568, -0.211222, -0.470193, -0.590466, -0.0675267, -0.113809, 0.00416355, 0.242637, -0.281998, -0.761044, 0.183163, -0.215006, -0.0955066, -0.0809392, -0.0242524, 0.207428, -0.244255, 0.0462841, -0.387975, -0.084301, -0.154985, 0.170097, -0.233109, -0.289692, -0.0795431, -0.21382, -0.0339668, -0.485693, 0.0764772, -0.12783, -0.02267, 0.0549296, 0.154926, -0.256512, 0.249838, -0.564304, -0.0298004, -0.0216109, -0.0919557, 0.0243306, 0.128355, -0.0679164, 0.31437, 0.200122, -0.0653335, 0.162062, -0.364454, 0.169998, 0.034809, -0.333175, 0.351921, -0.10564, 0.0459965, 0.265626], "internal": 1}
{"paper_id": "W13-5007", "abstract": "Bootstrapping has recently become the focus of much attention in natural language processing to reduce labeling cost. In bootstrapping, unlabeled instances can be harvested from the initial labeled “seed” set. The selected seed set affects accuracy, but how to select a good seed set is not yet clear. Thus, an “iterative seeding” framework is proposed for bootstrapping to reduce its labeling cost. Our framework iteratively selects the unlabeled instance that has the best “goodness of seed” and labels the unlabeled instance in the seed set. Our framework deepens understanding of this seeding process in bootstrapping by deriving the dual problem. We propose a method called expected model rotation (EMR) that works well on not well-separated data which frequently occur as realistic data. Experimental results show that EMR can select seed sets that provide significantly higher mean reciprocal rank on realistic data than existing naive selection methods or random seed sets.", "title": "", "venue": "W", "graph_vector": [0.146721, 0.385615, 0.141344, 0.0469359, 0.269181, -0.564804, 0.105434, 0.419231, -1.65247, 0.434271, -0.080409, -0.386994, 0.489154, 0.091043, -0.149674, 0.196995, 0.271156, -0.565992, 0.0256212, 0.624098, -0.545137, 0.382732, 0.131677, -0.166027, -0.454629, 0.0147349, -0.201902, -0.0587194, -0.195706, -0.100776, -0.0644557, -0.223181, -0.00720526, -0.429551, -0.098737, -0.126201, -0.709972, 0.859295, 0.060686, -0.324363, -0.132795, -0.400852, -0.207491, 0.406327, 0.76569, -0.67497, -0.0131972, -0.118739, -0.086127, -0.0293279, 0.531043, -0.501448, 0.731071, 0.679992, -0.392203, -0.161314, -0.222917, 0.298876, -0.181824, 0.137787, -0.198279, -0.20591, 0.315514, 0.0272296, -0.00891397, -0.365436, 0.266748, -0.127864, 0.0484915, -0.115223, 0.302207, 0.0455057, -0.0175733, 0.18349, -0.0615306, -0.218171, -0.611823, -0.460504, 0.16439, 0.0445682, 0.165184, 0.158681, 0.0757465, -0.153819, 0.360322, 0.353287, -0.0709446, -0.112217, -0.280275, -0.2741, 0.116778, -0.0313448, -0.665061, -0.0202507, 0.104365, 0.0726469, 0.18825, -0.122672, -0.0523967, -0.492738, -0.272267, -0.335561, -0.120165, 0.0407581, 0.250936, -0.0826866, 0.00941061, -0.125439, -0.149846, -0.0547549, -0.332186, 0.280337, 0.117006, 0.102052, -0.0341606, -0.0752554, 0.116676, 0.196562, -0.222788, 0.0458441, 0.0755406, -0.589403, -0.228387, 0.176884, 0.519461, 0.278144, -0.477538, 0.0643244], "internal": 1}
{"paper_id": "W13-3102", "abstract": "This document overviews the strategy, effort and aftermath of the MultiLing 2013 multilingual summarization data collection. We describe how the Data Contributors of MultiLing collected and generated a multilingual multi-document summarization corpus on 10 different languages: Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian and Spanish. We discuss the rationale behind the main decisions of the collection, the methodology used to generate the multilingual corpus, as well as challenges and problems faced per language. This paper overviews the work on Czech, Hebrew and Spanish languages.", "title": "Multi-document multilingual summarization corpus preparation, Part 2: Czech, Hebrew and Spanish", "venue": "W", "graph_vector": [-0.241548, 0.445422, 0.15105, 0.240444, 0.624646, -1.03412, -0.362449, 0.141799, -1.76959, 0.246075, -0.100452, -0.281155, 0.850673, 0.404813, 0.098276, 0.0911076, 0.591674, -0.481588, 0.044764, 0.439849, -0.263135, 0.418658, 0.623061, -0.379962, -0.598199, 0.142868, -0.297231, -0.18472, -0.335053, -0.324905, 0.188983, -0.0745858, 0.440581, -0.568664, -0.133531, 0.0372777, -0.254008, 0.580632, 0.481224, -0.224687, -0.00683474, -0.221835, -0.348328, 0.49963, 1.07847, -0.586377, -0.0931062, 0.546227, -0.100353, 0.256962, 0.181293, 0.354547, 0.620284, 0.786843, -0.00741386, 0.349854, 0.396255, 0.256659, -0.295341, 0.264991, -0.230358, -0.411662, 0.263695, 0.148402, -0.205961, 0.291372, 0.276887, -0.525978, 0.087022, -0.086546, -0.145816, -0.0159274, -0.186176, -0.0720906, 0.290272, -0.187268, -0.323071, -0.462326, 0.0389403, -0.374428, -0.0146954, 0.232299, 0.0685108, 0.166558, 0.0317432, -0.291502, -0.0331199, -0.0483911, 0.0699325, -0.212024, -0.0200357, 0.119808, -1.23829, -0.164705, -0.10232, 0.174099, 0.412273, -0.541803, 0.231595, -0.0282346, -0.257347, -0.0111046, 0.178103, 0.237314, 0.407913, 0.03492, 0.144238, -0.0822486, 0.0427065, 0.241387, 0.0411415, 0.154776, 0.119487, -0.0462555, -0.00767099, -0.229068, 0.771978, -0.025489, -0.00299207, 0.440577, 0.00775318, -0.00532914, -0.102665, -0.135014, 0.407966, -0.0878108, -0.309278, -0.242645], "internal": 1}
{"paper_id": "W13-0123", "abstract": "Current approaches to recognizing discourse relations rely on a combination of shallow, surfacebased features (e.g., bigrams, word pairs), and rather specialized hand-crafted features. As a way to avoid both the shallowness of word-based representations and the lack of coverage of specialized linguistic features, we use a graph-based representation of discourse segments, which allows for a more abstract (and hence generalizable) notion of syntactic (and partially of semantic) structure. Empirical evaluation on a hand-annotated corpus of German discourse relations shows that our graphbased approach not only provides a suitable representation for the linguistic factors that are needed in disambiguating discourse relations, but also improves results over a strong state-of-the-art baseline by more accurately identifying Temporal, Comparison and Reporting discourse relations.", "title": "Subgraph-based Classification of Explicit and Implicit Discourse Relations", "venue": "W", "graph_vector": [0.22131, 0.354088, -0.28336, -0.171327, 0.247519, -0.948624, -0.049356, -0.267547, -2.04587, -0.252113, -0.406501, -0.426893, 0.622301, 0.188721, 0.415916, 0.00442921, 0.0330189, -0.462009, 0.375252, 0.346126, -0.322393, 0.282922, -0.0390017, -0.246852, -0.661602, 0.282229, 0.00651498, -0.28716, -0.257163, -0.579395, -0.0391896, -0.20337, -0.187382, -0.513791, -0.00950852, -0.645162, -0.152183, 0.925854, -0.0383947, -0.117541, -0.077315, -0.41635, 0.116237, 0.288389, 0.579281, -0.75081, -0.113329, 0.22795, -0.506321, -0.0336567, 0.310007, -0.15728, 1.12769, 0.678359, -0.24939, 0.475169, -0.0362738, 0.141392, -0.192283, 0.100511, -0.39237, -0.395855, -0.00140127, 0.25214, -0.00734593, -0.401276, 0.410853, 0.0688535, -0.0899649, 0.145948, 0.0965711, 0.235607, 0.0762972, -0.0513204, 0.0294698, -0.0954993, -0.600636, 0.168379, 0.00916517, 0.10675, -0.155284, -0.0414398, 0.36417, -0.259901, -0.00461292, -0.410848, -0.0118604, 0.0316005, 0.260419, -0.152598, -0.0691033, 0.173617, -0.479621, -0.0939874, -0.151859, 0.183382, -0.0639538, 0.378937, 0.0722734, 0.228411, 0.0243884, -0.0985677, 0.0285386, -0.134261, -0.273613, 0.368158, -0.352473, 0.322139, -0.227401, 0.0222548, 0.0590998, 0.180058, 0.34706, -0.398695, -0.0978608, 0.15125, 0.511425, 0.12281, 0.162844, 0.488432, -0.205435, -0.0270435, 0.183895, 0.122677, 0.39093, 0.113971, 0.34363, -0.0786309], "internal": 1}
{"paper_id": "W13-3518", "abstract": "Previous incremental parsers have used monotonic state transitions. However, transitions can be made to revise previous decisions quite naturally, based on further information. We show that a simple adjustment to the Arc-Eager transition system to relax its monotonicity constraints can improve accuracy, so long as the training data includes examples of mistakes for the nonmonotonic transitions to repair. We evaluate the change in the context of a stateof-the-art system, and obtain a statistically significant improvement (p < 0.001) on the English evaluation and 5/10 of the CoNLL languages.", "title": "A Non-Monotonic Arc-Eager Transition System for Dependency Parsing", "venue": "W", "graph_vector": [0.193823, 0.325398, 0.0212796, 0.338008, 0.863558, -0.900323, 0.0511525, -0.166778, -1.67075, -0.0249557, -0.00953024, -0.309521, 0.397062, 0.112021, 0.0346381, -0.418275, 0.617721, -0.553838, -0.0536681, 0.365978, -0.134988, 0.759952, 0.212553, -0.174016, -0.385714, 0.0708704, 0.461697, -0.000915835, -0.169627, -0.306745, -0.0986453, 0.112348, 0.116378, -0.47077, -0.316632, 0.0552896, -0.255521, 0.620631, 0.0211829, -0.144009, 0.291208, -0.179658, 0.0251393, 0.380491, 0.836255, -1.02917, 0.248049, 0.0786524, -0.0963077, 0.410269, 0.233051, -0.406818, 0.569559, 0.639269, -0.283122, 0.136248, -0.484785, 0.0908894, -0.302846, -0.127182, -0.40361, -0.219266, -0.124263, 0.00750963, -0.0981543, 0.0572689, -0.137585, -0.219913, 0.146384, 0.195207, 0.060057, 0.0507827, -0.205908, 0.175575, 0.28965, -0.175908, -0.520364, -0.219148, -0.0842503, -0.010315, -0.0565471, -0.0859176, 0.282812, -0.0699068, 0.287903, -0.204652, -0.0478288, -0.0410521, 0.260716, -0.187172, 0.0417844, 0.137522, -0.508403, -0.0126657, 0.295149, -0.150048, -0.345967, -0.160262, 0.0285793, -0.172446, 0.252927, -0.375143, 0.121732, -0.457269, -0.0269836, 0.201471, -0.220781, -0.133388, 0.213957, -0.215738, 0.0314393, 0.134668, 0.104337, 0.299123, 0.246989, 0.179665, 0.242916, 0.238911, -0.0737171, 0.157312, 0.326553, -0.180047, -0.148248, -0.431651, 0.347637, 0.2827, -0.0532201, 0.0339504], "internal": 1}
{"paper_id": "W13-0111", "abstract": "This paper addresses the task of finding antecedents for locally uninstantiated arguments. To resolve such null instantiations, we develop a weakly supervised approach that investigates and combines a number of linguistically motivated strategies that are inspired by work on semantic role labeling and corefence resolution. The performance of the system is competitive with the current state-of-the-art supervised system.", "title": "Towards Weakly Supervised Resolution of Null Instantiations", "venue": "W", "graph_vector": [-0.196944, 0.140087, 0.241386, 0.206244, 0.702699, -0.601525, 0.045982, -0.515152, -1.29351, 0.43272, 0.00725025, -0.296022, 0.838101, 0.131396, -0.442801, 0.108138, 0.467525, -0.812823, 0.367208, 0.463081, -0.518278, 0.390731, -0.126266, 0.146265, -0.38289, 0.134928, -0.0633914, 0.140369, -0.345762, 0.0708835, 0.0815481, 0.010447, 0.119479, -0.424244, 0.136339, 0.0498166, -0.58039, 1.00874, 0.153324, -0.0307984, -0.0306982, -0.385835, -0.0305624, 0.470202, 0.873028, -1.08918, 0.0832421, 0.300714, 0.42064, 0.20762, -0.245895, -0.317323, 0.784707, 0.72867, -0.174681, 0.24825, 0.163921, 0.213398, 0.137953, -0.0851214, 0.0318516, -0.129833, -0.210159, -0.0828833, -0.198904, -0.199444, 0.378823, -0.14701, 0.46301, 0.0198198, 0.208659, -0.196528, -0.0308621, 0.0337494, 0.0515594, -0.375216, -0.392126, -0.268636, 0.283498, 0.237839, 0.0536248, -0.0594177, -0.246007, -0.162393, -0.00575707, -0.404877, 0.403388, -0.122155, 0.580187, 0.0737532, 0.072659, -0.172703, -0.486517, -0.390648, -0.151593, -0.224834, 0.200062, 0.0629619, -0.158388, -0.346229, 0.0940101, -0.175764, 0.136074, 0.0913269, 0.320175, 0.173701, -0.038144, -0.13615, 0.0116057, -0.189486, -0.0733702, 0.0549736, -0.00221199, 0.0633302, -0.0886869, 0.130507, 0.363326, 0.228451, 0.320409, 0.0283255, -0.0619604, 0.491227, -0.0176094, 0.000401932, 0.673869, 0.0976307, 0.24275, 0.100202], "internal": 1}
{"paper_id": "W13-4603", "abstract": "With the increase of the number of medical records written in an electronic format, natural language processing techniques in the medical domain have become more and more important. For the purpose of the development and evaluation of machine learning-based systems to extract medical information, we recently participated in the NTCIR-10 MedNLP task. The task focused on Japanese medical records and aimed at evaluating different information extraction techniques on the common data set provided by the organizers. We implemented our baseline system based on structured perceptron and have developed its extensions. In this paper, we describe our systems and report on the evaluation of and the analysis on their performance.", "title": "Developing ML-based Systems to Extract Medical Information from Japanese Medical History Summaries", "venue": "W", "graph_vector": [-0.0331521, -0.143822, 0.130173, 0.35442, 0.475463, -0.591861, -0.203121, -0.139416, -1.49388, 0.0554842, 0.0705977, -0.685528, 0.956895, 0.328239, -9.72033e-05, -0.115853, 0.514291, -0.448088, 0.197524, 0.559624, -0.167145, 0.709537, 0.0310036, 0.118027, -0.0478602, -0.311221, -0.150892, 0.109076, -0.155513, -0.149098, -0.0218859, -0.204475, 0.179196, -0.222537, 0.296191, 0.0944394, -0.112742, 0.972409, 0.0820954, -0.0343381, 0.273203, -0.867756, -0.185946, 0.367787, 0.933234, -0.603423, 0.0119576, 0.222085, -0.137289, -0.229528, 0.131595, -0.298042, 0.563961, 0.765032, -0.51813, 0.0276654, 0.121464, 0.28731, 0.0879481, 0.141918, -0.447716, -0.0131349, -0.0766097, -0.301235, -0.452564, 0.12033, 0.376825, 0.189122, 0.214238, 0.182771, 0.00869842, 0.0476712, 0.0576012, -0.0172096, -0.000357785, -0.283349, -0.508977, -0.193278, -0.00442984, -0.261121, -0.276011, -0.374815, 0.234795, 0.132258, 0.0609638, -0.403357, 0.243702, -0.262574, 0.234639, 0.0122167, 0.0339712, -0.153056, -0.653527, 0.107774, 0.235821, -0.192927, -0.158712, -0.0143937, 0.115331, 0.232026, 0.00377108, -0.271541, 0.318907, 0.0447295, 0.0730902, 0.085167, -0.04279, 0.140132, 0.322868, -0.0504804, -0.00673465, 0.288395, -0.303337, -0.203564, -0.245756, 0.265835, 0.442461, -0.0839251, 0.381784, 0.0161946, 0.044006, 0.313603, -0.083869, -0.263858, 0.17784, 0.422447, -0.309673, -0.0735065], "internal": 1}
{"paper_id": "W13-1803", "abstract": "We present a finite state technology based system capable of performing metrical scansion of verse written in English. Scansion is the traditional task of analyzing the lines of a poem, marking the stressed and non-stressed elements, and dividing the line into metrical feet. The system’s workflow is composed of several subtasks designed around finite state machines that analyze verse by performing tokenization, part of speech tagging, stress placement, and unknown word stress pattern guessing. The scanner also classifies its input according to the predominant type of metrical foot found. We also present a brief evaluation of the system using a gold standard corpus of human-scanned verse, on which a per-syllable accuracy of 86.78% is reached. The program uses open-source components and is released under the GNU GPL license.", "title": "ZeuScansion: a tool for scansion of English poetry", "venue": "W", "graph_vector": [-0.155198, 0.259867, 0.00374824, 0.337734, 0.336181, -0.582763, 0.00444815, 0.00614745, -1.88755, 0.0344773, -0.00722555, -0.0380149, 0.932605, 0.0278674, -0.136652, -0.347304, 0.372666, -0.382906, 0.547267, 0.537418, -0.449745, 0.647136, 0.214263, -0.616389, -0.202458, 0.0989369, 0.12149, -0.0155343, 0.103811, -0.335649, 0.0339792, 0.128954, -0.0853093, -0.15793, -0.624252, 0.493025, 0.145966, 0.524976, 0.104775, 0.0722676, -0.216296, -0.383953, -0.576923, 0.11789, 0.830228, -0.807883, 0.179056, 0.0158779, 0.0583388, 0.099231, 0.582386, -0.55038, 0.634666, 0.519389, 0.243163, 0.225804, 0.38581, -0.00550049, -0.0946166, 0.0424917, -0.36437, -0.0683678, -0.268099, -0.452582, -0.0873537, -0.113216, 0.213181, -0.288896, -0.0546239, -0.320054, -0.160192, -0.0289912, -0.207721, -0.29815, 0.433451, -0.0583945, -0.674553, -0.332313, 0.157082, -0.0364569, -0.0698895, 0.320876, -0.167667, -0.132067, 0.258373, 0.226793, 0.0729404, -0.117893, 0.234837, 0.148627, 0.292363, 0.0982635, -0.277859, -0.00238615, 0.103842, -0.135176, -0.195688, 0.119333, -0.215539, 0.281211, 0.0550802, -0.302156, 0.191967, -0.0346284, 0.105373, 0.112835, 0.00621401, -0.269145, -0.0696645, -0.16769, -0.0790038, 0.0231776, 0.381653, -0.196738, -0.0121932, 0.278464, 0.209697, 0.234501, -0.0460918, 0.161201, -0.358641, 0.320779, -0.395229, -0.0818892, 0.338619, 0.229589, 0.229379, -0.432453], "internal": 1}
{"paper_id": "W13-4060", "abstract": "We demonstrate a robotic agent in a 3D virtual environment that understands human navigational instructions. Such an agent needs to select actions based on not only instructions but also situations. It is also expected to immediately react to the instructions. Our agent incrementally understands spoken instructions and immediately controls a mobile robot based on the incremental understanding results and situation information such as the locations of obstacles and moving history. It can be used as an experimental system for collecting human-robot interactions in dynamically changing situations.", "title": "A Robotic Agent in a Virtual Environment that Performs Situated Incremental Understanding of Navigational Utterances", "venue": "W", "graph_vector": [0.270457, 0.161999, -0.0620562, 0.415083, 0.653781, -1.03113, 0.143624, -0.126732, -1.92259, 0.496397, -0.341752, -0.252806, 0.577771, 0.145697, -0.147935, -0.180631, 0.337286, -0.662547, 0.0900603, 0.21153, -0.418697, 0.262154, 0.516741, -0.13291, -0.0778972, -0.160484, -0.292033, 0.221556, 0.134661, -0.314783, 0.104375, 0.356291, -0.161898, -0.703375, -0.0789266, 0.365202, -0.0209373, 1.02121, 0.416066, 0.0448243, -0.049844, -0.774371, -0.358489, 0.631359, 0.966322, -1.01849, -0.281873, -0.251592, -0.0469716, -0.0909559, 0.616103, -0.379245, 1.03718, 0.71343, 0.201875, -0.169091, 0.0619432, -0.0935734, -0.319558, -0.15737, 0.0654319, -0.0265152, -0.158781, -0.0214963, 0.0242792, -0.00654692, 0.188271, -0.114551, -0.269262, -0.134621, -0.187089, -0.139623, 0.00221528, -0.0187142, -0.418049, 0.413791, -0.3616, -0.291351, -0.163358, 0.338653, 0.0421304, 0.1673, 0.431582, -0.123127, -0.11592, -0.465717, -0.0514528, -0.281443, 0.313637, -0.324528, -0.0497293, -0.0401409, -0.768653, -0.399713, -0.142772, 0.3329, -0.319926, 0.0820776, -0.255367, -0.285291, -0.378901, -0.389318, 0.39709, 0.165475, 0.0244505, -0.22411, 0.199114, -0.223932, -0.0630311, -0.00312193, -0.4294, 0.00219198, -0.143902, 0.285643, -0.334283, -0.32857, 0.0129408, 0.0270048, -0.0256133, 0.276301, 0.170017, 0.100823, 0.0384352, -0.463, 0.199406, 0.15532, 0.00461509, -0.262731], "internal": 1}
{"paper_id": "W13-4102", "abstract": "This paper proposes a method to extract sentiment topics from a text collection. The method utilizes sentiment clues and a relaxed labeling schema to extract sentiment topics. Experiments with a quantitative and a qualitative evaluations was done to confirm the performance of the method. The quantitative evaluation with a polarity classification marked the accuracy of 0.701 in tweets and 0.691 in newswire texts. These performances are comparable to support vector machine baselines. The qualitative evaluation of polarity topic extraction showed an overall accuracy of 0.729, and a higher accuracy of 0.889 for positive topic extraction. The result indicates the efficacy of our method in extracting sentiment topics.", "title": "Topic Modeling with Sentiment Clues and Relaxed Labeling Schema", "venue": "W", "graph_vector": [0.0155918, 0.263401, 0.41222, 0.2189, 0.455589, -0.69005, -0.214752, -0.0699227, -1.88113, -0.0238346, -0.177547, -0.436475, 0.648561, -0.146517, -0.120131, 0.218346, 0.469515, -0.400135, -0.201566, -0.205354, -0.110474, 0.691557, 0.328988, 0.0758908, -0.193179, -0.117788, -0.0287638, 0.0441922, 0.0382692, -0.234205, 0.00573233, 0.0560764, 0.214868, -0.534414, 0.0722241, 0.538426, -0.369855, 0.262595, 0.0690026, -0.327115, -0.00244634, -0.352499, -0.505939, 0.60361, 0.750822, -1.00583, 0.101263, 0.145719, -0.15297, 0.136741, 0.191624, -0.175123, 0.799511, 0.708274, -0.0699697, -0.0710159, 0.143322, 0.184898, -0.179062, -0.0195144, -0.276589, 0.0537587, 0.177749, 0.16368, -0.29871, 0.139734, 0.14694, -0.114921, 0.338834, 0.0141273, -0.125724, 0.0308937, 0.163743, -0.443341, 0.198078, -0.311846, -0.572898, -0.285067, 0.00642771, -0.25835, -0.39868, 0.000855894, 0.174932, -0.28219, 0.0935339, 0.284356, 0.204806, -0.245746, 0.302533, 0.104455, 0.134167, -0.0690428, -0.52129, -0.344563, -0.0893266, 0.14549, -0.0703543, -0.192091, 0.0702773, 0.0720203, 0.0528844, -0.480883, -0.0968809, 0.0432114, -0.300799, -0.120901, -0.237539, -0.0179315, -0.106076, -0.177214, -0.0577007, 0.0337576, 0.0974815, -0.121762, 0.0394493, -0.256139, 0.367806, -0.0463039, -0.0449228, -0.0968893, -0.583003, -0.0896284, -0.263943, -0.157303, 0.205654, 0.212967, -0.126404, -0.223123], "internal": 1}
{"paper_id": "W13-0907", "abstract": "A metaphor is a figure of speech that refers to one concept in terms of another, as in “He is such a sweet person”. Metaphors are ubiquitous and they present NLP with a range of challenges for WSD, IE, etc. Identifying metaphors is thus an important step in language understanding. However, since almost any word can serve as a metaphor, they are impossible to list. To identify metaphorical use, we assume that it results in unusual semantic patterns between the metaphor and its dependencies. To identify these cases, we use SVMs with tree-kernels on a balanced corpus of 3872 instances, created by bootstrapping from available metaphor lists.1 We outperform two baselines, a sequential and a vectorbased approach, and achieve an F1-score of 0.75.", "title": "Identifying Metaphorical Word Use with Tree Kernels", "venue": "W", "graph_vector": [-0.185105, 0.187761, -0.0950887, 0.463551, 0.375322, -0.546746, 0.0867053, 0.0327567, -1.39569, 0.422094, -0.122595, -0.359768, 0.690721, -0.010746, -0.033886, 0.0817853, 0.492288, -0.626851, -0.127865, -0.197289, -0.575614, 0.436905, 0.473225, -0.291067, -0.658921, 0.0678199, 0.0152539, 0.076771, -0.227682, -0.065054, -0.366381, -0.347041, 0.221871, -0.362444, -0.17522, 0.214429, 0.103024, 0.564197, -0.258497, 0.161164, -0.452494, -0.261367, -0.332981, 0.0768078, 1.14056, -0.715684, 0.13269, 0.157695, -0.512122, 0.0672793, 0.477873, -0.399865, 0.906297, 0.567926, 0.198473, 0.00939637, -0.163602, -0.0739399, -0.630597, 0.00913874, 0.132557, -0.360708, 0.616631, -0.159286, -0.0657116, -0.0597724, 0.289112, 0.0276484, 0.0012306, 0.341417, 0.165212, -0.335102, 0.224592, -0.231126, 0.300957, 0.173802, -0.41027, -0.251576, -0.00717908, -0.0695633, -0.0531785, 0.157156, 0.170966, 0.166997, 0.0237105, -0.0771343, 0.691606, -0.0513385, 0.374419, -0.0165856, 0.0831809, -0.213821, -0.761496, -0.0581838, 0.228467, 0.0542083, -0.195074, 0.391388, -0.115788, 0.0329939, -0.182258, -0.321922, 0.106172, -0.180525, 0.145799, 0.19009, -0.421574, 0.0645381, 0.106779, -0.343728, -0.149771, -0.0717203, -0.232336, -0.0561662, -0.140804, 0.150829, 0.37501, -0.270674, 0.159225, 0.382056, 0.119715, 0.203382, -0.17686, 0.0679296, 0.220589, 0.329009, 0.272903, 0.262538], "internal": 1}
{"paper_id": "W98-0804", "abstract": "Large phonetic corpora including both standard and variant transcriptions are available for many languages. However, applications requiring the use of dynamic vocabularies make necessary to transcribe words not present in the dictionary. Also, additional alternative pronunciations to standard forms have shown to improve recognition accuracy. Therefore, new techniques to automatically generate variants in pronunciations have been investigated and proven to be very effective. However, rule-based systems still remain useful to generate standard transcriptions not previously available or to build new corpora, oriented chiefly to synthesis applications. The present paper describes a letter-to-phone conversion system for Spanish designed to supply transcriptions to the flexible vocabulary speech recomiser and to the synthesiser, both developed at CSELT (Centro Studi e Laboratori Telecomunicazioni), Turin, Italy. Different sets of rules are designed for the two applications. Symbols inventories also differ, although the IPA alphabet is the reference system for both. Rules have been written in ANSI C and implemented on DOS and Windows 95 and can be selectively applied. Two speech corpora have been transcribed by means of these grapheme-to-phoneme conversion rules: a) the SpeechDat Spanish corpus which includes 4444 words extracted from the phonetically balanced sentences of the database b) a corpus designed to train an automatic aligner to segment units for synthesis, composed of 303 sentences (3240 words) and 338 isolated words; rule-based transcriptions of this corpus were manually corrected. The phonetic forms obtained by the rules matched satisfactorily the reference transcriptions: most mistakes on the first corpus were caused by the presence of secondary stresses in the SpeechDat transcriptions, which were not assigned by the rules, whereas errors on the synthesis corpus appeared mostly on hiatuses and on words of foreign origin. Further developments oriented to recognition can imply addition of rules to account for Latin American pronunciations (especially Mexican, Argentinian and Paraguayan); for synthesis, on the other hand, rules to represent coarticulatory phenomena at word boundaries can be implemented, in order to transcribe whole sentences.", "title": "Grapheme-to-phoneme transcription rules for Spanish, with application to automatic speech recognition and synthesis", "venue": "W", "graph_vector": [-0.212967, 0.379626, 0.280931, 0.286455, 1.11806, -1.37764, -0.159343, 0.117953, -3.15206, 0.30336, -0.429349, -1.01831, 1.5948, 0.0153116, -0.431107, -0.203396, 0.984623, -1.08781, 0.2594, 0.433464, -0.681782, 1.35547, 0.780933, 0.0681488, -0.795064, 0.210902, -0.046108, 0.369243, -0.392113, -0.336187, 0.183194, 0.550865, -0.27631, -0.678016, -0.56023, 0.190528, -0.321268, 1.09527, 0.649904, 0.16037, 0.245989, -0.810433, -0.600908, 0.766007, 2.29183, -1.93532, 0.627842, 0.233369, -0.249966, -0.140462, 0.315441, -0.352114, 1.87934, 0.951704, -0.247818, 0.304006, 0.251685, 0.0142204, -0.0519447, -0.352396, -0.0453413, -0.343305, 0.0106282, -0.229104, -0.0692307, -0.0240698, 0.0521208, 0.152044, 0.324139, 0.485018, 0.510163, 0.336124, 0.225913, -0.362643, -0.0247713, -0.452983, -1.19464, -0.58893, -0.270341, 0.34746, -0.0149924, -0.14377, 0.409335, -0.196391, 0.753461, -0.363542, -0.0162811, -0.138627, -0.0208268, -0.30945, 0.0162064, 0.225967, -0.990075, -0.451057, -0.100056, 0.15362, 0.266626, -0.219398, -0.190069, 0.144662, -0.285167, -0.557189, 0.0499957, -0.0979602, -0.132018, -0.0886075, -0.332365, -0.132879, 0.540355, -0.298488, -0.407344, 0.166425, -0.537666, 0.281076, -0.388314, 0.205592, 0.403395, 0.239443, 0.407553, 0.589492, 0.0308375, 0.0957489, -0.378182, -0.0397371, 0.823213, 0.550321, -0.934476, 0.209455], "internal": 1}
{"paper_id": "W98-1403", "abstract": "", "title": "A developer's guide to the Longbow discourse planning- system.", "venue": "W", "graph_vector": [0.0349595, 0.16326, 0.0607868, 0.375528, 0.60158, -0.876981, 0.099868, -0.324122, -2.06866, -0.267194, -0.0249243, -0.486536, 0.199494, -0.172216, -0.303827, 0.264829, 0.598277, -0.535214, 0.266607, 0.506968, -0.208385, 0.2257, 0.414692, -0.159754, -0.161192, 0.171276, 0.102117, 0.0287016, -0.0955397, -0.108312, -0.139437, -0.0104493, 0.0699224, -0.353602, -0.453558, 0.367687, -0.280774, 0.675172, 0.147798, -0.316611, -0.0607596, -0.456066, -0.108978, 0.144506, 0.771711, -0.568633, -0.351371, -0.482386, 0.15143, -0.0695638, -0.032273, -0.0111232, 1.10008, 0.351904, -0.157509, -0.188266, 0.205876, 0.225098, 0.0401175, -0.055659, -0.556558, -0.429611, -0.118452, -0.115107, 0.235985, 0.222649, 0.201652, 0.245913, 0.631384, -0.161536, 0.115884, 0.0481616, -0.425622, 0.126933, -0.0143901, -0.00619213, -0.138711, -0.599518, 0.167935, 0.502725, -0.0676092, -0.266201, 0.152878, -0.022599, 0.359758, 0.00570688, -0.184817, 0.147122, -0.438734, -0.0899101, -0.108279, -0.0103361, -0.682851, -0.227858, -0.255242, 0.325083, -0.161789, -0.157848, 0.0162198, 0.0519265, -0.0983131, -0.299154, -0.343855, -0.025392, -0.246504, 0.103363, 0.0574306, -0.0679749, 0.331529, -0.368499, -0.13595, 0.394559, 0.211652, -0.231253, -0.432432, -0.00662713, 0.248023, 0.207523, 0.150797, 0.241719, 0.226703, 0.237775, 0.0982806, -0.193028, 0.20124, 0.284307, -0.2169, 0.364917], "internal": 1}
{"paper_id": "W98-1227", "abstract": "In this paper, we propose a method for constructing bigram LR tables by way of incorporating bigram constraints into an LR table. Using a bigram LR table, it is possible for a GLR parser to make use of both bigram and CFG constraints in natural language processing. Applying bigram LR tables to our GLR method has the following advantages:", "title": "A Method of Incorporating Bigram Constraints into an LR Table and Its Effectiveness in Natural Language Processing", "venue": "W", "graph_vector": [0.0288364, 0.0632002, 0.265312, 0.300755, 0.445433, -0.631277, 0.133245, 0.375473, -1.98344, -0.419062, -0.136843, -0.314146, 0.498759, 0.328824, -0.153373, -0.334695, 0.401437, -0.763618, 0.0660472, 0.263267, -0.721304, 0.515586, 0.276851, -0.995955, -0.32057, 0.0980247, 0.157772, -0.0961408, -0.171761, -0.392815, 0.25053, -0.0647855, 0.144248, -0.404838, -0.229774, 0.446653, -0.174659, 0.575755, -0.213131, -0.337909, 0.0306595, -0.461151, 0.127917, 0.830519, 0.814591, -1.20815, -0.140177, -0.170129, -0.57705, -0.0785447, 0.182272, 0.0553969, 1.00701, 0.691621, -0.566265, -0.285553, 0.817459, 0.442691, 0.0282783, -0.120206, -0.396007, 0.246459, 0.00273109, 0.0712686, -0.0487277, -0.0279367, 0.141884, -0.050487, -0.171845, 0.233529, -0.072617, -0.124205, -0.397892, 0.0696204, 0.0467681, -0.0839847, -0.483477, -0.290498, 0.15723, 0.190118, 0.230882, 0.0954461, -0.186441, 0.203909, 0.23822, 0.0738081, 0.0217699, -0.101192, -0.176329, -0.479226, -0.00213772, -0.215139, -0.59023, -0.184412, 0.187486, 0.194061, -0.0890928, 0.272166, -0.0454771, -0.25097, -0.389183, -0.175764, 0.286977, 0.0695658, -0.236691, 0.419119, 0.0582718, -0.119924, 0.0874975, -0.585521, 0.0155347, 0.353236, -0.235796, 0.261349, 0.355843, -0.0939293, 0.165588, 0.357341, 0.256717, -0.139548, -0.0280163, -0.103342, -0.278392, 0.166834, 0.382127, 0.235378, -0.232759, -0.381937], "internal": 1}
{"paper_id": "W98-1414", "abstract": "In text, discourse markers signal the kind of coherence relation holding between adjacent text spans; for example, because, since, and for this reason are different markers for causal relations. For any but the most simple applications of text generation, marker selection is an important aspect of producing cohesive text. However, present systems use markers in fairly simplistic ways and cannot make use of the full potential of markers that language offers for a given relation. To improve this situation, we propose a specialized lexicon for discourse markers, which holds the relevant constraints and preferences associated with the markers, and which can be used by a text generator to make an informed choice among alternative ways of expressing a relation in the given context. We demonstrate how the lexicon can be employed in the generation process and propose to perform discourse marker choice in the sentence planning stage, where the interactions with other generation decisions can be accounted for.", "title": "", "venue": "W", "graph_vector": [0.153333, 0.0629544, 0.10969, 0.30985, 0.127484, -0.654768, 0.214105, -0.0647032, -1.89901, 0.258192, 0.0323426, -0.460285, 0.414943, -0.00874999, -0.127761, -0.0719517, 0.441975, -0.524931, 0.326223, 0.310545, -0.146301, 0.650751, -0.087887, -0.0724267, -0.352558, 0.115892, 0.0416131, -0.121782, -0.215336, -0.0435718, -0.0629979, -0.0724286, 0.0715661, -0.548441, -0.119577, -0.0425338, -0.0554469, 0.359257, 0.256338, 0.153243, -0.054197, -0.0137278, -0.122207, 0.386629, 0.953774, -0.598457, -0.104253, 0.0646295, -0.22052, -0.149588, 0.450506, -0.0611902, 1.06623, 0.32589, -0.12119, 0.0397891, 0.204492, 0.0839883, 0.303012, -0.0111387, -0.616525, -0.220289, 0.0161441, -0.0573853, -0.196068, -0.302027, -0.0220604, -0.162687, -0.0187801, -0.185308, 0.0246374, -0.00681043, 0.145856, -0.589054, -0.265502, -0.0835122, -0.199972, -0.0848442, -0.382708, 0.173959, -0.00446675, 0.0934033, 0.0995719, -0.088134, -0.185188, 0.0141278, -0.0648159, 0.179846, 0.273, -0.233614, -0.110377, 0.29434, -0.442413, -0.164356, -0.147738, 0.198427, -0.195873, 0.0568887, 0.212587, -0.0381741, -0.402211, -0.346305, 0.159775, -0.2583, 0.16114, -0.135048, -0.329255, 0.0712947, -0.514078, 0.0526841, 0.101372, 0.205687, 0.427013, 0.0199791, 0.138044, 0.247956, 0.455247, 0.0618053, -0.22935, 0.0240015, -0.220747, 0.0427691, 0.0854446, -0.0684443, 0.174619, -0.0947676, 0.0590388, -0.0131746], "internal": 1}
{"paper_id": "W12-4203", "abstract": "This paper presents an approach to improving performance of statistical machine translation by automatically creating new training data for difficult to translate phenomena. In particular this contribution is targeted towards tackling the poor performance of a state-of-the-art system on negated sentences. The corpus expansion is achieved by high quality rephrasing of existing sentences to their negated counterparts making use of semantic transfer. The method is designed to work on both sides of the parallel corpus while preserving the alignment. Our results show an overall improvement of 0.16 BLEU points, with a statistically significant increase of 1.63 BLEU points when tested on only negated test data.", "title": "Enriching Parallel Corpora for Statistical Machine Translation with Semantic Negation Rephrasing", "venue": "W", "graph_vector": [-0.0038197, -0.0662386, 0.0432696, 0.102917, 0.541279, -0.724588, 0.387345, -0.248952, -1.67144, 0.743243, 0.0825061, -0.411378, 0.673793, -0.000814384, -0.111694, 0.0224196, 0.136782, -0.854459, -0.0259208, 0.34943, 0.0279746, 0.68284, 0.352088, -0.029158, -0.498084, -0.115381, 0.41208, -0.356378, -0.307175, 0.0929814, -0.270311, -0.153086, 0.128284, -0.204375, -0.411742, 0.109497, -0.348854, 0.62761, 0.176557, -0.148062, -0.155309, -0.49307, -0.532197, 0.532696, 0.757127, -0.510602, 0.189039, 0.0368381, -0.210602, -0.146603, 0.0783895, -0.276898, 0.474218, 0.637561, -0.275146, 0.349212, 0.51361, -0.10605, -0.388195, 0.069087, 0.0350073, -0.203022, -0.325285, -0.105092, -0.139768, 0.044584, 0.489519, 0.187028, 0.0406581, -0.0894188, -0.228559, -0.492081, 0.00696754, -0.310707, 0.296776, 0.0136547, -0.640497, -0.297473, -0.237163, 0.00509701, 0.397276, -0.0197388, -0.137038, -0.048236, 0.217067, -0.0722812, 0.112874, -0.130755, 0.199962, 0.0836656, 0.0869598, 0.191597, -0.671616, -0.170423, 0.245353, 0.118783, 0.0843648, 0.0861273, -0.0476648, 0.0554685, 0.0368147, -0.219989, -0.317151, 0.239303, -0.14495, 0.00683274, 0.209578, -0.261096, 0.168108, -0.200412, 0.0322814, 0.40821, -0.123914, -0.0110948, -0.673613, 0.225519, 0.556827, 0.453379, -0.0508851, -0.0569891, 0.329706, 0.180979, -0.0550426, -0.103943, 0.392321, 0.0688641, -0.301506, 0.222595], "internal": 1}
{"paper_id": "W12-2407", "abstract": "In the English clinical and biomedical text domains, negation and certainty usage are two well-studied phenomena. However, few studies have made an in-depth characterization of uncertainties expressed in a clinical setting, and compared this between different annotation efforts. This preliminary, qualitative study attempts to 1) create a clinical uncertainty and negation taxonomy, 2) develop a translation map to convert annotation labels from an English schema into a Swedish schema, and 3) characterize and compare two data sets using this taxonomy. We define a clinical uncertainty and negation taxonomy and a translation map for converting annotation labels between two schemas and report observed similarities and differences between the two data sets.", "title": "Medical diagnosis lost in translation – Analysis of uncertainty and negation expressions in English and Swedish clinical texts", "venue": "W", "graph_vector": [-0.0354293, 0.418961, 0.614469, -0.0399907, 0.429152, -0.681006, -0.137586, 0.0619068, -2.12379, -0.00185909, 0.0793053, -0.0819966, 0.695039, 0.00706895, -0.0527784, -0.314225, 0.331955, -0.40807, 0.3494, 0.432607, -0.354421, 0.566457, 0.476845, 0.303043, -0.62003, 0.327234, 0.769015, -0.0397416, -0.240373, 0.126282, 0.33412, 0.184552, -0.166608, -0.204881, -0.447736, 0.190844, -0.0727955, 0.58945, -0.0974587, -0.0583908, 0.00295777, -0.268085, -0.441929, -0.0261281, 0.894937, -1.01655, -0.0200767, 0.676614, 0.0463006, 0.116569, 0.329624, -0.344465, 0.812355, 0.296942, 0.0982536, -0.0292368, 0.276831, 0.0598718, 0.0393276, 0.277591, -0.422322, 0.0696902, -0.0187498, -0.212464, -0.240405, -0.226168, 0.111746, 0.00109713, 0.493437, -0.304725, 0.18657, -0.0742947, 0.163342, -0.023598, 0.325544, -0.316274, -0.577673, -0.537737, 0.20228, 0.484683, -0.355873, 0.289542, 0.0206263, -0.249025, -0.208552, -0.528413, 0.146227, -0.0964337, 0.232837, 0.0772436, 0.229601, 0.384339, -0.605108, 0.0725081, -0.486499, -0.00590016, -0.0367634, -0.00670949, 0.0741612, 0.139786, -0.639185, -0.480623, -0.321808, -0.0946379, -0.0154783, 0.0388895, 0.0315992, -0.237868, 0.067364, -0.72116, -0.102492, 0.111761, -0.220137, 0.0442722, -0.0963804, -0.108012, 0.626564, 0.0789297, -0.0225171, -0.0186491, 0.161945, 0.0211882, 0.255309, -0.231533, 0.258392, 0.12433, -0.436948, -0.0174936], "internal": 1}
{"paper_id": "W12-3620", "abstract": "Morphological segmentation data for the METU-Sabancı Turkish Treebank is provided in this paper. The generalized lexical forms of the morphemes which the treebank previously lacked are added to the treebank. This data maybe used to train POS-taggers that use stemmer outputs to map these lexical forms to morphological tags.", "title": "Morpheme Segmentation in the METU-Sabancı Turkish Treebank", "venue": "W", "graph_vector": [-0.136286, 0.39755, -0.0841995, 0.317559, 0.444672, -0.868072, -0.101433, -0.179837, -1.57257, 0.0818202, 0.11623, -0.228097, 0.603408, -0.157719, -0.0309565, -0.331433, 0.676591, -0.553968, 0.319414, 0.373771, -0.409698, 0.746047, 0.149786, -0.301408, -0.43115, 0.458894, -0.0958024, -0.143658, 0.241693, -0.0147746, -0.212097, 0.0328546, -0.0958081, -0.203737, -0.568128, 0.101613, -0.178167, 0.329007, 0.168267, -0.0852627, 0.0452196, -0.0713941, -0.576349, 0.032421, 1.25949, -0.39097, -0.189153, 0.279512, -0.225959, 0.184163, 0.731163, -0.525752, 0.657247, 0.296112, -0.00171401, 0.310722, 0.293904, 0.0398612, 0.125203, 0.106038, 0.106763, 0.0438547, -0.29148, -0.110792, 0.171992, -0.293188, -0.0811404, -0.128113, 0.167001, 0.288299, 0.191258, -0.250883, -0.327389, 0.0650858, 0.17319, -0.410853, -0.620111, -0.306078, 0.0884946, -0.21669, 0.253597, 0.173779, 0.136713, 0.191553, 0.0560175, -0.206531, -0.0568596, 0.0330678, 0.296527, 0.106015, 0.538068, 0.243304, -0.542703, -0.197513, -0.0142867, 0.0833753, -0.0289289, -0.337076, -0.077388, 0.000451601, 0.0416552, -0.082041, -0.178209, 0.0063206, 0.014431, 0.110284, -0.351777, -0.0990573, -0.0223055, -0.145037, 0.09582, 0.202102, -0.285612, -0.279184, -0.0161976, -0.123449, 0.134227, 0.480905, -0.0215056, 0.690804, -0.244042, -0.137179, -0.182631, -0.0727478, 0.341935, 0.455046, -0.174815, -0.148219], "internal": 1}
{"paper_id": "W12-5117", "abstract": "", "title": "O semantičeskom sinteze. Problemy kibernetiki,", "venue": "W", "graph_vector": [0.349563, 0.802659, 0.0710974, -0.299908, 0.540079, -0.957998, 0.359912, -0.317861, -1.42339, 0.232874, 0.00764483, -0.312191, 0.694509, 0.136673, 0.459794, 0.224288, 0.460607, -0.324942, 0.25476, 0.401417, -0.152792, 0.670819, 0.0891277, 0.2462, -0.390175, 0.120791, -0.0556553, 0.219387, -0.42294, -0.124241, -0.0379936, -0.273293, 0.413764, -0.318709, -0.0706389, 0.215792, -0.274643, 1.20705, 0.0120717, -0.0595919, 0.111322, -0.294656, -0.271475, 0.523531, 0.785484, -0.924025, -0.143868, 0.231607, 0.343048, 0.0464371, 0.373609, 0.0958614, 0.51742, 0.100484, -0.0393281, 0.0822759, 0.345088, -0.0961041, -0.0863105, 0.159825, -0.0266884, 0.335086, 0.386809, -0.226131, -0.0721432, -0.0881323, -0.0616686, -0.201403, -0.0652702, -0.36607, 0.0948741, 0.0269474, 0.254048, -0.356881, 0.209397, -0.0673454, -0.558788, -0.160857, 0.26747, 0.161396, 0.420102, -0.0576325, -0.489762, 0.429436, -0.162209, -0.488363, 0.449688, -0.152469, 0.505678, -0.23445, 0.244634, -0.549897, -0.55908, -0.45425, -0.103078, 0.147725, -0.219205, 0.00701985, 0.0102365, 0.213098, -0.112291, -0.387753, -0.0255424, 0.308526, 0.142466, 0.308013, -0.111182, -0.1911, 0.0901431, -0.542633, -0.333437, -0.102757, -0.259307, -0.0958998, -0.18865, -0.441819, 0.547552, 0.112191, 0.114639, -0.324437, 0.00232176, 0.0513348, -0.0598268, -0.0943333, 0.634363, -0.0330026, 0.123635, -0.157519], "internal": 1}
{"paper_id": "W12-4507", "abstract": "This paper presents a mixed deterministic model for coreference resolution in the CoNLL-2012 shared task. We separate the two main stages of our model, mention detection and coreference resolution, into several sub-tasks which are solved by machine learning method and deterministic rules based on multi-filters, such as lexical, syntactic, semantic, gender and number information. We participate in the closed track for English and Chinese, and also submit an open result for Chinese using tools to generate the required features. Finally, we reach the average F1 scores 58.68, 60.69 and 61.02 on the English closed task, Chinese closed and open tasks.", "title": "A Mixed Deterministic Model for Coreference Resolution", "venue": "W", "graph_vector": [0.0537039, -0.040249, -0.0193624, 0.521308, 0.555337, -0.4633, 0.0816862, -0.080116, -1.74482, 0.533586, -0.0568021, -0.310653, 0.594502, 0.255981, 0.25787, -0.00408695, 0.338638, -0.848739, 0.259701, 0.589011, -0.702697, 0.610459, 0.0129713, -0.143269, -0.36587, 0.183388, 0.19634, 0.359398, -0.136563, -0.249809, 0.0742396, 0.142813, 0.0186649, -0.49618, 0.0368152, 0.24705, -0.168417, 0.628081, 0.0193018, -0.126628, 0.165467, -0.399994, -0.130441, 0.174832, 0.839186, -0.683563, 0.203336, 0.073387, -0.161651, -0.0303002, 0.0837524, -0.0566913, 0.806609, 0.673114, -0.0119712, 0.00788923, -0.13364, 0.176343, -0.0074829, 0.052122, -0.259155, 0.0199396, 0.048203, -0.0587257, -0.149987, -0.180143, 0.300764, -0.107109, -0.0845698, 0.0585828, 0.121853, 0.0693468, 0.00787247, -0.233052, 0.0628143, -0.218265, -0.343866, -0.195768, -0.234552, -0.261601, 0.034772, 0.0509701, 0.0938184, -0.111938, 0.0943646, -0.54424, -0.0125789, -0.115292, -0.0539306, 0.146516, 0.253125, 0.0719201, -0.39083, 0.0245376, -0.0697204, -0.178689, 0.259944, -0.100089, 0.046145, 0.00618142, 0.038063, -0.308645, -0.0392024, 0.332369, -0.273489, 0.0330802, -0.0330342, 0.017382, 0.0829364, -0.193903, -0.179438, 0.0065435, 0.00895333, -0.076855, 0.0857841, -0.1547, 0.458533, 0.110801, 0.016808, 0.178553, 0.0380318, -0.0369621, 0.244443, -0.118398, 0.407248, 0.132587, 0.0423659, -0.00179773], "internal": 1}
{"paper_id": "W12-4408", "abstract": "In this paper, we describe our approach to English-to-Korean transliteration task in NEWS 2012. Our system mainly consists of two components: an letter-to-phoneme alignment with m2m-aligner,and transliteration training model DirecTL-p. We construct different parameter settings to train several transliteration models. Then, we use two reranking methods to select the best transliteration among the prediction results from the different models. One re-ranking method is based on the co-occurrence of the transliteration pair in the web corpora. The other one is the JLIS-Reranking method which is based on the features from the alignment results. Our standard and non-standard runs achieves 0.398 and 0.458 in top-1 accuracy in the generation task.", "title": "English-Korean Named Entity Transliteration Using Substring Alignment and Re-ranking Methods", "venue": "W", "graph_vector": [0.0375043, 0.294625, -0.18473, 0.132401, 0.280388, -0.319997, 0.396115, 0.08828, -1.87045, 0.138762, -0.0532369, -0.135351, 0.639213, -0.0212658, -0.163519, 0.0749886, 0.743964, -0.55261, 0.571063, 0.529004, -0.189085, 0.747894, 0.304922, -0.410444, -0.229344, -0.100886, 0.111931, 0.0411763, -0.144185, -0.313531, 0.00644046, 0.271154, 0.0244811, 0.0199997, -0.280803, 0.456564, 0.0480952, 0.870791, 0.322691, -0.053673, 0.132128, -0.817102, -0.599608, 0.524022, 0.602173, -0.921835, 0.102506, 0.178557, -0.000431259, 0.0208053, 0.123201, -0.537677, 0.82899, 0.734104, -0.0599962, 0.181326, 0.129907, 0.0362519, 0.307035, -0.0236735, 0.100324, 0.273642, 0.183972, -0.217343, -0.24712, -0.26985, 0.281998, 0.179705, -0.0518777, -0.134122, -0.0816766, -0.107001, 0.252341, -0.157453, 0.186642, -0.157613, -0.590647, -0.0745422, -0.0234845, -0.183858, 0.0521529, -0.0301131, 0.0378196, -0.133451, -0.34555, -0.180191, -0.0659015, -0.563018, -0.13856, -0.0195768, -0.298204, 0.0404896, -0.596245, -0.0417915, 0.159364, -0.144604, -0.0975187, 0.137081, -0.342677, -0.171375, 0.214246, -0.153697, 0.165568, 0.289466, -0.269898, -0.128671, -0.236062, -0.0692792, 0.0777717, -0.376222, -0.280846, 0.0284805, -0.331454, 0.0635787, -0.0729181, 0.212606, -0.075505, 0.171801, -0.234419, 0.359281, -0.0664055, -0.157814, -0.364868, -0.219923, 0.806672, 0.208255, 0.279211, 0.0204132], "internal": 1}
{"paper_id": "W12-0705", "abstract": "Relation extraction is frequently and successfully addressed by machine learning methods. The downside of this approach is the need for annotated training data, typically generated in tedious manual, cost intensive work. Distantly supervised approaches make use of weakly annotated data, like automatically annotated corpora. Recent work in the biomedical domain has applied distant supervision for proteinprotein interaction (PPI) with reasonable results making use of the IntAct database. Such data is typically noisy and heuristics to filter the data are commonly applied. We propose a constraint to increase the quality of data used for training based on the assumption that no self-interaction of realworld objects are described in sentences. In addition, we make use of the University of Kansas Proteomics Service (KUPS) database. These two steps show an increase of 7 percentage points (pp) for the PPI corpus AIMed. We demonstrate the broad applicability of our approach by using the same workflow for the analysis of drug-drug interactions, utilizing relationships available from the drug database DrugBank. We achieve 37.31 % in F, measure without manually annotated training data on an independent test set.", "title": "Improving Distantly Supervised Extraction of Drug-Drug and Protein-Protein Interactions", "venue": "W", "graph_vector": [-0.0290117, 0.102573, 0.312127, 0.143416, 0.438841, -0.638924, -0.051437, -0.141693, -1.78851, 0.706534, 0.316133, -0.0822594, 0.755582, 0.2861, -0.117985, 0.0381075, 0.63774, -0.855507, -0.00489581, -0.068823, -0.268239, 0.565704, 0.512716, -0.240021, -0.608713, 0.473965, -0.180848, -0.167717, -0.0127329, -0.32593, 0.0643903, 0.168818, 0.000208716, -0.685129, -0.298677, -0.0108685, -0.285414, 1.03286, 0.0861771, -0.248142, 0.13856, -0.56179, -0.277414, 0.329236, 0.580867, -0.813645, 0.437891, 0.256539, -0.00506052, 0.381167, 0.179331, -0.094188, 1.01937, 0.638022, 0.269803, 0.309942, 0.0942369, -0.0803472, 0.118598, 0.236974, -0.105635, -0.2935, 0.0768579, 0.0709152, -0.121129, 0.220941, 0.286211, -0.331409, -0.149455, 0.272087, -0.087092, -0.170588, -0.148727, 0.191976, 0.302227, 0.182976, -0.615651, -0.0683124, 0.44904, -0.111294, -0.312081, 0.143561, 0.0721494, -0.385594, 0.358276, -0.312945, 0.328246, -0.0805143, 0.236986, -0.111878, 0.0207461, 0.102004, -0.792791, 0.0977172, 0.138439, 0.0603878, -0.298632, -0.298425, -0.100617, -0.198386, -0.786101, -0.000503862, 0.236658, -0.0882802, -0.440933, -0.203502, 0.0418367, 0.213918, 0.315637, -0.31913, 0.167185, -0.284907, -0.10636, 0.00885332, -0.209292, -0.387887, 0.655437, -0.410449, -0.24191, 0.411949, -0.286981, -0.402645, -0.193445, 0.103443, 0.339779, 0.282184, 0.145669, 0.202673], "internal": 1}
{"paper_id": "W12-4802", "abstract": "Since Japanese and Chinese languages have too many characters to be input directly using a standard keyboard, input methods for these languages that enable users to input the characters are required. Recently, input methods based on statistical models have become popular because of their accuracy and ease of maintenance. Most of them adopt word-based models because they utilize word-segmented corpora to train the models. However, such word-based models suffer from unknown words because they cannot convert words correctly which are not in corpora. To handle this problem, we propose a character-based model that enables input methods to convert unknown words by exploiting character-aligned corpora automatically generated by a monotonic alignment tool. In addition to the character-based model, we propose an ensemble model of both character-based and word-based models to achieve higher accuracy. The ensemble model combines these two models by linear interpolation. All of these models are based on joint source channel model to utilize rich context through higher order joint n-gram. Experiments on Japanese and Chinese datasets showed that the character-based model performs reasonably and the ensemble model outperforms the word-based baseline model. As a future work, the effectiveness of incorporating large raw data should be investigated.", "title": "An Ensemble Model of Word-based and Character-based Models for Japanese and Chinese Input Method", "venue": "W", "graph_vector": [0.0258433, -0.0351804, -0.0720393, 0.418554, 0.21376, -0.842824, 0.0802465, -0.124705, -1.6713, -0.161337, -0.0290094, -0.166112, 0.951506, 0.122028, -0.325159, -0.171019, 0.37497, -0.789674, 0.470631, 0.404608, -0.410288, 0.520176, 0.224086, -0.517772, -0.291495, -0.0320657, -0.0981262, 0.0986764, -0.222915, -0.559992, 0.197067, -0.0904352, 0.404778, -0.402699, -0.344809, 0.470695, 0.22217, 0.665986, 0.469414, -0.208448, -0.0592991, -0.697711, -0.443374, 0.119004, 0.929194, -0.981848, -0.297797, 0.0270483, -0.292651, 0.120003, 0.350095, -0.389678, 0.760109, 0.545769, -0.35783, 0.174329, 0.415642, 0.444681, -0.00946951, -0.141503, -0.245872, 0.385637, -0.118411, -0.328942, -0.182522, -0.455066, 0.165659, -0.0740601, -0.118585, 0.196964, -0.00267637, 0.43668, -0.0499432, -0.263765, 0.254046, -0.0448004, -0.853119, -0.191767, 0.166509, -0.0523106, -0.214279, -0.213259, -0.2575, -0.116629, 0.333511, -0.323744, 0.00463705, -0.777148, -0.113819, -0.302712, -0.189088, 0.0851252, -0.450914, 0.125722, 0.252021, 0.124519, -0.0547941, 0.0271266, -0.180338, -0.0595073, -0.330127, -0.152038, 0.351217, 0.216986, 0.24667, -0.312519, 0.0138873, -0.0951434, 0.00676838, -0.384522, 0.141858, 0.248463, -0.0490725, 0.215284, -0.152365, -0.148598, 0.124852, 0.318592, -0.0959779, 0.161219, 0.065793, -0.274246, -0.458562, 0.11464, 0.305485, 0.128514, -0.109032, -0.0496623], "internal": 1}
{"paper_id": "W12-5101", "abstract": "", "title": "Lexicographie des dictionnaires virtuels.", "venue": "W", "graph_vector": [-0.075427, 0.191465, -0.0364541, -0.069477, 0.248939, -1.22473, 0.353369, 0.145074, -1.8234, 0.672406, -0.0330668, -0.393533, 0.692311, 0.137564, -0.00350869, 0.0804552, 0.149377, -0.583196, 0.241157, 0.15114, -0.637466, 0.839422, 0.227759, -0.35828, -0.0425923, 0.535771, 0.247985, 0.536528, -0.214541, 0.121062, 0.131381, -0.254911, -0.177333, -0.464618, -0.142415, 0.121198, 0.00175545, 0.994508, 0.285767, 0.0254918, -0.117305, -0.352349, -0.0868535, 0.733545, 1.31802, -0.521122, -0.22841, 0.16762, 0.107313, 0.246732, 0.309002, -0.066523, 0.464625, 0.855379, -0.104292, 0.396473, -0.120273, 0.213573, -0.273761, 0.0132002, -0.228, -0.25139, -0.0370842, 0.0966628, 0.211475, -0.0680704, -0.074451, -0.0299962, -0.313278, -0.302681, 0.329839, 0.204807, 0.20075, -0.267588, 0.169752, 0.153998, -0.415339, -0.446888, -0.0913412, 0.0935421, -0.452748, -0.343391, -0.0693282, -0.0101353, 0.0963057, -0.17457, -0.285703, -0.414738, -0.18142, 0.168521, 0.147709, 0.0837164, -0.680677, -0.776923, 0.187918, 0.204683, -0.0116224, 0.140319, -0.135413, -0.152249, -0.415928, -0.348834, -0.376059, -0.0265922, 0.0381145, 0.144302, -0.197724, 0.113063, 0.220022, -0.068623, 0.470791, 0.195873, 0.00123413, 0.139493, 0.314861, -0.268412, 0.356083, 0.275292, 0.0757406, 0.133006, -0.399954, 0.168548, -0.510534, 0.227769, 0.50645, -0.230269, -0.208088, -0.267471], "internal": 1}
{"paper_id": "W12-4512", "abstract": "This paper describes a coreference resolution system for CONLL 2012 shared task developed by HLT_HITSZ group, which incorporates rule-based and statistic-based techniques. The system performs coreference resolution through the mention pair classification and linking. For each detected mention pairs in the text, a Decision Tree (DT) based binary classifier is applied to determine whether they form a coreference. This classifier incorporates 51 and 61 selected features for English and Chinese, respectively. Meanwhile, a rule-based classifier is applied to recognize some specific types of coreference, especially the ones with long distances. The outputs of these two classifiers are merged. Next, the recognized coreferences are linked to generate the final coreference chain. This system is evaluated on English and Chinese sides (Closed Track), respectively. It achieves 0.5861 and 0.6003 F1 score on the development data of English and Chinese, respectively. As for the test dataset, the achieved F1 scores are 0.5749 and 0.6508, respectively. This encouraging performance shows the effectiveness of our proposed coreference resolution system.", "title": "Incorporating Rule-based and Statistic-based Techniques for Coreference Resolution", "venue": "W", "graph_vector": [-0.103807, 0.199622, -0.160662, 0.476211, 0.216996, -0.43504, -0.0178283, -0.0964009, -2.02509, 0.625247, -0.0561818, -0.500022, 0.582198, 0.170554, 0.310891, 0.020591, 0.575592, -0.65828, 0.240415, 0.291701, -0.581578, 0.602665, 0.00298463, -0.0516432, -0.382503, 0.305858, 0.0864742, 0.501912, -0.215168, -0.355001, 0.205432, -0.00996477, 0.104454, -0.735389, -0.0790816, 0.15941, -0.0301905, 0.674224, 0.233824, -0.441575, 0.184552, -0.439076, -0.32179, 0.479238, 0.637226, -0.913049, 0.0117679, -0.0136514, -0.171145, 0.0390368, -0.0318428, -0.126081, 0.634802, 0.610445, -0.0957809, 0.0982018, -0.0532726, 0.186143, -0.0495641, 0.0134254, -0.299389, -0.133097, 0.0155013, -0.0943523, -0.0377291, -0.144829, 0.43407, -0.245914, 0.164617, 0.164102, -0.0284022, 0.366685, 0.273451, -0.183176, -0.336538, -0.265244, -0.350184, -0.432335, -0.411596, 0.127582, 0.0413341, -0.0251711, 0.0646195, -0.0989862, 0.0350128, -0.366786, 0.0138487, -0.235129, -0.142835, 0.176872, 0.250633, -0.13363, -0.589625, 0.144905, -0.20845, -0.122654, 0.323268, -0.0320906, -0.182325, -0.227987, 0.171407, -0.193507, 0.0809883, 0.294328, -0.135751, -0.124011, -0.302704, -0.0789151, 0.0507114, -0.106574, -0.351725, -0.107676, 0.152582, -0.100005, 0.123298, -0.0207442, 0.377294, 0.393706, 0.0873093, 0.252703, 0.139141, -0.181071, 0.37642, -0.00447467, 0.448687, 0.477573, 0.123132, 0.0208254], "internal": 1}
{"paper_id": "W12-5211", "abstract": "Extraction of named entities (NEs) from the text is an important operation in many natural language processing applications like information extraction, question answering, machine translation etc. Since early 1990s the researchers have taken greater interest in this field and a lot of work has been done regarding Named Entity Recognition (NER) in different languages of the world. Unfortunately Urdu language which is a scarce resourced language has not been taken into account. In this paper we present a statistical Named Entity Recognition (NER) system for Urdu language using two basic n-gram models, namely unigram and bigram. We have also made use of gazetteer lists with both techniques as well as some smoothing techniques with bigram NER tagger. This NER system is capable to recognize 5 classes of NEs using a training data containing 2313 NEs and test data containing 104 NEs. The unigram NER Tagger using gazetteer lists achieves up to 65.21% precision, 88.63% recall and 75.14% f-measure. While the bigram NER Tagger using gazetteer lists and Backoff smoothing achieves up to 66.20% precision, 88.18% recall and 75.83 f-measure. KEYWORDS : Named Entity Recognition, Unigram model, Bigram model, Gazetteer lists, smoothing techniques", "title": "N‐gram and Gazetteer List Based Named Entity Recognition for Urdu: A Scarce Resourced Language", "venue": "W", "graph_vector": [0.173943, 0.35848, 0.41501, -0.184397, 0.321129, -0.535699, 0.0537343, 0.219206, -2.48232, 0.279067, 0.28075, -0.323766, 0.177064, -0.203273, -0.164337, -0.177358, 0.544541, -0.72061, 0.353368, 0.585621, -0.48573, 0.929301, 0.602097, 0.0683727, -0.424798, 0.176207, -0.12637, 0.0363991, 0.00888923, -0.309336, 0.288196, -0.309412, 0.354403, -0.226169, -0.0129544, 0.067038, -0.640914, 0.779332, 0.479879, -0.150754, -0.178662, -0.953011, -0.389121, 0.766684, 1.51467, -0.695965, 0.259933, 0.474701, 0.218818, 0.136857, 0.352191, -0.0804564, 0.491019, 1.13427, -0.182721, -0.0089131, 0.0720983, 0.23195, 0.337884, 0.0738752, -0.136772, -0.0633425, 0.125087, 0.117866, -0.41872, -0.22151, 0.410556, 0.0833911, -0.158946, 0.029397, 0.381064, 0.269878, 0.042912, -0.493746, 0.504655, 0.0844296, -0.347537, -1.03412, -0.0374032, 0.0748722, -0.116478, -0.426815, 0.020599, 0.100242, 0.383057, -0.131113, -0.177434, -0.104157, 0.224864, -0.298747, 0.201086, 0.207722, -0.811473, -0.178426, -1.01136, -0.345559, -0.360413, -0.212122, 0.267919, -0.211731, -0.0133767, -0.34561, -0.131914, -0.411365, 0.425472, 0.0286356, 0.163287, 0.526637, 0.556938, -0.418608, -0.269808, 0.290494, -0.277573, -0.329769, -0.246793, -0.0106601, 0.652469, 0.35779, 0.289226, 0.543939, -0.139042, 0.0594694, -0.667588, 0.349955, 0.660408, 0.412955, -0.356272, -0.0505019], "internal": 1}
{"paper_id": "W12-3810", "abstract": "In this paper we investigate two distinct tasks. The first task involves detecting arguing subjectivity, a type of linguistic subjectivity on which relatively little work has yet to be done. The second task involves labeling instances of arguing subjectivity with argument tags reflecting the conceptual argument being made. We refer to these two tasks collectively as “recognizing arguments”. We develop a new annotation scheme and assemble a new annotated corpus to support our learning efforts. Through our machine learning experiments, we investigate the utility of a sentiment lexicon, discourse parser, and semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results.", "title": "Recognizing Arguing Subjectivity and Argument Tags", "venue": "W", "graph_vector": [-0.26219, 0.149947, -0.0927325, -0.103216, 0.131011, -0.43215, 0.113307, -0.0925631, -1.79849, 0.19154, -0.270913, -0.362519, 0.548504, 0.156717, 0.0731564, -0.0396313, 0.0757527, -0.707692, 0.196181, 0.226466, -0.223416, 0.522155, 0.223821, -0.290289, -0.113586, 0.332623, -0.0118927, -0.174557, -0.514178, -0.169421, -0.162815, 0.426952, -0.198268, -0.422539, 0.0368617, 0.196877, -0.614114, 0.492492, -0.117971, -0.0358672, -0.319471, -0.217446, -0.286098, 0.250586, 0.99672, -1.00303, -0.17482, -0.14124, 0.0168774, 0.219268, 0.353314, -0.113189, 0.654458, 0.665037, -0.344204, 0.0216092, 0.296736, -0.0681003, 0.0291252, 0.105372, -0.123223, 0.250396, 0.210227, 0.00336339, 0.13208, 0.256458, 0.231191, -0.107242, 0.179379, 0.090773, 0.175038, 0.0441386, 0.145934, -0.283123, -0.13441, -0.145193, -0.47181, -0.0600626, 0.0755126, 0.0676294, -0.442685, -0.0650442, 0.221242, 0.145268, 0.0536462, -0.222662, -0.174571, 0.115079, -0.0989508, -0.0571713, -0.0840962, 0.5571, -0.634662, -0.0367527, 0.0107988, 0.0392959, 0.0225315, -0.00304015, 0.0229963, 0.137841, 0.0137917, -0.389339, -0.065147, 0.255887, -0.0278381, 0.102446, -0.0961478, -0.0833516, 0.0461561, 0.103435, -0.140565, 0.0912686, 0.59638, 0.0964948, -0.145147, 0.156783, 0.266841, -0.149673, -0.077112, 0.162413, 0.109597, -0.0397411, 0.463669, -0.375388, 0.512329, 0.0319349, -0.106561, -0.146164], "internal": 1}
{"paper_id": "W12-6303", "abstract": "Globalization and multilingualism contribute to code-switching – the phenomenon in which speakers produce utterances containing words or expressions from a second language. Processing code-switched sentences is a significant challenge for multilingual intelligent systems. This study proposes a language modeling approach to the problem of codeswitching language processing, dividing the problem into two subtasks: the detection of code-switched sentences and the identification of code-switched words in sentences. A codeswitched sentence is detected on the basis of whether it contains words or phrases from another language. Once the code-switched sentences are identified, the positions of the code-switched words in the sentences are then identified. Experimental results on MandarinTaiwanese code-switching sentences show that the language modeling approach achieved a 79.52% F-measure and an accuracy of 80.23% for detecting code-switched sentences, and a 51.20% F-measure for the identification of code-switched words.", "title": "A Language Modeling Approach to Identifying Code-Switched Sentences and Words", "venue": "W", "graph_vector": [0.0458912, 0.188168, 0.247717, 0.56538, 0.422518, -1.03602, 0.480777, -0.222715, -2.27222, -0.0849862, -0.162622, -0.211054, 1.11047, 0.257451, 0.107305, -0.780044, 0.812273, -1.15009, -0.346107, 0.581226, -0.371274, 0.804889, 0.514925, 0.228595, -0.417019, -0.539275, 0.087747, -0.0498967, -0.237106, -0.197303, 0.0352529, 0.0357793, 0.064648, -0.0573783, -0.139024, 0.348688, -0.34357, 0.873221, 0.652935, -0.4074, 0.126375, -0.621278, 0.0968099, 0.598328, 1.50988, -1.07346, -0.483525, 0.417957, -0.248412, 0.226806, 0.279147, -0.301597, 1.29511, 1.02802, -0.759774, 0.174367, 0.307936, 0.374061, -0.411581, 0.314192, -0.453239, -0.0102639, -0.81978, 0.264931, -0.167615, -0.370125, 0.464165, 0.131301, 0.206076, 0.152438, -0.104052, 0.511497, 0.233339, -0.134619, 0.0633893, -0.0638333, -0.992433, -0.559097, -0.336772, -0.389014, -0.0626978, 0.303393, -0.156004, -0.145974, 0.357446, -0.637371, -0.0755729, -0.531049, -0.00499356, -0.360368, 0.245587, 0.0665251, -0.642055, 0.0332829, -0.13323, 0.343307, 0.0116748, 0.146122, 0.179034, -0.120296, -0.240652, -0.588368, -0.160639, -0.234731, 0.47009, -0.296812, -0.0904678, -0.082207, 0.188108, -0.555234, 0.160459, 0.129756, -0.0915557, -0.0254059, -0.148114, 0.0899709, 0.110881, 0.453234, -0.0405511, 0.426538, 0.309812, -0.54034, -0.400363, 0.22646, 0.723091, -0.131843, 0.34567, 0.161252], "internal": 1}
{"paper_id": "W12-4502", "abstract": "We describe a machine learning system based on large margin structure perceptron for unrestricted coreference resolution that introduces two key modeling techniques: latent coreference trees and entropy guided feature induction. The proposed latent tree modeling turns the learning problem computationally feasible. Additionally, using an automatic feature induction method, we are able to efficiently build nonlinear models and, hence, achieve high performances with a linear learning algorithm. Our system is evaluated on the CoNLL2012 Shared Task closed track, which comprises three languages: Arabic, Chinese and English. We apply the same system to all languages, except for minor adaptations on some language dependent features, like static lists of pronouns. Our system achieves an official score of 58.69, the best one among all the competitors.", "title": "Latent Structure Perceptron with Feature Induction for Unrestricted Coreference Resolution Eraldo Rezende Fernandes", "venue": "W", "graph_vector": [0.140413, 0.153021, 0.0503218, 0.337465, 0.530949, -0.801577, 0.0681699, -0.201538, -1.38806, 0.129285, -0.257635, -0.274487, 0.841287, 0.460417, 0.109262, -0.336686, 0.0607372, -0.695289, 0.38707, 0.507163, -0.701808, 0.718432, 0.167699, -0.173653, -0.10538, 0.113079, 0.0856973, 0.522027, -0.0377544, -0.210058, 0.0321376, 0.38315, 0.185861, -0.296905, -0.00298498, 0.178421, -0.26583, 0.559353, 0.117723, -0.0679748, 0.136987, -0.285309, -0.188234, 0.168607, 0.670748, -0.785432, 0.0698621, 0.109757, -0.352312, 0.189864, 0.0663829, 0.0125457, 0.705081, 0.610539, -0.0825735, 0.0547587, -0.0988959, 0.327803, 0.197894, 0.113787, -0.103821, 0.154659, -0.182414, -0.335338, -0.201437, -0.357063, 0.377939, -0.0487872, 0.117684, 0.0579127, 0.184533, -0.0624515, -0.0834411, 0.0321268, 0.201495, -0.0140132, -0.748682, -0.141124, 0.0309226, -0.0450077, 0.0304911, 0.00303471, 0.123095, -0.0575778, -0.309662, -0.324945, -0.262205, -0.0386408, 0.123209, -0.169638, 0.184124, -0.100181, -0.546803, -0.0696077, 0.0972919, -0.230098, 0.155924, -0.122471, 0.127074, -0.0682491, -0.148178, -0.281036, 0.23905, 0.382358, -0.701928, -0.302815, -0.200527, 0.0824661, 0.0056784, -0.15098, -0.28364, 0.0850734, 0.00480971, -0.136088, 0.193448, -0.0767464, 0.180458, 0.127421, -0.0035424, 0.734193, 0.250228, -0.357252, 0.295344, 0.0493925, 0.502081, -0.010555, -0.245203, -0.134264], "internal": 1}
{"paper_id": "W12-4805", "abstract": "Most of the past error correction systems for ESL learners focus on local, lexical errors in a postprocessing manner. However, learners with low English proficiency have difficulties even constructing basic sentence structure, and many grammatical errors can be prevented by presenting grammatical phrases or patterns while they are writing. To achieve this, we propose an integrated writing environment for ESL learners, called phloat to help such users look up dictionaries to find semantically appropriate and grammatical phrases in real-time. Using the system, users can look up phrases by either English or their native language (L1), without being aware of their input method. It subsequently suggests candidates to fill the slots of the phrases. Also, we cluster suggested phrases with semantic groups to help users find appropriate phrases. We conduct subject tests using the proposed system, and have found the system is useful to find the right phrases and expressions. KEYWORDS: Writing Environment, Input Method, English as a Second Language, Suggestion of Patterns, Clustering of Candidates, Predicate Argument Structure.", "title": "phloat : Integrated Writing Environment for ESL learners", "venue": "W", "graph_vector": [0.337247, -0.12141, 0.037177, 0.532985, 0.503163, -0.610874, 0.118074, 0.143811, -1.56146, 0.255014, -0.30893, -0.460843, 1.07696, 0.133713, -0.304652, -0.129879, 0.13483, -0.974967, -0.076287, 0.394581, -0.562733, 0.271206, -0.11652, 0.50278, -0.954712, -0.155277, -0.0173362, 0.517931, -0.496481, -0.293904, 0.565922, 0.0470661, 0.673305, -0.25779, -0.237376, 0.0841281, -0.224994, 0.778785, 1.12401, -0.139363, -0.0730484, -0.00186045, -0.0454277, 0.723089, 1.19162, -1.06664, -0.200725, -0.391265, -0.18485, 0.118085, 0.154671, -0.32814, 0.526334, 0.359306, -0.403922, 0.284616, 0.225788, -0.131009, 0.242559, 0.34036, -0.400729, -0.0742348, 0.0661662, -0.338146, -0.00417668, -0.206031, 0.107471, 0.2923, -0.14182, 0.0510998, -0.0272794, -0.0795496, -0.313185, -0.128077, 0.160197, -0.297434, -0.385851, -0.413967, -0.49677, 0.438727, 0.425545, -0.148095, -0.072214, 0.20879, 0.224119, -0.566594, 0.206713, 0.267107, 0.156402, -0.124737, 0.0408137, -0.0132078, -0.64591, -0.0191683, 0.0989458, -0.157299, 0.29278, -0.0107076, 0.0558092, -0.278479, 0.0357116, -0.0888224, -0.0689111, -0.164323, -0.0591049, -0.12824, 0.124794, -0.193594, 0.104016, -0.622986, 0.212298, 0.34094, 0.0702064, 0.0472725, -0.375738, 0.157727, 0.43585, 0.0680771, 0.365557, 0.0543949, -0.168061, -0.359896, 0.0412059, -0.0416936, 0.436084, 0.472643, 0.182041, 0.274808], "internal": 1}
{"paper_id": "W08-0301", "abstract": "The treatment of ‘spurious’ words of source language is an important problem but often ignored in the discussion on phrase-based SMT. This paper explains why it is important and why it is not a trivial problem, and proposes three models to handle spurious source words. Experiments show that any source word deletion model can improve a phrase-based system by at least 1.6 BLEU points and the most sophisticated model improves by nearly 2 BLEU points. This paper also explores the impact of training data size and training data domain/genre on source word deletion.", "title": "An Empirical Study in Source Word Deletion for Phrase-based Statistical Machine Translation", "venue": "W", "graph_vector": [0.140985, 0.00423158, 0.0691686, 0.286909, 0.0609702, -0.617499, -0.135029, 0.129934, -1.49599, 0.220746, 0.0814439, -0.322959, 0.915335, 0.0592215, -0.0901897, -0.435009, 0.555283, -0.520746, 0.0301385, 0.497684, -0.357645, 0.38753, 0.210666, 0.202504, -0.0444901, -0.0817394, 0.150548, -0.179052, -0.260745, -0.168715, 0.0396949, 0.139801, 0.226002, -0.00983857, -0.140223, 0.145567, -0.14301, 0.568286, 0.261987, 0.0508954, 0.294606, -0.142636, -0.552024, 0.348136, 0.988078, -0.463559, 0.220883, 0.14626, -0.0379725, -0.498113, 0.296292, 0.00851994, 0.64997, 0.432796, -0.307371, 0.0516076, 0.384918, 0.0480863, 0.103295, 0.0577579, -0.394628, -0.252189, 0.192246, -0.0971989, 0.0292583, 0.0497037, 0.247265, -0.0201399, 0.113954, 0.143402, -0.0756467, 0.0422206, 0.233888, -0.18505, 0.27399, -0.0482093, -0.433671, -0.377954, -0.332981, -0.307237, -0.145499, -0.242184, 0.193763, -0.296287, 0.0091832, -0.0988401, -0.127446, -0.204704, -0.0135751, 0.0477972, 0.0494789, -0.0978702, -0.405985, -0.484976, 0.00960891, 0.292827, -0.0699616, 0.291584, 0.062693, -0.1052, 0.104235, -0.193095, 0.103716, -0.102326, 0.0632123, -0.159613, 0.060309, -0.166943, 0.464176, -0.120844, 0.0305189, 0.0517542, -0.300416, -0.3156, 0.0524317, -0.123024, 0.469784, -0.115674, 0.261269, 0.189372, 0.309197, -0.161218, 0.230888, -0.0134807, 0.172929, 0.359098, 0.173684, 0.332482], "internal": 1}
{"paper_id": "W08-0607", "abstract": "We explore a linguistically motivated approach to the problem of recognizing speculative language (“hedging”) in biomedical research articles. We describe a method, which draws on prior linguistic work as well as existing lexical resources and extends them by introducing syntactic patterns and a simple weighting scheme to estimate the speculation level of the sentences. We show that speculative language can be recognized successfully with such an approach, discuss some shortcomings of the method and point out future research possibilities.", "title": "Recognizing Speculative Language in Biomedical Research Articles: A Linguistically Motivated Perspective", "venue": "W", "graph_vector": [-0.0177678, 0.344777, 0.391048, 0.140073, 0.83359, -0.455528, 0.189455, 0.156364, -1.72622, 0.361997, 0.00184089, 0.0272058, 0.846714, 0.17155, 0.154619, -0.124195, 0.533649, -0.313022, 0.242615, 0.336492, -0.3857, 0.568763, 0.570227, 0.135532, -0.247562, 0.359336, 0.489984, -6.31123e-05, -0.600116, -0.297601, 0.330947, 0.139262, -0.148835, -0.40005, -0.133318, 0.198379, -0.0574998, 0.562943, -0.274555, -0.0300956, -0.205443, -0.330308, -0.305782, -0.0052617, 0.678192, -0.916991, -0.072465, -0.00282001, -0.0201846, 0.248369, 0.518628, -0.312574, 0.631191, 0.488051, 0.0472565, 0.0394871, 0.236094, 0.470321, 0.0789806, -0.159472, -0.319482, 0.111624, -0.124014, -0.140938, -0.214517, -0.238636, 0.0198476, 0.0476447, 0.0685465, 0.040987, 0.0247517, -0.081955, 0.0312086, 0.209168, 0.0418358, -0.153235, -0.666094, -0.326664, -0.103213, 0.186529, -0.314436, -0.596948, 0.146847, -0.215587, -0.12145, -0.455188, 0.0735486, 0.144862, 0.0722296, -0.0767647, -0.029202, -0.236156, -0.601865, -0.192148, 0.193829, 0.0370743, 0.0890924, -0.087988, 0.0408771, 0.343388, -0.0784761, -0.0733821, -0.207988, -0.314521, -0.106207, -0.158696, 0.0783754, -0.123307, -0.0789829, -0.210111, 0.0471823, 0.302845, -0.167447, 0.122662, -0.32306, -0.0772723, 0.818212, 0.162278, -0.136553, 0.305288, 0.329365, -0.20999, 0.268586, 0.00563099, 0.513534, 0.0999448, -0.108867, 0.188779], "internal": 1}
{"paper_id": "W08-0411", "abstract": "We describe a multi-step process for automatically learning reliable sub-sentential syntactic phrases that are translation equivalents of each other and syntactic translation rules between two languages. The input to the process is a corpus of parallel sentences, word-aligned and annotated with phrase-structure parse trees. We first apply a newly developed algorithm for aligning parse-tree nodes between the two parallel trees. Next, we extract all aligned sub-sentential syntactic constituents from the parallel sentences, and create a syntax-based phrase-table. Finally, we treat the node alignments as tree decomposition points and extract from the corpus all possible synchronous parallel tree fragments. These are then converted into synchronous context-free rules. We describe the approach and analyze its application to Chinese-English parallel data.", "title": "Syntax-driven Learning of Sub-sentential Translation Equivalents and Translation Rules from Parsed Parallel Corpora", "venue": "W", "graph_vector": [0.00793704, 0.164719, 0.0395474, -0.112022, 0.397056, -0.957528, 0.0058727, 0.0142731, -1.62417, 0.213372, 0.110772, -0.515159, 0.638298, 0.168245, 0.105634, -0.111185, 0.76909, -0.59731, 0.0629437, -0.0312012, -0.457269, 0.363642, 0.654012, 0.030607, -0.365942, 0.31792, 0.332923, 0.216177, -0.321292, -0.130706, -0.290841, 0.271524, 0.304882, -0.293016, -0.422825, 0.271797, -0.124225, 0.425083, -0.0685835, 0.12081, 0.0466286, -0.325062, -0.681311, 0.28591, 1.05576, -0.756022, 0.160952, 0.309997, 0.274108, -0.204049, 0.403732, 0.130688, 0.761825, 0.463171, 0.0249513, 0.270406, 0.196032, 0.0431946, 0.0726734, 0.00511705, -0.253171, -0.347355, -0.401526, -0.238905, 0.0110228, -0.0910749, -0.19281, 0.216849, -0.460168, 0.0598219, 0.153186, 0.014314, 0.184913, -0.655858, 0.0223472, -0.137733, -0.498239, -0.307839, -0.0370319, -0.162682, -0.0738754, 0.0344921, 0.342288, 0.20848, 0.119549, -0.242661, 0.296527, 0.126225, -0.0538755, 0.124891, 0.0729171, -0.134529, -0.402795, 0.0887723, -0.0955249, -0.051438, -0.0151249, -0.0835769, -0.243356, -0.449466, -0.284496, -0.236696, 0.131157, 0.581403, -0.0250484, -0.14429, -0.0464716, -0.12485, 0.33204, -0.161807, -0.135684, 0.392853, 0.104349, -0.27841, -0.406348, -0.138089, 0.45093, -0.000165422, -0.417094, 0.0859603, 0.166031, 0.12169, -0.131201, 0.171414, 0.347951, 0.354555, -0.0671491, -0.0459664], "internal": 1}
{"paper_id": "W08-0609", "abstract": "The accumulation of online biomedical information has been growing at a rapid pace, mainly attributed to a rapid growth of a wide range of repositories of biomedical data and literature. The automatic construction and update of scientific knowledge bases is a major research topic in Bioinformatics. One way of populating these knowledge bases is through named entity recognition (NER). Unfortunately, biomedical NER faces many problems, e.g., protein names are extremely difficult to recognize due to ambiguity, complexity and variability. A further problem in protein name recognition arises at the tokenization stage. Some protein names include punctuation or special symbols, which may cause tokenization to lose some word concatenation information in the original sentence. For example, IL-2 and IL - 2 fall into the same token sequence IL - 2 as usually dash (or hyphen) is designated as a token delimiter. Research into NER is centred around three approaches: dictionary-based, rule-based and machine learning-based approaches. To overcome the usual NER pitfalls, we have opted for a hybrid approach combining dictionary-based and machine learning approaches, which we call dictionary-based statistical NER approach. After identifying protein names in text, we link these to semantic identifiers, such as UniProt accession numbers. In this paper, we focus on the evaluation of our dictionary-based statistical NER.", "title": "How to Make the Most of NE Dictionaries in Statistical NER", "venue": "W", "graph_vector": [-0.598618, -0.0592761, 0.326127, 0.486038, 0.451334, -0.755659, -0.185, -0.27854, -1.71513, 0.428121, 0.215417, -0.233098, 0.818348, 0.172225, 0.27288, -0.363983, 0.467851, -0.297358, 0.461309, 0.616187, -0.0770027, 0.37956, 0.32127, 0.0340842, -0.441977, 0.207194, -0.0382777, 0.0974079, -0.457252, -0.0795481, 0.367643, -0.213707, 0.136544, -0.288524, -0.260477, -0.12594, -0.147836, 0.649166, 0.312705, -0.120349, -0.0874829, -0.749659, -0.540049, -0.0481266, 0.952837, -0.557859, -0.284267, 0.111583, -0.154986, 0.333112, 0.338148, -0.14125, 0.909598, 0.831013, -0.498184, 0.119326, 0.174366, 0.107437, 0.571607, -0.0835617, -0.231765, -0.0702753, 0.141326, 0.0884724, -0.550337, -0.169822, 0.281226, 0.205814, 0.0483053, 0.381786, -0.249233, 0.233053, -0.188107, -0.137746, -0.088954, 0.112792, -0.513513, -0.465419, -0.063678, -0.185007, -0.412086, -0.0432781, 0.300943, 0.363393, 0.424639, -0.51762, 0.393561, 0.0900514, 0.0796034, 0.162979, -0.103401, -0.19302, -0.755654, -0.105544, 0.390208, -0.143037, -0.0918768, -0.0392662, -0.455129, 0.128373, -0.682631, 0.055714, 0.0759289, 0.196146, -0.270069, -0.00445871, 0.283323, -0.0111503, 0.299709, -0.422702, -0.101943, 0.302414, -0.27913, -0.0685212, -0.167745, -0.200395, 0.532653, 0.269316, 0.0170843, 0.109552, 0.0758919, -0.131052, 0.00108034, -0.248353, 0.272459, 0.256069, 0.0721846, -0.21928], "internal": 1}
{"paper_id": "W14-2304", "abstract": "Metaphor is a cognitive process that shapes abstract target concepts by mapping them to concrete source concepts. Thus, many computational approaches to metaphor make reference, directly or indirectly, to the abstractness of words and concepts. The property of abstractness, however, remains theoretically and empirically unexplored. This paper implements a multi-dimensional definition of abstractness and tests the usefulness of each dimension for detecting cross-domain mappings.", "title": "Multi-dimensional abstractness in cross-domain mappings", "venue": "W", "graph_vector": [0.0586611, 0.560791, -0.0906245, 0.228497, 0.636774, -0.618667, 0.0834609, -0.0754599, -1.76735, 0.49574, -0.291655, -0.3469, 0.494087, 0.549752, 0.328075, -0.0489553, 0.459512, -0.535767, -0.0379535, 0.1273, -0.282424, 0.524896, 0.0666642, 0.0860669, -0.654413, 0.21948, 0.218501, 0.0688105, -0.164976, -0.136039, -0.212995, -0.153924, 0.346371, -0.444042, -0.255087, 0.145571, -0.250894, 0.784861, 0.174503, -0.292666, -0.0670749, -0.290086, 0.100405, 0.0395077, 0.833108, -0.846422, -0.0985951, 0.0881343, 0.0225732, 0.349401, 0.404811, -0.251757, 0.604663, 0.458439, -0.364202, -0.0223567, 0.414516, -0.170781, -0.461241, 0.0276417, 0.428607, -0.14498, 0.524398, 0.0685263, -0.381189, 0.123237, 0.363754, 0.160927, -0.179892, 0.413284, -0.283631, -0.0306459, 0.148588, 0.054762, 0.375974, 0.127334, -0.624833, -0.00245675, -0.163376, 0.100237, -0.401003, -0.170267, -0.170049, -0.214289, -0.332814, -0.482176, 0.403167, -0.279326, 0.510599, -0.126058, -0.125483, -0.494484, -1.00632, -0.0435729, -0.0591757, 0.115295, -0.369512, 0.400229, -0.0480326, 0.215888, -0.214328, -0.478255, -0.100693, -0.146125, -0.0878777, 0.311803, -0.0229932, -0.0353045, -0.122482, -0.476973, -0.0870979, -0.143294, -0.317543, -0.266063, -0.0513246, 0.229163, 0.135805, -0.0268125, 0.216749, 0.523255, -0.567595, -0.153178, -0.0304689, 0.285079, 0.297378, 0.117852, -0.0895118, 0.201387], "internal": 1}
{"paper_id": "W14-0149", "abstract": "This paper aims to highlight morphosyntactic discrepancies encountered in representing the adjective equivalent in African WordNet, with reference to Northern Sotho. Northern Sotho is an agglutinating language with rich and productive morphology. The language also features a disjunctive orthographic system. The orthography determines the attachment selection of morphemes. The immediate issue, in this paper, is the absence of a one-to-one correspondence between the adjective in English and that in Northern Sotho. The meaning equivalent of the English adjective covers more than one morphosyntactic category in Northern Sotho. In addition, the categories’ structural diversity has a bearing on representation considerations. In some of these categories the stem suffices to represent the specific category unambiguously while in others there is a need to incorporate affixes with the stem. The challenge is to categorize semantic equivalents of the English adjective as such, while retaining their separate morphosyntactic tags in Northern Sotho, in harmony with the typology of the language. The present paper proposes morphologically feasible ways of representing this varied equivalent of the English adjective in Northern Sotho.", "title": "Morphosyntactic discrepancies in representing the adjective equivalent in African WordNet with reference to Northern Sotho", "venue": "W", "graph_vector": [0.364266, 0.224484, -0.0906342, 0.316988, 0.364061, -0.999905, 0.52708, -0.362293, -2.66065, 0.0920337, -0.0848046, -0.334, 0.88449, 0.420802, 0.130243, -0.187055, 0.507799, -0.816144, 0.0400794, 0.460285, -0.280767, 0.673037, 0.342739, -0.246667, -0.547815, -0.181743, 0.354872, 0.429746, -0.142797, -0.045084, 0.229166, 0.0551633, 0.0279676, -0.40359, -0.0496492, 0.0247436, -0.258613, 0.806698, 0.130216, 0.0267874, -0.0106019, -0.573476, -0.0393915, 0.238747, 1.0671, -0.882294, 0.168275, 0.295379, 0.100987, 0.0171253, 0.306767, 0.18359, 0.928442, 0.531678, 0.0793046, 0.10402, 0.108904, 0.0698643, -0.195783, -0.0916198, -0.261858, 0.186001, -0.412512, -0.0818595, 0.0526408, 0.173857, -0.152927, 0.168845, 0.0359997, -0.227395, 0.237991, 0.0965525, 0.346201, 0.0931114, -0.126947, -0.131338, -0.61483, -0.711537, 0.0435194, 0.3441, -0.285884, -0.179142, 0.0220486, -0.372721, 0.525633, -0.212181, 0.302668, 0.0320644, -0.0292488, 0.0313403, 0.388502, -0.0680224, -0.662198, -0.354064, 0.182055, 0.368289, -0.234401, 0.207262, 0.0748037, -0.215594, -0.180371, -0.505792, 0.193675, -0.254429, -0.0412476, -0.0996018, -0.419684, -0.334898, 0.321028, -0.213817, -0.338936, 0.0831856, -0.288541, 0.0903752, 0.111468, -0.0623587, 0.194934, 0.115951, 0.353405, 0.332945, -0.0536512, 0.0154422, -0.202584, -0.273915, 0.00860847, -0.0901699, 0.0697163, -0.0231473], "internal": 1}
{"paper_id": "W14-5706", "abstract": "This paper presents a comparative study of different methods for the identification of multiword expressions, applied to a Brazilian Portuguese corpus. First, we selected the candidates based on the frequency of bigrams. Second, we used the linguistic information based on the grammatical classes of the words forming the bigrams, together with the frequency information in order to compare the performance of different classification algorithms. The focus of this study is related to different classification techniques such as support-vector machines (SVM), multi-layer perceptron, naïve Bayesian nets, decision trees and random forest. Third, we evaluated three different multi-layer perceptron training functions in the task of classifying different patterns of multiword expressions. Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures.", "title": "A Comparative Study of Different Classification Methods for the Identification of Brazilian Portuguese Multiword Expressions", "venue": "W", "graph_vector": [-0.0162401, -0.0238521, -0.0959089, 0.271174, 0.393391, -0.945722, 0.089991, 0.0702518, -1.54766, 0.412267, 0.415622, 0.0560432, 0.753345, 0.0103883, -0.221796, 0.144516, 0.141148, -0.694926, 0.275793, 0.258815, 0.0444477, 0.485148, 0.094258, -0.198648, -0.275586, 0.221344, 0.487837, -0.0268523, -0.444997, -0.209296, 0.620953, -0.243786, 0.145916, 0.0273134, 0.195657, 0.173268, -0.420368, 0.662479, 0.0917513, 0.279249, 0.0899208, -0.251341, -0.420013, 0.299971, 0.904848, -0.691285, 0.461175, 0.119204, -0.139703, -0.0877494, 0.111569, -0.492348, 0.972289, 0.43344, -0.475039, 0.213735, -0.0743999, -0.0617131, -0.0805928, -0.0520239, -0.164793, -0.306877, 0.216175, -0.00708949, -0.246025, 0.0362336, 0.194044, 0.0106787, 0.0564135, -0.510242, 0.0193839, -0.0275098, -0.0726749, 0.0684314, 0.283969, -0.00685732, -0.0503497, 0.0365883, -0.130431, -0.107201, -0.330112, 0.439024, 0.163188, -0.38948, 0.0200877, -0.130289, -0.126593, 0.463116, -0.0857117, -0.0786212, 0.316191, 0.14039, -0.454455, -0.362742, -0.449639, 0.0146362, -0.203152, 0.30612, 0.0551362, -0.0413735, -0.116849, -0.473256, -0.358863, 0.223483, -0.104876, 0.00805226, -0.569545, 0.0265009, 0.0270499, -0.0872706, 0.284513, 0.214503, 0.0719761, -0.393581, -0.0441228, -0.0836001, -0.10293, -0.147423, 0.470722, 0.227828, -0.395634, 0.0312035, -0.208248, -0.272459, 0.288551, 0.0199247, 0.0911659, 0.275073], "internal": 1}
{"paper_id": "W14-1608", "abstract": "The task of detecting and generating hyponyms is at the core of semantic understanding of language, and has numerous practical applications. We investigate how neural network embeddings perform on this task, compared to dependency-based vector space models, and evaluate a range of similarity measures on hyponym generation. A new asymmetric similarity measure and a combination approach are described, both of which significantly improve precision. We release three new datasets of lexical vector representations trained on the BNC and our evaluation dataset for hyponym generation.", "title": "Looking for Hyponyms in Vector Space", "venue": "W", "graph_vector": [-0.0386603, 0.155401, -0.030464, 0.317374, 0.523729, -0.680917, 0.271171, -0.216527, -1.67596, 0.260104, 0.0468584, -0.536922, 0.437744, 0.168873, -0.128358, -0.0486247, 0.0368213, -0.433326, 0.238905, 0.20784, -0.457443, 0.537374, 0.152561, 0.34391, -0.529418, -0.0633638, -0.598481, 0.226473, -0.18119, 0.0125676, -0.0472727, -0.488889, -0.14825, -0.256745, -0.27253, 0.225849, -0.135744, 0.665685, 0.177712, -0.323534, -0.122319, -0.507233, 0.0511325, 0.217867, 0.718462, -0.750451, 0.107827, 0.227261, -0.241254, 0.0789479, 0.17287, 0.0500297, 0.5684, 0.62978, 0.0596309, 0.139927, 0.367648, 0.216558, -0.197616, -0.0881303, 0.038641, -0.541359, 0.198935, 0.217839, -0.00793324, -0.0867854, 0.15709, -0.145146, -0.380897, -0.0818949, -0.142551, 0.184869, -0.0345121, -0.26941, 0.0204144, -0.323015, -0.436813, -0.0316349, 0.264568, -0.0733869, -0.427177, 0.0351583, 0.196553, 0.0413087, 0.416379, -0.10802, 0.114676, 0.260277, -0.114211, -0.402315, -0.100162, -0.06579, -0.569364, -0.215944, 0.171705, 0.0750374, -0.221639, -0.128473, 0.159772, -0.0719859, -0.426496, -0.0443415, -0.00386824, 0.0341779, 0.41292, 0.242977, 0.189846, -0.176276, 0.080357, -0.184544, -0.062081, 0.151661, 0.329682, 0.238786, -0.0743346, 0.0480683, 0.432359, 0.23377, 0.208085, 0.238599, -0.207452, 0.232701, 0.26319, -0.365746, 0.286537, -0.157652, -0.0566248, 0.0270421], "internal": 1}
{"paper_id": "W14-3508", "abstract": "We explore the challenges and opportunities which arise in developing automatic visual input enhancement activities for Russian with a focus on target selection and adaptive feedback. Russian, a language with a rich fusional morphology, has many syntactically relevant forms that are not transparent to the language learner, which makes it a good candidate for visual input enhancement (VIE). VIE essentially supports incidental focus on form by increasing the salience of language forms to support noticing by the learner. The freely available VIEW system (Meurers et al., 2010) was designed to automatically generate VIE activities from any web content. We extend VIEW to Russian and discuss connected research issues regarding target selection, ambiguity management, prompt generation, and distractor generation. We show that the same information and techniques used for target selection can often be repurposed for adaptive feedback. Authentic Text ICALL (ATICALL) systems incorporating only native-language NLP, without the NLP analysis specific to learner language that is characteristic of Intelligent Language Tutoring Systems (ILTS), thus can support some forms of adaptive feedback. ATICALL and ILTS represent a spectrum of possibilities rather than two categorically distinct enterprises. KEYWORDS: CALL, ICALL, ATICALL, input enhancement, noticing, consciousness raising, adaptive feedback, scaffolding, part-of-speech tagging, finite-state technology, Constraint Grammar, Russian, stress, aspect, participles, case.", "title": "A VIEW of Russian: Visual Input Enhancement and adaptive feedback", "venue": "W", "graph_vector": [0.280417, 0.722289, -0.0854199, 0.750488, 0.908825, -0.519582, 0.421738, 0.0683219, -1.93853, 0.282345, 0.0386006, -0.316883, 0.81098, -0.0583216, 0.129093, 0.189761, 0.443509, -0.990475, 0.532103, 0.227553, -0.477046, 0.92536, 0.499544, -0.323926, -0.312022, 0.0221877, -0.0825729, -0.457714, -0.141943, -0.297543, 0.385654, 0.56686, 0.0773458, -0.364752, -0.716272, 0.484302, -0.444549, 0.778896, 0.124801, 0.568736, -0.109234, -0.0195695, -0.770604, 0.245858, 1.14902, -1.06607, -0.252412, -0.168718, -0.27094, -0.130825, 0.672339, -0.240993, 0.892357, 0.367566, -0.560783, 0.174653, 0.235598, 0.245881, -0.0684553, -0.259934, 0.0939187, -0.0304187, 0.380445, -0.0491914, -0.0054339, 0.0028682, 0.153268, 0.251438, -0.432185, 0.211425, -0.151482, 0.227113, 0.0900103, 0.404406, 0.494116, -0.352679, -0.41518, -0.331636, -0.318465, -0.117494, 0.0790236, 0.415794, 0.227851, -0.243288, 0.0937032, -0.0755328, -0.235614, -0.227121, -0.373404, 0.0671194, 0.404896, 0.103371, -0.428232, 0.0633972, 0.0239587, -0.274068, 0.295475, 0.0350014, 0.150341, -0.379927, -0.336144, -0.737984, -0.00341949, 0.12061, 0.539224, 0.595986, 0.0143392, -0.260606, 0.348821, -0.0887277, 0.289745, -0.163258, -0.243835, -0.504266, 0.0280426, 0.255847, 0.698512, 0.33185, -0.0866771, 0.542518, -0.420329, 0.705081, -0.195823, 0.59017, 0.289851, 0.525043, 0.108742, 0.341685], "internal": 1}
{"paper_id": "W14-3320", "abstract": "This paper describes the system jointly developed by members of the Departament de Llenguatges i Sistemes Inform`atics at Universitat d’Alacant and the Prompsit Language Engineering company for the shared translation task of the 2014 Workshop on Statistical Machine Translation. We present a phrase-based statistical machine translation system whose phrase table is enriched with information obtained from dictionaries and shallowtransfer rules like those used in rule-based machine translation. The novelty of our approach lies in the fact that the transfer rules used were not written by humans, but automatically inferred from a parallel corpus.", "title": "The UA-Prompsit hybrid machine translation system for the 2014 Workshop on Statistical Machine Translation", "venue": "W", "graph_vector": [0.0300311, 0.38688, 0.223849, 0.439489, 0.431099, -0.973168, 0.00962797, 0.124037, -1.57, -0.032205, 0.10984, -0.36212, 0.215547, 0.201408, -0.0193376, 0.306691, 0.469845, -0.635757, 0.120069, 0.49599, -0.345858, 0.544779, 0.461512, 0.0240523, -0.245103, 0.157446, -0.160464, 0.082292, -0.259105, -0.287517, 0.130555, -0.18979, 0.00595472, -0.0886012, -0.352226, 0.367984, -0.0641919, 0.662362, 0.502516, 0.180204, -0.0624368, -0.423596, -0.130358, 0.677006, 0.931846, -0.805417, 0.404349, 0.238144, 0.250549, -0.268641, 0.338148, 0.0876973, 0.873037, 0.339076, -0.341142, 0.237348, 0.440541, 0.151054, -0.346257, -0.0188489, -0.277429, -0.0501973, 0.0501248, -0.208703, 0.183603, 0.0988955, 0.102349, 0.089685, -0.306098, 0.313095, 0.213674, 0.132089, -0.283299, -0.415524, 0.478348, 0.269113, -0.376196, -0.52587, 0.00731128, 0.0484503, 0.231123, 0.14129, 0.346873, -0.196749, -0.0815002, -0.565146, 0.0447507, -0.202739, 0.056385, 0.043536, -0.0466551, -0.360359, -0.489754, -0.0792733, -0.0283732, 0.0655106, -0.0297771, 0.00770542, -0.0679805, -0.214735, -0.0897165, -0.22869, -0.418596, 0.00421671, -0.044133, -0.0956719, 0.0833012, -0.260886, 0.0204076, -0.262431, 0.523488, 0.0605237, 0.0309255, -0.100263, -0.00238509, 0.102983, 0.104495, 0.111559, -0.14032, 0.220267, -0.131304, -0.215274, -0.121571, -0.0328899, 0.0883476, 0.421612, 0.0222124, 0.228115], "internal": 1}
{"paper_id": "W14-4915", "abstract": "When annotating non-standard languages, descriptively incomplete language phenomena (EAGLES, 1996) are often encountered. In this paper, we present examples of ambiguous forms taken from a historical corpus and offer a classification of such descriptively incomplete language phenomena and its rationale. We then discuss various approaches to the annotation of these phenomena, arguing that multiple annotations provide the most appropriate encoding strategy for the annotator. Finally, we show how multiple annotations can be encoded in existing standards such as PAULA and GrAF.", "title": "Annotating descriptively incomplete language phenomena", "venue": "W", "graph_vector": [-0.270714, 0.83401, -0.0955298, -0.414614, 0.186615, -0.919773, 0.222454, 0.147611, -1.64702, 0.312144, -0.203503, -0.875835, 1.01605, 0.0866107, -0.396615, -0.0959651, 0.817511, -1.106, 0.327439, 0.380688, -0.559036, 0.662413, 0.81667, -0.224959, -0.0324658, 0.137025, 0.224717, -0.23362, -0.0361964, -0.22381, -0.0876595, 0.172817, 0.129357, -0.620971, -0.581686, 0.0902133, -0.341826, 1.08778, 0.299165, 0.128547, 0.35212, 0.0281331, -0.486967, 0.436282, 0.86606, -0.731603, -0.501559, 0.371104, -0.0652752, 0.0664132, 0.163001, -0.043008, 0.982992, 0.402191, 0.00477719, 0.202477, 0.116896, -0.168551, -0.0110123, 0.114334, -0.182193, -0.172353, 0.0627303, 0.22672, 0.428289, -0.646724, 0.271858, 0.825611, 0.342685, -0.0908137, -0.0255788, 0.171249, -0.0182436, -0.311814, -0.399717, -0.139683, 0.0256183, -0.80274, 0.276663, -0.14056, -0.304964, -0.0440072, 0.00546644, -0.206407, 0.154739, 0.00337108, 0.208525, -0.489035, -0.0154588, -0.68012, 0.175035, 0.303842, -0.794674, 0.0225598, 0.0417033, -0.112806, -0.251271, -0.21046, -0.174276, 0.155292, -0.333352, -0.127995, -0.466322, -0.273668, 0.0244526, 0.229016, -0.424142, -0.387429, 0.292499, -0.0423821, -0.372865, 0.721393, 0.180941, -0.087469, -0.234482, 0.132646, 0.522749, 0.101211, 0.0921061, 0.311161, -0.0783931, -0.191934, -0.153919, -0.188334, 0.287717, 0.062935, -0.218225, -0.249619], "internal": 1}
{"paper_id": "W14-6203", "abstract": "In this paper we consider the problem of distant supervision to extract relations (e.g. origin(musical artist, location)) for entities (e.g. ‘The Beatles’) of certain classes (e.g. musical artist) from Web pages by using background information from the Linking Open Data cloud to automatically label Web documents which are then used as training data for relation classifiers. Distant supervision approaches typically suffer from the problem of ambiguity when automatically labelling text, as well as the problem of incompleteness of background data to judge whether a mention is a true relation mention. This paper explores the hypothesis that simple statistical methods based on background data can help to filter unreliable training data and thus improve the precision of relation extractors. Experiments on a Web corpus show that an error reduction of 35% can be achieved by strategically selecting seed data.", "title": "Seed Selection for Distantly Supervised Web-Based Relation Extraction", "venue": "W", "graph_vector": [0.105069, 0.295682, 0.317592, 0.472146, 0.358153, -0.405021, 0.00887513, 0.317915, -1.66548, 0.445372, 0.162426, -0.533863, 0.819351, 0.278327, -0.340961, 0.182851, 0.57589, -0.419238, -0.0869727, 0.116112, -0.194492, 0.579407, 0.320713, 0.245585, -0.247361, 0.0951546, -0.301166, 0.142761, -0.216658, 0.167329, 0.0304773, -0.0510911, 0.326502, -0.585463, -0.00464261, 0.153392, -0.30098, 0.519648, 0.299872, -0.097142, 0.0140489, -0.846274, -0.141711, 0.324656, 0.73625, -0.547378, 0.130572, 0.16362, 0.0290569, -0.243223, 0.348438, -0.307643, 0.837129, 0.704259, -0.202533, -0.15359, -0.210465, 0.157588, -0.169846, 0.171118, -0.446163, -0.0993355, -0.0713078, 0.0411847, -0.198541, 0.0140458, 0.356485, -0.0992478, -0.0509744, -0.00238595, 0.0566759, 0.0265232, -0.108285, 0.210716, 0.445983, 0.0270337, -0.72793, -0.114751, -0.0391432, 0.0495866, -0.0988513, 0.0415592, 0.340363, -0.427213, -0.187323, -0.125125, -0.0442304, -0.125255, 0.357162, 0.307826, 0.144098, 0.309668, -0.883865, 0.0602044, 0.162656, 0.0923734, -0.24194, 0.150933, -0.10852, -0.0843031, -0.060961, -0.0124535, -0.00161587, 0.00202722, 0.010573, 0.455577, 0.0606281, -0.0293318, 0.0740673, -0.037542, -0.211959, -0.0671069, 0.0955404, 0.0779525, -0.0196772, 0.0780259, 0.236718, 0.134706, -0.202589, 0.0617723, 0.0351176, -0.408855, -0.128681, 0.244662, 0.176322, 0.0450093, 0.171954, 0.0516507], "internal": 1}
{"paper_id": "W14-0501", "abstract": "", "title": "The influence of referential processing on sentence complexity.", "venue": "W", "graph_vector": [0.176354, -0.0698848, -0.154386, 0.414271, 0.956681, -0.940124, 0.056738, -0.037196, -2.17257, 0.394844, -0.292472, -0.675419, 1.12214, -0.162653, 0.189286, -0.203083, 0.563179, -0.429451, -0.147842, 0.600117, -0.47999, 1.28169, 0.186437, 0.0731307, -0.460122, 0.0615489, -0.0857637, 0.23944, -0.215193, -0.216757, 0.0523825, 0.207937, 0.0311125, -0.43501, -0.183071, 0.228505, -0.349226, 0.589405, 0.356262, 0.0491763, 0.301638, -0.391932, -0.110169, 0.592767, 0.818559, -1.31611, -0.0601278, 0.207465, -0.205911, 0.0728799, 0.820285, -0.0387002, 0.850853, 0.919437, -0.169619, 0.474123, 0.41316, -0.204533, -0.0638065, 0.207514, -0.375969, -0.0553476, -0.143533, 0.207797, 0.0661392, 0.314934, -0.0739257, -0.0652208, 0.0647487, 0.103936, 0.0324753, 0.172829, -0.34806, 0.112972, -0.0037677, -0.126675, -0.540332, 0.16206, -0.216565, 0.496979, 0.0182729, 0.354234, 0.00397771, -0.313115, 0.224106, -0.298871, -0.0622041, -0.118711, 0.135676, -0.00521088, -0.188651, -0.190279, -0.540596, -0.276827, 0.424377, 0.0431813, -0.0900909, -0.0214615, 0.159044, -0.286042, 0.189414, -0.19542, 0.0855601, 0.000147237, 0.160086, 0.167709, -0.323908, -0.360936, 0.267984, -0.238238, 0.215206, 0.0798717, 0.311171, 0.00624286, -0.168778, 0.045264, 0.404771, -0.115587, -0.665009, 0.568921, 0.00739582, -0.0195769, -0.236095, -0.358278, 0.851423, 0.103079, -0.245245, 0.0439531], "internal": 1}
{"paper_id": "W14-4501", "abstract": "Recent approaches to relation extraction following the distant supervision paradigm have focused on exploiting large knowledge bases, from which they extract substantial amount of supervision. However, for many relations in real-world applications, there are few instances available to seed the relation extraction process, and appropriate named entity recognizers which are necessary for pre-processing do not exist. To overcome this issue, we learn entity filters jointly with relation extraction using imitation learning. We evaluate our approach on architect names and building completion years, using only around 30 seed instances for each relation and show that the jointly learned entity filters improved the performance by 30 and 7 points in average precision.", "title": "Application-Driven Relation Extraction with Limited Distant Supervision", "venue": "W", "graph_vector": [0.0245722, 0.271995, 0.405459, 0.66127, 0.598459, -0.420478, -0.158337, 0.00745283, -1.67425, 0.532267, 0.111345, -0.126388, 0.863436, 0.533933, -0.180657, -0.127206, 0.21369, -0.634271, 0.104789, -0.0343029, -0.468969, 0.318958, 0.245049, 0.221168, -0.520768, 0.21189, 0.0524857, 0.187472, -0.174818, -0.024152, -0.148673, -0.135027, -0.0825643, -0.308905, 0.0057846, 0.336259, -0.500634, 0.64334, 0.0502364, -0.194371, -0.0369506, -0.597727, -0.0835252, 0.501427, 0.340917, -0.446667, 0.0681073, 0.124257, 0.169211, -0.197982, 0.411909, -0.0437507, 0.843208, 0.977664, 0.0381277, 0.203088, -0.129738, -0.197255, -0.114336, -0.22028, -0.166949, -0.0841162, -0.377003, -0.216355, -0.229967, 0.103777, 0.0556487, 0.0450275, -0.0690825, 0.166753, 0.411894, 0.0256668, 0.11166, -0.0643647, 0.353454, 0.114267, -0.47201, 0.0248314, -0.200904, 0.0223199, 0.0369768, 0.0942167, 0.534027, -0.360877, -0.0957808, -0.378544, 0.231863, 0.0400657, 0.00767432, 0.267418, -0.144953, 0.293639, -0.647191, 0.607904, 0.323585, 0.0808146, -0.0890319, -0.104093, -0.116936, -0.241694, -0.439006, 0.250286, 0.0680601, 0.175262, -0.0096562, 0.364629, -0.200539, 0.0356, 0.147538, -0.221634, 0.0298829, -0.0882817, -0.00806679, 0.291565, -0.111589, -0.279879, 0.650906, 0.00762647, 0.0400065, 0.501094, 0.0386056, -0.262729, -0.0225622, 0.0359252, 0.0355252, 0.279033, 0.00346759, 0.0455351], "internal": 1}
{"paper_id": "W14-0502", "abstract": "The paper presents a system for transcribing and annotating phonological information in Brazilian Portuguese, including syllabification. An application of this system for the assessment of language understanding and production is described, following a child longitudinally, comparing expected production with observed production.", "title": "A Brazilian Portuguese Phonological-prosodic Algorithm Applied to Language Acquisition: A Case Study", "venue": "W", "graph_vector": [-0.044005, 0.39318, 0.228217, 0.4358, 1.02426, -1.2009, -0.327933, -0.323245, -2.89315, 0.379111, 0.189553, -0.71659, 0.965033, 0.14798, -0.336946, -0.0630027, 0.796027, -0.999736, 0.117894, 0.239088, -0.386686, 1.31781, 0.58725, -0.392908, -0.465981, 0.497826, -0.305954, -0.00189744, -0.328891, -0.878579, 0.219874, -0.108028, 0.214431, -0.575505, -0.233236, 0.373004, -0.251368, 0.932142, 0.506515, 0.495329, 0.0857948, -0.793176, -0.953877, 1.08182, 1.92352, -0.99131, -0.592129, 0.312104, -0.219828, -0.0260585, -0.188452, -0.144976, 1.18222, 0.715767, -0.306011, 0.148131, 0.107108, 0.0471587, -0.0366459, 0.0942591, -0.288816, -0.667803, 0.0544069, 0.0529855, -0.0718593, -0.0447321, -0.380002, -0.0338915, -0.245392, 0.0225254, -0.0363599, -0.00407817, -0.0643979, -0.248878, 0.0259243, -0.33452, -1.01323, -0.586766, -0.372595, -0.324501, -0.261266, -0.0517353, 0.749867, -0.245499, 0.233914, -0.66694, 0.0202722, -0.612636, 0.00878011, 0.112581, 0.417292, -0.306502, -0.481178, -0.199057, -0.218647, 0.265497, -0.0617367, -0.135842, 0.542079, 0.26526, -0.305596, -0.589026, 0.273956, 0.416034, 0.200522, 0.0533391, -0.36666, -0.0413996, 0.48463, -0.592055, -0.268908, 0.543567, -0.0267166, -0.399843, -0.155174, -0.427964, 0.585961, 0.635283, -0.0389324, 0.40457, -0.543149, 0.383278, -0.470784, 0.152464, 0.947274, 0.468284, 0.241669, 0.00188419], "internal": 1}
{"paper_id": "W14-5512", "abstract": "Named entity recognition aims to classify words in a document into pre-defined target entity classes. It is now considered to be fundamental for many natural language processing tasks such as information retrieval, machine translation, information extraction and question answering. This paper presents a workflow to build an English-Vietnamese named entity corpus from an aligned bilingual corpus. The workflow is based on a state of the art named entity recognition tool to identify English named entities and map them into Vietnamese text. The paper also presents a detailed discussion about several mapping errors and differences between English and Vietnamese sentences that affect this task.", "title": "Building English-Vietnamese Named Entity Corpus with Aligned Bilingual News Articles", "venue": "W", "graph_vector": [-0.00895167, 0.317278, 0.0191383, 0.261855, 0.467888, -0.555071, -0.224336, 0.332949, -1.63775, 0.639449, 0.113507, -0.378747, 0.696958, 0.33072, 0.123787, 0.0629318, 0.368333, -0.542095, 0.179835, 0.795813, -0.853034, 0.772894, 0.700604, 0.307611, -0.454765, 0.093292, -0.737457, 0.113829, -0.0102306, -0.336298, 0.0419135, -0.143145, 0.245884, -0.481907, -0.189253, 0.20204, -0.0370818, 0.741065, 0.60221, -0.511326, 0.32672, -0.462364, -0.134304, 0.397307, 1.18551, -0.498923, 0.248481, -0.165506, -0.262217, 0.286296, 0.156966, -0.116669, 1.19173, 0.634034, -0.448504, -0.027046, 0.271234, -0.307617, 0.0652381, -0.32123, -0.651867, -0.142766, 0.410986, 0.00364538, -0.364946, -0.475553, 0.217014, 0.419882, -0.156188, 0.275641, -0.187856, 0.394224, 0.142345, -0.439898, 0.50767, 0.372373, -0.432266, -0.169116, -0.202095, -0.187879, 0.180102, -0.0649945, 0.311252, -0.299739, 0.130852, 0.0331184, -0.0475392, 0.0140929, 0.0734449, 0.205102, 0.0636609, 0.086351, -0.560435, 0.154801, 0.174237, 0.230893, -0.291716, -0.514102, 0.321397, -0.502994, -0.14398, -0.445975, -0.0289844, -0.440575, -0.069961, -0.0464778, 0.0426097, 0.346131, -0.173439, -0.425085, -0.0779751, 0.00994033, -0.152085, 0.0673269, -0.208336, 0.0475095, 0.549725, 0.232935, 0.259416, 0.0704507, -0.216529, -0.29097, -0.31083, -0.111836, 0.19658, 0.675872, -0.0341034, -0.184086], "internal": 1}
{"paper_id": "W14-3603", "abstract": "This paper presents preliminary results in building an annotated corpus of the Palestinian Arabic dialect. The corpus consists of about 43K words, stemming from diverse resources. The paper discusses some linguistic facts about the Palestinian dialect, compared with the Modern Standard Arabic, especially in terms of morphological, orthographic, and lexical variations, and suggests some directions to resolve the challenges these differences pose to the annotation goal. Furthermore, we present two pilot studies that investigate whether existing tools for processing Modern Standard Arabic and Egyptian Arabic can be used to speed up the annotation process of our Palestinian Arabic corpus.", "title": "Building a Corpus for Palestinian Arabic: a Preliminary Study", "venue": "W", "graph_vector": [0.149998, 0.0548337, 0.0341615, 0.11034, 0.45919, -0.984262, 0.0732922, -0.132278, -1.70612, 0.270955, 0.192592, -0.0342065, 0.783689, 0.0637431, -0.0603868, -0.15139, 0.70788, -1.0319, 0.116685, 0.202128, -0.659198, 1.04633, 0.337529, 0.324521, -0.515541, -0.0911004, 0.221228, 0.0549262, -0.455066, 0.0452818, -0.205117, 0.116314, -0.184022, -0.598976, -0.665408, 0.506461, -0.0990084, 0.26168, 0.374468, 0.0312319, 0.105189, -0.520914, -0.720469, 0.416643, 1.14216, -0.50435, -0.0631268, 0.112029, 0.51244, 0.281255, 0.203288, -0.579497, 0.438932, 1.01634, 0.0840916, 0.245146, 0.173996, -0.0260178, 0.267706, -0.0163076, -0.28974, 0.0979828, -0.0540008, 0.108143, -0.283017, 0.35066, 0.0171076, -0.140823, -0.0129357, 0.282831, -0.102215, 0.144777, 0.128321, 0.226436, -0.0963561, 0.219925, -0.700607, -0.558036, 0.0573972, 0.0661384, 0.083622, -0.166354, 0.202524, -0.240401, 0.0133646, -0.365126, 0.132735, -0.26108, 0.138666, 0.10953, 0.293657, 0.0297176, -0.693836, -0.0576766, -0.221677, 0.0790736, -0.0142252, 0.22109, 0.019338, -0.0616162, 0.247442, -0.699066, -0.245917, 0.327123, -0.0444048, 0.172826, -0.165095, -0.24575, 0.0191165, -0.454565, 0.0570744, 0.0400143, 0.103757, -0.113834, -0.00220837, 0.110483, 0.274739, 0.107957, 0.257364, 0.487667, -0.0491338, -0.0752098, -0.157986, 0.293991, 0.612382, 0.16451, -0.144161, -0.245731], "internal": 1}
{"paper_id": "W14-5408", "abstract": "Profile inference of SNS users is valuable for marketing, target advertisement, and opinion polls. Several studies examining profile inference have been reported to date. Although information of various types is included in SNS, most such studies only use text information. It is expected that incorporating information of other types into text classifiers can provide more accurate profile inference. As described in this paper, we propose combined method of text processing and image processing to improve gender inference accuracy. By applying the simple formula to combine two results derived from a text processor and an image processor, significantly increased accuracy was confirmed.", "title": "Twitter User Gender Inference Using Combined Analysis of Text and Image Processing", "venue": "W", "graph_vector": [-0.145301, 0.49268, 0.269656, 0.347406, 0.188164, -0.825785, 0.176568, -0.475739, -1.37159, -0.121962, 0.223093, -0.301285, 0.586737, 0.017186, 0.147693, -0.0924902, 0.555261, -0.540482, 0.361873, 0.162248, -0.400062, 0.340311, 0.529122, -0.338199, -0.369966, 0.239202, 0.296879, -0.188382, -0.365987, 0.133145, -0.0138664, 0.024972, 0.387096, 0.158575, -0.283126, 0.294454, -0.341377, 0.743019, 0.693087, -0.0111554, 0.108573, -0.506744, -0.223626, 0.389166, 1.3117, -1.54639, -0.173892, 0.0226206, -0.0685602, -0.221738, 0.326911, -0.363819, 1.10266, 1.14704, 0.00197306, -0.131328, -0.491001, 0.455489, 0.110548, 0.239576, -0.339565, 0.045541, 0.239991, 0.309871, -0.0863727, -0.272317, -0.337098, 0.152238, 0.375567, 0.184924, -0.257337, -0.143446, 0.160685, -0.0916835, 0.0616655, 0.0270665, -0.53406, -0.124792, 0.341344, -0.299844, -0.180801, -0.002645, 0.251536, -0.369428, 0.0651713, 0.0038518, -0.101628, 0.124363, -0.24294, 0.439781, -0.192382, -0.273661, -0.380578, -0.38069, -0.349132, -0.150168, -0.137422, -0.0441384, 0.237615, -0.207523, -0.445218, -0.474786, -0.0200902, -0.0346391, 0.155047, 0.214272, -0.100813, -0.18489, -0.145363, 0.0421693, -0.0701045, -0.2608, -0.104525, 0.184074, 0.0904036, -0.532037, 0.204032, -0.098877, 0.348996, 0.411677, 0.312487, -0.414003, 0.0481378, -0.13368, 0.40489, 0.282859, -0.402245, 0.0677827], "internal": 1}
{"paper_id": "W14-0905", "abstract": "To date, document clustering by genres or authors has been performed mostly by means of stylometric and content features. With the premise that novels are societies in miniature, we build social networks from novels as a strategy to quantify their plot and structure. From each social network, we extract a vector of features which characterizes the novel. We perform clustering over the vectors obtained, and the resulting groups are contrasted in terms of author and genre.", "title": "Structure-based Clustering of Novels", "venue": "W", "graph_vector": [0.207062, 0.874771, 0.324079, 0.0741705, 0.478612, -0.810921, -0.428605, 0.235479, -1.72322, 0.894638, -0.275789, -0.18557, 0.893791, 0.300598, 0.172724, -0.181637, 0.403686, -0.793276, 0.369792, 0.282228, -0.805108, 0.44453, 0.21604, -0.113957, -0.517842, 0.318465, 0.399876, 0.141211, -0.371096, -0.428113, -0.0941039, -0.442315, 0.276745, -0.555177, -0.176163, 0.449703, -0.456234, 1.06843, -0.11962, -0.221256, -0.547932, -0.0972032, -0.401537, 0.762855, 1.42528, -0.811468, -0.0740618, 0.182649, -0.0461669, -0.0813293, 0.584121, -0.0945678, 0.531852, 0.489102, 0.241316, -0.114741, 0.107297, -0.130812, 0.00563363, 0.0335852, -0.517248, -0.0548279, -0.203229, 0.125695, -0.291073, -0.193714, -0.12271, 0.107247, -0.0743406, -0.448486, -0.26288, 0.353523, -0.0814377, -0.0314849, 0.421728, -0.399597, -0.632198, -0.276659, -0.228653, 0.205448, -0.312862, 0.0053496, 0.635633, -0.310725, 0.0719818, -0.463745, -0.146987, -0.170607, -0.148186, -0.0771399, 0.0989348, -0.0749274, -0.868247, 0.153709, -0.18045, -0.139317, 0.100527, -0.159229, -0.00276352, 0.222693, -0.639723, -0.596609, 0.240078, 0.343858, 0.214197, 0.191574, 0.185796, -0.0167728, 0.224123, 0.297972, -0.0116381, 0.0161811, 0.287343, 0.332373, -0.111254, -0.0828614, 0.147549, -0.313159, -0.407195, -0.19737, -0.102361, 0.268803, -0.196744, -0.22574, 1.00621, 0.37649, 0.0420125, -0.17951], "internal": 1}
{"paper_id": "W14-0312", "abstract": "The paper presents experiments with active learning methods for the acquisition of training data in the context of machine translation. We propose a confidencebased method which is superior to the state-of-the-art method both in terms of quality and complexity. Additionally, we discovered that oracle selection techniques that use real quality scores lead to poor results, making the effectiveness of confidence-driven methods of active learning for machine translation questionable.", "title": "Confidence-based Active Learning Methods for Machine Translation", "venue": "W", "graph_vector": [-0.0518044, 0.115166, 0.341257, 0.233538, 0.207818, -0.840971, 0.269052, 0.172404, -1.58051, 0.374267, 0.0478681, -0.00335321, 0.602442, -0.0119112, -0.0713304, -0.137059, 0.29239, -0.479212, 0.0902741, 0.259656, -0.480372, 0.429793, 0.791111, 0.194746, -0.326158, -0.257025, 0.0361107, 0.485389, -0.289126, -0.0602092, -0.211074, 0.17221, -0.101451, -0.329079, -0.196313, 0.109332, -0.286746, 0.762279, 0.357965, -0.0363068, -0.183947, -0.716017, -0.610167, 0.454245, 1.1182, -0.86543, 0.268545, -0.0139933, 0.36401, 0.0208573, 0.428276, -0.200476, 0.72571, 0.537959, -0.381485, 0.0133667, 0.22741, 0.239824, 0.0208939, -0.137154, 0.112482, -0.122937, -0.0735885, -0.121627, -0.157347, 0.0273251, 0.0229331, -0.227323, 0.333586, 0.0920373, 0.481787, -0.320222, 0.23803, 0.0138896, 0.138541, 0.245329, -0.55799, -0.534442, -0.0605911, 0.0636521, 0.404784, 0.243755, 0.055701, -0.146014, 0.156556, -0.244013, -0.274431, -0.115125, -0.0790197, 0.0266014, 0.0140629, -0.255971, -0.46503, 0.125241, 0.0457387, 0.260624, 0.334879, 0.0743151, -0.340312, 0.162313, -0.0608444, -0.262662, 0.288109, 0.0700203, 0.489275, -0.0328325, -0.376059, -0.114201, 0.0569435, -0.453836, 0.149601, 0.202268, 0.0116785, -0.105937, -0.124047, 0.0163925, 0.280984, 0.301187, 0.0912676, -0.17846, 0.184758, -0.129489, -0.271961, -0.227004, 0.552931, 0.0440024, -0.183747, 0.113439], "internal": 1}
{"paper_id": "W14-3213", "abstract": "Suicide is a leading cause of death in the United States. One of the major challenges to suicide prevention is that those who may be most at risk cannot be relied upon to report their conditions to clinicians. This paper takes an initial step toward the automatic detection of suicidal risk factors through social media activity, with no reliance on self-reporting. We consider the performance of annotators with various degrees of expertise in suicide prevention at annotating microblog data for the purpose of training text-based models for detecting suicide risk behaviors. Consistent with crowdsourcing literature, we found that novice-novice annotator pairs underperform expert annotators and outperform automatic lexical analysis tools, such as Linguistic Inquiry and Word Count.", "title": "Toward Macro-Insights for Suicide Prevention: Analyzing Fine-Grained Distress at Scale", "venue": "W", "graph_vector": [0.0514958, 0.459172, 0.110708, -0.0346118, 0.533693, -1.14878, -0.134214, -0.00398808, -1.89626, 0.496282, 0.0267136, -0.0125425, 0.734375, -0.311622, 0.342285, 0.0360385, 0.201371, -0.375437, 0.00166134, 0.0106404, -0.0133823, 0.853274, -0.332097, -0.0842089, -0.219717, 0.155641, -0.133913, -0.0830316, -0.237296, -0.896486, -0.142858, 0.247624, 0.400989, -0.658992, -0.364447, 0.0809761, -0.217255, 0.496012, -0.168521, -0.0967852, -0.360519, -0.747668, -0.200293, 0.590313, 1.02074, -1.16833, 0.0936099, -0.0469999, -0.00491526, -0.240059, -0.0370991, -0.456998, 0.764703, 1.14538, 0.0322246, 0.201543, 0.572904, 0.544379, -0.221457, 0.314683, -0.180096, 0.239492, -0.0402511, -0.0790694, -0.514482, 0.0508772, 0.02668, 0.0859351, 0.0191148, 0.217552, -0.00854406, 0.622938, -0.146163, -0.140773, 0.119404, -0.234754, -0.561648, -0.224719, -0.10008, 0.148581, 0.221326, -0.346051, 0.352515, -0.165587, -0.18354, -0.0584465, 0.335894, 0.0446183, 0.0424371, -0.0697368, -0.0345464, -0.0764772, -0.693312, -0.202737, -0.465458, 0.0666033, -0.0992629, 0.178939, -0.491146, -0.345366, -0.519202, -0.666089, -0.173493, 0.0511016, 0.143786, 0.111201, -0.132811, -0.337576, 0.0736332, -0.272277, -0.370921, -0.0400678, 0.34974, -0.0834648, -0.286654, -0.37805, 0.211492, -0.108671, 0.143168, 0.357251, 0.15175, 0.281673, 0.125904, 0.00476841, 0.544475, -0.0263832, 0.0344883, 0.27789], "internal": 1}
{"paper_id": "W14-2714", "abstract": "Twitter has become one of the foremost platforms for information sharing. Consequently, it is beneficial for the consumers of Twitter to know the origin of a tweet, as it affects how they view and interpret this information. In this paper, we classify tweets based on their origin, exploiting only the textual content of tweets. Specifically, using a rich, linguistic feature set and a supervised classifier framework, we classify tweets into two user types - organizations and individual persons. Our user type classifier achieves an 89% Fl-score for identifying tweets that originate from organizations in English and an 87% Fl-score for Spanish. We also demonstrate that classifying the user type of a tweet can improve downstream event recognition tasks. We analyze several schemes that exploit user type information to enhance Twitter event recognition and show that substantial improvements can be achieved by training separate models for different user types.", "title": "User Type Classification of Tweets with Implications for Event Recognition", "venue": "W", "graph_vector": [-0.0454623, 0.489626, 0.118001, -0.151594, 0.472627, -0.734011, -0.217985, 0.286419, -1.58551, 0.16888, 0.0198021, -0.362705, 0.494624, 0.0147047, 0.110704, 0.0219538, 0.705585, -0.530047, 0.383076, 0.184923, -0.238888, 0.636025, 0.274523, 0.101427, -0.395641, 0.326028, 0.209793, -0.11737, 0.0268645, -0.169961, -0.0417278, -0.0434836, 0.346157, -0.368549, -0.38466, 0.0730676, -0.126198, 0.63897, 0.421061, -0.195127, 0.41653, -0.471199, -0.230654, 0.805122, 1.11837, -1.13655, 0.105486, 0.53839, -0.150379, -0.109458, 0.125, -0.00743332, 0.781999, 1.2828, -0.0787915, 0.285764, -0.19559, 0.626029, 0.121266, 0.00749028, -0.124606, 0.0970206, 0.428707, 0.118888, -0.599429, -0.0273642, -0.0192064, -0.0707742, 0.401977, 0.174343, 0.292419, -0.0860316, 0.255648, -0.268244, -0.300296, 0.089389, -0.185954, -0.330276, 0.130622, 0.0944844, -0.0590915, -0.0736421, 0.0893443, -0.115625, 0.220896, -0.224263, -0.0710704, 0.114945, 0.0526109, 0.526086, 0.125137, 0.195082, -0.696945, -0.251727, 0.280477, 0.192852, -0.204243, -0.282378, 0.173067, -0.311219, -0.376785, -0.166089, -0.023087, -0.0528983, 0.410969, -0.161761, 0.263317, -0.1851, 0.063899, -0.250807, 0.10182, -0.0974856, 0.1532, -0.0325635, -0.30988, -0.327915, 0.357032, -0.153764, 0.000828197, 0.714959, -0.201047, 0.137935, -0.0946442, 0.237646, 0.554508, 0.182914, 0.0551462, 0.174013], "internal": 1}
{"paper_id": "W14-3321", "abstract": "This paper describes the AFRL statistical MT system and the improvements that were developed during the WMT14 evaluation campaign. As part of these efforts we experimented with a number of extensions to the standard phrase-based model that improve performance on Russian to English and Hindi to English translation tasks. In addition, we describe our efforts to make use of monolingual English speakers to correct the output of machine translation, and present the results of monolingual postediting of the entire 3003 sentences of the WMT14 Russian-English test set.", "title": "Machine Translation and Monolingual Postediting: The AFRL WMT-14 System", "venue": "W", "graph_vector": [0.0585552, 0.290946, 0.2876, 0.410631, 0.803233, -0.694921, -0.0502774, 0.139406, -1.25189, 0.139217, -0.0259237, -0.374301, 0.345195, 0.0480163, 0.167794, -0.304801, 0.239393, -0.496119, 0.199399, 0.480625, -0.515313, 0.599562, 0.639726, 0.31556, -0.479911, -0.201765, -0.0341251, 0.509189, -0.382453, -0.176419, -0.0440242, 0.0174096, -0.00843851, -0.126201, -0.267891, 0.214661, -0.21264, 0.479432, 0.314949, 0.0213618, 0.176453, -0.537248, -0.376524, 0.692864, 1.36549, -0.804214, -0.129934, 0.0686101, 0.113868, -0.362884, 0.33738, -0.0724327, 0.766106, 0.724266, -0.342941, 0.194009, -0.103607, -0.0453817, -0.155189, 0.0817169, -0.268165, 0.0445701, 0.125904, -0.0967396, -0.0768051, 0.0919745, -0.302938, 0.301329, 0.191298, 0.0782818, 0.160078, 0.349355, -0.278057, -0.3377, 0.253249, -0.169578, -0.78088, -0.110172, -0.0706864, 0.188354, 0.046203, -0.0855265, 0.102633, -0.0657007, 0.163005, -0.385839, -0.0310223, -0.0406668, -0.0484246, -0.452054, -0.10683, 0.0787888, -0.392699, -0.0703464, 0.0772233, 0.0353665, 0.0904455, 0.153394, -0.284124, 0.088177, -0.394208, -0.117035, 0.164352, 0.0696489, -0.109664, 0.307561, -0.181373, 0.191994, 0.264422, 0.333859, 0.217191, 0.280028, 0.035618, 0.156714, -0.0703512, 0.06473, 0.201506, 0.0902886, 0.466537, 0.0177793, -0.0496926, 0.162994, 0.0357744, 0.341626, 0.642478, 0.178088, -0.134177, 0.420379], "internal": 1}
{"paper_id": "W14-3623", "abstract": "Most opinion mining methods in English rely successfully on sentiment lexicons, such as English SentiWordnet (ESWN). While there have been efforts towards building Arabic sentiment lexicons, they suffer from many deficiencies: limited size, unclear usability plan given Arabic’s rich morphology, or nonavailability publicly. In this paper, we address all of these issues and produce the first publicly available large scale Standard Arabic sentiment lexicon (ArSenL) using a combination of existing resources: ESWN, Arabic WordNet, and the Standard Arabic Morphological Analyzer (SAMA). We compare and combine two methods of constructing this lexicon with an eye on insights for Arabic dialects and other low resource languages. We also present an extrinsic evaluation in terms of subjectivity and sentiment analysis.", "title": "A Large Scale Arabic Sentiment Lexicon for Arabic Opinion Mining", "venue": "W", "graph_vector": [0.2174, 0.314602, -0.366154, -0.0117467, 0.328177, -1.03781, 0.165892, -0.120667, -1.60331, 0.252531, 0.0499282, -0.205553, 0.507133, 0.0703638, -0.0946191, 0.110883, 0.587764, -0.503417, 0.4585, 0.0329875, -0.199891, 0.846484, 0.258402, 0.260076, -0.458299, -0.108637, 0.119268, -0.058274, -0.297682, -0.30193, -0.0646275, 0.485721, -0.219693, -0.588524, -0.110351, -0.0855508, -0.211621, 0.534737, 0.00120374, 0.129717, 0.0115719, -0.364324, -0.472119, 0.723357, 1.19807, -0.297078, -0.0382371, 0.162723, 0.312134, 0.6071, 0.281909, -0.289038, 0.52065, 0.943602, 0.197886, 0.107132, -0.00460187, 0.212375, -0.067234, 0.191675, 0.298344, 0.0890318, 0.0324532, 0.246511, 0.0693975, 0.0483919, 0.305167, -0.490674, -0.212199, 0.261258, -0.121548, 0.112573, -0.00780482, -0.149475, 0.147793, 0.0362762, -0.671459, -0.470775, 0.122082, 0.159987, -0.413921, -0.0451042, 0.209861, 0.0241345, 0.30691, -0.056447, 0.0893261, -0.250116, 0.160136, -0.106281, 0.231622, 0.093386, -0.746618, -0.24421, -0.105206, 0.0132483, 0.122013, 0.082803, -0.0253979, 0.113675, -0.166805, -0.565872, -0.412855, 0.0942026, -0.140644, 0.0754889, -0.333563, 0.0540089, 0.130116, -0.455335, 0.215158, -0.103157, 0.162429, 0.033372, 0.411578, 0.10553, 0.0881968, 0.163227, 0.164262, 0.379092, -0.315612, -0.185725, 0.0478078, 0.24125, 0.397307, 0.0278252, 0.104162, -0.0339203], "internal": 1}
{"paper_id": "W14-2604", "abstract": "In this paper, we discuss how domainspecific noun polarity lexicons can be induced. We focus on the generation of good candidates and compare two machine learning scenarios in order to establish an approach that produces high precision. Candidates are generated on the basis of polarity preferences of adjectives derived from a large domain-independent corpus. The polarity preference of a word, here an adjective, reflects the distribution of positive, negative and neutral arguments the word takes (here: its nominal head). Given a noun modified by some adjectives, a vote among the polarity preferences of these adjectives establishes a good indicator of the polarity of the noun. In our experiments with five domains, we achieved f-measure of 59% up to 88% on the basis of two machine learning approaches carried out on top of the preference votes.", "title": "Inducing Domain-specific Noun Polarity Guided by Domain-independent Polarity Preferences of Adjectives", "venue": "W", "graph_vector": [-0.210233, 0.57317, 0.156778, -0.147934, 0.479522, -0.671946, -0.0890974, -0.110445, -1.95845, 0.220411, -0.0909165, -0.285336, 0.722161, -0.233351, 0.018894, -0.220338, 0.40534, -0.411317, 0.16378, 0.228838, -0.160743, 0.675221, 0.0907967, 0.1506, -0.364271, 0.204137, 0.300486, 0.095713, -0.403163, -0.473898, -0.19251, -0.0302415, -0.105285, -0.429756, -0.00916145, -0.0882152, -0.201949, 0.716047, 0.0694765, -0.239268, -0.171829, -0.331333, -0.5775, 0.574909, 0.769396, -0.704279, -0.140532, 0.155059, 0.212823, 0.100546, 0.198396, -0.360236, 0.667525, 0.859527, -0.0582864, 0.170358, -0.0202336, 0.247173, -0.26521, 0.328611, 0.0539514, 0.307633, 0.135737, 0.0812323, -0.0388497, 0.258095, 0.165365, 0.0855687, 0.107011, 0.136659, -0.138651, -0.00714877, 0.196276, -0.0181523, -0.148456, -0.262148, -0.544998, -0.255121, -0.0864722, -0.0927623, -0.269982, -0.0538085, 0.107323, -0.396843, 0.356141, -0.0639278, 0.189317, -0.129054, -0.283064, -0.125733, 0.170185, 0.0911171, -0.893488, -0.112072, 0.0012956, 0.19009, -0.0865324, 0.0531158, 0.149758, 0.233462, 0.0248985, -0.416734, -0.210954, 0.0305184, 0.065453, -0.0715339, -0.139447, 0.0315587, 0.292262, -0.383605, 0.0922843, -0.0138397, -0.0542642, -0.0546577, 0.365132, -0.307571, 0.223275, 0.277092, 0.0721046, -0.176317, -0.243093, 0.0697249, 0.133987, 0.139757, 0.515485, 0.497547, 0.0938339, -0.140997], "internal": 1}
{"paper_id": "W14-0127", "abstract": "This paper addresses problems in equivalence among concepts, within and between languages. The Kamusi Project has begun building a massively multilingual dictionary that relates as many languages as possible for which data can be gathered. In the process, we have encountered numerous complexities that we attempt to address through the design of our data structure. This paper presents the issues we have encountered, and discusses the solutions that we have developed.", "title": "Elephant Beer and Shinto Gates: Managing Similar Concepts in a Multilingual Database", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W14-3303", "abstract": "We use parallel FDA5, an efficiently parameterized and optimized parallel implementation of feature decay algorithms for fast deployment of accurate statistical machine translation systems, taking only about half a day for each translation direction. We build Parallel FDA5 Moses SMT systems for all language pairs in the WMT14 translation task and obtain SMT performance close to the top Moses systems with an average of 3.49 BLEU points difference using significantly less resources for training and development.", "title": "Parallel FDA5 for Fast Deployment of Accurate Statistical Machine Translation Systems", "venue": "W", "graph_vector": [-0.290799, 0.195819, 0.149864, 0.31109, 0.436247, -0.435292, 0.287096, -0.412538, -1.7844, 0.266701, 0.0776834, -0.240719, 0.358144, -0.00692213, 0.209074, -0.0923425, 0.435025, -0.795877, 0.14102, -0.12905, -0.476163, 0.417594, 0.202749, -0.0316281, -0.670275, 0.0969896, -0.207029, -0.0752038, -0.489911, 0.0604523, -0.0698188, 0.36671, -0.124127, 0.0344169, -0.283554, 0.0243223, -0.0746967, 0.703824, 0.0944068, -0.140746, -0.336942, 0.0337029, -0.495071, 0.557963, 0.929204, -0.670893, 0.167732, 0.170685, 0.184675, -0.0730761, -0.430717, 0.122065, 1.008, 0.6182, -0.480027, 0.0371751, -0.0084639, 0.384387, -0.0831003, -0.0601922, -0.170703, -0.137307, 0.00848694, -0.226949, -0.418321, 0.00347046, 0.427051, 0.039177, 0.144234, -0.146112, 0.0148236, 0.283751, -0.224903, -0.184205, 0.231888, -0.411845, -0.844872, -0.174083, 0.305835, 0.0113961, -0.1193, -0.420925, -0.249843, -0.32743, 0.155526, -0.570379, -0.118977, -0.260122, -0.284978, -0.0923251, 0.281037, 0.073176, -0.446694, -0.0498189, 0.233447, 0.139699, -0.169387, 0.147904, -0.239024, -0.139367, -0.286097, 0.0571159, -0.0454996, 0.287274, 0.304528, 0.0318396, -0.248115, -0.531996, 0.149735, -0.0809483, -0.0868867, 0.380705, 0.0885871, -0.212834, 0.0228117, -0.057256, -0.0560746, 0.217892, -0.323885, 0.134964, 0.138866, -0.182154, -0.0116317, 0.223412, 0.56268, 0.221416, 0.198829, -0.0319826], "internal": 1}
{"paper_id": "W14-1308", "abstract": "Text normalization is an indispensable stage for natural language processing of social media data with available NLP tools. We divide the normalization problem into 7 categories, namely; letter case transformation, replacement rules & lexicon lookup, proper noun detection, deasciification, vowel restoration, accent normalization and spelling correction. We propose a cascaded approach where each ill formed word passes from these 7 modules and is investigated for possible transformations. This paper presents the first results for the normalization of Turkish and tries to shed light on the different challenges in this area. We report a 40 percentage points improvement over a lexicon lookup baseline and nearly 50 percentage points over available spelling correctors.", "title": "A Cascaded Approach for Social Media Text Normalization of Turkish", "venue": "W", "graph_vector": [0.37718, -0.119765, 0.429446, 0.101408, 0.414585, -0.567047, -0.0219522, 0.135925, -1.61341, 0.306301, 0.137621, -0.0137004, 0.559863, 0.0134398, 0.1072, -0.14103, 0.571925, -0.764559, -0.148875, 0.586814, -0.218527, 0.91155, 0.0887109, -0.22267, -0.327441, -0.118917, 0.121691, 0.19848, 0.0307659, -0.33845, -0.338799, 0.118459, 0.0255266, -0.257472, -0.152711, 0.63348, -0.395119, 0.7061, 0.25308, -0.089787, 0.0182292, -0.487796, -0.337266, 0.402423, 1.06127, -0.988587, -0.1494, 0.167873, -0.137951, -0.446123, 0.112999, -0.238202, 1.07248, 0.993646, -0.00148602, 0.0840657, -0.104162, 0.585102, -0.151487, 0.23577, -0.299453, 0.273666, 0.286795, -0.0556039, -0.15093, -0.00041432, 0.228777, -0.187953, -0.118618, 0.357187, 0.175302, -0.128698, 0.049705, 0.0711625, 0.101923, 0.0469271, -0.70445, -0.419156, -0.118944, -0.0920343, 0.0328599, -0.37327, 0.369212, -0.18249, 0.00783046, -0.0449202, 0.418563, -0.0751188, -0.085861, 0.284971, 0.19634, 0.42826, -0.350484, -0.47734, 0.320713, 0.242931, -0.0529589, 0.0747275, 0.0137305, 0.0138945, -0.0539174, -0.0787164, -0.100913, 0.0627095, 0.245483, -0.0529188, -0.0314885, 0.00187351, -0.0133558, -0.0212518, 0.104227, 0.0397999, 0.304395, 0.0524633, -0.14396, -0.0337804, -0.230919, 0.200565, -0.360844, 0.0392446, -0.264523, -0.0632283, -0.286125, -0.0248767, 0.915045, 0.434852, -0.0397397, -0.10441], "internal": 1}
{"paper_id": "W14-3352", "abstract": "We present novel automatic metrics for machine translation evaluation that use discourse structure and convolution kernels to compare the discourse tree of an automatic translation with that of the human reference. We experiment with five transformations and augmentations of a base discourse tree representation based on the rhetorical structure theory, and we combine the kernel scores for each of them into a single score. Finally, we add other metrics from the ASIYA MT evaluation toolkit, and we tune the weights of the combination on actual human judgments. Experiments on the WMT12 and WMT13 metrics shared task datasets show correlation with human judgments that outperforms what the best systems that participated in these years achieved, both at the segment and at the system level.", "title": "DiscoTK: Using Discourse Structure for Machine Translation Evaluation", "venue": "W", "graph_vector": [0.171386, 0.138795, 0.0969779, 0.0561677, 0.113129, -0.789333, 0.0584367, 0.18334, -1.48582, -0.239657, -0.201297, -0.171393, 0.52184, 0.190681, 0.194572, 0.047103, 0.605935, -0.450992, 0.155354, 0.196717, -0.280068, 0.56746, 0.46161, -0.12535, -0.427344, 0.169726, -0.307333, 0.251338, -0.282259, -0.495341, -0.130945, -0.141266, 0.123444, -0.260156, -0.219755, 0.398148, -0.43213, 0.699529, 0.265455, -0.0218096, -0.281204, -0.265388, -0.576728, 0.21721, 1.10952, -0.49975, -0.0696332, 0.0835464, -0.076227, -0.0702632, 0.142612, -0.0523287, 1.01766, 0.744737, -0.205435, 0.0363377, 0.226359, 0.193502, -0.10301, -0.110763, -0.305625, -0.382775, -0.159239, 0.11494, -0.0342539, -0.178441, 0.0696019, -0.0344098, 0.243979, -0.319699, 0.17236, -0.413765, -0.0708207, -0.262878, 0.328505, -0.15813, -0.322116, -0.158441, -0.186364, 0.190323, 0.272951, 0.0242961, 0.362397, -0.113615, 0.0367141, -0.403814, -0.104743, -0.517303, 0.159408, 0.08437, 0.0986642, -0.219019, -0.628376, 0.16556, -0.0745589, 0.267269, -0.219658, -0.0152725, -0.2226, -0.0546312, -0.250309, 0.0797894, 0.552923, -0.28385, -0.186958, -0.223439, -0.202772, 0.249307, 0.0230735, 0.0863543, 0.287082, 0.232051, -0.224212, -0.13464, 0.107874, -0.199315, 0.400307, 0.0536995, -0.350317, 0.278791, 0.342952, 0.00510777, -0.080067, 0.135668, 0.587222, 0.190409, -0.0430193, 0.0479942], "internal": 1}
{"paper_id": "W14-1609", "abstract": "Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003—significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.", "title": "Lexicon Infused Phrase Embeddings for Named Entity Resolution", "venue": "W", "graph_vector": [0.0426252, -0.0327823, 0.137239, 0.339494, 0.341855, -0.809963, 0.0520173, 0.144688, -1.35555, 0.375102, 0.0861003, -0.632277, 0.418734, 0.34673, -0.0367506, -0.232926, 0.242017, -0.312473, 0.16713, 0.506905, -0.539339, 0.709776, -0.152536, 0.294468, -0.529068, 0.047778, -0.23176, 0.27644, 0.111339, 0.0620798, -0.16789, -0.0618458, 0.122527, -0.495429, -0.265968, 0.223028, -0.340808, 0.522769, 0.36974, -0.0977266, 0.10225, -0.559174, -0.422466, 0.525694, 0.910464, -0.815527, -0.146826, 0.234339, -0.346924, -0.192599, 0.35941, 0.027117, 0.813567, 0.416927, -0.0548752, -0.153021, 0.0460993, 0.407491, -0.00483151, -0.116224, -0.603617, -0.0510238, 0.149003, 0.0312595, 0.0963439, 0.0194631, 0.452441, 0.0700447, 0.160225, 0.0262128, -0.0493336, 0.292339, -0.109127, -0.386161, 0.317822, -0.0676222, -0.591206, -0.227551, 0.178093, -0.29175, -0.276326, 0.174786, 0.345315, 0.0815484, 0.211152, -0.230886, 0.264582, -0.180667, -0.00244292, 0.0946723, 0.0753481, 0.259154, -0.296398, -0.123946, 0.0358377, -0.122174, -0.271347, -0.063108, 0.377674, -0.250382, -0.340858, -0.514677, 0.13637, -0.18409, -0.304526, 0.303566, -0.0751967, -0.0215425, -0.0180593, -0.201845, -0.123961, -0.138156, -0.205938, 0.266066, -0.396794, 0.166088, 0.291599, 0.0760515, -0.0503301, -0.00225368, -0.15774, 0.070983, 0.155074, -0.127361, 0.219187, 0.368911, 0.0151388, 0.0242139], "internal": 1}
{"paper_id": "W14-2403", "abstract": "In present CCG-based semantic parsing systems, the extraction of a semantic grammar from sentence-meaning examples poses a computational challenge. An important factor is the decomposition of the sentence meaning into smaller parts, each corresponding to the meaning of a word or phrase. This has so far limited supervised semantic parsing to small, specialised corpora. We propose a set of heuristics that render the splitting of meaning representations feasible on a largescale corpus, and present a method for grammar induction capable of extracting a semantic CCG from the Groningen Meaning Bank.", "title": "Large-scale CCG Induction from the Groningen Meaning Bank", "venue": "W", "graph_vector": [0.0263808, 0.0203386, 0.0425863, 0.146646, 0.600333, -0.796817, 0.202731, -0.318876, -1.58604, 0.534779, 0.10062, -0.399763, 0.58173, 0.242764, 0.0266915, -0.0712155, 0.583512, -0.462607, -0.140063, 0.54974, -0.0971735, 0.406907, 0.192895, 0.0258354, -0.407204, 0.100336, 0.127053, 0.0651853, 0.309178, -0.152001, -0.138979, 0.510617, 0.260392, -0.262132, -0.305512, 0.0787899, -0.234117, 0.452784, 0.126413, -0.0173334, 0.00251633, -0.374232, -0.511353, 0.323266, 0.869473, -0.840215, 0.193545, 0.365685, 0.466772, -0.018847, 0.28594, 0.022244, 0.87549, 0.421559, -0.0947783, 0.311111, -0.158406, -0.167186, -0.254637, -0.153574, 0.0642642, -0.211198, -0.116777, -0.159876, 0.0607673, 0.0923317, 0.123589, 0.0899808, -0.149641, 0.478757, 0.125628, 0.0478673, 0.172887, -0.116955, -0.092271, -0.011228, -0.219667, -0.23112, -0.0653573, 0.421163, 0.0655919, 0.301374, 0.0834485, -0.414106, 0.118852, 0.203813, -0.150362, 0.0954741, -0.0521615, -0.0451853, -0.401016, 0.283295, -0.713545, -0.116481, -0.277927, 0.149098, -0.4332, 0.0425088, -0.364419, 0.0367384, -0.186733, -0.00647703, 0.160361, 0.0468905, -0.127942, 0.366244, 0.221661, -0.0490616, 0.335485, 0.00744721, 0.00302468, 0.123847, -0.200668, 0.172755, -0.195961, 0.185724, 0.509044, 0.0291457, -0.399867, 0.2463, 0.30905, 0.0391955, -0.0142708, -0.277571, 0.3476, 0.115481, -0.063034, -0.0666664], "internal": 1}
{"paper_id": "W14-4407", "abstract": "In this paper, we present an automatic abstractive summarization system of meeting conversations. Our system extends a novel multi-sentence fusion algorithm in order to generate abstract templates. It also leverages the relationship between summaries and their source meeting transcripts to select the best templates for generating abstractive summaries of meetings. Our manual and automatic evaluation results demonstrate the success of our system in achieving higher scores both in readability and informativeness.", "title": "A Template-based Abstractive Meeting Summarization: Leveraging Summary and Source Text Relationships", "venue": "W", "graph_vector": [-0.332235, 0.346551, -0.121484, 0.0664483, 0.277555, -0.923395, -0.16842, -0.364998, -1.67456, -0.069221, -0.582834, 0.0800073, 1.02841, 0.352855, 0.144536, -0.176201, 0.414772, -0.270804, -0.545071, 0.483279, 0.0940642, 0.561126, -0.125631, -0.153574, -0.645935, 0.0870359, 0.160493, 0.136972, -0.19487, -0.331254, 0.256241, 0.0615296, 0.166015, -0.54307, -0.146512, -0.0463791, 0.106662, 0.553915, 0.627874, 0.0601786, 0.124255, -0.825649, 0.352958, 0.0385754, 0.830649, -0.961247, 0.101214, 0.377623, -0.275792, -0.302091, 0.365696, -0.17734, 1.02202, 0.659192, -0.285991, 0.0922064, -0.129656, -0.130966, -0.242739, 0.010775, -0.31289, -0.539736, -0.250811, 0.186846, 0.25147, -0.20068, 0.504545, -0.0490284, 0.161581, -0.0358276, -0.160331, -0.135294, 0.0695175, -0.0692329, 0.0386471, 0.0841924, -0.445976, -0.24125, -0.170793, -0.428463, -0.160946, -0.259668, -0.0726277, -0.0616244, 0.14023, -0.232365, -0.136026, -0.302146, 0.151351, -0.123346, 0.107669, 0.222239, -0.687092, -0.435692, 0.138132, 0.285745, 0.149354, -0.56577, -0.222786, 0.187642, -0.128317, -0.435855, -0.258127, 0.0211128, -0.508066, -0.0374825, 0.171415, -0.231674, 0.012235, -0.108932, 0.270776, 0.266594, 0.0430955, -0.240242, 0.261329, -0.105614, 0.469148, -0.25265, 0.327403, 0.342639, -0.207629, 0.22398, 0.227492, 0.0356411, 0.222687, 0.58821, -0.135723, -0.0965888], "internal": 1}
{"paper_id": "W14-4111", "abstract": "With high dropout rates as observed in many current larger-scale online courses, mechanisms that are able to predict student dropout become increasingly important. While this problem is partially solved for students that are active in online forums, this is not yet the case for the more general student population. In this paper, we present an approach that works on click-stream data. Among other features, the machine learning algorithm takes the weekly history of student data into account and thus is able to notice changes in student behavior over time. In the later phases of a course (i.e., once such history data is available), this approach is able to predict dropout significantly better than baseline methods.", "title": "Predicting MOOC Dropout over Weeks Using Machine Learning Methods", "venue": "W", "graph_vector": [-0.371599, 0.13313, 0.298487, 0.817527, 0.288469, -0.754786, 0.206266, -0.0450828, -1.47919, 0.00028582, 0.251627, -0.260258, 0.863881, -0.134382, -0.136186, 0.0796255, 0.26891, -0.523212, 0.297512, 0.349612, -0.32097, 0.557173, 0.266224, -0.253056, -0.473242, 0.125645, 0.579749, -0.0224548, -0.00238511, -0.351508, -0.0699005, 0.102752, 0.142922, 0.00656519, -0.414856, -0.118559, -0.105459, 0.90969, 0.112659, -0.351966, -0.133472, -0.862229, -0.299396, 0.394075, 1.05662, -0.341703, 0.088463, -0.0274525, -0.0496813, -0.0331227, -0.00511032, -0.517284, 0.754284, 0.618283, -0.0898596, -0.0753274, 0.0752998, -0.224881, -0.106205, -0.124663, 0.196803, 0.005609, 0.00876531, 0.205868, -0.223928, -0.311235, 0.150168, -0.311188, -0.449971, 0.30528, 0.0401998, 0.196103, 0.187609, -0.101013, 0.0924038, -0.0591676, -0.413113, 0.0228263, 0.00800274, -0.269711, -0.318808, 0.130709, 0.205944, 0.300897, -0.149999, -0.624556, 0.019394, -0.212875, 0.0679615, 0.339097, -0.16711, 0.0659223, -1.00754, -0.0876521, -0.0910574, 0.325127, -0.102227, -0.0352837, -0.141694, 0.1014, -0.50971, -0.058458, 0.198976, -0.174282, -0.365197, -0.356113, -0.11903, 0.252431, 0.0839232, -0.40446, -0.289464, 0.0397144, 0.431498, -0.239082, -0.240444, 0.0531953, 0.301561, -0.0370467, -0.00954829, 0.533957, -0.0890241, 0.00209442, 0.140166, -0.154451, 0.461089, 0.24377, 0.0691187, 0.167392], "internal": 1}
{"paper_id": "W14-4106", "abstract": "Learning Analytics can be conceptualized as an action control process. Information is collected at the behavioral level and then re-mapped to serve diagnosis at higher levels of control. We describe the rationale for moving up the ladder of behavior control with examples from eyetracking and clickstream analysis.", "title": "Analytics: climbing up the ladder of behavior control", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W14-1306", "abstract": "Given a set of texts discussing a particular entity (e.g., customer reviews of a smartphone), aspect based sentiment analysis (ABSA) identifies prominent aspects of the entity (e.g., battery, screen) and an average sentiment score per aspect. We focus on aspect term extraction (ATE), one of the core processing stages of ABSA that extracts terms naming aspects. We make publicly available three new ATE datasets, arguing that they are better than previously available ones. We also introduce new evaluation measures for ATE, again arguing that they are better than previously used ones. Finally, we show how a popular unsupervised ATE method can be improved by using continuous space vector representations of words and phrases.", "title": "Aspect Term Extraction for Sentiment Analysis: New Datasets, New Evaluation Measures and an Improved Unsupervised Method", "venue": "W", "graph_vector": [-0.0524857, 0.387532, 0.09485, 0.448559, 0.281087, -0.697886, 0.537803, 0.0135672, -1.68414, 0.130671, -0.014861, -0.320747, 0.937585, -0.0723842, -0.0849018, -0.325095, 0.302916, -0.42839, -0.21847, 0.260023, -0.199511, 0.76393, 0.446568, -0.0487395, -0.470734, 0.165552, -0.250421, 0.173914, -0.284035, 0.0609086, -0.122994, 0.0903314, 0.283084, -0.399672, -0.125959, 0.1223, -0.261076, 0.650527, -0.0465767, -0.00562341, -0.0130241, -0.207874, -0.396272, 0.495797, 0.902369, -0.931111, 0.0412146, 0.143218, 0.0709891, 0.0357454, 0.426037, 0.332906, 0.824128, 0.70951, 0.0468015, -0.0228732, 0.285462, 0.188464, -0.14623, -0.0973741, -0.267536, 0.348328, 0.130518, -0.208915, -0.148399, 0.199645, 0.0666877, -0.265854, 0.354854, 0.190098, 0.0118924, 0.0527404, -0.0913627, -0.722938, -0.288881, -0.104388, -0.3023, -0.255381, -0.184667, -0.278766, -0.289193, 0.0837988, 0.279825, -0.068337, 0.374249, -0.411457, 0.280429, -0.0517753, -0.368352, -0.220023, 0.309271, 0.220667, -0.476231, -0.113641, -0.0916845, 0.0430324, 0.163638, -0.11852, 0.0258017, -0.0599122, -0.212699, -0.576627, -0.156888, 0.145119, 0.00536499, 0.0264734, -0.197742, 0.0942919, 0.253004, -0.221112, 0.193794, 0.190075, 0.186858, 0.0559848, -0.115207, 0.0513023, 0.452228, -0.0255866, 0.318057, 0.257623, -0.443858, -0.118847, 0.356253, -0.258895, 0.363683, 0.180574, -0.0603999, 0.0379831], "internal": 1}
{"paper_id": "W14-0611", "abstract": "In this paper, we describe a tool designed to produce a gold-standard word alignment between a text and its translation with a novel visualization. In addition, the tool is designed to aid the aligners in producing an alignment at a high level of quality and consistency. This tool is presently being used to align the Hebrew Bible with an English translation of it.", "title": "A Tool for a High-Carat Gold-Standard Word Alignment", "venue": "W", "graph_vector": [0.114079, 0.499349, 0.122319, -0.163624, 0.926005, -0.48246, 0.0484662, -0.206642, -1.50711, 0.440169, -0.313014, -0.487944, 0.850457, 0.150235, -0.0817956, -0.0931605, 0.0402151, -0.945148, 0.28609, 0.899156, -0.276735, 0.685613, 0.178199, -0.209097, -0.366172, 0.0657952, -0.0649629, -0.0747117, -0.359312, -0.072581, -0.402311, -0.0295562, 0.159074, -0.566176, -0.40876, 0.408715, -0.120242, 0.420179, -0.0179606, -0.265726, 0.321861, -0.17142, -0.653702, 0.511722, 1.15528, -0.885569, 0.0606753, 0.248779, -0.208301, -0.129216, 0.301503, -0.402621, 0.859536, 0.862878, -0.155814, -0.282858, 0.017067, -0.183582, -0.0511808, -0.0239773, -0.063817, -0.239564, -0.19584, -0.0476045, -0.224146, -0.422108, 0.0704396, -0.358814, -0.158631, -0.0727859, -0.204853, -0.0434424, 0.573005, -0.569252, 0.481913, 0.0800426, -0.720638, -0.400966, -0.228435, 0.177249, -0.258385, 0.00613415, -0.390838, 0.318561, 0.0975346, -0.0144993, 0.114439, -0.134845, -0.224823, -0.370449, -0.227348, -0.241979, -0.597259, 0.2406, 0.080464, -0.12467, -0.428007, 0.115223, -0.568431, -0.331702, -0.197784, 0.0495756, -0.110416, 0.486741, -0.111164, -0.244236, -0.206424, -0.218493, 0.45337, 0.144631, 0.0652392, 0.0491306, 0.030683, -0.213181, -0.039843, -0.44421, 0.381928, 0.208468, -0.180552, 0.638415, 0.215221, 0.424703, 0.472368, 0.121491, 0.556449, 0.406962, -0.0748625, 0.0512546], "internal": 1}
{"paper_id": "W14-1613", "abstract": "This paper proposes to learn languageindependent word representations to address cross-lingual dependency parsing, which aims to predict the dependency parsing trees for sentences in the target language by training a dependency parser with labeled sentences from a source language. We first combine all sentences from both languages to induce real-valued distributed representation of words under a deep neural network architecture, which is expected to capture semantic similarities of words not only within the same language but also across different languages. We then use the induced interlingual word representation as augmenting features to train a delexicalized dependency parser on labeled sentences in the source language and apply it to the target sentences. To investigate the effectiveness of the proposed technique, extensive experiments are conducted on cross-lingual dependency parsing tasks with nine different languages. The experimental results demonstrate the superior cross-lingual generalizability of the word representation induced by the proposed approach, comparing to alternative comparison methods.", "title": "Distributed Word Representation Learning for Cross-Lingual Dependency Parsing", "venue": "W", "graph_vector": [-0.0192632, 0.162609, -0.207831, -0.0784687, 0.328889, -0.713951, 0.338519, -0.302867, -1.46589, 0.350201, -0.315381, -0.395838, 0.391053, -0.400983, -0.205383, -0.113269, 0.382146, -0.605261, -0.229252, 0.565223, 0.030556, 0.729266, 0.369054, -0.195327, -0.207369, 0.361182, -0.146507, 0.101798, -0.273227, -0.197259, -0.111434, -0.25703, -0.0342602, -0.455336, -0.157135, 0.222454, -0.247842, 0.681225, -0.107869, -0.462965, -0.217328, -0.471227, -0.0175183, 0.657986, 0.78471, -0.826076, 0.13812, 0.192864, -0.19173, -0.164257, 0.344332, -0.387702, 0.41813, 0.762371, -0.036147, -0.00994846, 0.231668, 0.122911, 0.18717, -0.23964, -0.286177, -0.0299727, -0.149171, 0.153302, 0.0658653, -0.0579512, 0.188427, -0.117326, -0.0532579, 0.0702967, 0.280388, 0.178606, 0.0973664, -0.00658035, 0.373409, 0.0285942, -0.46857, -0.43847, -0.341855, -0.298614, 0.205355, -0.203649, 0.0158944, -0.111502, 0.26586, -0.593193, 0.0237835, -0.169019, -0.260072, -0.143037, -0.0395464, 0.323117, -0.73846, -0.320129, -0.107869, -0.230842, -0.064173, -0.152923, -0.0883332, -0.145648, 0.0204977, -0.135458, -0.0713368, 0.0661981, -0.0656066, -0.0923619, -0.0570509, -0.325552, -0.229386, -0.359338, -0.320429, -0.321758, -0.161525, -0.136468, -0.285637, 0.127767, 0.387983, -0.285238, -0.0605975, 0.229607, -0.161306, -0.0360718, -0.11934, -0.0893761, 0.297995, 0.296672, 0.277843, 0.278991], "internal": 1}
{"paper_id": "W14-4813", "abstract": "This paper presents a comparative analysis based on different classification algorithms and tools for the identification of Portuguese multiword expressions. Our focus is on two-word expressions formed by nouns, adjectives and verbs. The candidates are selected on the basis of the frequency of the bigrams; then on the basis of the grammatical class of each bigram’s constituent words. This analysis compares the performance of three different multi-layer perceptron training functions in the task of extracting different patterns of multiword expressions, using and comparing nine different classification algorithms, including decision trees, multilayer perceptron and SVM. Moreover, this analysis compares two different tools, Text-NSP and Termostat for the identification of multiword expressions using different association measures.", "title": "Identifying Portuguese Multiword Expressions using Different Classification Algorithms - A Comparative Analysis", "venue": "W", "graph_vector": [0.00674602, 0.0401597, 0.0539517, 0.16127, 0.502726, -0.988525, 0.238443, -0.131365, -1.67982, 0.159568, 0.400936, -0.029543, 0.677623, -0.0690166, -0.736823, 0.15688, 0.0593857, -0.740454, 0.32289, 0.336316, -0.414783, 0.514171, 0.213541, -0.231483, -0.338537, 0.606687, 0.521096, 0.0953785, -0.515396, -0.106157, 0.448732, 0.0280987, 0.247142, -0.0379844, 0.0252584, 0.193805, -0.642735, 0.627518, 0.279545, 0.0647875, 0.332013, -0.321649, -0.160403, 0.468798, 1.04321, -0.790528, 0.753825, -0.195335, -0.115852, -0.210357, -0.033048, -0.274779, 0.759392, 0.640749, -0.362467, -0.045846, -0.162368, 0.0253985, -0.385714, -0.0801142, -0.0916398, -0.51136, 0.166719, -0.0676156, -0.349875, -0.0409258, 0.241758, 0.227942, 0.272614, -0.494438, -0.206639, -0.396385, -0.182162, -0.239033, -0.103389, -0.0497086, -0.194961, -0.23914, 0.0510351, 0.222686, 0.0433129, 0.365268, 0.130771, 0.0574391, -0.241564, -0.190903, 0.00807167, 0.565854, 0.0776284, 0.0771572, 0.333003, 0.144286, -0.577221, -0.0153285, -0.469708, -0.169302, -0.290744, 0.197243, 0.127118, -0.0809829, -0.391988, -0.699406, -0.273431, 0.424871, -0.0125552, 0.0843532, -0.566255, -0.104659, 0.205366, 0.0155855, -0.170766, 0.0853364, -0.159434, -0.281238, 0.155734, -0.106236, -0.019816, -0.338882, 0.347008, 0.711151, -0.330375, 0.0304263, -0.121932, -0.191401, 0.485579, 0.142995, 0.0679953, 0.561742], "internal": 1}
{"paper_id": "W14-2114", "abstract": "Argumentation in a scientific article is composed of unexpressed and explicit statements of old and new knowledge combined into a logically coherent textual argument. Discourse relations, linguistic coherence relations that connect discourse segments, help to communicate an argument’s logical steps. A biomedical relation exhibits a relationship between biomedical entities. In this paper, we are primarily concerned with the extraction of connections between biomedical relations, a connection that we call a higher order relation. We combine two methods, namely biomedical relation extraction and discourse relation parsing, to extract such higher order relations from biomedical research articles. Finding and extracting these relations can assist in automatically understanding the scientific arguments expressed by the author in the text.", "title": "Extracting Higher Order Relations From Biomedical Text", "venue": "W", "graph_vector": [0.238568, 0.441915, 0.311889, 0.192972, 0.191638, -0.52818, 0.208637, -0.315755, -2.06605, 0.457142, 0.0515615, -0.26818, 0.6179, -0.0729908, 0.0190034, -0.188508, 0.417659, -0.426899, 0.456745, 0.010175, -0.441146, 0.457505, 0.266761, 0.0213591, -0.585911, 0.146243, -0.0327483, -0.00588465, -0.370642, -0.48764, 0.0561354, -0.104415, 0.0221909, -0.362725, 0.0563784, -0.167195, -0.244974, 0.527535, 0.335224, -0.207964, -0.172014, -0.196967, -0.493559, 0.26304, 1.24383, -0.649245, 0.102617, -0.308826, -0.357256, 0.279942, 0.104709, -0.0692609, 1.04437, 0.523277, -0.172015, 0.392555, 0.251911, -0.102428, 0.297693, 0.281142, -0.196686, -0.21225, -0.156084, -0.0108955, -0.105774, 0.227221, 0.11197, -0.256321, 0.164136, 0.000865023, 0.0446702, -0.214327, -0.236413, -0.128887, -0.16665, 0.381529, -0.0245908, -0.150343, 0.163059, -0.0676682, -0.374197, -0.0899917, -0.0462027, -0.279558, 0.106595, -0.157017, 0.00156865, -0.0324985, 0.248093, -0.342477, 0.118592, 0.482067, -0.389461, -0.0752148, -0.170518, -0.193777, -0.302755, -0.453177, 0.0696542, -0.0508918, -0.411074, 0.0172492, 0.159031, -0.0805182, -0.303812, -0.00101592, -0.286776, 0.415347, -0.158824, 0.0835973, 0.0164046, 0.0885869, 0.14448, -0.122811, -0.120019, -0.118154, 1.14484, -0.0291447, -0.0961329, 0.181846, 0.226974, -0.139109, -0.0136733, -0.0446997, 0.528578, 0.309111, 0.247657, 0.132826], "internal": 1}
{"paper_id": "W14-6202", "abstract": "The rapid growth in IT in the last two decades has led to a growth in the amount of information available online. A new style for sharing information is social media. Social media is a continuously instantly updated source of information. In this position paper, we propose a framework for Information Extraction (IE) from unstructured user generated contents on social media. The framework proposes solutions to overcome the IE challenges in this domain such as the short context, the noisy sparse contents and the uncertain contents. To overcome the challenges facing IE from social media, State-Of-The-Art approaches need to be adapted to suit the nature of social media posts. The key components and aspects of our proposed framework are noisy text filtering, named entity extraction, named entity disambiguation, feedback loops, and uncertainty handling.", "title": "Information Extraction for Social Media", "venue": "W", "graph_vector": [0.0983017, 0.211342, 0.273679, -0.164381, 0.529965, -0.15937, 0.100087, 0.493601, -1.70951, 0.493614, 0.345054, -0.537423, 0.707548, -0.0299836, 0.234242, 0.122468, 0.522924, -0.387381, -0.251807, 0.139979, -0.41969, 0.561677, -0.029004, -0.133509, -0.242552, -0.0913966, 0.0702745, 0.307895, -0.16107, 0.144369, -0.112601, 0.0388841, 0.160602, -0.591871, -0.427133, 0.060537, -0.235537, 0.71911, 0.436017, -0.153605, 0.289368, -0.740463, -0.104004, 1.1697, 0.982186, -0.471468, -0.180965, 0.449734, -0.182528, -0.130695, 0.200977, 0.299984, 0.946736, 0.980874, -0.144592, -0.169285, -0.0977347, 0.245197, -0.208996, -0.185778, -0.190299, -0.581256, -0.0493837, -0.0215327, -0.317336, -0.0490421, 0.0129892, -0.120134, 0.0481504, 0.483027, 0.0955522, 0.0420385, -0.24718, 0.0336409, -0.0590776, -0.547821, -0.492531, -0.423537, 0.0881559, -0.0561169, -0.0523705, -0.0287078, 0.087167, -0.260286, -0.0918168, -0.224957, -0.0775124, 0.110004, 0.138831, 0.0588603, -0.399211, 0.266523, -0.783333, 0.0567762, 0.0307972, 0.0901816, -0.332795, 0.273595, -0.0526412, 0.156333, -0.42589, -0.197548, 0.173259, 0.11311, -0.0698325, 0.136807, -0.05494, 0.39204, 0.387068, -0.142091, -0.0003819, 0.0468394, -0.245542, 0.141725, -0.242084, 0.119338, 0.45271, -0.0696443, 0.0676402, 0.362708, -0.154115, 0.0464059, -0.134052, 0.0769559, 0.37272, 0.578087, -0.304378, -0.192124], "internal": 1}
{"paper_id": "W14-3507", "abstract": "The paper describes the learner corpus composed of English essays written by native Russian speakers. REALEC (Russian Error-Annotated Learner English Corpus) is an error-annotated, available online corpus, now containing more than 200 thousand word tokens in almost 800 essays. It is one of the first Russian ESL corpora, dynamically developing and striving to improve both in size and in features offered to users. We describe our perspective on the corpus, data sources and tools used in compiling it. Elaborate self-made classification of learners’ errors types is thoroughly described. The paper also presents a pilot experiment on creating test sets for particular learners’ problems using corpus data. KEYWORDS: learner corpora, English as a second language, computer-assisted language learning.", "title": "Russian Error-Annotated Learner English Corpus: a Tool for Computer-Assisted Language Learning", "venue": "W", "graph_vector": [0.356085, 0.347581, 0.581631, 0.269195, 0.857586, -0.317911, 0.477114, 0.050426, -1.70446, 0.200328, -0.158207, -0.262252, 1.06354, 0.307497, 0.0572094, 0.0631289, 0.979108, -0.315544, 0.194452, 0.473325, -1.21872, 1.45704, 0.16307, 0.440343, -0.366905, 0.170108, -0.219088, 0.264248, -1.01359, -0.0419069, 0.369108, 0.32604, 0.101216, -0.292489, 0.332793, 0.383012, 0.0141269, 0.594886, 0.529837, 0.208743, -0.0388153, -0.147599, -0.136855, -0.329985, 1.35446, -0.898348, 0.0948033, 0.295057, -0.275669, 0.414619, 0.429098, -0.224012, 0.992591, 1.41769, 0.175458, 0.155761, -0.13586, -0.0528227, 0.300411, 0.0742828, 0.213634, 0.16263, 0.0897534, 0.179805, -0.137124, 0.441195, 0.0980805, -0.0905727, -0.236757, 0.207976, 0.074862, -0.346962, -0.0481452, 0.252523, 0.342325, 0.0551289, -0.432924, -0.57239, -0.367292, 0.328611, -0.0141329, 0.334087, 0.407578, -0.179773, 0.439097, -0.122681, 0.457694, -0.479049, -0.53708, 0.288265, 0.111084, 0.175464, -0.836508, -0.516832, 0.163017, 0.0511628, 0.262032, 0.383207, -0.233087, -0.0507932, -0.23401, -0.511283, 0.161148, 0.611379, -0.234347, -0.0600162, -0.404466, -0.232648, -0.108186, 0.127421, 0.573523, -0.00265262, -0.348915, 0.00645287, -0.34763, 0.497897, 0.130883, 0.130279, -0.478154, 0.194966, -0.0208016, -0.246866, -0.123885, 0.355938, 0.719506, 0.0881263, -0.080179, 0.475414], "internal": 1}
{"paper_id": "W14-3619", "abstract": "In this paper we describe the implementation of an Arabic error correction system developed for the EMNLP2014 shared task on automatic error correction for Arabic text. We proposed a novel algorithm, where we find some correction rules and calculate their probability based on the training data, they we rank the correction rules, then we apply them on the text to maximize the overall Fscore for the provided data. The system achieves and F-score of 0.6573 on the test data.", "title": "Fast and Robust Arabic Error Correction System", "venue": "W", "graph_vector": [0.194848, 0.115218, 0.0490161, 0.196216, 0.351498, -0.632136, 0.203954, 0.0710214, -1.83054, 0.18738, 0.461338, 0.169908, 0.672685, -0.0270573, -0.267015, -0.282057, 0.50362, -0.937512, 0.308458, 0.423333, -0.678645, 1.02085, 0.260838, -0.139624, -0.390993, 0.320752, -0.0165833, 0.0638076, -0.36375, -0.0743128, 0.188545, 0.107766, 0.0104877, -0.592616, -0.168319, 0.0846002, -0.158339, 0.545727, 0.417851, -0.230415, -0.103837, -0.251486, -0.582434, 0.536268, 1.05213, -0.534865, -0.228268, 0.042474, 0.220383, -0.0107021, 0.368103, -0.678243, 0.49062, 0.638836, -0.220251, 0.0769217, 0.0177981, 0.229356, -0.136763, 0.460979, -0.307656, 0.0196908, -0.0425923, 0.0585945, 0.125263, 0.293676, 0.256481, -0.0829981, -0.423946, 0.437551, -0.298513, -0.0853123, -0.0462822, 0.00665173, -0.097713, -0.108269, -0.458032, -0.487059, 0.360903, 0.068191, -0.327674, 0.128568, 0.0572169, 0.166991, -0.00455774, -0.336678, -0.0189598, -0.195289, 0.000525442, -0.152407, 0.0196996, -0.213347, -0.376206, -0.118789, -0.226777, 0.436785, -0.149895, -0.114988, -0.19725, 0.0413936, -0.0600002, -0.242258, -0.246841, 0.424285, 0.121192, 0.160341, 0.0444225, -0.212414, -0.308461, -0.258355, 0.226335, 0.223933, 0.332612, 0.0305611, -0.0377113, 0.0944985, 0.34191, 0.372997, 0.140162, 0.424574, -0.30965, -0.127571, -0.219192, 0.0301674, 0.582872, 0.0873647, -0.153249, -0.0553681], "internal": 1}
{"paper_id": "W14-4921", "abstract": "This paper presents an annotation scheme for a new semantic annotation task with relevance for analysis and computation at both the clause level and the discourse level. More specifically, we label the finite clauses of texts with the type of situation entity (e.g., eventualities, statements about kinds, or statements of belief) they introduce to the discourse, following and extending work by Smith (2003). We take a feature-driven approach to annotation, with the result that each clause is also annotated with fundamental aspectual class, whether the main NP referent is specific or generic, and whether the situation evoked is episodic or habitual. This annotation is performed (so far) on three sections of the MASC corpus, with each clause labeled by at least two annotators. In this paper we present the annotation scheme, statistics of the corpus in its current version, and analyses of both inter-annotator agreement and intra-annotator consistency.", "title": "Situation entity annotation", "venue": "W", "graph_vector": [-0.387064, 0.564775, 0.220504, 0.452239, 0.395633, -0.608803, -0.41368, -0.466189, -1.65006, 0.250029, -0.415032, -0.44607, 0.254461, 0.109768, -0.251397, 0.435391, 0.292331, -0.722919, 0.0444265, 0.38604, -0.607855, 0.621172, 0.105321, 0.0204425, -0.736561, -0.0968738, 0.0766482, 0.0357821, -0.122247, -0.199745, -0.200777, 0.149453, -0.0945552, 0.050044, 0.117203, 0.142739, -0.161358, 0.659063, 0.245295, 0.00753022, -0.0145095, -0.513383, -0.112357, -0.0940755, 1.17774, -0.250893, 0.122391, -0.00369529, -0.00120718, -0.332471, 0.420456, 0.0995129, 1.00567, 0.44454, -0.0622164, 0.349785, -0.0541877, 0.193495, -0.426326, -0.25394, -0.155872, -0.0808701, -0.0542672, -0.368374, 0.111895, -0.198434, 0.191182, -0.171716, 0.339472, -0.238331, 0.157289, -0.221869, 0.277086, 0.334131, -0.00386865, -0.0439855, -0.631563, -0.364746, -0.23667, 0.57182, -0.455645, -0.175836, 0.275386, 0.0979728, 0.110225, 0.0132331, 0.0127573, 0.17698, 0.164478, -0.110166, 0.435033, 0.185749, -0.730479, -0.282127, 0.0251053, -0.226822, -0.0259868, 0.177161, -0.194823, 0.0229262, 0.0519391, -0.0550796, 0.234434, 0.0473041, -0.29073, 0.182314, 0.209185, -0.0720292, -0.387338, -0.287041, 0.0622579, 0.353466, 0.235583, 0.133751, 0.01756, 0.474706, 0.317595, -0.329584, 0.0971262, 0.165719, -0.248982, 0.0479235, -0.165112, -0.151868, -0.0260641, 0.492351, -0.268618, -0.737967], "internal": 1}
{"paper_id": "W14-1903", "abstract": "We aim to build dialogue agents that optimize the dialogue strategy, specifically through learning the dialogue model components from dialogue data. In this paper, we describe our current research on automatically learning dialogue strategies in the healthcare domain. We go through our systematic approach of learning dialogue model components from data, specifically user intents and the user model, as well as the agent reward function. We demonstrate our experiments on healthcare data from which we learned the dialogue model components. We conclude by describing our current research for automatically learning dialogue features that can be used in representing dialogue states and learning the reward function.", "title": "Dialogue Strategy Learning in Healthcare: A Systematic Approach for Learning Dialogue Models from Data", "venue": "W", "graph_vector": [0.161304, 0.561072, 0.0764677, 0.209413, 0.594858, -0.619592, 0.361427, -0.13348, -1.80844, 0.00534675, -0.574402, -0.0383355, 0.76004, 0.0982365, -0.458789, -0.48844, 0.611522, -0.541183, -0.371715, -0.219676, -0.180353, 0.604837, 0.49605, -0.158798, -0.528046, -0.0203434, 0.0284422, -0.184041, -0.345023, -0.123537, 0.201167, 0.126476, 0.497639, -0.478389, -0.103388, 0.38455, -0.319275, 1.08836, -0.0229429, 0.146766, 0.122084, -0.333023, -0.407526, 0.790412, 1.05543, -1.07536, 0.115081, -0.189947, -0.218236, 0.0536286, 0.256384, 0.0925272, 0.478535, 0.819721, -0.084352, 0.292273, -0.440707, 0.666004, 0.104424, -0.343528, 0.054567, -0.295719, 0.124211, 0.132252, -0.249077, 0.208979, 0.199983, -0.222834, -0.0476356, -0.0897748, -0.173406, 0.277675, 0.0805288, -0.402831, 0.511173, -0.514273, -0.385094, -0.194066, -0.0873035, 0.202837, -0.0261955, -0.0613887, 0.552763, -0.427321, 0.0589574, -0.0697573, 0.0174369, 0.137651, 0.164299, 0.352067, -0.188358, -0.156489, -0.482682, 0.0777968, 0.397508, 0.204585, -0.0316032, -0.360658, 0.0282227, -0.393521, -0.0403607, -0.593436, -0.284647, 0.0824639, 0.0224389, 0.245575, -0.548953, -0.165053, 0.37652, 0.103682, -0.359843, 0.209588, -0.585802, -0.151185, -0.171145, -0.18274, 0.323181, 0.335685, -0.200552, 0.252612, -0.293544, 0.273235, -0.60904, -0.0515441, -0.0364316, 0.0920673, -0.326474, -0.0248687], "internal": 1}
{"paper_id": "W14-4807", "abstract": "This paper introduces ACL RD-TEC: a dataset for evaluating the extraction and classification of terms from literature in the domain of computational linguistics. The dataset is derived from the Association for Computational Linguistics anthology reference corpus (ACL ARC). In its first release, the ACL RD-TEC consists of automatically segmented, part-of-speech-tagged ACL ARC documents, three lists of candidate terms, and more than 82,000 manually annotated terms. The annotated terms are marked as either valid or invalid, and valid terms are further classified as technology and non-technology terms. Technology terms signify methods, algorithms, and solutions in computational linguistics. The paper describes the dataset and reports the relevant statistics. We hope the step described in this paper encourages a collaborative effort towards building a full-fledged annotated corpus from the computational linguistics literature.", "title": "The ACL RD-TEC: A Dataset for Benchmarking Terminology Extraction and Classification in Computational Linguistics", "venue": "W", "graph_vector": [-0.0973561, 0.444614, 0.446196, 0.441062, 1.07639, -0.411486, -0.337167, 0.395009, -1.38302, 0.314544, -0.194111, -0.12598, 1.04951, 0.07918, -0.0860463, -0.261165, 0.609616, -0.38182, 0.318206, 0.539871, -0.534074, 0.333989, 0.26376, 0.234441, -0.49655, 0.391872, -0.476592, -0.0476282, -0.66019, -0.174129, 0.294623, -0.146806, -0.201981, 0.322907, -0.237676, 0.136279, -0.28646, 0.640068, 0.381961, -0.160027, -0.040947, -0.720513, -0.2908, 0.37784, 1.19211, -0.774346, 0.18356, -0.365088, -0.421232, 0.382005, 0.485439, -0.481788, 0.94162, 1.34209, -0.127722, 0.403196, 0.0327901, -0.226658, -0.459911, -1.03373, -0.217911, -0.471727, -0.232567, 0.134735, 0.194595, -0.356126, 0.491646, -0.048185, -0.335032, -0.196581, -0.364846, -0.115156, -0.498899, -0.150768, 0.148822, -0.300627, -0.256728, -0.592586, -0.419329, -0.216692, -0.145929, -0.293445, -0.122777, -0.319065, 0.335579, 0.0587892, 0.23291, 0.032068, -0.66411, -0.376401, -0.323659, -0.0820596, -0.86667, -0.0295888, -0.222049, -0.0786675, -0.651497, -0.507725, -0.0855434, -0.00701449, -0.608761, -0.117759, 0.133753, 0.26893, -0.393929, 0.0127299, 0.126207, -0.0531813, 0.136172, -0.349861, 0.139089, -0.204228, 0.0425209, -0.163016, 0.0706223, -0.422645, 0.401446, 0.338681, 0.0396599, 0.0965793, -0.276437, -0.232178, 0.0190801, -0.473581, 0.236924, -0.218219, 0.0757522, -0.124522], "internal": 1}
{"paper_id": "W14-4108", "abstract": "This work is an attempt to discover hidden structural configurations in learning activity sequences of students in Massive Open Online Courses (MOOCs). Leveraging combined representations of video clickstream interactions and forum activities, we seek to fundamentally understand traits that are predictive of decreasing engagement over time. Grounded in the interdisciplinary field of network science, we follow a graph based approach to successfully extract indicators of active and passive MOOC participation that reflect persistence and regularity in the overall interaction footprint. Using these rich educational semantics, we focus on the problem of predicting student attrition, one of the major highlights of MOOC literature in the recent years. Our results indicate an improvement over a baseline ngram based approach in capturing “attrition intensifying” features from the learning activities that MOOC learners engage in. Implications for some compelling future research are discussed.", "title": "Capturing “attrition intensifying” structural traits from didactic interaction sequences of MOOC learners", "venue": "W", "graph_vector": [-0.357769, 0.242126, 0.925532, 0.587991, 0.342217, -0.771, 0.519695, 0.0177427, -2.42162, 0.0531493, -0.21109, -0.174239, 0.951229, -0.141767, -0.237789, 0.15992, 0.594197, -0.583679, 0.0318728, 0.198176, -0.476822, 0.781297, 0.167453, -0.152505, -0.701183, -0.0319734, 0.423774, -0.183502, -0.177748, -0.0307775, 0.0572611, 0.414589, 0.662004, -0.420223, -0.359862, -0.228022, -0.323105, 1.10806, 0.043312, -0.348943, -0.25414, -0.669392, -0.394806, 0.824711, 1.46049, -0.699857, 0.228326, -0.0204158, -0.162183, 0.328005, 0.226149, 0.0415179, 1.31306, 0.629571, -0.0778194, 0.000148411, -0.0275605, -0.0338242, -0.281011, -0.00146309, 0.205275, 0.258353, -0.260735, -0.11333, -0.35376, 0.404171, -0.0641242, -0.342232, -0.350632, 0.256995, -0.0272517, 0.134958, 0.197634, -0.390624, 0.469088, -0.0487865, -0.547155, -0.220678, -0.617375, -0.684226, -0.120715, 0.0668128, 0.0654452, 0.338648, 0.187263, -0.739531, -0.332667, 0.0486445, 0.0147933, 0.333738, 0.168261, -0.0470343, -1.07285, -0.106418, -0.510977, 0.526024, -0.0799271, -0.0638403, -0.170255, 0.164364, -0.725841, -0.372221, -0.0316429, -0.119692, -0.30544, -0.45438, -0.0672697, 0.232724, 0.373728, -0.460923, -0.363609, 0.258265, 0.176357, -0.227802, -0.273799, 0.0651887, 0.284136, -0.37195, -0.00430191, 0.318108, -0.265836, -0.437428, -0.190337, -0.301318, 0.717454, 0.535644, 0.1011, -0.117874], "internal": 1}
{"paper_id": "W14-6102", "abstract": "In this paper we present several approaches towards constructing joint ensemble models for morphosyntactic tagging and dependency parsing for a morphologically rich language – Bulgarian. In our experiments we use state-of-the-art taggers and dependency parsers to obtain an extended version of the treebank for Bulgarian, BulTreeBank, which, in addition to the standard CoNLL fields, contains predicted morphosyntactic tags and dependency arcs for each word. In order to select the most suitable tag and arc from the proposed ones, we use several ensemble techniques, the result of which is a valid dependency tree. Most of these approaches show improvement over the results achieved individually by the tools for tagging and parsing.", "title": "Joint Ensemble Model for POS Tagging and Dependency Parsing", "venue": "W", "graph_vector": [0.143263, 0.128223, 0.0876227, 0.242722, 0.897135, -0.881499, 0.0783458, -0.407219, -1.4407, 0.273478, -0.178823, -0.465726, 0.704359, 0.142056, -0.189714, -0.353651, 0.559209, -0.769779, -0.359791, 0.211291, -0.259898, 1.03978, 0.0629061, -0.304639, -0.0940606, 0.230214, 0.0637671, 0.0514133, -0.608175, -0.348798, 0.01812, -0.277069, -0.113254, -0.323349, -0.165493, 0.278667, -0.34302, 0.54577, 0.253323, 0.119339, 0.0084465, -0.0669049, 0.0166908, 0.0615222, 0.841884, -0.599106, -0.195471, 0.645081, -0.0624868, 0.186585, 0.310665, -0.293255, 0.91699, 0.467345, -0.177623, -0.23833, 0.0582057, 0.111981, 0.194085, 0.161205, 0.0814696, 0.0321156, 0.178061, -0.241088, -0.405242, 0.123134, 0.228195, -0.0974735, -0.101805, 0.583049, 0.368113, 0.360947, -0.458473, -0.0806344, 0.332633, 0.0666398, -0.582783, -0.184076, 0.030071, -0.0427513, -0.0330654, -0.0929238, 0.235466, -0.33113, -0.0238182, -0.566648, -0.00322755, -0.104728, 0.192745, -0.374602, 0.381593, 0.0939037, -0.41262, 0.0811956, -0.00421987, -0.252571, -0.106376, -0.0395742, -0.317527, 0.121319, 0.162545, -0.360502, 0.0872706, 0.48952, 0.0566602, 0.0457097, -0.311149, 0.0955863, 0.290738, -0.0927261, -0.305191, 0.1026, 0.117544, -0.126527, -0.019054, -0.188004, 0.399895, -0.00569592, 0.264868, 0.209959, -0.409412, -0.130345, -0.102683, -0.0323601, 0.325004, 0.227961, -0.228192, -0.079374], "internal": 1}
{"paper_id": "W14-4309", "abstract": "Although data-driven techniques are commonly used for Natural Language Understanding in dialogue systems, their efficacy is often hampered by the lack of appropriate annotated training data in sufficient amounts. We present an approach for rapid and cost-effective annotation of training data for classification-based language understanding in conversational dialogue systems. Experiments using a webaccessible conversational character that interacts with a varied user population show that a dramatic improvement in natural language understanding and a substantial reduction in expert annotation effort can be achieved by leveraging non-expert annotation.", "title": "Improving Classification-Based Natural Language Understanding with Non-Expert Annotation", "venue": "W", "graph_vector": [0.335292, -0.0328263, -0.288708, 0.0808271, 0.358254, -1.19094, 0.31235, -0.0359475, -1.74098, 0.119012, -0.344139, 0.140677, 0.59222, -0.250372, 0.00121772, 0.044974, 0.501704, -0.275978, -0.350245, 0.0587545, -0.365572, 0.692141, 0.16172, -0.0527802, -0.481448, 0.129216, -0.353784, 0.0578379, -0.176076, 0.165846, -0.309136, -0.29733, -0.0867793, -1.31366, -0.10857, -0.216969, -0.23086, 0.564027, 0.311242, 0.450831, 0.359478, -0.14876, -0.500526, 0.0692801, 0.956286, -1.02114, 0.06169, -0.518406, 0.0117779, -0.407459, 0.63858, -0.142667, 0.9116, 0.75661, -0.140887, 0.081073, 0.56485, 0.393087, 0.315496, 0.0274182, -0.0610544, -0.0863696, 0.00518692, 0.149039, -0.251961, 0.313394, 0.110712, 0.260752, 0.0200207, 0.268119, 0.291441, 0.299225, 0.323946, -0.0342667, -0.0702125, -0.041313, -0.43586, -0.441086, -0.116788, 0.521104, -0.1608, -0.234446, 0.259047, -0.134777, 0.0162817, -0.0255953, 0.190201, 0.000729049, 0.21014, -0.206712, 0.265849, 0.0403319, -0.489145, -0.0721503, 0.233779, 0.204268, 0.042066, -0.0958739, 0.245155, -0.327014, -0.424796, -0.492603, 0.122235, 0.361635, -0.6866, 0.0412489, 0.34863, 0.299218, 0.154489, -0.451952, -0.120795, 0.115747, -0.145818, -0.0520557, 0.165507, -0.311647, 0.0965945, -0.138289, 0.027828, -0.104541, 0.237819, -0.198247, -0.343459, -0.0684671, 0.29249, 0.716836, -0.267145, 0.058192], "internal": 1}
{"paper_id": "W14-6904", "abstract": "We present a supervised hybrid approach for Sentiment Analysis in Twitter. A sentiment lexicon is built from a dataset, where each tweet is labelled with its overall polarity. In this work, skipgrams are used as information units (in addition to words and n-grams) to enrich the sentiment lexicon with combinations of words that are not adjacent in the text. This lexicon is employed in conjunction with machine learning techniques to create a polarity classifier. The evaluation was carried out against different datasets in English and Spanish, showing an improvement with the usage of skipgrams.", "title": "A Supervised Approach for Sentiment Analysis using Skipgrams", "venue": "W", "graph_vector": [0.147091, 0.183659, 0.00815198, 0.396494, 0.287903, -0.818483, -0.11817, 0.104641, -1.03929, 0.0644073, -0.301454, -0.234942, 0.533382, -0.124848, -0.235026, -0.253542, 0.17757, -0.438194, 0.107253, 0.000498037, -0.098486, 0.276573, 0.25179, 0.0750576, -0.225732, 0.110229, 0.370235, -0.0572858, -0.0922349, -0.0194623, 0.120827, -0.189722, 0.140061, -0.305717, -0.0320347, 0.223994, -0.0529205, 0.51309, 0.352346, -0.249662, -0.271313, -0.349078, -0.381584, 0.284583, 0.758497, -0.745224, 0.144416, -0.012562, -0.196733, 0.0570126, 0.172164, 0.0675687, 0.686278, 0.538834, -0.124441, 0.00693861, 0.100603, -0.0469989, 0.0628966, -0.11118, 0.0369066, 0.182633, -0.12518, -0.0828324, -0.20882, 0.188446, 0.161089, 0.0357937, 0.0985361, 0.0488475, -0.190338, 0.0351312, 0.0616435, 0.0576606, 0.394897, -0.355289, -0.629213, -0.339156, 0.149964, -0.0150759, 0.0180382, 0.14708, 0.14406, 0.190122, 0.010253, -0.0667609, 0.0469053, 0.074914, 0.164923, 0.0457265, -0.249682, 0.0170193, -0.888901, -0.119239, 0.01159, 0.199545, -0.0996282, -0.116221, -0.261508, 0.0539058, 0.00923462, -0.38496, -0.0509244, -0.210012, -0.125753, -0.0167409, -0.0844539, 0.13576, 0.145846, -0.15164, -0.132508, 0.0113561, 0.234574, 0.357907, -0.0266238, -0.0982242, 0.16734, 0.00685056, -0.0249696, 0.302115, -0.172673, -0.141074, -0.106513, -0.0102676, 0.176581, 0.142014, 0.125107, 0.1942], "internal": 1}
{"paper_id": "W10-3911", "abstract": "The rapid spread of electronic health records raised an interest to large-scale information extraction from clinical texts. Considering such a background, we are developing a method that can extract adverse drug event and effect (adverse—effect) relations from massive clinical records. Adverse—effect relations share some features with relations proposed in previous relation extraction studies, but they also have unique characteristics. Adverse—effect relations are usually uncertain. Not even medical experts can usually determine whether a symptom that arises after a medication represents an adverse— effect relation or not. We propose a method to extract adverse—effect relations using a machine-learning technique with dependency features. We performed experiments to extract adverse—effect relations from 2,577 clinical texts, and obtained F,-score of 37.54 with an optimal parameters and F,-score of 34.90 with automatically tuned parameters. The results also show that dependency features increase the extraction F,-score by 3.59.", "title": "Adverse—Effect Relations Extraction from Massive Clinical Records Yasuhide Miura a, Eiji Aramaki b, Tomoko Ohkuma a, Masatsugu Tonoike a, Daigo Sugihara &quot;, Hiroshi Masuichi&quot; and Kazuhiko Ohe `", "venue": "W", "graph_vector": [-0.365845, -0.0136889, 0.435178, 0.330637, 0.703822, -0.29746, 0.24844, 0.0894615, -1.61362, 0.464463, -0.0930568, -0.435047, 0.621374, 0.241953, 0.104945, -0.184492, 0.500285, -0.660314, 0.504586, 0.330733, -0.270037, 0.348748, 0.519479, -0.00785747, -0.568258, 0.15529, 0.00242889, -0.0819707, -0.531335, -0.244028, 0.456535, -0.0225774, -0.20861, -0.222435, 0.156018, 0.0513453, -0.407572, 0.771184, 0.0806019, 0.0630053, -0.407198, -0.327763, -0.495264, 0.0240393, 0.845504, -0.396203, -0.0469644, 0.128262, -0.0412158, 0.363006, 0.213295, -0.294212, 0.59427, 0.62859, 0.261059, -0.0197051, -0.0420309, 0.384218, 0.0402491, -0.18224, 0.207075, -0.0230304, -0.208045, -0.21016, -0.296673, -0.120786, 0.233855, -0.196258, 0.288356, 0.156411, 0.141421, 0.133226, 0.0696806, 0.248584, 0.00390929, -0.254088, -0.261339, -0.378529, 0.0203797, -0.0148976, -0.0645733, 0.110239, 0.247383, 0.0475331, -0.279759, -0.519745, 0.154074, 0.404748, 0.174029, -0.133729, -0.0532051, -0.137599, -0.52176, -0.300499, 0.102582, -0.0799169, -0.243529, -0.114202, -0.0165217, -0.254339, -0.0611334, 0.00480811, -0.0903074, -0.0406568, -0.283453, -0.337426, -0.00322626, -0.0806208, -0.0642085, -0.300827, 0.145501, 0.0414125, 0.0305328, 0.243631, -0.472379, -0.439665, 0.51227, 0.117601, 0.0604714, 0.0791737, -0.0641373, -0.462614, -0.422861, -0.0182198, 0.597783, 0.0750277, -0.0850784, 0.216629], "internal": 1}
{"paper_id": "W10-1002", "abstract": "Second language acquisition research since the 90s has emphasized the importance of supporting awareness of language categories and forms, and input enhancement techniques have been proposed to make target language features more salient for the learner. We present an NLP architecture and webbased implementation providing automatic visual input enhancement for web pages. Learners freely choose the web pages they want to read and the system displays an enhanced version of the pages. The current system supports visual input enhancement for several language patterns known to be problematic for English language learners, as well as fill-in-the-blank and clickable versions of such pages supporting some learner interaction.", "title": "Enhancing Authentic Web Pages for Language Learners", "venue": "W", "graph_vector": [0.33573, 0.535485, 0.00130448, 0.395297, 0.727802, -0.363181, 0.263303, -0.202623, -1.86862, 0.553019, 0.0530508, -0.100309, 1.11957, -0.268679, 0.217642, -0.0976423, 0.212006, -0.659672, 0.0301902, -0.130193, -0.300987, 0.796075, 0.162705, 0.133911, -0.319298, 0.0720585, -0.0385403, -0.0692782, -0.212231, -0.272671, 0.593909, 0.433159, 0.348849, -0.125819, -0.496369, 0.356726, -0.505116, 0.824721, -0.176383, 0.651043, 0.167248, -0.0377403, -0.666765, 0.048076, 1.0715, -0.776933, -0.320817, -0.116491, 0.214298, -0.0436386, 0.683376, -0.0648263, 0.97121, 0.269171, -0.488304, 0.112895, 0.323576, 0.02616, -0.0171577, -0.394448, -0.0276148, -0.558493, 0.207724, -0.319142, -0.156607, -0.0666017, 0.284154, -0.0918495, 0.140202, 0.357086, -0.0743183, -0.106346, 0.151581, 0.350866, 0.382946, -0.384437, -0.22712, -0.800477, -0.483035, 0.131473, -0.290262, 0.151941, 0.278943, 0.248565, -0.147867, -0.00086055, 0.00471209, -0.237998, -0.265236, -0.0304368, 0.152068, 0.254403, -0.631787, 0.204642, 0.0999263, -0.0042465, 0.0460732, 0.157268, 0.0441547, -0.0554226, -0.120735, -0.48424, -0.30092, 0.536731, -0.133429, 0.502151, 0.0917239, -0.512902, -0.0443885, -0.1807, 0.658385, -0.150331, -0.184, -0.445075, 0.355098, 0.245619, 0.681163, 0.21882, -0.495863, 0.384902, -0.0551867, 0.37346, 0.186429, 0.278867, 0.0997206, 0.392542, 0.0285588, 0.237261], "internal": 1}
{"paper_id": "W10-3711", "abstract": "In this paper we tackle the challenging task of Multi-word term (MWT) extraction from different types of specialized corpora. Contrastive filtering of previously extracted MWTs results in a considerable increment of acquired domainspecific terms.", "title": "Contrastive Filtering of Domain-Specific Multi-Word Terms from Different Types of Corpora", "venue": "W", "graph_vector": [], "internal": 1}
{"paper_id": "W10-2309", "abstract": "This paper examines the influence of features based on clusters of co-occurrences for supervised Word Sense Disambiguation and Lexical Substitution. Cooccurrence cluster features are derived from clustering the local neighborhood of a target word in a co-occurrence graph based on a corpus in a completely unsupervised fashion. Clusters can be assigned in context and are used as features in a supervised WSD system. Experiments fitting a strong baseline system with these additional features are conducted on two datasets, showing improvements. Cooccurrence features are a simple way to mimic Topic Signatures (Martinez et al., 2008) without needing to construct resources manually. Further, a system is described that produces lexical substitutions in context with very high precision.", "title": "Co-occurrence Cluster Features for Lexical Substitutions in Context", "venue": "W", "graph_vector": [-0.182866, 0.49937, -0.240629, 0.160816, 0.433688, -0.549633, 0.253386, -0.190541, -1.13247, 0.63894, -0.175287, -0.463842, 0.725513, 0.292426, 0.0815456, -0.732307, 0.238053, -1.08174, -0.168534, 0.636114, -0.250003, 0.400887, -0.132035, -0.113489, -0.312798, 0.140182, 0.238427, 0.438195, -0.150622, -0.215606, 0.00368141, 0.0324413, 0.00874907, -0.260899, 0.056007, -0.175287, -0.448639, 0.784905, -0.100549, -0.56566, -0.00979071, -0.426949, -0.643536, 0.0278618, 0.900226, -0.83191, 0.178193, 0.0550412, 0.0352942, 0.138687, 0.0790831, -0.067375, 0.567446, 0.745929, -0.524481, 0.152704, 0.0279221, 0.137502, -0.224958, -0.253862, -0.105371, -0.248381, 0.0849844, 0.220903, -0.0399334, -0.0050299, -0.267198, -0.149649, 0.287401, -0.126588, -0.127745, 0.0943381, -0.0921038, 0.078634, -0.120669, -0.31005, -0.715287, -0.26512, -0.141944, 0.171832, -0.0735833, -0.152362, 0.097357, -0.154851, -0.213322, -0.289707, 0.0625549, 0.0765766, 0.0389346, -0.29133, 0.136909, 0.156817, -0.677445, -0.258279, -0.208882, 0.282251, -0.235874, 0.246254, 0.0269157, 0.328634, -0.460606, -0.47416, 0.0132158, 0.284466, -0.00827702, 0.0321994, -0.157165, 0.135641, 0.158558, -0.041364, -0.181045, 0.206571, 0.14175, 0.195684, -0.166456, -0.117521, 0.184256, 0.0222299, -0.185159, 0.258049, -0.125244, 0.184279, -0.177026, -0.221206, 0.435136, 0.0712574, -0.0443996, -0.194023], "internal": 1}
{"paper_id": "W10-2923", "abstract": "We propose a method for annotating postto-post discourse structure in online user forum data, in the hopes of improving troubleshooting-oriented information access. We introduce the tasks of: (1) post classification, based on a novel dialogue act tag set; and (2) link classification. We also introduce three feature sets (structural features, post context features and semantic features) and experiment with three discriminative learners (maximum entropy, SVM-HMM and CRF). We achieve abovebaseline results for both dialogue act and link classification, with interesting divergences in which feature sets perform well over the two sub-tasks, and go on to perform preliminary investigation of the interaction between post tagging and linking.", "title": "Tagging and Linking Web Forum Posts", "venue": "W", "graph_vector": [0.284474, 0.113832, 0.1057, 0.274409, 0.0167018, -0.616872, -0.255281, -0.149431, -1.87344, -0.378993, -0.21493, -0.121282, 0.351508, 0.190924, -0.124027, -0.283756, 0.571631, -0.503239, 0.57184, 0.235199, -0.337193, 0.71136, 0.157998, 0.0511299, -0.273413, -0.255572, -0.0113948, -0.111343, 0.50739, -0.143323, 0.0167062, -0.364906, -0.178335, -0.695124, -0.167406, 0.392668, 0.0192357, 0.508446, 0.388618, -0.192616, 0.21427, -0.268321, -0.0177164, 0.0827086, 0.738645, -0.589609, 0.0438627, -0.455354, 0.0953137, 0.216117, 0.404463, -0.203809, 1.09011, 0.439491, -0.310258, -0.132792, 0.114305, 0.0408508, 0.00216174, 0.306715, -0.168202, -0.306307, -0.0909275, 0.134327, -0.122927, -0.168088, -0.155747, -0.115333, 0.114468, 0.00459641, -0.103638, -0.476793, 0.219003, -0.148632, 0.0481477, -0.266021, -0.309107, -0.230394, -0.366809, 0.0854985, -0.404731, -0.248729, -0.241686, -0.0141561, -0.239361, -0.277886, -0.383935, -0.0856506, -0.142618, 0.21274, -0.0266044, -0.0539156, -0.742712, -0.36356, 0.443376, -0.0397096, -0.146245, -0.184071, -0.167694, -0.0539857, -0.182302, -0.638106, -0.259626, -0.169922, -0.220553, 0.152579, -0.287055, -0.0355014, 0.301869, 0.0873319, 0.055861, 0.117543, -0.263789, -0.00822586, 0.0191435, -0.112378, 0.105361, -0.0748743, -0.0132009, 0.577125, 0.0192919, 0.39444, -0.0460508, -0.170037, 0.135092, 0.278061, 0.125848, 0.180036], "internal": 1}
{"paper_id": "W10-0215", "abstract": "The NewsViz system aims to enhance news reading experiences by integrating 30 seconds long Flash-animations into news article web pages depicting their content and emotional aspects. NewsViz interprets football match news texts automatically and creates abstract 2D visualizations. The user interface enables animators to further refine the animations. Here, we focus on the emotion extraction component of NewsViz which facilitates subtle background visualization. NewsViz detects moods from news reports. The original text is part-of-speech tagged and adjectives and/or nouns, the word types conveying most emotional meaning, are filtered out and labeled with an emotion and intensity value. Subsequently reoccurring emotions are joined into longer lasting moods and matched with appropriate animation presets. Different linguistic analysis methods were tested on NewsViz: word-by-word, sentence-based and minimum threshold summarization, to find a minimum number of occurrences of an emotion in forming a valid mood. NewsViz proved to be viable for the fixed domain of football news, grasping the overall moods and some more detailed emotions precisely. NewsViz offers an efficient technique to cater for the production of a large number of daily updated news stories. NewsViz bypasses the lack of information for background or environment depiction encountered in similar applications. Further development may refine the detection of emotion shifts through summarization with the full implementation of football and common linguistic knowledge.", "title": "NewsViz: Emotional Visualization of News Stories", "venue": "W", "graph_vector": [0.238124, 0.644603, -0.0197006, -0.11499, 0.447988, -0.748104, 0.0781861, -0.359467, -1.82604, 0.434074, 0.00500679, -0.76249, 0.270358, 0.168771, 0.531167, -0.219088, 0.0559972, -0.789074, -0.317382, 0.181186, -0.349759, 0.465931, 0.294684, 0.125484, -0.538131, -0.133148, 0.223915, 0.494815, 0.346557, -0.160997, 0.128098, -0.14174, 0.492844, -0.426967, -0.195071, -0.0181124, 0.32091, 0.49577, 0.339074, 0.505052, -0.264966, -0.200403, -0.523383, 0.162059, 0.671833, -0.919444, -0.521117, -0.207231, 0.168186, -0.25182, 0.125748, -0.629152, 0.867519, 0.816875, 0.321682, 0.570907, 0.595979, -0.0206783, -0.0483695, 0.399344, -0.367051, 0.506498, -0.202659, -0.0169755, 0.00384252, 0.0716588, 0.0946243, -0.279194, 0.238152, -0.0462892, -0.189563, -0.129279, -0.0543221, -0.269687, 0.504611, 0.293592, -0.126662, -0.320877, -0.253961, -0.208785, 0.0423345, -0.0434699, -0.0506053, -0.562761, -0.0823624, -0.0809897, 0.114006, -0.304806, 0.233627, -0.0728821, -0.00589527, -0.489795, -0.854697, -0.278789, -0.403146, -0.371142, -0.346385, 0.298063, 0.0034589, 0.194997, -0.400236, -0.421735, -0.208293, 0.239032, -0.136415, 0.0775616, 0.355815, 0.0267133, 0.167782, -0.426359, 0.058293, -0.280979, -0.763883, -0.0954509, 0.202728, -0.173264, 0.336304, 0.212438, 0.107811, -0.217779, -0.327019, 0.366536, -0.260114, 0.0383369, 0.245855, 0.408236, 0.290322, 0.0543436], "internal": 1}
{"paper_id": "W10-2420", "abstract": "Human annotation for Co-reference Resolution (CRR) is labor intensive and costly, and only a handful of annotated corpora are currently available. However, corpora with Named Entity (NE) annotations are widely available. Also, unlike current CRR systems, state-of-the-art NER systems have very high accuracy and can generate NE labels that are very close to the gold standard for unlabeled corpora. We propose a new set of metrics collectively called CONE for Named Entity Coreference Resolution (NE-CRR) that use a subset of gold standard annotations, with the advantage that this subset can be easily approximated using NE labels when gold standard CRR annotations are absent. We define CONE B3 and CONE CEAF metrics based on the traditional B3 and CEAF metrics and show that CONE B3 and CONE CEAF scores of any CRR system on any dataset are highly correlated with its B3 and CEAF scores respectively. We obtain correlation factors greater than 0.6 for all CRR systems across all datasets, and a best-case correlation factor of 0.8. We also present a baseline method to estimate the gold standard required by CONE metrics, and show that CONE B3 and CONE CEAF scores using this estimated gold standard are also correlated with B3 and CEAF scores respectively. We thus demonstrate the suitability of CONE B3and CONE CEAF for automatic evaluation of NE-CRR.", "title": "CONE: Metrics for Automatic Evaluation of Named Entity Co-reference Resolution", "venue": "W", "graph_vector": [0.280691, 0.229287, -0.272442, 0.134746, 0.466725, -0.450949, -0.0523195, 0.104132, -1.40814, 0.23189, -0.45076, -0.237079, 0.605593, 0.212274, -0.122367, -0.099512, 0.258532, -0.596358, 0.231108, 0.356735, -0.79921, 0.495334, -0.442554, -0.398408, -0.508317, -0.0168589, -0.151608, 0.28118, -0.497811, -0.0809403, 0.114217, 0.0549681, 0.199492, -0.466275, -0.113962, 0.27637, -0.195313, 0.917245, 0.263121, -0.63137, 0.230126, -0.416138, -0.321143, -0.0204463, 0.646109, -0.556785, 0.204099, 0.333114, 0.272467, -0.227119, -0.0066828, 0.340882, 0.819028, 0.718699, -0.203592, -0.0380147, 0.181032, -0.209311, 0.0241446, 0.274463, -0.0801068, -0.133956, 0.427783, 0.15499, -0.143929, -0.188634, 0.378003, -0.366075, -0.0760424, 0.0883135, 0.29756, 0.518441, -0.0787192, -0.511045, 0.0801188, -0.00489417, -0.264543, -0.449975, -0.467466, -0.379425, -0.119512, 0.306443, -0.17759, -0.20784, 0.0868412, -0.505263, -0.351135, -0.325971, -0.00762037, -0.0250649, -0.0610345, 0.0693982, -0.892488, -0.167061, 0.185422, -0.261154, 0.122907, 0.336433, -0.129277, 0.397279, -0.0632684, -0.233226, -0.114518, 0.271475, -0.197376, -0.00861799, -0.48795, -0.228061, -0.0665675, -0.115571, 0.133341, 0.0119614, -0.568557, -0.0987328, -0.375404, -0.124118, 0.0794088, -0.224318, 0.00741361, 0.221558, -0.183584, 0.161882, 0.261127, -0.124192, 0.216025, 0.315683, -0.133704, -0.110042], "internal": 1}
{"paper_id": "W10-4102", "abstract": "Textual emotion recognition has gained a lot of attention recent years; it is however less developed due to the complexity nature of emotion. In this paper, we start with the discussion of a number of fundamental yet unresolved issues concerning emotion, which includes its definition, representation and technology. We then propose an alternative solution for emotion recognition taking into account of emotion causes. Two pilot experiments are done to justify our proposal. The first experiment explores the impact of emotion recognition. It shows that the context contains rich and crucial information that effectively help emotion recognition. The other experiment examines emotion cause events in the context. We find that most emotions are expressed with the presence of causes. The experiments prove that emotion cause serves as an important cue for emotion recognition. We suggest that the combination of both emotion study and event analysis would be a fruitful direction for deep emotion processing.", "title": "Textual Emotion Processing From Event Analysis", "venue": "W", "graph_vector": [0.539138, 0.296917, 0.25012, 0.10781, 0.649254, -1.07479, -0.215588, -0.326043, -1.74529, 0.112744, -0.420922, -0.243195, 0.579833, 0.220621, 0.222682, 0.312229, 0.0501107, -1.02442, 0.497299, 0.139517, -0.205535, 0.765776, 0.0089112, 0.470279, -0.395661, -0.219522, -0.0739543, -0.428295, -0.407765, -0.897888, -0.0533527, 0.301612, -0.0537637, -0.6651, 0.283858, -0.373258, -0.033769, 0.597233, 0.416508, -0.114157, 0.150146, -0.354162, -0.12466, 0.509948, 1.24055, -1.05767, 0.0410049, 0.0544388, 0.00240387, 0.267146, 0.0573397, -0.382004, 0.48274, 0.703348, -0.0774679, -0.0121829, 0.104118, 0.514515, 0.167254, 0.209758, -0.351042, -0.0787727, 0.0447005, -0.0528808, -0.397652, -0.432624, -0.147288, -0.46305, -0.00325257, 0.0669065, -0.113428, 0.0746251, 0.131203, -0.290334, -0.185392, 0.191634, -0.225314, 0.110691, 0.0808171, -0.157994, -0.0563076, 0.125117, 0.2357, -0.23871, -0.0941329, -0.110765, 0.461163, -0.0414167, -0.214019, -0.442074, -0.133113, 0.035533, -0.965423, -0.313323, -0.173627, -0.0396029, -0.115634, 0.450135, -0.433864, -0.108101, -0.590047, -0.358386, -0.142353, -0.376835, 0.0645177, 0.0214665, -0.442811, 0.0323295, -0.0880868, 0.118024, -0.303041, 0.208742, 0.0280354, -0.0114426, -0.30499, -0.0991682, 0.589675, 0.239025, -0.299341, -0.0793659, -0.313091, 0.171658, -0.294683, -0.252385, 0.506332, 0.0897316, 0.15442, 0.223951], "internal": 1}
{"paper_id": "D09-1101", "abstract": "Traditional learning-based coreference resolvers operate by training a mentionpair classifier for determining whether two mentions are coreferent or not. Two independent lines of recent research have attempted to improve these mention-pair classifiers, one by learning a mentionranking model to rank preceding mentions for a given anaphor, and the other by training an entity-mention classifier to determine whether a preceding cluster is coreferent with a given mention. We propose a cluster-ranking approach to coreference resolution that combines the strengths of mention rankers and entitymention models. We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution. Experimental results on the ACE data sets demonstrate its superior performance to competing approaches.", "title": "Supervised Models for Coreference Resolution", "venue": "D", "graph_vector": [0.402331, 0.0486142, 0.0495333, 0.565065, 0.456986, -0.371048, 0.110419, -0.226245, -1.44679, 0.297978, -0.39268, -0.0968124, 0.517565, 0.0893185, 0.142447, 0.139598, 0.197921, -0.871979, 0.348991, 0.317752, -0.570548, 0.621959, -0.0310922, 0.0680607, -0.476415, 0.49603, 0.0350938, 0.240855, -0.157608, -0.0365211, -0.0620976, 0.143009, -0.00616226, -0.525633, 0.0293942, 0.265687, -0.0204825, 0.782291, 0.0283301, -0.223648, 0.219892, -0.365636, -0.0275353, 0.304485, 0.795698, -0.826465, 0.240335, -0.162018, -0.165936, -0.105023, -0.156591, 0.0822154, 0.910556, 0.800021, 0.0474012, 0.190391, -0.110256, -0.0325725, -0.0216809, 0.108014, -0.126668, -0.308019, -0.0849528, 0.0649196, -0.12057, -0.143269, 0.280104, -0.171782, 0.0257886, -0.0887545, 0.215952, 0.242535, 0.120438, -0.228571, 0.277418, -0.221151, -0.215356, -0.0108289, -0.33498, -0.0390569, -0.0415622, 0.126474, 0.0651445, -0.0839679, 0.168465, -0.169575, 0.0542272, 0.0896657, 0.0221287, 0.107662, 0.402985, -0.146163, -0.440195, 0.115498, 0.0296912, -0.356032, 0.176891, 0.069532, 0.0284068, -0.12911, -0.0844579, -0.0763053, 0.0161703, 0.224197, -0.25105, 0.00256611, -0.0758564, 0.0280577, 0.0291408, -0.15582, -0.0557241, 0.0801439, 0.016937, -0.0341411, -0.123719, -0.121497, 0.464193, 0.363912, -0.054624, 0.13656, 0.0439725, -0.0745028, 0.146662, -0.152892, 0.412451, 0.345194, -0.0358786, 0.0345471], "internal": 1}
{"paper_id": "D09-1001", "abstract": "We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic. Our USP system transforms dependency trees into quasi-logical forms, recursively induces lambda forms from these, and clusters them to abstract away syntactic variations of the same meaning. The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them. We evaluate our approach by using it to extract a knowledge base from biomedical abstracts and answer questions. USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.", "title": "Unsupervised Semantic Parsing", "venue": "D", "graph_vector": [-0.194324, 0.294598, -0.0273221, 0.220165, 0.484804, -0.647484, 0.390672, -0.27722, -1.39347, 0.467341, -0.387867, -0.524136, 0.642559, 0.215773, 0.355971, 0.203419, 0.560913, -0.55561, -0.00196686, 0.544693, 0.121729, 0.473757, 0.0274267, -0.079436, -0.451997, 0.00835151, -0.444696, -0.172342, -0.226704, -0.0341365, 0.28581, -0.102834, 0.144354, -0.567588, 0.29352, 0.251528, -0.0569122, 0.689884, -0.0426449, -0.0552907, 0.228694, -0.732845, -0.415014, 0.233341, 0.738445, -1.12874, -0.11608, -0.111037, 0.134523, 0.375301, 0.25744, 0.0226452, 0.636366, 0.443318, -0.0751556, 0.08386, -0.0738857, -0.013737, 0.191868, 0.238829, 0.0270378, -0.0643785, -0.171007, 0.0920152, -0.0135941, 0.297016, 0.13473, 0.0345209, -0.13216, 0.169185, 0.090338, -0.286442, -0.139702, -0.213483, -0.180738, -0.210993, -0.216147, -0.226497, -0.194932, -0.247071, 0.333334, 0.188998, 0.13447, -0.170338, 0.0907846, -0.0353147, 0.0240932, 0.0794052, 0.119782, 0.0246966, -0.324454, 0.00662548, -0.772184, 0.234242, 0.242462, 0.236725, -0.0537527, -0.0652953, -0.0233003, -0.119969, -0.256313, 0.013792, -0.00303347, 0.31048, -0.18101, -0.203879, 0.151214, -0.125735, 0.130707, -0.232507, -0.190536, -0.234961, -0.0593769, 0.0828649, -0.135956, -0.012228, 0.42552, 0.325336, -0.152709, 0.14205, -0.0511161, -0.124326, -0.195601, 0.103547, 0.205691, 0.172279, 0.0795306, -0.236879], "internal": 1}
{"paper_id": "D09-1120", "abstract": "Coreference systems are driven by syntactic, semantic, and discourse constraints. We present a simple approach which completely modularizes these three aspects. In contrast to much current work, which focuses on learning and on the discourse component, our system is deterministic and is driven entirely by syntactic and semantic compatibility as learned from a large, unlabeled corpus. Despite its simplicity and discourse naivete, our system substantially outperforms all unsupervised systems and most supervised ones. Primary contributions include (1) the presentation of a simpleto-reproduce, high-performing baseline and (2) the demonstration that most remaining errors can be attributed to syntactic and semantic factors external to the coreference phenomenon (and perhaps best addressed by non-coreference systems).", "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features", "venue": "D", "graph_vector": [-0.00282037, -0.0444431, -0.241161, 0.427191, 0.511533, -0.424418, -0.00692696, 0.11411, -1.57662, 0.520482, -0.137261, -0.307861, 0.655894, 0.363913, 0.352574, 0.118202, 0.677156, -0.570973, -0.0762489, 0.477385, -0.560631, 0.35571, -0.128076, 0.0200007, -0.320376, 0.187668, 0.271269, 0.207902, -0.0772549, -0.485052, 0.3359, -0.153066, 0.276739, -0.382064, -0.00299999, 0.0816794, -0.0189035, 0.409563, 0.145846, -0.0575714, 0.103028, -0.269162, -0.187979, 0.267621, 0.729713, -0.666335, 0.227528, 0.368847, -0.013467, -0.216216, 0.293159, 0.0872639, 0.660614, 0.744452, 0.202929, -0.190396, 0.0785748, 0.000887349, -0.0881251, -0.057576, -0.126233, -0.134167, -0.100027, 0.0998188, -0.00286621, -0.220852, 0.203078, 0.0375098, 0.0904504, 0.129346, 0.132575, 0.109911, -0.0519472, -0.181437, 0.0179566, -0.247995, -0.317086, 0.0853758, -0.0375286, -0.170053, 0.0693458, 0.208546, -0.0329697, -0.44778, 0.277762, -0.462893, -0.175159, -0.13667, -0.0540275, -0.0206367, 0.0376359, 0.117894, -0.449105, -0.199135, -0.191076, -0.0455922, 0.360878, 0.0689163, 0.0789572, -0.0934469, 0.0471193, -0.208611, -0.0887989, 0.26048, -0.0052733, 0.164509, -0.156971, 0.294331, 0.0781139, -0.235547, -0.373043, 0.146412, 0.157829, 0.0199088, 0.0296115, -0.0298958, 0.445824, 0.162841, -0.145769, 0.36943, 0.0692748, -0.171713, 0.243956, -0.00178898, 0.325132, 0.265654, 0.211191, -0.102782], "internal": 1}
{"paper_id": "D09-1063", "abstract": "Sentiment analysis often relies on a semantic orientation lexicon of positive and negative words. A number of approaches have been proposed for creating such lexicons, but they tend to be computationally expensive, and usually rely on significant manual annotation and large corpora. Most of these methods use WordNet. In contrast, we propose a simple approach to generate a high-coverage semantic orientation lexicon, which includes both individual words and multi-word expressions, using only a Roget-like thesaurus and a handful of affixes. Further, the lexicon has properties that support the Polyanna Hypothesis. Using the General Inquirer as gold standard, we show that our lexicon has 14 percentage points more correct entries than the leading WordNet-based high-coverage lexicon (SentiWordNet). In an extrinsic evaluation, we obtain significantly higher performance in determining phrase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above.", "title": "Generating High-Coverage Semantic Orientation Lexicons From Overtly Marked Words and a Thesaurus", "venue": "D", "graph_vector": [-0.0714964, 0.278739, 0.467919, 0.197868, 0.353455, -0.839425, -0.076644, -0.0872102, -1.63291, 0.0169685, -0.42512, -0.398437, 0.639914, -0.117335, 0.251473, 0.139958, 0.451798, -0.462474, 0.114851, 0.174315, 0.0273451, 0.631534, -0.0855764, 0.034883, -0.186157, 0.0935574, -0.00417759, 0.34572, -0.1092, -0.0581066, -0.0933891, -0.105829, -0.0823349, -0.383473, -0.0444642, -0.101547, -0.419382, 0.754596, 0.510164, 0.0324121, -0.334673, -0.234517, -0.100237, 0.413362, 0.875858, -1.14192, -0.214413, 0.167188, -0.139744, 0.259012, 0.199375, -0.427021, 0.617819, 0.591782, -0.115631, 0.105832, 0.251616, 0.0398046, 0.126102, 0.21013, -0.303355, 0.0831507, 0.20096, -0.14492, 0.0567333, -0.176668, 0.284719, 0.109949, 0.217393, 0.018068, 0.0187657, -0.164188, 0.107549, -0.259409, -0.308084, -0.22604, -0.391897, -0.304644, -0.322957, 0.163162, -0.198947, -0.161108, 0.374518, -0.299398, 0.260777, -0.0961542, 0.0336754, -0.201441, -0.255349, 0.00144741, -0.0159217, 0.0771257, -0.468908, -0.333888, -0.227547, 0.00977103, 0.363021, 0.0618937, -0.0276096, 0.06905, -0.441037, -0.340322, -0.143557, 0.00961443, -0.0221022, 0.0265762, -0.0918061, 0.094434, 0.250988, -0.17718, 0.12475, 0.0310923, -0.0515455, 0.33083, -0.0631668, 0.068808, 0.0535253, 0.328177, 0.00425593, 0.31234, -0.288953, -0.0907168, -0.0902182, 0.162102, 0.564445, 0.294534, -0.147314, -0.493011], "internal": 1}
{"paper_id": "D09-1082", "abstract": "In this paper, we first compare several strategies to handle the newly proposed three-way Recognizing Textual Entailment (RTE) task. Then we define a new measurement for a pair of texts, called Textual Relatedness, which is a weaker concept than semantic similarity or paraphrase. We show that an alignment model based on the predicate-argument structures using this measurement can help an RTE system to recognize the Unknown cases at the first stage, and contribute to the improvement of the overall performance in the RTE task. In addition, several heterogeneous lexical resources are tested, and different contributions from them are observed.", "title": "Recognizing Textual Relatedness with Predicate-Argument Structures", "venue": "D", "graph_vector": [-0.258867, 0.0723894, 0.103844, 0.217086, 0.523444, -0.805129, 0.194421, 0.143465, -1.59283, 0.404107, -0.00282809, -0.282273, 0.622771, -0.113832, 0.0798718, 0.0467079, 0.0812743, -0.939006, -0.00359176, 0.387702, -0.599774, 0.816485, 0.119845, 0.143312, -0.322342, -0.142374, 0.100292, 0.00459311, 0.0822077, -0.0462014, 0.108787, -0.193616, -0.126789, -0.373724, -0.0552752, -0.430127, 0.00160176, 0.503239, 0.106871, -0.153884, -0.215012, 0.0142307, 0.0893928, 0.272777, 0.714069, -0.861889, 0.261493, 0.349695, -0.127578, -0.0877582, 0.139773, -0.0361957, 0.670979, 0.380735, -0.00973892, 0.236261, 0.102701, 0.157535, -0.0769091, -0.140979, -0.171937, 0.0057194, -0.225997, 0.0747352, 0.0614269, -0.400991, 0.338372, 0.152363, 0.0700477, 0.0345938, 0.15701, -0.542985, 0.0890839, -0.229844, 0.0503984, -0.291934, -0.259189, 0.0416192, 0.0151763, -0.371891, -0.183343, -0.182006, -0.131862, -0.37878, -0.249453, -0.403843, 0.0388844, -0.0673198, 0.0898874, -0.0879995, -0.246947, -0.0948686, -0.921254, -0.339117, 0.108184, 0.151337, 0.0149915, 0.108065, -0.0165484, -0.0499946, -0.0182868, -0.157741, -0.121893, 0.154046, 0.25549, -0.137416, 0.100791, 0.113933, 0.256573, 0.439008, -0.0979399, -0.0103537, -0.115952, 0.0273031, -0.141316, -0.070927, 0.353453, 0.314677, 0.237119, 0.129111, -0.0303605, -0.0915302, -0.139399, 0.0415848, 0.402817, 0.403332, -0.0394542, -0.0746086], "internal": 1}
{"paper_id": "D13-1030", "abstract": "Interpreting anaphoric shell nouns (ASNs) such as this issue and this fact is essential to understanding virtually any substantial natural language text. One obstacle in developing methods for automatically interpreting ASNs is the lack of annotated data. We tackle this challenge by exploiting cataphoric shell nouns (CSNs) whose construction makes them particularly easy to interpret (e.g., the fact that X). We propose an approach that uses automatically extracted antecedents of CSNs as training data to interpret ASNs. We achieve precisions in the range of 0.35 (baseline = 0.21) to 0.72 (baseline = 0.44), depending upon the shell noun.", "title": "Interpreting Anaphoric Shell Nouns using Antecedents of Cataphoric Shell Nouns as Training Data", "venue": "D", "graph_vector": [0.306829, 0.106378, 0.0180074, 0.345386, 0.544453, -0.76419, 0.302305, -0.098546, -1.7845, 0.219431, -0.525752, 0.312273, 0.404612, -0.0160786, 0.402974, 0.0711209, 0.241017, -1.01677, 0.125946, 0.0667223, -0.411257, 0.682836, 0.038536, -0.412351, -0.177967, 0.183564, 0.511191, 0.150704, -0.209804, -0.097405, -0.0287201, 0.491019, -0.204889, -0.0145771, -0.181883, 0.171323, 0.133138, 0.624237, 0.0370463, -0.0156295, -0.064384, -0.674384, 0.124434, 0.194048, 0.713375, -0.642278, 0.042387, -0.149315, -0.0549208, 0.222224, 0.379, -0.236437, 1.18841, 0.813095, -0.120369, -0.0934412, -0.171205, 0.176092, -0.186331, 0.056466, -0.592355, -0.331199, -0.295926, -0.115755, 0.539985, 0.0355308, 0.114345, -0.127724, 0.284886, 0.49857, 0.146934, 0.0217865, 0.407986, -0.205888, -0.344415, -0.488714, 0.0210507, 0.000602388, -0.344542, 0.285727, 0.294964, 0.200041, -0.230246, -0.24272, 0.0832381, -0.234502, 0.383919, 0.1978, 0.271837, 0.0317652, 0.175266, -0.113235, -0.583, 0.0393273, 0.342928, 0.139903, 0.137709, 0.31578, 0.0441926, -0.0340043, -0.184738, -0.539681, 0.0607658, -0.0940937, -0.00508924, -0.119839, -0.235672, -0.00539741, 0.0829475, 0.216439, -0.18486, -0.10937, -0.0995978, -0.524515, -0.186543, 0.341814, 0.648795, 0.204109, -0.171594, 0.0997572, -0.0971989, 0.238933, -0.0923641, 0.369445, 0.383248, -0.324379, -0.0357741, -0.43616], "internal": 1}
{"paper_id": "D13-1029", "abstract": "Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context. This paper demonstrates that these two tasks are complementary. We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. Experiments show consistent improvements across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.", "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves", "venue": "D", "graph_vector": [0.114389, 0.156677, -0.189577, 0.342704, 0.409385, -0.424223, -0.000486977, -0.0828985, -1.48844, 0.803583, -0.300883, -0.355475, 0.46598, 0.303454, 0.119839, 0.126297, 0.465224, -0.705093, 0.198416, 0.540247, -0.373444, 0.501965, -0.0881729, -0.174253, -0.137208, 0.0544689, 0.125003, 0.306707, -0.10605, -0.050767, 0.197283, 0.31462, 0.186282, -0.425776, -0.231914, 0.240819, -0.389306, 0.583856, 0.216682, -0.17075, 0.213538, -0.488745, -0.255748, 0.361579, 0.812181, -1.05133, 0.0811829, 0.101875, -0.192147, -0.0320452, 0.280924, 0.0819068, 0.72042, 0.692917, 0.0542471, 0.202816, -0.370825, -0.0643591, 0.0753045, -0.0480957, -0.131144, 0.0299034, -0.055527, 0.0857277, -0.0577345, -0.194318, 0.470276, 0.00587084, -0.148357, 0.251257, 0.34475, 0.215091, -0.336835, -0.288283, 0.0109663, -0.336752, -0.45467, -0.0957288, -0.196892, -0.268198, 0.0968404, -0.0766839, 0.0384611, -0.379995, 0.159814, -0.394596, -0.0195818, -0.0693774, -0.130562, 0.165425, 0.18594, 0.107287, -0.558645, 0.0236556, -0.16251, 0.0475407, 0.0538832, 0.239742, -0.0390713, 0.133643, 0.018719, -0.0987568, -0.0163068, 0.100474, -0.273689, 0.0828216, -0.126343, 0.289469, -0.155379, -0.309604, -0.362624, -0.237501, -0.0375509, 0.252756, 0.146719, -0.300581, 0.381646, 0.358328, 0.0715792, 0.301232, 0.254736, -0.0727482, 0.266879, 0.088106, 0.41436, 0.199927, -0.0010706, -0.193476], "internal": 1}
{"paper_id": "D13-1057", "abstract": "Coreference resolution is a well known clustering task in Natural Language Processing. In this paper, we describe the Latent Left Linking model (L3M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution. We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning. Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.", "title": "A Constrained Latent Variable Model for Coreference Resolution", "venue": "D", "graph_vector": [-0.114021, 0.188275, -0.264117, 0.539772, 0.535789, -0.263386, 0.0515353, 0.0898889, -1.65698, 0.491972, -0.144144, -0.254224, 0.578207, 0.061775, 0.0774562, 0.0366903, 0.286411, -0.671795, 0.351058, 0.279065, -0.498373, 0.434637, -0.097988, -0.346546, -0.429792, -0.0108857, 0.103272, 0.369528, -0.152124, -0.149876, 0.0599798, 0.218803, 0.0333733, -0.457363, -0.444126, 0.0888287, -0.379617, 0.704266, 0.241793, -0.254897, 0.311624, -0.504689, -0.134228, 0.606884, 0.635869, -0.947299, 0.238798, -0.0510381, -0.200603, -0.107922, 0.102193, -0.121521, 0.765457, 0.555133, -0.223672, 0.0572821, -0.368012, 0.100026, -0.134671, 0.0596004, -0.181766, -0.185697, 0.0693642, -0.132699, 0.108265, -0.018465, 0.359471, -0.159718, -0.0766227, -0.0414028, 0.223482, 0.069377, -0.180954, -0.25624, -0.142305, -0.0338164, -0.319094, -0.062249, -0.318292, -0.28494, 0.180539, -0.0225384, 0.256051, -0.315677, -0.00597475, -0.454611, -0.123295, -0.322755, 0.0295291, -0.173511, 0.187532, -0.0777394, -0.315779, -0.131958, -0.0569916, -0.134495, 0.0705702, 0.022806, 0.16992, 0.010322, -0.0599973, -0.243922, 0.0137947, 0.178679, -0.425559, 0.0293107, -0.15471, 0.0957629, 0.159158, -0.208585, -0.400399, -0.22111, -0.0988328, 0.0630457, 0.0572525, 0.0256237, 0.517413, 0.241604, 0.147643, 0.141246, 0.0273791, 0.0331675, 0.312852, -0.171359, 0.50225, 0.281374, 0.106491, -0.0385141], "internal": 1}
{"paper_id": "D13-1028", "abstract": "Coreference resolution plays a critical role in discourse analysis. This paper focuses on exploiting zero pronouns to improve Chinese coreference resolution. In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution. Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution.", "title": "Exploiting Zero Pronouns to Improve Chinese Coreference Resolution", "venue": "D", "graph_vector": [0.0634323, 0.174117, 0.124101, 0.558099, 0.0664013, -0.728671, -0.190083, -0.249558, -1.56674, 0.583315, 0.169777, -0.516147, 0.462598, 0.500381, -0.00484428, 0.12, 0.451667, -0.799992, 0.116644, 0.200946, -0.322898, 0.351524, 0.0745906, -0.0856212, -0.584339, 0.259208, 0.366432, 0.250339, -0.20234, -0.491541, 0.130525, 0.223155, -0.0515454, -0.347453, 0.0339167, 0.179179, -0.0324126, 0.876414, 0.238596, -0.231198, 0.0184549, -0.350672, -0.581621, 0.110367, 0.818319, -0.586586, 0.023382, 0.203515, 0.141977, -0.109953, 0.0615055, -0.0289625, 0.690089, 0.551888, -0.192937, -0.0635708, -0.0540038, 0.220999, 0.174259, -0.0400517, -0.220155, -0.496603, 0.181524, -0.175803, -0.327863, -0.229688, 0.122206, 0.112704, -0.179398, 0.0322715, -0.0456475, 0.183845, -0.0648376, -0.272583, -0.0796424, -0.591926, -0.123363, -0.573482, -0.188948, -0.0899737, 0.22588, -0.0231855, -0.102404, -0.0497095, 0.214998, -0.346936, 0.101301, -0.0514338, 0.103241, 0.208569, 0.327237, 0.00377159, -0.386192, 0.0794697, 0.0589939, -0.00367799, 0.201852, 0.209378, 0.175673, -0.238883, 0.487806, -0.484922, -0.406456, 0.344065, -0.341253, 0.0491978, -0.267074, 0.0334336, 0.207048, -0.0726947, -0.197481, -0.155083, 0.125909, -0.213645, 0.279691, 0.151701, 0.329312, 0.17773, 0.303087, 0.25075, 0.310455, -0.354597, 0.142316, 0.0963042, 0.656448, 0.518647, -0.0469289, 0.192305], "internal": 1}
{"paper_id": "D13-1109", "abstract": "When using a machine translation (MT) model trained on OLD-domain parallel data to translate NEW-domain text, one major challenge is the large number of out-of-vocabulary (OOV) and new-translation-sense words. We present a method to identify new translations of both known and unknown source language words that uses NEW-domain comparable document pairs. Starting with a joint distribution of source-target word pairs derived from the OLD-domain parallel corpus, our method recovers a new joint distribution that matches the marginal distributions of the NEW-domain comparable document pairs, while minimizing the divergence from the OLD-domain distribution. Adding learned translations to our French-English MT model results in gains of about 2 BLEU points over strong baselines.", "title": "Monolingual Marginal Matching for Translation Model Adaptation", "venue": "D", "graph_vector": [-0.180527, 0.398778, 0.0623784, 0.422034, 0.214618, -0.699196, -0.00750109, -0.655858, -1.56003, 0.10828, -0.401301, -0.203397, 0.704145, 0.112255, -0.104795, 0.149486, 0.216635, -0.460916, 0.299357, 0.165254, -0.198891, 0.467978, 0.262466, -0.13477, -0.241096, 0.070387, 0.503688, 0.352609, -0.186803, -0.294909, 0.0378316, 0.233113, 0.101539, 0.0349679, -0.340728, -0.115547, 0.122548, 0.515486, 0.0886413, -0.241561, -0.340712, -0.247202, -0.577954, 0.910902, 1.26564, -0.756515, 0.147214, 0.0508374, 0.124535, 0.0962845, 0.00130208, -0.0935028, 0.801631, 0.520457, -0.139069, -0.032056, 0.46968, 0.138018, -0.0855673, 0.0410471, -0.130464, -0.191939, 0.0808132, -0.195876, -0.164317, -0.220834, -0.134487, -0.189959, -0.363373, 0.513472, 0.0547292, -0.055876, 0.220307, -0.139886, -0.102122, -0.0299615, -0.783556, -0.383786, -0.0894646, 0.0263938, -0.0706226, -0.178693, 0.354825, -0.105922, -0.150592, -0.235787, 0.249164, -0.290052, 0.257286, -0.186596, 0.221905, 0.0496112, -0.303227, 0.322231, 0.286574, -0.174489, -0.0868877, -0.304935, 0.0214279, 0.0202943, -0.129709, -0.503757, 0.141232, 0.387742, -0.0483502, 0.490278, -0.149281, -0.310698, -0.22178, 0.22244, -0.316482, 0.183635, -0.216347, 0.117381, -0.267725, 0.031633, 0.220697, 0.139794, -0.0810939, 0.0297012, 0.158529, -0.295134, -0.0808097, -0.0463164, 0.393225, 0.455003, -0.31263, 0.0356361], "internal": 1}
{"paper_id": "D13-1171", "abstract": "We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.", "title": "Open Domain Targeted Sentiment", "venue": "D", "graph_vector": [-0.22835, 0.369236, -0.00275694, 0.0167581, 0.154295, -0.574491, -0.11644, -0.207803, -1.72393, 0.0877168, -0.0309742, -0.573844, 0.597857, 0.0719399, 0.194554, 0.225012, 0.391971, -0.423258, 0.038432, 0.059072, -0.228673, 0.594049, 0.104415, -0.2657, -0.0575204, 0.0721599, 0.0696656, 0.262149, -0.297466, -0.373032, -0.137122, 0.207435, -0.136788, -0.402878, -0.0880723, 0.265113, 0.122317, 0.58528, -0.12232, -0.135749, 0.355383, -0.564854, -0.371286, 0.719963, 0.650641, -0.7215, -0.145397, 0.0431543, 0.0938106, -0.122144, 0.323964, -0.1385, 0.830246, 0.736155, -0.0136693, 0.0348717, 0.252296, 0.274214, -0.220765, 0.121497, -0.543155, 0.378802, 0.323988, -0.167157, -0.105358, 0.317594, 0.0475521, -0.131766, 0.410885, -0.0938415, -0.295719, -0.154062, 0.154307, -0.124077, -0.0318251, -0.195538, -0.699859, -0.29753, 0.0928267, -0.250821, -0.0667021, -0.0274895, 0.432967, -0.0291216, 0.330483, -0.146717, 0.202981, -0.131334, -0.118885, -0.113343, 0.287833, 0.109965, -0.599828, -0.427913, 0.0245607, 0.0288696, 0.0185853, 0.0557224, 0.0996829, 0.148868, -0.0239031, -0.651781, 0.339554, -0.128077, 0.0588824, 0.125707, -0.0259965, -0.0422292, 0.0761542, 0.0429163, 0.239506, 0.218691, -0.0726678, 0.0267063, -0.199352, -0.168843, 0.0464507, -0.17014, 0.366349, 0.0318996, 0.0573373, 0.0676434, 0.208607, 0.176139, 0.673155, 0.153484, 8.99851e-05, -0.0710942], "internal": 1}
{"paper_id": "D13-1162", "abstract": "The goal of our research is to distinguish veterinary message board posts that describe a case involving a specific patient from posts that ask a general question. We create a text classifier that incorporates automatically generated attribute lists for veterinary patients to tackle this problem. Using a small amount of annotated data, we train an information extraction (IE) system to identify veterinary patient attributes. We then apply the IE system to a large collection of unannotated texts to produce a lexicon of veterinary patient attribute terms. Our experimental results show that using the learned attribute lists to encode patient information in the text classifier yields improved performance on this task.", "title": "Classifying Message Board Posts with an Extracted Lexicon of Patient Attributes", "venue": "D", "graph_vector": [0.30094, 0.335377, 0.0988194, 0.294157, 0.14909, -0.619802, -0.202755, 0.348327, -1.51154, 0.331882, -0.136593, -0.45836, 0.896925, 0.0695456, -0.129798, -0.487374, 0.240323, -0.573893, 0.0694144, 0.256142, -0.370597, 0.452624, 0.287252, -0.0439337, -0.418205, 0.226691, 0.0915474, -0.137534, -0.124719, -0.468055, 0.335144, 0.00335651, -0.301921, -0.524461, -0.145939, 0.0569995, -0.0925763, 0.306888, 0.236771, -0.631333, -0.171431, -0.436386, -0.491151, 0.188982, 0.823903, -0.661398, -0.0162252, 0.0208328, -0.108783, -0.279586, 0.674695, -0.0298676, 0.610278, 0.999042, 0.182879, -0.341784, 0.328276, 0.287208, 0.0827145, 0.297461, -0.132186, -0.0565333, 0.0578583, -0.23469, -0.189216, -0.0609283, 0.459459, -0.0379426, 0.22363, -0.0270831, -0.19092, 0.107228, 0.246079, -0.0666315, 0.237996, -0.0844662, -0.344461, -0.575175, 0.284854, -0.103754, 0.340748, 0.133684, 0.305996, 0.239841, -0.00444403, 0.255393, 0.184398, 0.0562595, -0.0105715, 0.0821534, -0.0761312, 0.112714, -1.05384, -0.316401, 0.0210413, 0.21024, -0.204015, -0.219937, -0.0467047, -0.0925553, -0.0762726, -0.258344, 0.00460136, -0.150059, 0.336883, 0.0431402, -0.465429, 0.0747895, 0.452295, -0.300463, -0.430562, 0.252922, 0.208587, 0.0743799, 0.044473, 0.241611, 0.471936, -0.00152127, -0.222697, 0.235603, 0.0371239, -0.185687, -0.257401, 0.0641777, 0.045183, 0.134297, -0.225455, 0.353017], "internal": 1}
{"paper_id": "D13-1037", "abstract": "This paper addresses the task of predicting the correct French translations of third-person subject pronouns in English discourse, a problem that is relevant as a prerequisite for machine translation and that requires anaphora resolution. We present an approach based on neural networks that models anaphoric links as latent variables and show that its performance is competitive with that of a system with separate anaphora resolution while not requiring any coreference-annotated training data. This demonstrates that the information contained in parallel bitexts can successfully be used to acquire knowledge about pronominal anaphora in an unsupervised way.", "title": "Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction", "venue": "D", "graph_vector": [0.277049, 0.218005, -0.0933951, 0.507758, 0.382013, -0.513256, 0.196021, -0.331116, -1.2467, 0.521255, -0.0505078, -0.477545, 0.296133, 0.0732578, 0.258021, 0.0303981, 0.563792, -0.695812, 0.273457, 0.44814, -0.527078, 0.516439, 0.369672, -0.237807, -0.194453, 0.300644, 0.267433, 0.157292, -0.227283, -0.622018, 0.113762, -0.261857, 0.0419394, -0.3631, -0.196989, 0.214977, -0.0690007, 0.584091, 0.136182, -0.161191, 0.0266195, -0.20631, -0.389098, 0.313354, 0.962243, -1.03417, 0.198426, 0.100126, -0.33198, -0.200399, 0.34437, 0.148002, 0.902427, 0.391715, -0.00439783, 0.288287, 0.03162, 0.13479, 0.100091, 0.326998, -0.120969, -0.0784733, 0.0352253, 0.400753, 0.0100535, -0.0467341, 0.397987, -0.162019, 0.104503, -0.0556605, 0.127714, 0.205575, -0.0617872, -0.255996, 0.170875, 0.096991, -0.42508, -0.486702, -0.0870747, -0.062675, 0.0530537, 0.216266, -0.0523164, -0.391781, 0.0929767, -0.340146, 0.136653, -0.00779395, -0.185352, -0.114846, 0.528472, 0.137726, -0.623602, 0.10064, -0.035601, 0.380826, 0.411013, 0.248417, 0.171715, -0.0326581, 0.138944, -0.305278, -0.0895968, -0.049742, -0.206952, 0.0304717, 0.0446971, -0.172113, 0.0304786, -0.253217, -0.101565, 0.0853722, 0.184514, -0.104361, -0.215126, 0.224714, 0.367492, 0.101822, 0.0126457, 0.101421, 0.158749, -0.298705, 0.165527, 0.162659, 0.363513, 0.189403, 0.301886, -0.0611292], "internal": 1}
{"paper_id": "D13-1201", "abstract": "Minimum Error Rate Training (MERT) remains one of the preferred methods for tuning linear parameters in machine translation systems, yet it faces significant issues. First, MERT is an unregularized learner and is therefore prone to overfitting. Second, it is commonly used on a noisy, non-convex loss function that becomes more difficult to optimize as the number of parameters increases. To address these issues, we study the addition of a regularization term to the MERT objective function. Since standard regularizers such as `2 are inapplicable to MERT due to the scale invariance of its objective function, we turn to two regularizers—`0 and a modification of `2— and present methods for efficiently integrating them during search. To improve search in large parameter spaces, we also present a new direction finding algorithm that uses the gradient of expected BLEU to orient MERT’s exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets.", "title": "Regularized Minimum Error Rate Training", "venue": "D", "graph_vector": [-0.000384623, 0.28408, -0.260374, 0.244541, 0.609569, -0.862653, 0.0209037, 0.174957, -1.69202, 0.0241428, -0.390163, -0.109832, 0.515151, 0.332328, 0.306547, -0.126966, 0.263797, -0.573221, 0.0259018, 0.598034, -0.14655, 0.538002, 0.459485, -0.177371, -0.412565, -0.132705, 0.039422, 0.203216, -0.281393, -0.338211, -0.142799, 0.0557678, -0.300617, -0.488885, -0.133781, 0.461341, -0.266266, 0.656665, 0.321114, -0.426606, 0.049605, -0.568473, -0.447062, 0.556579, 1.17861, -0.729304, 0.125681, -0.0890147, 0.0323797, 0.0971791, 0.137951, -0.206668, 0.775986, 0.490562, -0.24222, 0.47278, 0.179659, 0.190445, 0.0564496, 0.0706279, -0.0663841, -0.0492022, 0.0486471, -0.278783, -0.222154, 0.0389174, 0.00157282, 0.262256, 0.0497627, -0.000502628, 0.022775, -0.256326, -0.163194, -0.176403, 0.153778, 0.0852116, -0.438376, -0.412032, -0.291326, -0.0344846, -0.0266291, -0.117131, 0.470975, -0.217971, -0.292924, -0.584023, -0.0377816, -0.146631, 0.0456787, -0.231658, 0.0583736, -0.342641, -0.326874, -0.00273813, 0.0267301, 0.174436, 0.0592493, 0.159054, -0.0207757, 0.0639932, -0.581468, -0.358617, 0.146726, -0.122274, 0.052637, 0.0439543, -0.266803, 0.0379473, 0.151978, 0.0489525, 0.0390028, 0.0940778, -0.254777, 0.0736078, -0.101783, 0.159929, 0.459466, 0.128409, 0.00732552, 0.267839, -0.0834581, -0.14272, -0.0597244, 0.0759587, 0.327605, 0.16575, -0.231721, -0.106988], "internal": 1}
{"paper_id": "D08-1005", "abstract": "Having seen a news title “Alba denies wedding reports”, how do we infer that it is primarily about Jessica Alba, rather than about weddings or reports? We probably realize that, in a randomly driven sentence, the word “Alba” is less anticipated than “wedding” or “reports”, which adds value to the word “Alba” if used. Such anticipation can be modeled as a ratio between an empirical probability of the word (in a given corpus) and its estimated probability in general English. Aggregated over all words in a document, this ratio may be used as a measure of the document’s topicality. Assuming that the corpus consists of on-topic and off-topic documents (we call them the core and the noise), our goal is to determine which documents belong to the core. We propose two unsupervised methods for doing this. First, we assume that words are sampled i.i.d., and propose an information-theoretic framework for determining the core. Second, we relax the independence assumption and use a simple graphical model to rank documents according to their likelihood of belonging to the core. We discuss theoretical guarantees of the proposed methods and show their usefulness for Web Mining and Topic Detection and Tracking (TDT).", "title": "One-Class Clustering in the Text Domain", "venue": "D", "graph_vector": [0.0202286, 0.71518, -0.160781, 0.789452, 0.284067, -0.589461, -0.058072, 0.633636, -1.71304, 0.494289, -0.423316, -0.365362, 0.704675, -0.116929, 0.00874466, 0.0690551, 0.313828, -0.588744, -0.291026, -0.487317, -0.504922, 0.77093, 0.480353, 0.0329443, -0.632441, -0.0821253, 0.445024, 0.152218, -0.578142, 0.047255, -0.367096, 0.0161379, -0.15773, -0.955979, -0.44335, 0.261389, -0.501188, 0.824326, 0.141632, -0.511363, 0.0685406, -0.553633, -0.34902, 0.465204, 0.558983, -0.776385, 0.18006, 0.235738, -0.384309, 0.162974, 0.372872, -0.505933, 1.2271, 0.908242, -0.327443, -0.239034, 0.39262, -0.107956, 0.410948, -0.0758424, -0.164024, -0.490182, 0.0682131, -0.304962, 0.0831001, -0.336207, -0.372132, -0.349001, -0.212415, -0.291904, 0.407317, 0.209051, -0.284123, -0.21233, -0.221911, -0.597556, -0.579157, -0.187851, -0.448299, 0.18498, 0.405487, 0.0439289, 0.546564, -0.0277744, 0.0717172, -0.317851, 0.169988, -0.144292, 0.40062, -0.146457, 0.0413936, 0.0903417, -0.96732, -0.191208, -0.360195, -0.00574412, -0.132054, -0.111628, -0.535172, 0.182411, -0.213514, -0.0865237, 0.130972, 0.170924, 0.165433, -0.143563, -0.250248, -0.0767256, 0.0707043, -0.666633, -0.253083, 0.553066, -0.250064, 0.164931, 0.237397, -0.353081, 0.532867, 0.050113, -0.0525495, 0.286878, 0.00489411, 0.265722, -0.454468, 0.148156, 0.249325, -0.243268, -0.0403186, -0.237179], "internal": 1}
{"paper_id": "D14-1010", "abstract": "There is rich knowledge encoded in online web data. For example, punctuation and entity tags in Wikipedia data define some word boundaries in a sentence. In this paper we adopt partial-label learning with conditional random fields to make use of this valuable knowledge for semi-supervised Chinese word segmentation. The basic idea of partial-label learning is to optimize a cost function that marginalizes the probability mass in the constrained space that encodes this knowledge. By integrating some domain adaptation techniques, such as EasyAdapt, our result reaches an F-measure of 95.98% on the CTB-6 corpus, a significant improvement from both the supervised baseline and a previous proposed approach, namely constrained decode.", "title": "Semi-Supervised Chinese Word Segmentation Using Partial-Label Learning With Conditional Random Fields", "venue": "D", "graph_vector": [0.00642725, 0.0592271, 0.0536754, 0.584525, 0.632973, -0.900554, -0.0920343, -0.152995, -1.4329, 0.199833, 0.134843, -0.414181, 0.404733, 0.27904, -0.618366, -0.245249, 0.331924, -0.845592, -0.267512, 0.554978, -0.305924, 0.517447, 0.197495, 0.205421, 0.0492959, 0.10007, -0.0555387, -0.0366997, -0.249872, -0.327146, -0.153476, 0.100302, 0.34138, -0.445486, -0.0633418, -0.0219507, -0.263516, 0.734817, 0.175702, -0.253495, -0.130131, -0.414008, -0.471043, 0.415147, 0.897052, -0.717219, -0.218687, -0.190336, -0.245649, 0.210831, 0.297944, -0.389771, 0.888777, 0.795623, -0.516727, -0.24322, 0.149087, 0.554623, 0.0578327, 0.32896, -0.470938, 0.140959, 0.0775325, 0.226631, -0.269401, -0.240717, 0.0587798, 0.123418, -0.131563, 0.01495, 0.126212, 0.00715026, 0.0202679, -0.0897241, 0.389217, -0.151072, -0.527887, -0.204342, 0.0203812, -0.152996, -0.254308, 0.0687548, 0.39276, 0.356171, 0.458523, -0.521416, 0.0969237, -0.365612, -0.0245064, 0.117601, 0.166646, 0.0905735, -0.352084, -0.288028, 0.233638, -0.227733, 0.00811619, -0.0557106, -0.107821, -0.123479, -0.302121, -0.417876, 0.00857429, 0.170017, 0.0973886, 0.00734447, 0.103072, 0.201487, 0.00741069, -0.29481, -0.230544, -0.122915, -0.17741, -0.162255, 0.0477887, 0.142604, 0.403471, 0.339974, -0.139043, 0.244144, 0.148488, -0.195318, -0.0161231, 0.155457, 0.41405, 0.0778783, -0.247833, 0.0777611], "internal": 1}
{"paper_id": "D14-1049", "abstract": "We introduce a Semantic Role Labeling (SRL) parser that finds semantic roles for a predicate together with the syntactic paths linking predicates and arguments. Our main contribution is to formulate SRL in terms of shortest-path inference, on the assumption that the SRL model is restricted to arc-factored features of the syntactic paths behind semantic roles. Overall, our method for SRL is a novel way to exploit larger variability in the syntactic realizations of predicate-argument relations, moving away from pipeline architectures. Experiments show that our approach improves the robustness of the predictions, producing arc-factored models that perform closely to methods using unrestricted features from the syntax.", "title": "A Shortest-path Method for Arc-factored Semantic Role Labeling", "venue": "D", "graph_vector": [0.081201, 0.158081, 0.317089, 0.27389, 0.26316, -0.832111, 0.0708945, -0.2955, -1.75901, 0.0540247, 0.0809708, -0.233139, 0.900736, -0.010902, -0.122549, -0.22956, 0.628356, -0.514326, -0.163999, -0.0684482, -0.519368, 0.664599, 0.211419, -0.147836, -0.57561, 0.124838, 0.289627, 0.198774, -0.351205, -0.393193, 0.0389159, -0.0279402, 0.014098, -0.437174, -0.199725, -0.0350047, 0.0874455, 0.720228, 0.163209, 0.0339541, -0.0263674, -0.360627, -0.0863504, 0.239439, 0.560879, -0.398382, -0.0411566, 0.2358, 0.0980791, 0.136139, -0.0941177, -0.395021, 0.645096, 0.435508, -0.237413, -0.0387124, 0.173859, 0.117543, 0.0285786, -0.0556141, -0.352624, 0.102163, -0.0738451, -0.254707, -0.447552, -0.0882319, 0.41082, 0.277208, -0.0579881, 0.000232677, 0.0803498, -0.029541, -0.198874, -0.19855, 0.0405654, -0.328806, -0.497259, -0.264094, 0.421553, -0.393253, 0.00511173, -0.178636, -0.208182, -0.153521, -0.132875, -0.227027, 0.024482, -0.76013, 0.669053, 0.0937784, -0.124495, -0.0500514, -0.649485, -0.396033, 0.141548, -0.21721, -0.117215, 0.0559867, -0.172223, -0.0898477, 0.0406771, -0.0110017, 0.190465, 0.133196, -0.289203, -0.110114, -0.471332, -0.187081, 0.444011, -0.0480501, -0.15352, -0.213059, -0.411874, -0.045665, 0.0247515, -0.110152, 0.381375, 0.113646, 0.144205, -0.102248, -0.250646, -0.0525169, -0.0437244, -0.25336, 0.375278, -0.00988115, 0.189865, -0.274413], "internal": 1}
{"paper_id": "D14-1072", "abstract": "Wikipedia’s link structure is a valuable resource for natural language processing tasks, but only a fraction of the concepts mentioned in each article are annotated with hyperlinks. In this paper, we study how to augment Wikipedia with additional high-precision links. We present 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98.", "title": "Adding High-Precision Links to Wikipedia", "venue": "D", "graph_vector": [0.348644, 0.147134, -0.0377365, -0.0381545, 0.45542, -0.322432, 0.270977, 0.20345, -1.33749, 0.249629, -0.299517, -0.417472, 0.537564, 0.325246, 0.0695965, 0.225231, 0.795489, -0.413889, 0.00249188, 0.324676, -0.463453, 0.62802, 0.146289, -0.0852806, -0.214632, 0.119492, 0.0456064, 0.198787, -0.258227, 0.419759, 0.233335, 0.09324, 0.151874, -0.36626, 0.0787668, 0.0885705, -0.270171, 0.712279, 0.436872, -0.0107439, 0.124244, -0.606055, -0.210753, 0.634475, 1.07679, -0.606051, 0.12883, 0.221171, -0.144695, -0.0340786, 0.295735, -0.0358595, 0.766321, 1.16382, -0.0876454, 0.150286, -0.472277, 0.0764807, -0.0823353, -0.246969, -0.0540869, -0.0247867, -0.241236, 0.0320987, -0.131839, -0.298499, 0.173308, 0.123624, 0.14829, -0.0922266, 0.19955, -0.17549, -0.456476, 0.169233, 0.143057, -0.265042, -0.568755, -0.239554, -0.241918, -0.283819, -0.171448, 0.217144, 0.360678, -0.336233, 0.36688, -0.552819, -0.16326, 0.0234358, -0.0465001, 0.248145, -0.0337577, 0.358648, -0.73269, -0.319175, -0.208537, 0.0982853, -0.197088, 0.00382502, 0.272543, 0.0455719, 0.161748, -0.0584134, -0.253933, 0.0235576, -0.203131, 0.165764, -0.0317596, 0.221184, -0.0650338, -0.164344, -0.0251454, -0.337508, -0.136327, 0.225409, 0.186311, -0.147126, 0.308669, 0.171028, 0.269146, 0.45214, 0.102568, -0.111802, -0.404175, 0.134603, 0.120134, 0.16095, -0.00622908, -0.0640639], "internal": 1}
{"paper_id": "D14-1143", "abstract": "Predicting vocabulary of second language learners is essential to support their language learning; however, because of the large size of language vocabularies, we cannot collect information on the entire vocabulary. For practical measurements, we need to sample a small portion of words from the entire vocabulary and predict the rest of the words. In this study, we propose a novel framework for this sampling method. Current methods rely on simple heuristic techniques involving inflexible manual tuning by educational experts. We formalize these heuristic techniques as a graph-based non-interactive active learning method as applied to a special graph. We show that by extending the graph, we can support additional functionality such as incorporating domain specificity and sampling from multiple corpora. In our experiments, we show that our extended methods outperform other methods in terms of vocabulary prediction accuracy when the number of samples is small.", "title": "Formalizing Word Sampling for Vocabulary Prediction as Graph-based Active Learning", "venue": "D", "graph_vector": [0.12057, 0.751761, 0.306173, 0.62369, 0.159192, -0.925789, -0.145789, 0.75038, -2.11951, 0.59018, -0.193194, -0.543276, 0.813387, -0.0898311, -0.0547659, -0.285534, 0.729605, -0.795014, -0.0239657, 0.662944, -0.707138, 0.630322, 0.508152, -0.195455, -0.747968, 0.0641225, -0.177135, 0.18739, -0.388664, -0.276814, 0.211161, -0.0622325, 0.454057, -0.719496, -0.489013, 0.0527502, -0.569652, 1.33099, 0.234987, -0.249821, 0.189224, -0.766059, -0.361218, 0.564114, 1.41842, -1.05723, 0.0367578, -0.0843651, 0.0477155, 0.222342, 0.663432, -0.378858, 1.05472, 0.751051, -0.337725, -0.197959, -0.146465, 0.241492, -0.143945, 0.215623, -0.291425, -0.598506, 0.192143, -0.166675, -0.112177, -0.441509, 0.287815, -0.508815, 0.0584891, -0.199442, 0.278414, 0.11168, 0.0787426, -0.149204, 0.0471407, -0.246985, -1.15042, -0.268981, -0.307451, 0.510897, 0.241972, 0.201123, -0.293786, -0.172914, 0.400437, -0.263204, 0.0492118, -0.414958, -0.370099, -0.25832, 0.0117545, -0.406195, -0.681048, -0.40672, -0.00740312, 0.0307305, -0.0790815, 0.137389, -0.132647, -0.230409, -0.44115, -0.481617, -0.101421, 0.267707, 0.451764, -0.251644, 0.1446, -0.167143, -0.063465, -0.380248, -0.39465, 0.428166, 0.010912, 0.0904414, -0.29423, -0.128401, 0.609037, 0.0763446, -0.000410462, -0.23259, -0.0774653, -0.645767, -0.333264, -0.0330267, 0.580814, 0.0598082, -0.61371, 0.246537], "internal": 1}
{"paper_id": "D14-1123", "abstract": "Microblog has become a major platform for information about real-world", "title": "Exploiting Community Emotion for Microblog Event Detection", "venue": "D", "graph_vector": [0.250544, 0.668069, 0.324042, 0.101999, 0.38347, -0.716452, -0.229641, 0.0237904, -1.61467, 0.235907, -0.23886, -0.445692, 0.6391, -0.0632507, -0.087536, 0.148085, 0.636194, -0.454961, 0.0276243, 0.468057, 0.087216, 0.744308, 0.32707, -0.239122, -0.247079, 0.0200788, -0.0710989, -0.0715993, 0.171976, -0.393989, -0.198418, 0.218403, 0.0447951, -0.219518, -0.185325, 0.0400576, -0.329238, 0.833993, -0.258485, -0.327441, 0.130521, -0.37805, -0.345218, 0.752146, 0.84283, -1.11479, -0.0866347, 0.0884996, 0.00727561, 0.0599247, 0.330436, -0.523602, 0.953399, 0.799552, 0.0568983, 0.293061, 0.229496, 0.301848, -0.12395, -0.078204, -0.323997, 0.0260047, 0.286727, -0.0966137, -0.364447, 0.0428089, 0.145199, -0.20828, 0.337679, -0.264777, -0.101256, 0.174812, 0.139417, -0.187114, -0.404124, -0.169171, -0.570891, -0.262959, 0.32629, -0.0476228, -0.059762, -0.299148, 0.233442, -0.0990966, 0.457718, -0.438136, -0.040966, 0.19018, 0.156466, -0.19194, 0.116851, 0.221673, -0.718446, 0.170684, 0.289867, 0.207062, 0.245675, -0.204574, -0.105043, 0.148198, -0.2213, -0.376129, -0.323699, 0.155354, 0.20108, -0.280438, -0.0788988, -0.433401, 0.35097, -0.208149, -0.0631632, -0.0619292, 0.161535, 0.263532, -0.391277, -0.363728, 0.0527813, -0.139692, -0.0731499, 0.0942832, -0.175141, 0.183283, -0.169186, 0.0709837, 0.692024, 0.08999, 0.0566246, -0.0187503], "internal": 1}
{"paper_id": "D14-1015", "abstract": "We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation (SMT). Despite bilingual embedding’s success, the contextual information, which is of critical importance to translation quality, was ignored in previous work. To employ the contextual information, we propose a simple and memory-efficient model for learning bilingual embedding, taking both the source phrase and context around the phrase into account. Bilingual translation scores generated from our proposed bilingual embedding model are used as features in our SMT system. Experimental results show that the proposed method achieves significant improvements on large-scale Chinese-English translation task.", "title": "Improve Statistical Machine Translation with Context-Sensitive Bilingual Semantic Embedding Model", "venue": "D", "graph_vector": [0.201925, 0.294658, -0.127459, 0.333961, 0.291255, -0.618676, 0.373569, -0.136859, -1.34395, 0.013433, -0.122095, -0.541316, 0.607988, -0.0742636, -0.039324, -0.0231571, 0.499228, -0.502421, -0.0967775, 0.170297, 0.191828, 0.574017, 0.429968, -0.0950861, -0.382978, 0.126567, 0.0463576, 0.143551, 0.00542838, -0.375796, -0.145899, 0.215251, 0.274864, -0.49072, -0.168359, 0.311981, -0.484156, 0.436268, -0.0661695, -0.365334, -0.349494, -0.222604, -0.257903, 0.521175, 1.20554, -0.946053, 0.265591, 0.20606, -0.114791, -0.152485, 0.200872, -0.15946, 0.879865, 0.689499, -0.288099, 0.356976, 0.318474, 0.238898, -0.00861384, -0.00518681, -0.22995, -0.0230283, 0.0341148, 0.0481923, -0.0212548, 0.00123853, 0.123201, -0.427824, -0.128599, -0.0607954, -0.17889, 0.103536, 0.0753389, -0.136655, 0.342641, -0.117915, -0.836802, -0.155266, -0.0130446, -0.171765, -0.23365, -0.0593012, 0.142325, 0.0659935, 0.0100898, -0.331987, 0.16479, -0.159662, 0.00909764, -0.252171, 0.136897, 0.404621, -0.740749, 0.143006, -0.0260301, 0.20586, 0.177841, 0.139178, 0.194756, -0.128624, 0.122894, -0.199228, -0.159532, 0.0795586, -0.0847779, 0.151962, 0.0245879, -0.490079, -0.0741355, -0.371183, 0.285068, -0.0194981, -0.0962726, 0.0418872, -0.340647, 0.251712, 0.258174, 0.234248, -0.0138737, -0.149562, 0.0110276, -0.0956686, -0.126493, -0.216096, 0.216702, 0.266295, 0.206741, 0.407746], "internal": 1}
{"paper_id": "D14-1153", "abstract": "When it is not possible to compare the suspicious document to the source document(s) plagiarism has been committed from, the evidence of plagiarism has to be looked for intrinsically in the document itself. In this paper, we introduce a novel languageindependent intrinsic plagiarism detection method which is based on a new text representation that we called n-gram classes. The proposed method was evaluated on three publicly available standard corpora. The obtained results are comparable to the ones obtained by the best state-of-the-art methods.", "title": "Intrinsic Plagiarism Detection using N-gram Classes", "venue": "D", "graph_vector": [0.176835, 0.566775, -0.405038, -0.0135933, 0.178461, -0.903593, 0.0612387, 0.0670546, -1.66682, 0.21662, 0.0602812, -0.312719, 0.747894, -0.0113101, -0.0106097, -0.27282, 0.391295, -1.09052, 0.518768, 0.15393, -0.509977, 0.287059, 0.524889, 0.367711, -0.460493, 0.109027, 0.556687, -0.00852642, -0.200176, 0.0826534, -0.391971, -0.00862954, 0.52713, -0.298382, -0.191832, 0.226115, -0.201898, 0.679808, 0.0185265, -0.482679, -0.144963, -0.384369, -0.574023, 0.457466, 0.957428, -1.0979, 0.18092, 0.169313, -0.193276, -0.0298586, 0.541104, -0.124321, 0.817498, 1.00093, -0.140732, -0.234901, 0.0667338, -0.689258, 0.0407801, 0.25861, -0.636679, -0.216175, -0.118157, 0.111338, -0.120819, 0.349755, 0.105606, 0.301749, -0.0173816, -0.27798, -0.388928, 0.110263, -0.182376, -0.0103766, 0.31577, -0.410451, -0.713756, -0.102584, -0.334098, 0.284411, -0.285628, 0.00672171, 0.0111721, -0.647857, 0.0742136, -0.202909, -0.252536, 0.0301256, 0.0501233, 0.258776, -0.0136222, 0.299978, -0.944535, -0.0983184, 0.269023, 0.421898, -0.0334944, -0.186537, 0.158009, 0.212574, -0.54361, -0.345365, 0.0764988, -0.0185752, -0.323841, 0.102894, 0.210997, 0.118541, 0.0423433, -0.143085, -0.231908, -0.401656, 0.358833, -0.202126, 0.1891, -0.113767, 0.20235, -0.0818848, 0.257365, -0.0796098, -0.566418, 0.327435, -0.385951, 0.321823, 0.828287, -0.0328822, 0.427631, -0.288498], "internal": 1}
{"paper_id": "D14-1181", "abstract": "We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.", "title": "Convolutional Neural Networks for Sentence Classification", "venue": "D", "graph_vector": [0.0706354, 0.320523, 0.203013, -0.00819872, 0.50764, -0.812586, 0.217583, -0.135749, -1.44217, 0.111275, 0.0883989, -0.14138, 0.335678, 0.185295, 0.0385289, 0.0716888, 0.314802, -0.431231, 0.0353453, 0.291025, -0.217324, 0.343826, 0.577741, -0.110427, -0.18074, 0.171481, 0.249769, 0.263154, -0.178861, -0.555568, -0.277091, -0.108171, 0.274985, -0.686079, 0.0533599, 0.19641, -0.265397, 0.572228, -0.0172315, -0.0290555, 0.106379, -0.636093, -0.325914, 0.406072, 1.04158, -0.958504, 0.0648849, -0.000837603, -0.259778, 0.0302624, 0.200335, -0.0486576, 1.0058, 0.671036, 0.171875, -0.0140372, 0.186799, 0.0850529, -0.112119, 0.133729, 0.191029, 0.089728, -0.122884, 0.0943004, 0.105991, 0.0152986, 0.00434432, -0.128077, 0.140751, -0.109973, -0.165565, -0.00941453, 0.325804, -0.335456, 0.237798, -0.244138, -0.401846, -0.235811, 0.0543205, -0.16266, -0.16625, 0.316878, 0.468538, 0.179007, 0.304529, -0.300951, -0.0548481, 0.0196214, -0.0594743, -0.0172295, 0.278156, 0.432696, -0.843498, -0.221096, -0.133232, 0.0244757, 0.0187648, 0.166642, -0.372727, -0.150215, 0.134608, -0.244846, 0.0240441, -0.165789, 0.0752437, 0.259866, 0.0845564, -0.147206, 0.13702, -0.286574, 0.0953159, -0.0468194, -0.023236, 0.0891637, 0.162337, 0.297737, 0.341848, 0.187739, -0.0362913, 0.482739, 0.0610445, -0.0531677, 0.0555717, 0.0162876, 0.336805, -0.0868703, -0.0270906, 0.341577], "internal": 1}
{"paper_id": "D14-1061", "abstract": "Inspired by previous work, where decipherment is used to improve machine translation, we propose a new idea to combine word alignment and decipherment into a single learning process. We use EM to estimate the model parameters, not only to maximize the probability of parallel corpus, but also the monolingual corpus. We apply our approach to improve Malagasy-English machine translation, where only a small amount of parallel data is available. In our experiments, we observe gains of 0.9 to 2.1 B over a strong baseline.", "title": "Beyond Parallel Data: Joint Word Alignment and Decipherment Improves Machine Translation", "venue": "D", "graph_vector": [0.0992008, 0.258191, -0.181748, 0.20146, 0.197931, -1.032, -0.20205, -0.360816, -1.60004, -0.0159291, -0.273501, -0.191001, 0.760207, -0.191175, -0.0278928, 0.104541, 0.374535, -0.260612, 0.337287, 0.520155, -0.125845, 0.733317, 0.4218, -0.468381, -0.37338, 0.0211499, 0.325681, 0.235177, -0.372669, -0.0155919, -0.0127918, -0.0563302, 0.0868571, -0.286471, -0.383458, 0.254603, 0.118435, 0.255542, 0.00805491, -0.114287, -0.0569446, 0.0445943, -0.236162, 0.724014, 1.23739, -0.637148, 0.390135, 0.130527, -0.0253569, 0.0912702, 0.000356919, -0.309097, 0.790829, 0.461513, -0.208478, -0.0171494, 0.270733, 0.0597088, -0.426998, 0.0241399, -0.47228, -0.234596, 0.18704, -0.334008, -0.372299, -0.230059, 0.00418641, -0.543768, -0.0716662, 0.18941, 0.283524, -0.182409, -0.00981353, -0.159929, 0.040746, -0.383339, -0.712743, -0.391988, -0.215344, 0.0898275, -0.0138489, -0.227336, 0.0863202, -0.315017, 0.0838609, -0.111808, 0.173295, -0.176657, -0.00824438, -0.000580518, 0.33351, -0.0895282, -0.345668, -0.260778, -0.0238997, -0.34766, -0.0220766, 0.012765, -0.311806, -0.181831, -0.326019, -0.248271, 0.0296084, 0.202637, -0.0958215, 0.523717, -0.0802281, -0.136628, -0.0342202, -0.125408, -0.374808, -0.0847752, 0.036115, -0.0653682, -0.195823, 0.242526, 0.108879, -0.0899654, -0.125391, 0.0769159, 0.193799, -0.0682853, -0.0380772, 0.0211313, 0.260616, 0.374489, -0.457611, 0.0436717], "internal": 1}
{"paper_id": "D14-1201", "abstract": "Open Relation Extraction (ORE) overcomes the limitations of traditional IE techniques, which train individual extractors for every single relation type. Systems such as ReVerb, PATTY, OLLIE, and Exemplar have attracted much attention on English ORE. However, few studies have been reported on ORE for languages beyond English. This paper presents a syntax-based Chinese (Zh) ORE system, ZORE, for extracting relations and semantic patterns from Chinese text. ZORE identifies relation candidates from automatically parsed dependency trees, and then extracts relations with their semantic patterns iteratively through a novel double propagation algorithm. Empirical results on two data sets show the effectiveness of the proposed system.", "title": "ZORE: A Syntax-based System for Chinese Open Relation Extraction", "venue": "D", "graph_vector": [-0.102802, 0.184161, 0.0740803, 0.0630202, 0.395814, -1.03259, -0.0654474, -0.0168292, -1.58473, 0.69127, 0.399753, -0.724471, 0.524504, 0.323122, -0.182587, 0.382903, 0.277275, -0.821275, -0.215432, 0.22883, 0.0448919, 0.222869, -0.0241149, 0.0468598, -0.319442, 0.0704593, -0.00522606, 0.343151, -0.480707, -0.262343, 0.134924, -0.0644979, 0.439893, -0.590345, -0.370612, 0.0820409, -0.935809, 0.53405, 0.406603, 0.063361, 0.0616399, -0.580971, -0.0373458, 0.233715, 0.791394, -0.470623, -0.0774404, 0.26159, -0.331685, 0.19545, 0.675872, -0.109077, 0.479475, 0.555661, -0.190496, -0.0252035, 0.113842, 0.0984845, -0.214924, 0.272383, -0.343341, -0.22437, 0.208476, 0.0387456, -0.448324, -0.0655393, 0.263485, -0.321269, -0.046955, -0.0574009, -0.10905, -0.178327, 0.0526883, 0.0761498, 0.484243, -0.322775, -0.229651, -0.347347, -0.368045, -0.51349, -0.0139036, 0.105967, 0.127198, 0.0615354, 0.0540827, -0.43223, 0.228602, -0.289827, 0.143867, -0.0721056, -0.118412, 0.623367, -0.849309, -0.324319, -0.198158, -0.0801747, -0.26134, -0.393987, -0.375687, -0.195239, -0.132587, 0.0822292, -0.166709, -0.00188051, -0.0346137, -0.0315761, -0.125904, 0.031858, 0.752827, -0.0321803, 0.0595421, 0.221328, 0.194681, -0.147392, 0.138888, 0.0730719, 0.335977, -0.0547656, -0.135229, 0.280546, 0.134582, -0.0527519, -0.259094, -0.0821964, 0.136078, 0.218399, -0.0320052, -0.253794], "internal": 1}
{"paper_id": "D14-1002", "abstract": "This paper presents a deep semantic similarity model (DSSM), a special type of deep neural networks designed for text analysis, for recommending target documents to be of interest to a user based on a source document that she is reading. We observe, identify, and detect naturally occurring signals of interestingness in click transitions on the Web between source and target documents, which we collect from commercial Web browser logs. The DSSM is trained on millions of Web transitions, and maps source-target document pairs to feature vectors in a latent space in such a way that the distance between source documents and their corresponding interesting targets in that space is minimized. The effectiveness of the DSSM is demonstrated using two interestingness tasks: automatic highlighting and contextual entity search. The results on large-scale, real-world datasets show that the semantics of documents are important for modeling interestingness and that the DSSM leads to significant quality improvement on both tasks, outperforming not only the classic document models that do not use semantics but also state-of-the-art topic models.", "title": "Modeling Interestingness with Deep Neural Networks", "venue": "D", "graph_vector": [0.27402, 0.400393, 0.280203, 0.192667, 0.407426, -0.55436, 0.128213, 0.0818121, -1.20574, 0.287989, 0.00638472, -0.00405144, 0.52706, 0.083484, -0.014098, -0.402331, 0.479452, -0.81327, -0.0545752, 0.314341, 0.100333, 0.52974, 0.224538, -0.255641, -0.339588, 0.138161, 0.00135316, -0.192041, -0.212362, -0.398558, -0.0990418, -0.142998, 0.109297, -0.434494, -0.232892, 0.345754, -0.481086, 0.691151, 0.00810906, -0.434873, -0.00995025, -0.104363, -0.118474, 0.729809, 1.2217, -1.33441, -0.0552826, -0.030305, -0.222074, -0.101319, 0.513143, -0.440739, 0.871737, 0.426879, 0.117981, 0.0754903, 0.330631, 0.324222, -0.38594, 0.0704819, 0.218625, -0.43083, -0.339912, -0.290362, 0.274075, 0.0956925, 0.0560173, -0.122765, -0.0771516, -0.186311, -0.397705, -0.234225, 0.060409, -0.238622, 0.00608096, -0.32145, -0.512444, -0.132321, 0.464019, -0.32437, -0.168497, 0.0479577, 0.491556, -0.0441197, -0.00985093, -0.358558, -0.0684203, 0.181178, -0.0193554, -0.183144, 0.178625, 0.0704246, -0.421855, -0.236047, -0.0459005, 0.175224, 0.0554452, 0.0613971, -0.575861, -0.486279, -0.183434, -0.363709, -0.31815, 0.173798, -0.16037, 0.223487, 0.119855, -0.127684, 0.0268578, -0.313927, -0.195277, -0.357759, -0.153043, 0.097109, -0.187906, -0.184387, 0.18348, 0.1876, -0.226206, 0.324486, 0.0908699, 0.186357, 0.0346897, 0.0527288, 0.27193, -0.181971, -0.0785246, -0.137466], "internal": 1}
{"paper_id": "D14-1004", "abstract": "This paper investigates the use of neural networks for the acquisition of selectional preferences. Inspired by recent advances of neural network models for NLP applications, we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments for a particular predicate. The model is entirely unsupervised – preferences are learned from unannotated corpus data. We propose two neural network architectures: one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences. The model’s performance is evaluated on a pseudo-disambiguation task, on which it is shown to achieve state of the art performance.", "title": "A Neural Network Approach to Selectional Preference Acquisition", "venue": "D", "graph_vector": [0.0250139, -0.119543, 0.247267, 0.324418, 0.746836, -0.550385, 0.137018, -0.300798, -1.18257, 0.139753, -0.0518708, -0.50453, 0.642133, -0.123601, -0.120833, -0.049007, 0.34683, -0.449481, 0.243199, -0.0624977, -0.331828, 0.592479, 0.095672, 0.0246605, -0.411618, 0.333331, -0.124472, -0.048329, -0.328411, -0.23253, 0.0182738, -0.30369, 0.366181, -0.506873, -0.246017, 0.107704, -0.24052, 0.602414, -0.00338605, -0.0557551, 0.272208, -0.666918, -0.335221, 0.444768, 0.917922, -0.742895, 0.0664535, -0.0414968, -0.0927272, -0.167483, 0.264974, -0.157104, 0.76616, 0.735836, -0.0026187, -0.374404, 0.175111, 0.302876, -0.146568, 0.0443955, -0.0997215, -0.157355, 0.038267, 0.168135, 0.0525071, -0.390807, -0.0498502, 0.0161876, -0.0929149, -0.0891489, 0.235752, 0.0441785, -0.181293, -0.303997, 0.314062, 0.301723, -0.201866, -0.318972, 0.116409, -0.154335, -0.330889, -0.0969253, -0.128483, -0.0335363, 0.132272, -0.642061, 0.00824469, -0.346052, 0.25211, -0.463401, -0.321081, -0.316106, -0.651372, 0.0114126, 0.105399, -0.0618223, 0.0159725, 0.144488, 0.00035996, -0.126225, -0.0215804, -0.314056, -0.117792, 0.208787, 0.24651, 0.115938, 0.196608, -0.253381, 0.264207, 0.00261433, 0.0270446, 0.111961, 0.0196591, 0.0177767, 0.187978, -0.00150301, 0.419671, 0.224983, -0.255654, 0.400336, -0.677356, -0.00691518, 0.00565105, -0.262856, 0.0433673, 0.112053, 0.131887, -0.135426], "internal": 1}
{"paper_id": "D14-1161", "abstract": "Many forms of word relatedness have been developed, providing different perspectives on word similarity. We introduce a Bayesian probabilistic tensor factorization model for synthesizing a single word vector representation and per-perspective linear transformations from any number of word similarity matrices. The resulting word vectors, when combined with the per-perspective linear transformation, approximately recreate while also regularizing and generalizing, each word similarity perspective. Our method can combine manually created semantic resources with neural word embeddings to separate synonyms and antonyms, and is capable of generalizing to words outside the vocabulary of any particular perspective. We evaluated the word embeddings with GRE antonym questions, the result achieves the state-ofthe-art performance.", "title": "Word Semantic Representations using Bayesian Probabilistic Tensor Factorization", "venue": "D", "graph_vector": [-0.0855278, -0.0702534, -0.131413, 0.331039, 0.155363, -0.646919, 0.280745, -0.229088, -1.24254, 0.205134, -0.214825, -0.574491, 0.571724, 0.0396281, 0.490227, 0.0701276, 0.442421, -0.518577, 0.0103637, 0.187976, -0.155476, 0.744375, 0.182257, 0.196917, -0.470926, -0.0902752, -0.154307, 0.0107061, -0.125, -0.198556, -0.150877, -0.501874, 0.350476, -0.532678, -0.250149, 0.0186011, -0.215012, 0.571668, 0.278776, -0.193678, -0.274521, -0.225283, -0.4586, 0.244218, 0.902563, -1.20681, -0.132331, 0.137388, -0.165056, 0.313573, 0.163802, -0.193445, 0.716995, 0.594398, 0.00208978, 0.189193, -0.0133052, 0.121417, -0.306592, 0.403481, -0.550158, -0.0220531, -0.25081, -0.193209, -0.104762, 0.084223, 0.456818, -0.131592, -0.0450508, -0.0694532, 0.0734068, -0.19526, 0.184095, -0.0355251, 0.293594, -0.15605, -0.602416, -0.438297, -0.020415, 0.125887, -0.00995506, 0.00890193, 0.294751, -0.197328, 0.19337, -0.437385, 0.0687495, 0.0826549, -0.23115, -0.232751, 0.363485, 0.200805, -0.727262, -0.250577, 0.117614, 0.449667, 0.00409656, 0.0930762, 0.300895, -0.0780396, -0.347701, -0.257563, -0.244126, 0.105818, -0.0654628, 0.0647204, -0.127806, -0.244886, 0.178236, -0.0799645, 0.19497, -0.24277, -0.212841, 0.4052, -0.0163179, 0.182551, 0.282857, 0.0861143, 0.0255889, 0.263173, -0.234931, -0.119796, -0.0827785, 0.0817169, 0.247322, -0.232743, -0.131563, -0.385619], "internal": 1}
{"paper_id": "D14-1199", "abstract": "The efficiency of Information Extraction systems is known to be heavily influenced by domain-specific knowledge but the cost of developing such systems is considerably high. In this article, we consider the problem of event extraction and show that learning word representations from unlabeled domain-specific data and using them for representing event roles enable to outperform previous state-of-the-art event extraction models on the MUC-4 data set.", "title": "Event Role Extraction using Domain-Relevant Word Representations", "venue": "D", "graph_vector": [0.298912, 0.376515, 0.0911218, 0.209076, 0.317559, -0.601569, 0.190867, -0.0100952, -1.53464, 0.107812, -0.0659981, -0.661586, 0.0133298, 0.268528, 0.347287, -0.196555, 0.435333, -0.401201, 0.493901, 0.434534, -0.0279157, 0.686465, 0.438289, -0.311767, -0.199488, 0.186216, -0.0409474, 0.0191624, -0.127263, -0.152739, 0.0921574, -0.160238, -0.0714178, -0.730095, -0.176778, 0.139487, -0.0857397, 0.940208, 0.247752, -0.28848, -0.254886, -0.633189, -0.251219, 0.260933, 1.11698, -0.482386, -0.153684, 0.0940194, -0.390426, -0.0435665, 0.193838, 0.227474, 0.966424, 0.579016, -0.0904073, 0.15257, 0.243514, -0.0666454, -0.555616, -0.177777, -0.275761, -0.145054, 0.13809, -0.000413809, -0.0717717, 0.274492, 0.418204, -0.492637, 0.277385, 0.0935358, 0.0058198, 0.263339, 0.431473, -0.00552689, 0.0878458, -0.10221, -0.324897, -0.386894, -0.127786, -0.19379, -0.0845545, -0.320847, 0.112985, -0.00288104, 0.00348517, -0.326907, 0.135787, -0.101747, -0.150007, -0.0797113, -0.141453, 0.240396, -0.836042, 0.201466, -0.00317817, -0.290887, 0.044317, -0.0545994, 1.73902e-05, -0.482677, -0.43838, 0.0283732, 0.0732644, 0.0782112, 0.279635, 0.18734, 0.0628689, -0.153937, 0.200123, 0.229797, 0.00613147, -0.536217, -0.186471, 0.142866, -0.301096, 0.0290431, 0.464625, 0.0608397, 0.0168333, 0.262382, -0.305708, -0.13623, -0.125969, 0.265195, 0.363239, 0.0458074, -0.0775725, 0.415706], "internal": 1}
{"paper_id": "D14-1108", "abstract": "We describe a new dependency parser for English tweets, TWEEBOPARSER. The parser builds on several contributions: new syntactic annotations for a corpus of tweets (TWEEBANK), with conventions informed by the domain; adaptations to a statistical parsing algorithm; and a new approach to exploiting out-of-domain Penn Treebank data. Our experiments show that the parser achieves over 80% unlabeled attachment accuracy on our new, high-quality test set and measure the benefit of our contributions. Our dataset and parser can be found at http://www.ark.cs.cmu.edu/TweetNLP.", "title": "A Dependency Parser for Tweets", "venue": "D", "graph_vector": [-0.197831, 0.131559, 0.224936, -0.0353106, 0.603071, -1.06598, 0.195054, 0.141159, -1.47295, -0.100826, -0.201654, -0.409246, 0.772442, -0.270603, 0.180095, -0.122878, 0.395554, -0.323548, -0.233468, 0.453392, -0.764702, 0.558993, 0.312113, -0.116176, 0.0341376, -0.0159497, 0.164468, 0.187673, -0.17258, -0.260476, -0.011452, 0.191109, 0.11942, -0.035498, -0.0527406, 0.567887, -0.647019, 0.503484, 0.135946, 0.325275, 0.126805, -0.278275, 0.256814, 0.396026, 0.789383, -0.689343, 0.19299, 0.0393414, -0.217171, 0.100515, 0.310458, -0.487956, 0.753345, 0.517263, 0.106748, 0.224573, 0.117353, 0.162691, 0.0576083, -0.0726748, -0.247301, -0.14454, 0.198992, -0.223636, -0.268644, -0.0477828, -0.0147557, -0.171238, 0.0505667, 0.0018195, 0.276928, 0.037388, 0.084288, 0.375417, 0.0585099, 0.0112887, -0.361356, -0.222535, 0.0965357, 0.00760393, -0.0883925, 0.0628595, 0.376815, 0.0953836, 0.254777, -0.241988, 0.0448481, 0.0574197, 0.0465863, -0.0142943, 0.206987, 0.329587, -0.684073, 0.217843, 0.238474, -0.28002, -0.287253, 0.195124, -0.0168683, 0.0920561, 0.245984, -0.288615, 0.0605226, 0.177105, 0.0791502, 0.0810888, -0.243826, -0.370207, -0.015119, -0.243306, -0.167915, -0.101611, 0.0410197, 0.0647617, -0.204706, -0.203489, 0.012592, 0.0892962, -0.117725, -0.00797499, -0.210866, -0.158087, 0.0816624, 0.0514799, 0.661898, -0.242361, -0.0223695, 0.0166942], "internal": 1}
{"paper_id": "D12-1045", "abstract": "We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.", "title": "Joint Entity and Event Coreference Resolution across Documents", "venue": "D", "graph_vector": [-0.0397403, 0.056034, 0.0720854, 0.297504, 0.644319, -0.390371, 0.131023, 0.0406974, -1.47729, 0.547408, 0.0768447, -0.0703952, 0.625728, 0.126996, 0.07506, -0.123818, 0.524627, -0.891087, 0.147774, 0.737223, -0.264737, 0.407881, -0.0631336, -0.230105, -0.429617, -0.236554, 0.302837, 0.407734, -0.0253816, -0.356549, 0.229875, 0.279031, 0.0897193, -0.500895, -0.403281, 0.339898, 0.00861265, 0.448851, -0.121759, -0.215477, 0.0191434, -0.283063, -0.0233305, -0.0477742, 0.934695, -0.752459, 0.192364, 0.0901832, -0.230527, 0.161944, 0.0214035, 0.0111879, 0.707678, 0.790178, -0.00610822, -0.0384885, 0.00704548, 0.183138, -0.0997904, 0.205961, -0.241383, 0.00147144, 0.0878618, 0.0957517, 0.281594, -0.184512, 0.220337, -0.00426058, 0.26945, 0.215919, 0.49551, 0.149178, 0.139162, -0.52796, -0.126096, -0.428551, -0.362041, -0.467901, 0.0224825, 0.0891958, 0.0521673, 0.160677, 0.154427, -0.240456, 0.218317, -0.229788, -0.00212948, -0.31372, 0.213634, 0.32782, 0.113395, -0.405654, -0.563077, -0.211918, -0.112756, 0.0130218, 0.127674, 0.0206484, -0.119173, -0.294715, 0.00843979, 0.0045616, -0.00577504, 0.252439, -0.244141, 0.187313, -0.13545, 0.0867507, 0.00793876, -0.232114, -0.282281, 0.0987938, 0.0495387, -0.0999273, 0.217159, -0.0956795, 0.309576, 0.0723385, 0.0372265, 0.134703, -0.140501, 0.0922309, 0.365498, 0.0220181, 0.359711, 0.0770186, 0.0825174, -0.293677], "internal": 1}
{"paper_id": "D12-1113", "abstract": "We explore the interplay of knowledge and structure in co-reference resolution. To inject knowledge, we use a state-of-the-art system which cross-links (or “grounds”) expressions in free text to Wikipedia. We explore ways of using the resulting grounding to boost the performance of a state-of-the-art co-reference resolution system. To maximize the utility of the injected knowledge, we deploy a learningbased multi-sieve approach and develop novel entity-based features. Our end system outperforms the state-of-the-art baseline by 2 B3 F1 points on non-transcript portion of the ACE 2004 dataset.", "title": "Learning-based Multi-Sieve Co-reference Resolution with Knowledge*", "venue": "D", "graph_vector": [0.0872145, -0.0982386, -0.179768, 0.33733, 0.479063, -0.385002, 0.247111, 0.00839618, -1.6144, 0.480651, -0.0298521, -0.453255, 0.594294, 0.160894, -0.164208, 0.203365, 0.532779, -0.595928, 0.0658833, 0.256263, -0.733811, 0.712061, 0.0979625, -0.278213, -0.183563, 0.00155982, 0.151176, 0.476051, 0.0304788, -0.0365392, 0.176729, 0.124919, -0.166474, -0.497423, -0.21059, -0.0778556, -0.294771, 0.59271, 0.250204, -0.142513, 0.107697, -0.543168, -0.189513, 0.471121, 0.782282, -0.945291, 0.249392, 0.366026, -0.257361, -0.0793656, 0.0952117, 0.010974, 0.746995, 0.939027, -0.0846044, 0.116786, -0.491269, 0.105435, -0.15533, -0.146472, 0.137418, -0.310603, 0.0194524, -0.0899318, -0.11813, -0.100549, 0.470823, -0.0710387, -0.000300848, 0.32755, 0.3725, 0.211243, -0.395845, -0.159204, -0.110131, -0.315106, -0.319463, -0.133042, -0.222943, -0.179926, 0.0160173, 0.129711, 0.236389, -0.450952, 0.0804939, -0.574144, -0.230406, -0.272232, 0.041212, 0.134924, 0.255218, -0.0641723, -0.656573, -0.14831, -0.341194, 0.0283866, 0.164668, -0.0637997, 0.0723276, -0.121221, 0.189504, -0.193702, -0.101211, 0.0848608, -0.351057, 0.16441, -0.153513, 0.0201157, -0.106172, -0.0839931, -0.230966, -0.019446, -0.0819959, 0.0725725, 0.251682, 0.00676003, 0.166269, 0.33943, -0.0127358, 0.103707, -0.0176224, -0.0758599, 0.0186018, -0.0547319, 0.63793, 0.222738, -0.0311176, -0.204457], "internal": 1}
{"paper_id": "D15-1002", "abstract": "Distributional methods have proven to excel at capturing fuzzy, graded aspects of meaning (Italy is more similar to Spain than to Germany). In contrast, it is difficult to extract the values of more specific attributes of word referents from distributional representations, attributes of the kind typically found in structured knowledge bases (Italy has 60 million inhabitants). In this paper, we pursue the hypothesis that distributional vectors also implicitly encode referential attributes. We show that a standard supervised regression model is in fact sufficient to retrieve such attributes to a reasonable degree of accuracy: When evaluated on the prediction of both categorical and numeric attributes of countries and cities, the model consistently reduces baseline error by 30%, and is not far from the upper bound. Further analysis suggests that our model is able to “objectify” distributional representations for entities, anchoring them more firmly in the external world in measurable ways.", "title": "Distributional vectors encode referential attributes", "venue": "D", "graph_vector": [0.281254, 0.152584, 0.399701, 0.446891, 0.55272, -1.07747, 0.21008, -0.37249, -1.43039, 0.483829, 0.367597, -0.127036, 0.698486, 0.0769852, 0.0315917, -0.00488024, 0.477698, -0.544136, 0.258233, 0.328759, -0.311993, 0.156723, 0.291897, -0.271651, -0.535194, -0.0823935, -0.243104, 0.288504, -0.64152, 0.302733, -0.13002, 0.0224158, 0.156653, 0.0119182, 0.132847, -0.145601, -0.550385, 0.841138, 0.108783, 0.0110424, 0.16427, -0.598722, -0.04611, 0.438792, 1.1937, -0.902545, -0.0697708, 0.397783, 0.15247, 0.084757, 0.510892, -0.404131, 1.08435, 0.775751, -0.0327026, 0.0390325, 0.313103, 0.221488, 0.0658556, 0.210552, -0.256652, -0.41834, -0.370023, -0.0875358, -0.500928, 0.073038, -0.104576, -0.540509, -0.210697, 0.0944299, 0.197883, -0.134214, -0.0364839, -0.165791, 0.142712, -0.0557167, -0.886847, -0.641836, 0.193943, -0.313217, -0.0242875, 0.38029, 0.223217, -0.341174, 0.124179, -0.266324, -0.000662193, -0.101692, 0.0449921, -0.201119, 0.172619, 0.0116588, -0.299408, -0.375759, -0.177457, 0.0884672, 0.0383766, 0.0281248, 0.326084, -0.303096, -0.0532168, -0.379762, 0.254981, 0.153004, 0.128418, 0.215419, -0.00433964, -0.0314554, 0.164471, -0.310517, 0.0906945, -0.0739804, -0.211716, 0.229072, -0.53895, -0.0580925, 0.590171, 0.119205, -0.113751, 0.410177, -0.0838579, -0.268781, 0.295504, 0.088609, -0.0408468, -0.202636, 0.122309, 0.572617], "internal": 1}
{"paper_id": "D15-1222", "abstract": "ROUGE is a widely adopted, automatic evaluation measure for text summarization. While it has been shown to correlate well with human judgements, it is biased towards surface lexical similarities. This makes it unsuitable for the evaluation of abstractive summarization, or summaries with substantial paraphrasing. We study the effectiveness of word embeddings to overcome this disadvantage of ROUGE. Specifically, instead of measuring lexical overlaps, word embeddings are used to compute the semantic similarity of the words used in summaries instead. Our experimental results show that our proposal is able to achieve better correlations with human judgements when measured with the Spearman and Kendall rank coefficients.", "title": "Better Summarization Evaluation with Word Embeddings for ROUGE", "venue": "D", "graph_vector": [-0.185604, 0.0993806, 0.107852, 0.452042, 0.86032, -1.28076, -0.27419, 0.366981, -1.57589, 0.346753, 0.0366741, -0.340967, 0.699283, 0.0937357, 0.502166, 0.0879631, 0.681267, -0.622131, 0.04378, 0.356589, -0.153365, 0.465853, 0.143983, -0.396905, -0.297334, -0.0724072, -0.160586, 0.296178, -0.0799382, -0.185913, 0.0226537, -0.314478, 0.534929, -0.606242, -0.268743, 0.204344, -0.443379, 0.643674, -0.0561514, 0.020744, 0.0835959, -0.133195, -0.44439, 0.295874, 0.953387, -0.719561, -0.177704, 0.461784, -0.019307, 0.118229, 0.243456, 0.335296, 0.638365, 0.364671, 0.283707, 0.139944, 0.550112, 0.166234, -0.332508, 0.227859, -0.196004, -0.325192, 0.0930863, -0.14049, 0.0619892, -0.267684, 0.530696, -0.324079, 0.064581, -0.0213232, -0.0461091, -0.052315, 0.478064, -0.0594365, -0.165197, 0.0118634, -0.533502, -0.469479, -0.0723372, -0.0246617, -0.168311, 0.370165, 0.413444, -0.133954, -0.0575272, -0.571748, -0.23614, 0.021919, -0.0214295, -0.0842091, 0.116048, -0.20245, -0.936436, -0.195545, 0.0507509, 0.0998585, 0.00627796, -0.373076, 0.105983, -0.0204405, 0.139366, -0.218471, 0.265492, 0.265637, 0.0611627, 0.257075, -0.186625, -0.400683, -0.260727, 0.190635, 0.143292, -0.0306104, -0.0324291, 0.305968, -0.0195946, -0.326971, 0.565136, -0.159629, -0.114692, 0.237411, -0.061482, 0.114491, 0.153289, -0.466568, 0.243957, -0.152084, 0.125729, -0.0123943], "internal": 1}
{"paper_id": "D15-1146", "abstract": "Learning semantic representations and tree structures of bilingual phrases is beneficial for statistical machine translation. In this paper, we propose a new neural network model called Bilingual Correspondence Recursive Autoencoder (BCorrRAE) to model bilingual phrases in translation. We incorporate word alignments into BCorrRAE to allow it freely access bilingual constraints at different levels. BCorrRAE minimizes a joint objective on the combination of a recursive autoencoder reconstruction error, a structural alignment consistency error and a crosslingual reconstruction error so as to not only generate alignment-consistent phrase structures, but also capture different levels of semantic relations within bilingual phrases. In order to examine the effectiveness of BCorrRAE, we incorporate both semantic and structural similarity features built on bilingual phrase representations and tree structures learned by BCorrRAE into a state-of-the-art SMT system. Experiments on NIST Chinese-English test sets show that our model achieves a substantial improvement of up to 1.55 BLEU points over the baseline.", "title": "Bilingual Correspondence Recursive Autoencoders for Statistical Machine Translation", "venue": "D", "graph_vector": [0.220871, 0.0600459, 0.105731, 0.153666, 0.668121, -0.633708, 0.0957536, -0.242357, -1.39205, -0.0710262, 0.0140456, -0.380611, 0.349045, 0.0947262, -0.101773, -0.0480819, 0.368081, -0.349961, -0.0748399, 0.268031, -0.194558, 0.694184, 0.417248, -0.504643, -0.43522, 0.129543, -0.0827276, -0.091282, -0.0840633, -0.363463, -0.252662, -0.0389234, 0.109419, -0.523417, -0.143076, 0.246597, -0.350041, 0.621381, 0.15617, -0.352323, 0.00865895, -0.25254, -0.316705, 0.313728, 1.32329, -0.70273, 0.296722, 0.177759, -0.29581, 0.0673202, 0.160797, -0.197453, 0.799821, 0.695685, -0.150812, 0.228, 0.295861, -0.0102935, -0.136743, -0.0415512, -0.0949328, -0.172269, -0.11948, -0.0587328, 0.365447, -0.019796, 0.237703, -0.127157, -0.125797, -0.136783, 0.0125865, 0.226211, 0.027579, -0.0189964, 0.321714, -0.183422, -0.554825, -0.358309, -0.0471058, -0.0268012, -0.151313, 0.0747252, 0.505252, -0.130434, 0.277559, -0.446334, 0.193336, -0.0248301, -0.190426, -0.166518, -0.00994689, 0.253955, -0.512645, -0.150952, -0.121625, 0.257801, 0.020086, 0.121715, -0.0374459, -0.264943, -0.0727626, -0.197741, 0.114046, 0.092582, -0.143178, 0.0693936, -0.011707, -0.18174, 0.0576232, -0.143667, 0.106295, -0.109727, 0.0375536, 0.00020304, -0.140517, -0.0570865, 0.491098, 0.158568, 0.139195, 0.254695, -0.0448257, -0.128646, 0.00984085, -0.0417956, 0.0527485, 0.0728111, 0.0901094, 0.0588899], "internal": 1}
{"paper_id": "D15-1287", "abstract": "This paper describes a novel target-side syntactic language model for phrase-based statistical machine translation, bilingual structured language model. Our approach represents a new way to adapt structured language models (Chelba and Jelinek, 2000) to statistical machine translation, and a first attempt to adapt them to phrasebased statistical machine translation. We propose a number of variations of the bilingual structured language model and evaluate them in a series of rescoring experiments. Rescoring of 1000-best translation lists produces statistically significant improvements of up to 0.7 BLEU over a strong baseline for Chinese-English, but does not yield improvements for ArabicEnglish.", "title": "Bilingual Structured Language Models for Statistical Machine Translation", "venue": "D", "graph_vector": [0.368827, 0.275251, 0.161802, -0.0599263, 0.630145, -0.768916, 0.282241, -0.275966, -1.4976, -0.156173, 0.172066, -0.601672, 0.322707, -0.163137, -0.139142, 0.0605299, 0.531101, -0.860265, 0.0874967, 0.393866, -0.483495, 0.430173, 0.42098, -0.0307996, -0.25939, 0.14133, 0.0131551, 0.138702, -0.207349, 0.0704825, 0.0570449, 0.119423, -0.211503, -0.62924, -0.252739, 0.334115, -0.506983, 0.585346, 0.242734, -0.588486, 0.254882, 0.0298351, -0.318343, 0.448004, 1.12204, -0.846027, 0.100408, 0.353003, -0.231048, 0.0865737, 0.32788, 0.131186, 0.515423, 0.535138, 0.131483, 0.461404, 0.178512, 0.190014, 0.138846, 0.112925, -0.237255, -0.212397, 0.0378832, -0.0219547, -0.0665416, -0.0862418, 0.150742, -0.0339941, 0.0149445, -0.0120018, 0.0963155, 0.248825, -0.0122229, -0.238211, 0.361365, -0.201686, -0.248545, -0.328649, -0.207783, -0.217792, -0.431619, -0.0135538, 0.0572877, 0.099634, -0.287422, -0.559071, 0.0997103, -0.20851, -0.013091, -0.163758, 0.0584023, -0.0667703, -0.411783, -0.188114, -0.0975377, 0.154179, -0.0318956, -0.135101, -0.403834, -0.23852, -0.032471, -0.0930942, -0.142753, 0.254136, -0.0659179, -0.0771337, 0.0022555, -0.0904268, -0.119718, -0.41446, -0.00194046, 0.206935, -0.0953045, -0.111549, 0.201971, -0.198833, 0.249036, -0.201233, 0.366535, 0.256701, 0.0396905, -0.0530887, -0.178359, 0.123382, 0.606098, 0.213085, -0.0754564, -0.0349905], "internal": 1}
{"paper_id": "D11-1002", "abstract": "Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.", "title": "Predicting Thread Discourse Structure over Technical Web Forums", "venue": "D", "graph_vector": [-0.0227221, 0.211424, 0.148449, 0.293715, 0.504533, -0.568169, 0.123434, -0.485277, -1.73288, -0.398476, -0.154101, -0.217651, 0.424435, 0.0138724, 0.00357238, -0.14025, 0.417557, -0.630721, 0.434075, 0.279689, -0.546169, 0.728604, 0.123555, 0.0981622, -0.245322, -0.128941, -0.0126932, -0.15864, 0.266188, -0.337891, 0.102737, -0.265578, -0.251443, -0.323633, -0.0612901, 0.00258347, -0.0933797, 0.493283, 0.450605, -0.0671525, 0.348056, -0.163315, 0.0172761, 0.0444727, 0.621526, -0.578861, 0.234887, -0.134699, 0.153314, 0.0740347, 0.317032, -0.0801063, 1.14858, 0.780757, -0.172574, 0.0004439, -0.0784073, 0.0332372, 0.0985832, 0.138015, 0.07692, -0.0324109, -0.121108, 0.0623526, -0.235044, -0.123164, -0.34994, -0.294285, 0.322131, -0.182161, 0.19617, -0.67961, -0.0619344, 0.0240047, 0.0806589, -0.178516, -0.266665, -0.0294926, -0.319536, -0.0678549, -0.0551447, -0.149237, -0.235034, -0.0396157, -0.149367, -0.203668, -0.129669, -0.11188, 0.167735, 0.350672, -0.105161, 0.121385, -0.808531, -0.12575, 0.395103, -0.0839621, -0.120885, -0.0649821, -0.156858, -0.0632976, -0.181206, -0.664663, -0.267185, -0.00378316, -0.433208, 0.154437, -0.382428, -0.129622, 0.304816, -0.110707, -0.140005, 0.125543, -0.133209, -0.0368879, 0.0309477, -0.26726, 0.0503984, -0.214326, 0.200967, 0.341734, -0.0321986, 0.32957, -0.304285, 0.00500852, 0.1267, 0.207136, 0.0116827, -0.396845], "internal": 1}
{"paper_id": "D11-1043", "abstract": "The Text Analysis Conference (TAC) ranks summarization systems by their average score over a collection of document sets. We investigate the statistical appropriateness of this score and propose an alternative that better distinguishes between human and machine evaluation systems.", "title": "Ranking Human and Machine Summarization Systems", "venue": "D", "graph_vector": [0.0887423, 0.304451, 0.108704, 0.202389, 0.8298, -1.33391, -0.253513, -0.0538375, -1.52654, 0.389244, -0.0572679, -0.205104, 0.631953, 0.376517, -0.134405, 0.0897094, 0.472457, -0.46842, 0.284222, 0.136096, -0.0800005, 0.426802, 0.556342, -0.595231, -0.472741, -0.0461205, -0.18138, 0.077026, -0.419811, -0.242124, 0.0216985, 0.0170032, 0.2883, -0.420443, 0.0849413, -0.103647, -0.412863, 0.683044, 0.287057, -0.137778, 0.146422, -0.622679, 0.107685, 0.265412, 1.03813, -0.778836, 0.0621042, 0.535726, 0.0490618, 0.162374, -0.195441, 0.216084, 1.00153, 1.31021, -0.207971, 0.0382123, 0.45442, 0.194447, -0.182294, -0.0193236, -0.174581, -0.672731, -0.0749319, -0.140713, -0.34658, -0.108949, 0.536814, -0.680164, 0.38884, 0.121431, 0.325587, -0.0248611, -0.142216, -0.339954, 0.0567461, -0.0985204, -0.205933, -0.659935, -0.069963, -0.291151, -0.114327, 0.0606318, -0.113602, 0.215628, 0.222155, -0.499674, -0.294104, -0.173816, 0.00111499, -0.295324, 0.154486, -0.184801, -0.485293, -0.480018, -0.0418484, -0.103165, 0.342949, -0.124862, 0.459997, 0.405319, 0.111966, -0.269218, 0.127036, 0.324282, 0.352426, -0.153109, 0.0750876, -0.529709, -0.156547, -0.285616, 0.362357, 0.0582401, 0.00566755, 0.0989141, -0.206811, 0.263477, 0.696448, -0.215117, -0.0497739, 0.533697, -0.0114735, 0.438898, 0.0575243, -0.0222506, 0.531065, 0.134744, -0.0696793, 0.294786], "internal": 1}
{"paper_id": "D11-1001", "abstract": "Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011 Infectious Diseases task.", "title": "Fast and Robust Joint Models for Biomedical Event Extraction", "venue": "D", "graph_vector": [-0.211002, 0.0669871, 0.0956621, 0.226156, 0.587145, -0.630014, 0.0682028, -0.0400863, -1.5961, 0.64356, -0.227664, -0.0453372, 0.686102, 0.175272, 0.182095, 0.296, 0.793044, -0.504075, 0.394458, 0.505424, -0.33687, 0.469263, 0.416597, -0.163956, -0.225471, -0.00300374, 0.0493751, -0.0593183, -0.4219, -0.252106, 0.316219, -0.0966188, -0.0256558, -0.564398, -0.258509, 0.000169632, 0.17015, 0.539243, 0.18508, 0.0974065, -0.0459609, -0.379674, -0.0878593, 0.342433, 0.815557, -0.521819, 0.141536, 0.152797, -0.167463, 0.294095, 0.0379136, -0.175903, 0.764941, 0.875185, -0.172875, 0.0848883, 0.0500708, 0.269502, 0.00338008, -0.113988, -0.222029, -0.128133, 0.0116675, -0.10844, -0.369766, 0.0934731, -0.00911832, -0.26085, 0.0396908, 0.109914, 0.0646128, 0.049159, 0.228337, -0.116764, 0.240373, -0.0689022, -0.294047, -0.0427823, -0.0721711, 0.0808533, -0.325121, 0.104506, 0.136715, -0.0670456, -0.038214, -0.522392, 0.127715, -0.213869, 0.209404, -0.421333, 0.239327, 0.215716, -0.335654, 0.173602, 0.0767506, -0.165926, 0.0948374, -0.303758, -0.318593, -0.0363135, 0.0439297, -0.0142368, 0.215179, -0.019056, -0.191427, 0.0307409, -0.0360804, -0.505183, 0.244287, -0.353672, -0.0725544, -0.396476, -0.350008, -0.00619158, -0.121101, -0.146612, 0.605424, 0.172147, -0.165686, 0.331575, 0.044011, -0.453387, 0.0604423, -0.219288, 0.712785, -0.043773, 0.252986, 0.291289], "internal": 1}
{"paper_id": "P07-1056", "abstract": "Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains.", "title": "Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification", "venue": "P", "graph_vector": [-0.0528319, 0.10793, -0.0219139, 0.340151, 0.206787, -0.63956, 0.0974433, -0.132147, -1.30491, 0.077518, -0.224515, -0.0718929, 0.688133, -0.139126, -0.103037, -0.0459326, 0.302262, -0.438579, 0.0298581, 0.14539, -0.0777644, 0.783158, 0.496425, 0.128696, -0.43267, 0.410298, -0.126289, -0.0730855, -0.435946, -0.209356, 0.0163157, -0.124605, 0.200103, -0.49178, -0.155085, 0.0490011, -0.0975543, 1.03422, -0.230533, -0.331882, -0.092921, -0.265257, -0.481519, 0.541562, 0.792011, -0.796594, 0.0433635, 0.129587, -0.00735363, -0.00210929, 0.315699, -0.32738, 1.06317, 0.606276, 0.0113317, 0.0524248, 0.0136764, 0.52543, 0.0658437, -0.0637828, 0.00137256, -0.0211776, -0.112267, 0.247729, -0.0181429, 0.0730179, 0.306073, -0.360222, 0.200463, 0.246381, 0.198005, -0.342817, -0.0673134, -0.156583, -0.121231, -0.259826, -0.426162, -0.113906, -0.290379, 0.230616, -0.543591, 0.269838, 0.341365, 0.00933087, 0.260254, 0.130486, 0.159241, -0.07566, -0.233989, 0.0640104, -0.157856, -0.0768738, -0.573432, 0.20694, -0.183281, -0.129498, 0.0913682, -0.435898, -0.0361272, -0.0409598, 0.0550569, -0.225327, -0.107816, -0.193905, -0.0392189, 0.127962, -0.214966, 0.119235, 0.231613, -0.275369, 0.141007, -0.0701056, -0.0830574, 0.342335, 0.0303329, -0.0436367, 0.250901, -0.0319306, 0.229478, -0.0117995, -0.272008, -0.0890112, 0.129204, 0.0314147, 0.485889, 0.140781, -0.0578387, -0.103868], "internal": 1}
{"paper_id": "P07-1055", "abstract": "In this paper we investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Inference in the model is based on standard sequence classification techniques using constrained Viterbi to ensure consistent solutions. The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation.", "title": "Structured Models for Fine-to-Coarse Sentiment Analysis", "venue": "P", "graph_vector": [0.0112068, 0.21438, -0.00442538, 0.23541, 0.738296, -0.508846, -0.123911, 0.00431148, -1.67055, -0.151427, -0.306542, -0.324982, 0.751552, 0.0567867, -0.172947, 0.022845, 0.136257, -0.50949, 0.180375, 0.120426, -0.248785, 0.557131, 0.162003, -0.111255, -0.200382, 0.276822, -0.335879, 0.194635, -0.232481, -0.193949, -0.212219, 0.223714, -0.0417891, -0.399657, -0.0535763, 0.0176091, -0.433455, 0.73711, 0.268453, -0.170616, 0.0494658, -0.336221, -0.207468, 0.281009, 0.529576, -0.827454, -0.128609, 0.248455, 0.139982, -0.0333422, 0.666801, -0.351436, 0.694385, 0.59684, -0.203316, 0.00594192, 0.205488, 0.377344, 0.260909, 0.149056, 0.104716, 0.532736, 0.0871566, -0.25356, -0.216637, 0.0712172, 0.360925, -0.166311, 0.108919, 0.0695239, 0.0786619, -0.0771754, 0.20783, 0.0013573, 0.0665096, -0.282224, -0.280132, -0.216782, -0.227278, 0.0352894, -0.152249, -0.0288904, 0.189589, -0.428899, -0.0375415, -0.104903, 0.0423513, -0.56497, -0.14257, -0.138179, -0.100943, -0.00149256, -0.565836, 0.023131, 0.0646662, 0.0198629, -0.0442774, -0.368268, -0.103078, 0.077726, 0.0161197, -0.216432, -0.0604063, -0.247414, -0.117663, -0.0808411, -0.166707, -0.0508741, 0.417617, -0.207813, -0.178727, 0.254943, -0.164028, -0.174552, 0.106633, -0.172824, 0.46576, -0.134812, 0.182752, -0.0959724, -0.258496, -0.16386, 0.00451008, -0.0742299, 0.285195, -0.0433013, 0.440451, 0.142219], "internal": 1}
{"paper_id": "P07-1106", "abstract": "Standard approaches to Chinese word segmentation treat the problem as a tagging task, assigning labels to the characters in the sequence indicating whether the character marks a word boundary. Discriminatively trained models based on local character features are used to make the tagging decisions, with Viterbi decoding finding the highest scoring segmentation. In this paper we propose an alternative, word-based segmentor, which uses features based on complete words and word sequences. The generalized perceptron algorithm is used for discriminative training, and we use a beamsearch decoder. Closed tests on the first and second SIGHAN bakeoffs show that our system is competitive with the best in the literature, achieving the highest reported F-scores for a number of corpora.", "title": "Chinese Segmentation with a Word-Based Perceptron Algorithm", "venue": "P", "graph_vector": [0.0477555, 0.118023, -0.0149451, 0.429354, 0.547167, -0.670606, -0.0331893, -0.103745, -1.65152, 0.11394, -0.0583127, -0.328326, 0.632139, 0.408678, -0.225056, -0.337986, 0.45292, -0.9741, -0.270966, 0.406563, -0.222847, 0.674735, 0.49691, 0.0561524, -0.177985, -0.0252652, 0.197164, 0.0955497, 0.0196726, -0.367159, -0.0860492, 0.070296, 0.288545, -0.458849, -0.252878, 0.285529, -0.334827, 0.472111, 0.0827827, -0.137958, 0.195271, -0.376109, -0.0483673, 0.32645, 0.864857, -0.721339, -0.412202, -0.139336, -0.0859559, 0.187655, 0.199212, -0.375614, 0.889541, 0.776259, -0.562816, -0.1033, 0.34804, 0.278935, 0.0740335, 0.153993, -0.580016, 0.104745, -0.0331883, -0.136581, -0.362192, -0.220815, 0.316328, -0.116886, -0.239314, -0.0529426, 0.211436, 0.0544219, 0.150055, 0.0303483, 0.204399, -0.171301, -0.579039, -0.243601, -0.280423, -0.0944222, 0.0150088, -0.0179491, 0.421517, 0.0677389, 0.349523, -0.458625, -0.157032, -0.101883, -0.184973, 0.110321, 0.360644, 0.423524, -0.466178, -0.0287019, 0.136147, -0.173987, -0.180027, -0.112328, -0.0474852, 0.0877612, 0.0866442, -0.138368, 0.154942, 0.00558673, 0.122229, 0.181015, 0.0613369, 0.160286, 0.350429, -0.222549, 0.0819545, -0.199028, -0.178755, 0.00666092, 0.0180823, 0.175659, 0.28898, 0.213799, -0.175662, 0.330234, 0.0749187, -0.336344, -0.111276, -0.114563, 0.336099, 0.112696, -0.322532, -0.140068], "internal": 1}
{"paper_id": "P07-2044", "abstract": "This paper describes a fully automatic twostage machine learning architecture that learns temporal relations between pairs of events. The first stage learns the temporal attributes of single event descriptions, such as tense, grammatical aspect, and aspectual class. These imperfect guesses, combined with other linguistic features, are then used in a second stage to classify the temporal relationship between two events. We present both an analysis of our new features and results on the TimeBank Corpus that is 3% higher than previous work that used perfect human tagged features.", "title": "Classifying Temporal Relations Between Events", "venue": "P", "graph_vector": [-0.511231, 0.264168, 0.367954, 0.374, 0.226411, -0.659758, 0.118613, 0.133296, -1.59417, 0.460221, 0.026181, -0.201653, 0.483766, 0.440133, -0.144291, 0.171527, 0.343041, -0.387321, 0.605797, 0.519036, -0.265416, 0.31133, 0.362908, -0.26248, -0.301782, 0.175289, 0.356497, -0.548682, -0.244887, 0.0867035, 0.158869, -0.082316, 0.0163355, -0.489902, 0.306069, -0.0885447, 0.0386669, 0.72211, -0.104606, 0.121722, 0.0316117, -0.229622, -0.0687202, 0.326087, 1.2847, -0.901162, -0.00680206, 0.275112, -0.120205, -0.237654, 0.249451, -0.096206, 0.865489, 0.463277, 0.0307395, 0.227725, 0.0405768, 0.196128, -0.318054, -0.282083, -0.423055, -0.218931, 0.177974, 0.0377452, -0.0661421, -0.290697, -0.075666, -0.371724, 0.597591, -0.255453, -0.00289297, -0.148825, 0.260896, -0.0698435, 0.280114, -0.610114, -0.137577, -0.336756, -0.0661628, -0.0941036, -0.385998, 0.389831, 0.154981, -0.417292, -0.113756, -0.433197, 0.244534, 0.000923105, 0.48715, 0.0749619, 0.0850676, -0.232741, -0.575756, -0.0689136, -0.135907, 0.0844624, 0.280531, -0.0422375, -0.107742, -0.0902437, -0.1357, -0.288635, 0.362589, 0.178932, -0.217114, 0.0626444, -0.073397, -0.00912604, 0.0256748, -0.435624, 0.0293402, -0.272445, 0.135305, 0.0576168, -0.0516318, 0.283542, 0.0981122, 0.236254, 0.0245975, 0.303049, -0.129491, -0.138719, -0.194224, 0.0309183, 0.350257, 0.121211, -0.126031, -0.0377584], "internal": 1}
{"paper_id": "P07-1006", "abstract": "We present a novel approach to the word sense disambiguation problem which makes use of corpus-based evidence combined with background knowledge. Employing an inductive logic programming algorithm, the approach generates expressive disambiguation rules which exploit several knowledge sources and can also model relations between them. The approach is evaluated in two tasks: identification of the correct translation for a set of highly ambiguous verbs in EnglishPortuguese translation and disambiguation of verbs from the Senseval-3 lexical sample task. The average accuracy obtained for the multilingual task outperforms the other machine learning techniques investigated. In the monolingual task, the approach performs as well as the state-of-the-art systems which reported results for the same set of verbs.", "title": "Learning Expressive Models for Word Sense Disambiguation", "venue": "P", "graph_vector": [0.282969, -0.0267039, 0.100841, 0.346877, 0.474565, -0.858115, 0.371096, 0.107826, -1.49103, 0.410638, -0.347659, -0.0291633, 0.495358, 0.437292, -0.0707379, -0.0382966, 0.408765, -0.649818, 0.114175, 0.620118, 0.202791, 0.641553, -0.108935, 0.376487, -0.114872, 0.489151, -0.00565297, 0.327452, 0.342255, -0.316601, 0.138941, -0.0154843, -0.131456, -0.220373, -0.170218, 0.202828, -0.388227, 0.644317, 0.346753, -0.0480624, -0.507902, -0.14848, 0.128867, 0.355549, 0.801325, -0.716689, 0.35112, 0.377777, 0.086284, 0.0431529, 0.549003, -0.108892, 0.769024, 0.661896, -0.285749, -0.0507921, 0.0359607, 0.591005, -0.131825, -0.198151, -0.620077, 0.148046, -0.117235, -0.0453608, -0.0590557, -0.426653, -0.202706, -0.240378, -0.0465026, -0.247473, 0.490399, 0.0828415, 0.265049, 0.129459, -0.0739927, 0.0307878, -0.62624, -0.478038, -0.158894, 0.0496448, 0.225781, 0.293641, 0.219135, -0.0580724, -0.0446388, -0.350267, -0.27449, 0.00434075, 0.292826, -0.0501503, 0.21213, -0.30918, -0.479473, 0.15468, 0.180397, -0.159924, 0.0260618, -0.0114705, -0.204398, 0.0121392, -0.101813, -0.384366, -0.0595304, 0.165275, 0.233327, -0.106802, 0.0109479, 0.100237, 0.0783928, -0.183724, 0.383989, 0.115144, -0.39753, 0.0915456, 0.0734953, -0.138639, 0.321919, 0.137709, -0.175958, -0.250228, -0.528831, 0.139118, -0.17719, -0.152323, 0.261299, 0.588523, 0.190426, 0.677501], "internal": 1}
{"paper_id": "P09-2004", "abstract": "Discourse connectives are words or phrases such as once, since, and on the contrary that explicitly signal the presence of a discourse relation. There are two types of ambiguity that need to be resolved during discourse processing. First, a word can be ambiguous between discourse or non-discourse usage. For example, once can be either a temporal discourse connective or a simply a word meaning “formerly”. Secondly, some connectives are ambiguous in terms of the relation they mark. For example since can serve as either a temporal or causal connective. We demonstrate that syntactic features improve performance in both disambiguation tasks. We report state-ofthe-art results for identifying discourse vs. non-discourse usage and human-level performance on sense disambiguation.", "title": "Using Syntax to Disambiguate Explicit Discourse Connectives in Text∗", "venue": "P", "graph_vector": [0.135619, 0.407058, 0.486818, 0.11405, 0.430115, -0.477048, -0.167136, -0.380627, -1.7326, 0.0204527, -0.212736, -0.413533, 0.528665, 0.145713, -0.0336585, -0.0195632, 0.222063, -0.653888, 0.339006, 0.436039, -0.381085, 0.386313, 0.215101, -0.0889802, -0.374832, 0.159628, 0.0278494, -0.346165, -0.417522, -0.483905, -0.204699, -0.168912, -0.217284, -0.228285, 0.0555491, -0.20774, -0.276803, 0.642242, -0.235849, -0.0367514, -0.0264941, -0.449296, -0.0206985, 0.193116, 0.871757, -0.612003, -0.150907, -0.0777609, -0.442549, -0.0392094, -0.0608166, -0.246777, 0.650342, 0.812948, -0.23814, 0.446313, 0.193531, -0.0986381, -0.129167, 0.0383168, -0.274192, -0.524804, -0.150704, 0.150555, -0.15164, -0.206152, 0.349573, -0.225736, 0.346454, -0.00393236, 0.262174, -0.0438552, -0.0625592, -0.288566, 0.0999836, 0.334624, 0.0963576, -0.35523, -0.204452, 0.0375712, -0.172245, 0.275398, 0.177732, -0.0664152, -0.017422, -0.313436, -0.049549, 0.117631, 0.388877, -0.260673, -0.0681624, 0.130837, -0.481095, -0.090682, -0.00752374, 0.0134319, -0.0762779, 0.224012, 0.135434, 0.196273, -0.0335899, -0.113469, 0.12986, 0.112456, -0.142429, -0.147016, -0.164684, 0.104525, -0.207825, -0.0832159, 0.0561651, 0.00179933, 0.271601, -0.151814, -0.190504, 0.0761374, 0.606243, 0.341954, -0.048086, 0.15493, 0.223126, 0.0792063, -0.185402, -0.207925, 0.153867, 0.226694, 0.340711, -0.192952], "internal": 1}
{"paper_id": "P09-2054", "abstract": "This paper presents a new term extraction approach using relevance between term candidates calculated by a link analysis based method. Different types of relevance are used separately or jointly for term verification. The proposed approach requires no prior domain knowledge and no adaptation for new domains. Consequently, the method can be used in any domain corpus and it is especially useful for resource-limited domains. Evaluations conducted on two different domains for Chinese term extraction show significant improvements over existing techniques and also verify the efficiency and relative domain independent nature of the approach.", "title": "Chinese Term Extraction Using Different Types of Relevance", "venue": "P", "graph_vector": [-0.0800419, 0.132912, 0.146407, 0.134045, 0.175681, -0.3178, 0.035895, 0.0762669, -1.33827, 0.210839, 0.0103693, -0.0542213, 0.209601, 0.239966, -0.190383, -0.354714, 0.436972, -0.257324, 0.0531171, 0.154412, 0.0165481, 0.352707, -0.00981011, -0.0686725, -0.668862, 0.241816, 0.161512, -0.137875, -0.706921, -0.0927657, 0.56359, -0.364633, 0.278106, -0.314104, -0.328669, -0.185294, 0.10568, 0.354785, 0.549797, -0.0978206, -0.0905827, -0.327012, -0.465196, 0.249296, 0.899064, -0.799389, -0.0617589, 0.00818288, -0.215622, -0.076261, 0.184178, -0.269093, 0.902618, 0.80534, -0.325324, 0.0438329, 0.0545258, 0.288899, 0.32148, -0.33099, -0.0180328, -0.0726124, -0.00278769, -0.143127, 0.166945, -0.12209, 0.133868, 0.278578, -0.18924, 0.104584, -0.0163181, 0.341366, -0.0580454, -0.505081, -0.203233, -0.364499, -0.24463, -0.149124, 0.0793861, -0.0619422, -0.145964, 0.165943, 0.281008, 0.122955, 0.0489844, -0.398094, 0.209899, -0.112106, 0.0706796, -0.135336, 0.180398, 0.180652, -0.71386, -0.182345, -0.408669, -0.0537113, -0.172465, -0.0287615, -0.239358, -0.0339797, 0.0114007, -0.506589, 0.0166708, 0.278012, -0.117481, -0.305945, -0.400818, -0.00326137, 0.115331, -0.247612, 0.0518844, 0.0919565, 0.120156, -0.0434071, 0.0944658, -0.1117, 0.454335, -0.0269285, -0.0345687, 0.155237, -0.247668, 0.0102003, -0.333132, -0.114845, 0.240197, 0.154312, -0.0007383, -0.0298064], "internal": 1}
{"paper_id": "P09-2087", "abstract": "We experiment with splitting words into their stem and suffix components for modeling morphologically rich languages. We show that using a morphological analyzer and disambiguator results in a significant perplexity reduction in Turkish. We present flexible n-gram models, FlexGrams, which assume that the n−1 tokens that determine the probability of a given token can be chosen anywhere in the sentence rather than the preceding n −1 positions. Our final model achieves 27% perplexity reduction compared to the standard n-gram model.", "title": "Modeling Morphologically Rich Languages Using Split Words and Unstructured Dependencies", "venue": "P", "graph_vector": [0.287493, 0.0508344, 0.18941, 0.586757, 0.204394, -0.752188, 0.467051, -0.200145, -1.37144, -0.284747, -0.225412, -0.179947, 0.443583, 0.132383, 0.231915, -0.487621, 0.579754, -0.668768, 0.670838, 0.123907, -0.567305, 0.384528, 0.200343, 0.148686, -0.174366, 0.25195, -0.463353, -0.0848233, -0.191381, -0.191638, 0.19417, -0.0910303, -0.0659304, -0.50817, -0.174898, 0.44819, -0.199579, 0.555463, 0.25407, 0.133819, -0.0770213, -0.0218576, -0.450088, 0.0323474, 1.13082, -0.544079, -0.242697, 0.486489, -0.344475, -0.538245, 0.113131, -0.191587, 0.805005, 0.436467, -0.421124, 0.179737, 0.45178, 0.244227, -0.387577, 0.218009, 0.034487, -0.178106, -0.11015, 0.00763789, 0.286393, 0.0878845, -0.404225, -0.0491034, 0.561677, 0.519942, -0.0457711, 0.0195755, 0.0229245, 0.141196, 0.117939, 0.0452895, -0.958335, -0.675451, 0.226702, -0.205216, 0.0733157, -0.132686, 0.00301897, -0.0342545, 0.23414, 0.17643, -0.0633506, -0.161886, -0.0569264, -0.25568, -0.0646415, 0.265925, -0.17159, -0.186774, 0.386179, 0.365708, -0.209753, -0.005369, 0.039078, -0.0410457, -0.589632, -0.294001, -0.116146, -0.0689824, 0.121683, -0.595941, -0.379921, -0.211804, 0.260188, -0.318172, -0.0216645, 0.137482, 0.163052, 0.105652, 0.116156, -0.0539032, 0.329895, 0.264541, -0.0271457, 0.203882, -0.486211, -0.459397, -0.339204, 0.165616, 0.226127, -0.0253627, -0.0953296, -0.378035], "internal": 1}
{"paper_id": "P14-2096", "abstract": "Creating cross-language article links among different online encyclopedias is now an important task in the unification of multilingual knowledge bases. In this paper, we propose a cross-language article linking method using a mixed-language topic model and hypernym translation features based on an SVM model to link English Wikipedia and Chinese Baidu Baike, the most widely used Wiki-like encyclopedia in China. To evaluate our approach, we compile a data set from the top 500 Baidu Baike articles and their corresponding English Wiki articles. The evaluation results show that our approach achieves 80.95% in MRR and 87.46% in recall. Our method does not heavily depend on linguistic characteristics and can be easily extended to generate crosslanguage article links among different online encyclopedias in other languages.", "title": "Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation", "venue": "P", "graph_vector": [0.118873, 0.561509, 0.255309, 0.481859, 0.169422, -0.515473, -0.0124294, 0.445269, -1.62652, 0.429763, -0.0383288, -0.410097, 0.612156, -0.0527471, -0.245853, 0.193557, 0.694735, -0.405398, -0.112528, 0.0521512, -0.625891, 0.590026, 0.139476, -0.0636617, -0.691776, -0.0544774, 0.0341437, 0.534962, -0.0841218, -0.0665806, 0.0464377, -0.151566, 0.619372, -0.386118, -0.376073, 0.395192, -0.180805, 0.696645, 0.274623, -0.398033, -0.488584, -0.321702, -0.202712, 0.512872, 1.04932, -0.798347, 0.0112793, -0.0205671, 0.175049, -0.187103, 0.05502, -0.272546, 0.677892, 0.62358, -0.180434, 0.283084, 0.0354751, 0.12927, -0.157282, -0.128059, -0.0162796, -0.142351, 0.0609909, -0.325334, -0.564655, 0.044932, 0.181839, -0.101916, -0.00686672, -0.128409, -0.14159, 0.115263, -0.22829, -0.227299, -0.0897481, -0.483293, -0.522338, -0.555087, 0.204971, -0.402541, -0.229752, -0.427775, -0.0164852, -0.29252, 0.112887, -0.106855, -0.106186, -0.132959, 0.11313, -0.35072, -0.253541, 0.241674, -0.78151, -0.20732, -0.0619598, 0.307701, 0.01427, 0.291829, 0.0129176, 0.237023, -0.221158, -0.197369, 0.193557, 0.221407, -0.378197, 0.241659, -0.0786032, -0.0647145, 0.0907731, 0.016149, -0.626631, 0.22652, 0.0522597, -0.0806558, -0.401777, -0.19731, 0.353306, -0.136752, 0.0780274, -0.243788, -0.363492, -0.100679, -0.246144, 0.0626824, 0.142336, 0.302943, -0.0216914, 0.137517], "internal": 1}
{"paper_id": "P14-2055", "abstract": "In order to summarize a document, it is often useful to have a background set of documents from the domain to serve as a reference for determining new and important information in the input document. We present a model based on Bayesian surprise which provides an intuitive way to identify surprising information from a summarization input with respect to a background corpus. Specifically, the method quantifies the degree to which pieces of information in the input change one’s beliefs’ about the world represented in the background. We develop systems for generic and update summarization based on this idea. Our method provides competitive content selection performance with particular advantages in the update task where systems are given a small and topical background corpus.", "title": "A Bayesian Method to Incorporate Background Knowledge during Automatic Text Summarization", "venue": "P", "graph_vector": [0.0214832, 0.311934, 0.0941682, 0.405116, 0.744338, -0.567178, -0.270963, 0.0450219, -1.77298, -0.00849666, -0.232549, -0.371745, 0.684994, 0.0186946, 0.145768, 0.0454376, 0.486133, -0.254428, -0.0838729, 0.0931898, 0.0249949, 0.602299, -0.107051, -0.185493, -0.460977, -0.0996188, -0.0508212, 0.223943, -0.275039, 0.139852, 0.220586, 0.335009, 0.0818031, -0.376109, 0.0569309, -0.00681413, -0.432507, 0.231286, 0.450195, -0.109272, -0.319893, -0.155725, -0.425498, 0.415473, 0.789915, -0.697417, 0.389591, 0.0610801, -0.0616533, -0.200621, 0.119164, 0.144956, 0.967735, 0.887118, -0.241771, 0.265105, 0.541374, 0.314511, -0.782616, 0.35583, -0.688479, -0.301206, 0.0104691, 0.322704, -0.512043, -0.517369, 0.104882, -0.168734, 0.470183, -0.0809291, 0.016177, -0.0314802, -0.113408, 0.0297464, -0.12189, 0.0096055, -0.346497, -0.585478, -0.574199, -0.0204634, -0.140566, 0.0213492, -0.047489, 0.0550617, 0.265981, -0.213702, -0.311687, 0.210237, 0.287958, -0.444699, 0.183672, -0.0437443, -1.10575, -0.0979461, 0.0471623, 0.216517, 0.0733256, -0.223112, 0.138778, -0.262943, -0.00751127, -0.256949, -0.226062, 0.443139, -0.0238322, 0.302258, -0.282578, -0.0810739, 0.473175, 0.259422, -0.0384314, 0.14105, -0.0458557, -0.366049, -0.393156, -0.00400037, 0.116796, -0.111621, -0.263647, 0.235594, -0.304371, -0.0779571, 0.0358012, -0.0511075, 0.469635, 0.0323952, 0.162357, -0.535503], "internal": 1}
{"paper_id": "P14-2070", "abstract": "While many lexica annotated with words polarity are available for sentiment analysis, very few tackle the harder task of emotion analysis and are usually quite limited in coverage. In this paper, we present a novel approach for extracting – in a totally automated way – a highcoverage and high-precision lexicon of roughly 37 thousand terms annotated with emotion scores, called DepecheMood. Our approach exploits in an original way ‘crowd-sourced’ affective annotation implicitly provided by readers of news articles from rappler.com. By providing new state-of-the-art performances in unsupervised settings for regression and classification tasks, even using a naive approach, our experiments show the beneficial impact of harvesting social media data for affective lexicon building.", "title": "DepecheMood: a Lexicon for Emotion Analysis from Crowd-Annotated News", "venue": "P", "graph_vector": [0.166059, 0.270879, 0.0499301, -0.0462573, 0.551254, -1.0078, -0.0174262, -0.0523509, -1.58952, 0.31693, -0.0821149, -0.282016, 0.235525, -0.309034, 0.0183267, -0.288412, 0.429433, -0.943548, 0.352003, -0.127662, -0.314567, 0.585849, 0.147823, 0.342333, -0.293221, -0.397456, 0.0882032, -0.195938, -0.160218, -0.625417, 0.0194885, 0.480917, 0.183944, -0.474158, -0.0766847, -0.213891, -0.11572, 0.874952, 0.328488, -0.126328, -0.070595, -0.38195, -0.374114, 0.400539, 1.20705, -0.932219, -0.0527755, 0.0299839, -0.104527, 0.321153, -0.126216, -0.537255, 0.490108, 0.745793, 0.17606, 0.148419, 0.270659, 0.20733, 0.0651631, 0.576945, 0.229052, -0.0587695, 0.212091, 0.050734, -0.205087, -0.102919, 0.101629, -0.196282, 0.109218, 0.34393, 0.016856, -0.0976393, 0.0735439, -0.323349, 0.0333298, -0.149785, -0.532455, -0.0946866, -0.123283, -0.0668626, -0.306417, -0.0162905, 0.092133, -0.274336, 0.291738, -0.353029, 0.338045, -0.459881, -0.270802, -0.109389, -0.137789, 0.0278568, -0.984156, -0.228742, -0.0787505, 0.00254566, -0.0451302, 0.0834266, -0.229545, 0.336316, -0.111284, -0.280389, -0.284053, 0.0369384, -0.0967356, 0.025232, -0.350762, -0.0761421, 0.234885, -0.393858, 0.133531, -0.132224, -0.0229051, 0.257178, 0.16502, -0.0569466, 0.218486, 0.168554, 0.190245, 0.0794415, -0.30618, 0.313849, -0.0702195, 0.0691943, 0.41066, 0.261289, 0.0897839, 0.0378819], "internal": 1}
{"paper_id": "P14-1062", "abstract": "The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline.", "title": "A Convolutional Neural Network for Modelling Sentences", "venue": "P", "graph_vector": [-0.00310231, 0.109685, 0.412654, 0.179363, 0.660938, -0.870772, 0.176717, -0.0339465, -1.41164, 0.228525, 0.134341, -0.380857, 0.284162, -0.225362, -0.117645, 0.0123637, 0.505642, -0.2258, 0.0179911, 0.116031, -0.199298, 0.493872, 0.422752, -0.222326, -0.403198, 0.000456265, 0.0639934, 0.318533, -0.0205231, -0.563785, -0.288677, -0.0866324, 0.0503877, -0.466006, -0.112955, 0.305678, -0.354696, 0.750253, 0.0563516, 0.0382993, -0.0991086, -0.544237, -0.328805, 0.408241, 0.93874, -0.837921, 0.11779, 0.144475, -0.387788, 0.0774819, 0.0525958, -0.218602, 0.895129, 0.418462, 0.0209037, -0.0754222, 0.310337, 0.144847, -0.113, 0.161568, 0.0724368, -0.165569, -0.014966, 0.244318, 0.0931524, -0.138918, 0.0361911, 0.0705304, -0.0170367, 0.0463158, -0.00519257, 0.189714, 0.370109, -0.0285576, -0.119358, -0.168304, -0.559787, -0.477921, -0.0561254, -0.11557, -0.0759229, 0.19897, 0.634096, -0.14065, 0.237845, -0.397424, 0.0271344, 0.011631, -0.0431595, -0.138542, -0.000485079, 0.34518, -0.599609, -0.16101, -0.209214, 0.046047, -0.160831, 0.0783341, -0.145427, -0.217782, -0.025164, -0.165521, 0.140422, 0.0293242, -0.105146, 0.105736, -0.00326973, -0.182583, 0.256112, -0.150918, 0.140204, 0.0397642, -0.208653, -0.00589372, 0.0500307, 0.135387, 0.349218, 0.195873, 0.079327, 0.199776, -0.180146, 0.0527708, -0.106903, -0.0549717, 0.310394, -0.169083, 0.10678, 0.485235], "internal": 1}
{"paper_id": "P14-1042", "abstract": "This paper is concerned with building linguistic resources and statistical parsers for deep grammatical relation (GR) analysis of Chinese texts. A set of linguistic rules is defined to explore implicit phrase structural information and thus build high-quality GR annotations that are represented as general directed dependency graphs. The reliability of this linguistically-motivated GR extraction procedure is highlighted by manual evaluation. Based on the converted corpus, we study transition-based, datadriven models for GR parsing. We present a novel transition system which suits GR graphs better than existing systems. The key idea is to introduce a new type of transition that reorders top k elements in the memory module. Evaluation gauges how successful GR parsing for Chinese can be by applying datadriven models.", "title": "Grammatical Relations in Chinese: GB-Ground Extraction and Data-Driven Parsing", "venue": "P", "graph_vector": [0.208667, 0.125166, 0.246111, 0.429615, 0.520037, -0.748704, 0.0383869, -0.0991681, -1.91898, 0.173319, 0.0929263, -0.62946, 0.576715, 0.135166, 0.208105, -0.157494, 0.212265, -0.706039, 0.181698, 0.344625, -0.161886, 0.756939, 0.23201, -0.220501, -0.115175, -0.0402656, -0.0545734, -0.0747243, -0.0526655, -0.153144, -0.231685, -0.184502, 0.268689, -0.381219, -0.44186, -0.0315872, -0.338006, 0.680769, 0.105048, -0.205914, 0.0156917, 0.0353314, -0.197293, 0.458921, 0.642846, -0.305559, 0.227569, -0.180355, 0.20066, 0.193236, 0.0776422, -0.157797, 0.632429, 0.599309, -0.29506, 0.127675, -0.161777, 0.0792214, -0.267932, 0.0342911, -0.388929, -0.166685, -0.226672, -0.0145882, -0.288406, -0.317517, -0.00850529, -0.0986561, -0.0340231, 0.543218, 0.188261, -0.217681, 0.0453392, 0.0651287, 0.422079, -0.314679, -0.54069, -0.0131518, -0.230892, -0.306154, -0.0402326, 0.12807, -0.0529773, 0.0946132, 0.116272, -0.324553, 0.176965, 0.0578962, 0.216543, -0.00658317, 0.152848, 0.192077, -0.379623, -0.384403, 0.289788, -0.0430707, -0.521203, -0.321073, -0.0597653, 0.0372758, 0.144662, -0.227444, -0.00888324, 0.168627, -0.0973412, -0.0768782, 0.244083, 0.0953209, 0.0883061, -0.274929, 0.0597129, 0.0376347, -0.0242979, 0.0278523, 0.180959, 0.145034, 0.369336, -0.0789093, -0.0630675, 0.162303, 0.0968272, -0.179605, -0.17252, -0.185889, 0.580394, 0.419673, -0.352546, 0.136266], "internal": 1}
{"paper_id": "P14-2062", "abstract": "Crowdsourcing lets us collect multiple annotations for an item from several annotators. Typically, these are annotations for non-sequential classification tasks. While there has been some work on crowdsourcing named entity annotations, researchers have largely assumed that syntactic tasks such as part-of-speech (POS) tagging cannot be crowdsourced. This paper shows that workers can actually annotate sequential data almost as well as experts. Further, we show that the models learned from crowdsourced annotations fare as well as the models learned from expert annotations in downstream tasks.", "title": "Experiments with crowdsourced re-annotation of a POS tagging data set", "venue": "P", "graph_vector": [-0.336977, 0.0743175, 0.112616, 0.366366, 0.429914, -0.645015, -0.229019, 0.0590456, -1.24211, 0.149668, 0.0536047, -0.393947, 0.72159, 0.119486, 0.221781, -0.100716, 0.589854, -0.612781, -0.406442, 0.561552, -0.751926, 0.803237, 0.182225, -0.415239, -0.0898955, -0.18517, -0.0750936, -0.248422, -0.01719, -0.210042, -0.214023, 0.151593, 0.0843786, -0.261517, -0.322721, 0.15239, 0.493136, 0.291026, 0.0289489, -0.0589416, -0.176382, -0.374551, -0.453721, 0.602673, 1.07948, -0.796998, -0.0606171, 0.261515, -0.0851079, -0.215869, 0.372608, -0.202127, 1.08665, 0.636076, -0.0115052, -0.167558, 0.0309614, 0.296495, -0.268903, 0.110126, -0.410255, 0.0634414, 0.252905, -0.326977, 0.246989, -0.0193838, -0.212209, -0.0256785, 0.437317, 0.527811, 0.329871, -0.335335, -0.0891599, 0.0526244, -0.0273739, 0.159544, -0.186867, -0.273193, 0.0938392, -0.19716, -0.0532707, -0.204193, 0.138073, 0.0550064, 0.0747209, -0.264473, 0.223791, 0.175253, -0.19374, 0.0772202, -0.0803291, -0.113558, -0.564922, -0.600351, 0.0388139, 0.0650579, -0.256175, 0.348482, 0.233261, 0.113562, -0.46087, -0.503443, -0.0412817, -0.149126, 0.181012, 0.436406, 0.00914856, -0.118265, -0.306743, -0.20518, -0.213813, 0.377036, -0.12933, -0.389771, -0.0638695, -0.20026, 0.432532, -0.477152, -0.156892, 0.063354, -0.223375, 0.168909, -0.241308, -0.0337923, 0.378261, 0.388401, -0.00551564, -0.161547], "internal": 1}
{"paper_id": "P14-1011", "abstract": "We propose Bilingually-constrained Recursive Auto-encoders (BRAE) to learn semantic phrase embeddings (compact vector representations for phrases), which can distinguish the phrases with different semantic meanings. The BRAE is trained in a way that minimizes the semantic distance of translation equivalents and maximizes the semantic distance of nontranslation pairs simultaneously. After training, the model learns how to embed each phrase semantically in two languages and also learns how to transform semantic embedding space in one language to the other. We evaluate our proposed method on two end-to-end SMT tasks (phrase table pruning and decoding with phrasal semantic similarities) which need to measure semantic similarity between a source phrase and its translation candidates. Extensive experiments show that the BRAE is remarkably effective in these two tasks.", "title": "Bilingually-constrained Phrase Embeddings for Machine Translation", "venue": "P", "graph_vector": [0.216761, 0.165182, 0.0430801, 0.0160296, 0.493066, -0.760936, 0.234335, -0.167602, -1.52675, 0.039017, -0.0233635, -0.523047, 0.555569, 0.0197977, -0.135791, 0.192179, 0.345171, -0.323188, 0.0294071, 0.184571, 0.0195341, 0.600186, 0.347044, -0.678984, -0.33681, 0.144948, -0.0450849, -0.0626823, -0.101223, 0.0322828, -0.205327, 0.0016592, 0.310829, -0.623897, -0.403145, -0.143995, -0.248723, 0.468924, 0.248667, -0.386376, -0.0192693, -0.326086, -0.530613, 0.430002, 1.28633, -0.977537, 0.110441, -0.0893944, -0.321278, -0.247397, 0.276318, -0.365982, 0.748, 0.664992, 0.0361404, -0.0477066, 0.516274, 0.0696168, 0.162827, 0.0786709, 0.0108434, -0.261725, -0.114359, -0.114133, 0.263236, -0.0566972, 0.400737, 0.0180671, -0.0486333, 0.0303792, -0.0430351, -0.0286485, 0.165206, -0.148306, 0.293127, -0.305642, -0.505423, -0.305572, -0.108293, -0.0612497, 0.0143412, 0.172313, 0.39263, -0.131596, 0.109665, -0.29452, 0.353709, -0.11895, -0.0809106, -0.0711005, 0.0561479, 0.271571, -0.291648, -0.120743, -0.207549, -0.00622185, 0.168447, 0.118645, 0.177967, -0.365077, -0.203665, -0.341423, 0.170725, 0.024337, -0.128471, 0.190603, -0.0692634, -0.342102, -0.0357081, -0.34381, 0.119341, -0.0500657, 0.068963, 0.0661599, -0.148888, 0.0135487, 0.428967, 0.218222, 0.227657, 0.332131, 0.140099, -0.072628, 0.0005376, 0.0413832, 0.0114879, 0.0626776, 0.050287, 0.0455536], "internal": 1}
{"paper_id": "P14-5002", "abstract": "We present the ICARUS Coreference Explorer, an interactive tool to browse and search coreference-annotated data. It can display coreference annotations as a tree, as an entity grid, or in a standard textbased display mode, and lets the user switch freely between the different modes. The tool can compare two different annotations on the same document, allowing system developers to evaluate errors in automatic system predictions. It features a flexible search engine, which enables the user to graphically construct search queries over sets of documents annotated with coreference.", "title": "Visualization, Search, and Error Analysis for Coreference Annotations", "venue": "P", "graph_vector": [0.12885, 0.0563714, 0.00265482, 0.693232, 0.181804, -0.66446, 0.115308, -0.170392, -1.69643, 0.565534, -0.0518115, -0.0779117, 0.660849, 0.197425, 0.170381, 0.0511103, 0.312435, -0.700824, 0.258635, 0.139415, -0.692542, 0.453382, -0.155882, -0.0471894, -0.272781, 0.305871, 0.226837, 0.189383, -0.103049, -0.100276, 0.0760767, 0.0322169, 0.0205533, -0.346674, 0.0866479, 0.430933, -0.0185478, 0.708303, 0.0796286, -0.0776785, -0.00843633, -0.246406, -0.144168, 0.234754, 0.810607, -0.873281, 0.0994031, 0.181028, -0.0700579, 0.10134, 0.0364308, 0.132146, 0.687151, 0.822618, 0.00296362, 0.193339, -0.305145, 0.377316, -0.00194259, 0.147263, -0.223731, -0.0400168, -0.0442519, 0.020551, -0.0818243, -0.34387, 0.404882, -0.108323, 0.14708, 0.126234, 0.139438, 0.242738, 0.163285, -0.347039, 0.0985437, -0.305736, -0.494253, -0.338416, -0.283233, -0.272696, 0.276461, 0.346528, 0.0480876, -0.290854, 0.144375, -0.318549, -0.0482439, -0.255726, -0.125225, 0.00970353, 0.323679, -0.0601843, -0.398638, -0.077644, 0.0802563, -0.308386, 0.138261, 0.0315168, 0.051391, -0.0696659, 0.137117, -0.354828, -0.0229082, 0.194001, -0.372195, -0.0433591, -0.210117, -0.0932731, -0.264056, 0.00900674, -0.226787, 0.0661813, 0.256924, -0.275852, 0.181299, 0.0640449, 0.487164, 0.314403, -0.129999, 0.0905671, -0.0841096, 0.0945461, -0.0205799, -0.0255258, 0.490712, -0.185563, 0.121365, 0.036474], "internal": 1}
{"paper_id": "P14-2099", "abstract": "To support empirical study of online privacy policies, as well as tools for users with privacy concerns, we consider the problem of aligning sections of a thousand policy documents, based on the issues they address. We apply an unsupervised HMM; in two new (and reusable) evaluations, we find the approach more effective than clustering and topic models.", "title": "Unsupervised Alignment of Privacy Policies using Hidden Markov Models", "venue": "P", "graph_vector": [-0.778034, 0.188941, 0.112754, 0.740149, 0.671631, -0.88137, -0.140017, 0.131871, -1.94307, -0.0502641, -0.551375, 0.0408213, 0.425355, 0.709556, -0.0870688, -0.165705, 0.15412, -0.34658, 0.547679, 0.653098, 0.145705, 0.502461, 0.169253, -0.0551994, -0.576888, 0.451228, 0.268018, 0.370368, 0.109843, -0.2591, 0.241702, 0.253148, 0.245708, -0.0865602, -0.641306, 0.0504405, -0.067931, 0.718917, 0.0289177, 0.143808, -0.139034, -0.42527, -0.251722, 0.382143, 1.08361, -1.23124, -0.304189, -0.264064, 0.157608, -0.0774057, 0.61452, 0.113488, 0.548192, 0.592013, -0.325873, -0.0523434, 0.191484, -0.141355, 0.442915, 0.142526, -0.111502, -0.103821, 0.383266, 0.0818987, -0.570908, 0.447414, 0.359171, -0.394822, 0.331684, -0.200123, 0.13838, 0.0790954, 0.249035, -0.305291, 0.567963, -0.0999258, -0.870706, -0.544415, 0.171872, -0.0982846, 0.281631, -0.343958, 0.561802, -0.120733, 0.151961, -0.381859, 0.370402, -0.165571, 0.418536, 0.125813, -0.366563, -0.11698, -0.570385, -0.179574, 0.583483, -0.252402, -0.33622, -0.359582, -0.0304869, -0.142143, -0.137879, -0.451767, -0.232136, 0.109796, 0.166546, 0.249387, 0.222517, -0.364494, 0.18578, -0.242184, -0.232517, 0.102479, -0.249499, -0.526399, 0.0168109, -0.439003, 0.150095, 0.0413145, -0.0593331, -0.0862266, 0.276318, 0.457605, -0.314174, -0.0436598, 0.0426021, -0.0937646, -0.130521, 0.0668059], "internal": 1}
{"paper_id": "P14-2056", "abstract": "We introduce the problem of predicting who has power over whom in pairs of people based on a single written dialog. We propose a new set of structural features. We build a supervised learning system to predict the direction of power; our new features significantly improve the results over using previously proposed features.", "title": "Predicting Power Relations between Participants in Written Dialog from a Single Thread", "venue": "P", "graph_vector": [0.0095982, 0.271931, 0.176472, -0.303173, 0.0214908, -1.05929, -0.500269, -0.366786, -1.83217, 0.202839, -0.180931, -0.362269, 0.590287, -0.183349, 0.246743, 0.0169052, 0.489627, -0.720545, 0.201408, -0.0353777, -0.48551, 0.604337, 0.401385, -0.159516, -0.073162, 0.00697013, -0.135932, 0.284976, 0.110245, -0.118939, 0.153769, -0.13022, -0.26752, -0.590966, -0.412757, 0.274519, -0.295756, 0.919946, 0.117542, -0.215143, -0.220624, -0.501396, -0.284557, 0.26947, 0.987887, -0.573079, 0.0766019, 0.490574, -0.0815734, -0.12407, 0.235165, -0.169952, 1.28554, 0.543268, -0.39026, 0.0609669, -0.0181094, -0.274922, -0.20518, 0.158325, -0.0851303, -0.16082, -0.151029, 0.0318634, -0.659804, -0.25444, 0.0730283, -0.211226, -0.296814, -0.532389, 0.205728, -0.0693022, -0.108358, -0.820001, 0.141995, 0.058584, -0.094171, -0.162413, -0.388751, 0.290213, -0.336859, -0.207366, -0.0627539, -0.0443392, -0.0975318, -0.0158823, -0.0450602, -0.451547, -0.226513, 0.39787, -0.307256, -0.00441857, -0.95457, -0.415488, -0.00191811, 0.0495255, 0.578214, -0.193034, 0.127243, -0.118066, -0.0631796, -0.639538, -0.161458, -0.0668202, -0.307016, 0.0921928, 0.210095, -0.137356, 0.0864394, -0.405841, -0.15493, -0.20129, 0.148117, -0.10569, 0.364203, -0.346478, 0.309856, 0.136456, -0.0334297, 0.397466, 0.437217, 0.00367078, 0.290404, -0.175043, 0.259323, 0.487188, 0.237777, 0.443851], "internal": 1}
{"paper_id": "P14-1008", "abstract": "Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics. In this paper, we equip the DCS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS. An inference engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show promising results.", "title": "Logical Inference on Dependency-based Compositional Semantics", "venue": "P", "graph_vector": [-0.27233, 0.361648, 0.0365672, 0.339432, 0.290145, -0.736792, 0.41743, -0.316546, -1.85147, 0.261813, -0.299254, -0.517256, 0.405572, -0.0136552, 0.103088, 0.146658, 0.172911, -0.734918, -0.161314, 0.568377, -0.503729, 0.623193, -0.181188, 0.240789, -0.35175, 0.0425811, 0.062649, 0.0636448, -0.0808196, -0.0435103, -0.0502621, -0.00675061, 0.342916, -0.523666, 0.0985953, -0.0138713, 0.0538016, 0.406029, 0.419706, -0.130416, -0.338395, -0.084587, -0.417949, 0.0337822, 0.924263, -0.480124, 0.0317102, 0.510491, -0.117895, 0.143446, 0.0953344, -0.0416456, 0.949595, 0.27779, 0.0148058, 0.200668, 0.0748221, 0.122046, -0.273162, -0.0636157, -0.236463, -0.0265902, 0.0264918, 0.0245637, -0.164096, 0.0252356, 0.455759, 0.0782567, -0.036731, 0.183258, 0.334487, 0.141553, 0.0449411, -0.102354, 0.194194, -0.0194118, -0.207356, -0.229409, 0.0178017, -0.0620561, 0.247152, -0.105834, 0.23318, -0.220688, 0.401948, -0.391252, -0.202404, 0.139383, -0.0933715, 0.0462134, -0.202774, 0.0731454, -0.531936, -0.25238, 0.0796786, 0.242707, -0.0153019, 0.0174127, -0.268257, -0.313856, 0.0537882, -0.015881, -0.11516, 0.0373454, -0.01778, 0.311402, 0.777359, -0.107002, 0.329071, 0.12678, -0.0718481, -0.27059, 0.0919792, 0.215688, -0.049315, -0.0942454, 0.529895, 0.289924, 0.0974217, 0.147135, -0.328517, -0.417169, -0.0333423, -0.180537, 0.354112, 0.202773, -0.0878038, -0.0954844], "internal": 1}
{"paper_id": "P14-2121", "abstract": "This paper presents the first computationally-derived scalar measurement of metaphoricity. Each input sentence is given a value between 0 and 1 which represents how metaphoric that sentence is. This measure achieves a correlation of 0.450 (Pearson’s R, p <0.01) with an experimental measure of metaphoricity involving human participants. While far from perfect, this scalar measure of metaphoricity allows different thresholds for metaphoricity so that metaphor identification can be fitted for specific tasks and datasets. When reduced to a binary classification evaluation using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches.", "title": "Measuring metaphoricity", "venue": "P", "graph_vector": [0.242023, 0.232841, -0.144469, 0.448283, 0.727413, -0.96626, -0.0845004, -0.146685, -1.72125, 0.214721, -0.382356, -0.399475, 0.758795, 0.200847, 0.127275, 0.0697491, 0.555161, -0.514992, -0.107412, 0.123878, -0.347006, 0.571952, 0.0270645, 0.0985709, -0.824305, 0.0870914, 0.0482148, 0.235115, -0.119125, -0.058694, -0.0498188, -0.280062, 0.208143, -0.323821, -0.164676, 0.101493, -0.176166, 0.80657, -0.00610687, -0.364454, -0.113123, -0.189927, 0.198735, 0.166064, 1.16156, -0.787924, 0.0359271, 0.0380012, -0.231202, 0.250753, 0.174851, -0.219318, 0.998964, 0.375333, -0.158966, -0.0690289, 0.470194, -0.0286577, -0.504185, 0.0883751, 0.453329, -0.456583, 0.313885, -0.117777, -0.450049, -0.101077, 0.283191, -0.00331813, -0.516675, 0.0982956, 0.00964946, 0.139222, 0.0746246, 0.200581, 0.0997599, 0.0751126, -0.74627, -0.21694, -0.294941, -0.153104, -0.181935, -0.228933, -0.0827901, -0.19643, -0.332052, -0.390249, 0.445167, -0.341747, 0.607701, 0.18977, -0.168804, -0.525904, -0.781048, -0.0806068, -0.0982914, -0.0531436, -0.35724, 0.37578, -0.172748, 0.252435, -0.142016, -0.533696, -0.219828, -0.142939, 0.148462, 0.263091, -0.0644413, 0.068487, 0.0172726, -0.201757, -0.0212063, -0.196821, -0.382885, -0.107241, -0.236622, 0.23745, 0.312348, 0.0644724, 0.258952, 0.343583, -0.479735, 0.174141, -0.210881, 0.171957, 0.428622, 0.157022, 0.0880418, 0.550963], "internal": 1}
{"paper_id": "P14-2107", "abstract": "In this paper we extend the cube-pruned dependency parsing framework of Zhang et al. (2012; 2013) by forcing inference to maintain both label and structural ambiguity. The resulting parser achieves state-ofthe-art accuracies, in particular on datasets with a large set of dependency labels.", "title": "Enforcing Structural Diversity in Cube-pruned Dependency Parsing", "venue": "P", "graph_vector": [0.0018545, 0.173957, -0.177689, 0.148643, 0.838302, -0.922583, 0.0730906, -0.0802211, -1.61857, -0.0862083, -0.233091, -0.555995, 0.738438, 0.124532, -0.204113, -0.419661, 0.602446, -0.178216, 0.0364507, 0.277306, -0.510864, 0.618815, 0.491999, -0.111912, -0.260397, -0.187768, -0.00214189, 0.193196, -0.224514, -0.283182, 0.219194, 0.00280283, 0.105101, -0.51109, -0.0719918, 0.11092, -0.372901, 0.0739522, 0.120152, -0.0500238, 0.264397, -0.0881713, -0.12462, 0.30412, 0.944336, -0.817438, 0.0311152, 0.371052, -0.0408533, 0.0531776, 0.18122, -0.265652, 0.551286, 0.541261, -0.0300581, 0.0218532, 0.182103, 0.42583, 0.084487, -0.109267, -0.256486, 0.241518, -0.370953, -0.0191843, -0.167788, -0.323104, 0.351249, 0.248217, -0.142478, 0.237501, 0.288507, -0.171581, -0.170242, -0.104822, 0.188776, 0.0606263, -0.53446, -0.507148, -0.0144227, -0.183578, -0.052733, -0.100138, 0.220715, 0.012637, -0.0236392, -0.469052, 0.281339, -0.301769, 0.275438, -0.103297, 0.0730306, 0.060814, -0.413512, 0.14142, 0.141429, -0.242933, 0.0572578, -0.16387, -0.115819, -0.293835, -0.0181514, -0.425824, 0.304928, 0.220208, -0.138735, -0.124775, -0.0227903, -0.224156, -0.0725952, -0.05967, 0.0557124, -0.315585, -0.0567072, 0.315939, 0.157731, 0.120576, 0.379268, 0.088787, 0.221967, 0.317298, -0.0419561, -0.0579847, 0.207712, -0.264652, 0.680945, 0.0820334, -0.0561367, 0.0891439], "internal": 1}
{"paper_id": "P14-5008", "abstract": "This paper presents the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for textual inference in multiple languages. The platform includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting and testing innovative approaches. The EOP is distributed as an open source software.", "title": "The Excitement Open Platform for Textual Inferences", "venue": "P", "graph_vector": [-0.264577, 0.0872377, -0.0370559, 0.0868135, 0.0790499, -0.324692, 0.191266, -0.287452, -1.82765, 0.450758, -0.0886416, -0.408969, 0.666616, 0.00915289, 0.141922, 0.0660217, 0.286734, -0.868458, 0.137986, 0.444668, -0.678433, 0.724698, 0.352201, -0.00976711, -0.55052, -0.0166557, 0.018185, 0.0498615, -0.16382, -0.173942, 0.246125, -0.348618, -0.0725725, -0.47616, 0.0317108, 0.0395906, -0.0724217, 0.276079, 0.159188, -0.408355, -0.189932, -0.233205, -0.0985085, 0.172787, 0.871159, -0.623061, 0.267537, 0.602397, -0.122013, -0.0258798, 0.0119002, -0.086232, 0.853106, 0.142111, -0.0156893, -0.19057, 0.0539873, 0.0894827, -0.00930339, 0.181567, 0.077467, -0.153458, -0.212268, 0.222161, 0.135971, -0.14276, 0.0762071, -0.137688, 0.00653026, -0.066, -0.105351, -0.347775, 0.0792467, -0.513617, 0.187416, -0.0465245, -0.503404, -0.159381, 0.202409, 0.258985, -0.168077, -0.371184, 0.191113, -0.000715565, 0.214005, -0.462682, -0.0711799, 0.137513, -0.0784677, 0.0224419, 0.120475, 0.114916, -0.405591, -0.0368667, 0.288769, 0.121219, -0.0900336, -0.072132, 0.315119, 0.0373613, -0.0754806, -0.0917941, -0.00661519, 0.181144, 0.0672435, 0.179193, -0.246875, -0.0111657, 0.468097, 0.352172, 0.0641479, 0.263014, 0.0490834, 0.178433, 0.238685, -0.452139, 0.433188, 0.267767, -0.19762, 0.0961581, 0.0134016, 0.0406371, -0.0829564, 0.186793, 0.74328, 0.111062, -0.116124, -0.0281688], "internal": 1}
{"paper_id": "P14-5003", "abstract": "We present two recently released opensource taggers: NameTag is a free software for named entity recognition (NER) which achieves state-of-the-art performance on Czech; MorphoDiTa (Morphological Dictionary and Tagger) performs morphological analysis (with lemmatization), morphological generation, tagging and tokenization with state-of-the-art results for Czech and a throughput around 10-200K words per second. The taggers can be trained for any language for which annotated data exist, but they are specifically designed to be efficient for inflective languages, Both tools are free software under LGPL license and are distributed along with trained linguistic models which are free for non-commercial use under the CC BY-NC-SA license. The releases include standalone tools, C++ libraries with Java, Python and Perl bindings and web services.", "title": "Open-Source Tools for Morphology, Lemmatization, POS Tagging and Named Entity Recognition", "venue": "P", "graph_vector": [0.144745, 0.266521, -0.0343751, 0.464863, 0.598231, -0.463543, -0.0444158, -0.0573998, -1.32563, -0.188646, 0.0844616, 0.0909773, 0.794155, 0.0706387, -0.011183, -0.0569966, 0.561918, -0.37909, 0.190975, 0.520015, -0.597347, 0.491691, 0.214489, 0.0710748, -0.295687, 0.170679, 0.2217, -0.117202, -0.088592, -0.365216, -0.134658, -0.0777984, 0.286626, -0.329206, -0.0518932, 0.174112, -0.41382, 0.189034, -0.147238, 0.0945221, -0.000279475, -0.491336, -0.21562, 0.395152, 0.530136, -0.980543, 0.0939208, 0.408166, -0.048327, -0.229144, 0.25581, -0.344803, 0.804204, 0.389684, -0.387074, 0.12254, 0.0163548, 0.0230726, -0.247945, -0.0458784, -0.448892, -0.249195, -0.0438235, -0.339766, -0.339489, 0.107218, 0.811791, -0.0631559, -0.194558, 0.055266, -0.0493922, 0.313312, -0.154467, -0.0456042, 0.263452, -0.196929, -0.377842, -0.357945, 0.0413663, 0.0557232, -0.281283, 0.0361292, 0.336786, 0.111281, -0.0451889, 0.0700178, -0.291785, -0.236982, -0.107653, 0.109095, 0.485284, -0.383278, -0.221092, -0.268645, 0.0070134, -0.338667, -0.572885, -0.053032, 0.199481, 0.0915795, 0.11778, -0.225912, -0.287153, -0.351127, 0.337222, 0.0353837, 0.105274, -0.0971283, 0.235923, -0.261154, 0.00707219, -0.0631119, -0.120588, 0.169366, 0.193033, -0.21839, 0.580046, 0.114049, -0.0643798, 0.159195, -0.252951, 0.326057, -0.0339505, 0.0796681, 0.342074, 0.320364, -0.0922761, -0.106801], "internal": 1}
{"paper_id": "P14-2026", "abstract": "In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT. We present a set of dependency-based preordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data. We also investigate the accuracy of the rule set by conducting human evaluations.", "title": "Dependency-based Pre-ordering for Chinese-English Machine Translation", "venue": "P", "graph_vector": [0.275265, 0.318015, -0.0959311, -0.238121, 0.851296, -0.656478, 0.0915542, -0.0750346, -1.55973, 0.464176, 0.195537, -0.422489, 0.754111, 0.187738, -0.193076, -0.172994, 0.467891, -0.680237, 0.121121, 0.104629, -0.226268, 0.36706, 0.291942, -0.425117, -0.352947, -0.238795, 0.00659204, -0.352385, -0.225149, -0.256783, 0.103292, -0.0632852, -0.376842, -0.339641, -0.405842, 0.483637, -0.43422, 0.637899, 0.054361, -0.352852, 0.171603, -0.107012, -0.50955, 0.584391, 0.845968, -0.574168, -0.00268108, -0.0353613, -0.0328936, 0.0242961, 0.480005, -0.151317, 0.561278, 0.590762, -0.18434, 0.118944, 0.407502, -0.177531, 0.0419087, -0.121621, -0.139635, -0.1927, -0.218105, 0.372933, -0.406905, 0.0168388, 0.554059, -0.0584823, -0.160046, 0.137626, 0.084319, -0.016125, -0.15483, -0.197232, 0.664436, -0.184886, -0.0819822, -0.293267, -0.417153, -0.305142, -0.263954, -0.175911, -0.202792, 0.0959901, -0.238713, -0.501129, 0.123357, -0.0400818, 0.125914, -0.137621, -0.0917033, 0.295023, -0.271397, -0.116937, -0.0531004, 0.123867, 0.208811, 0.333525, -0.384356, 0.143789, 0.03908, -0.0932304, 0.140095, 0.0913841, -0.226637, -0.185432, -0.00408473, 0.0886674, 0.182021, -0.451543, 0.070797, 0.0808514, -0.0728917, -0.0295551, 0.152309, -0.0978081, 0.512531, -0.00532386, 0.00448319, 0.0929965, -0.127465, -0.017043, -0.0995532, 0.113167, 0.649967, 0.370887, -0.383065, 0.303948], "internal": 1}
{"paper_id": "P14-1036", "abstract": "Wikification for tweets aims to automatically identify each concept mention in a tweet and link it to a concept referent in a knowledge base (e.g., Wikipedia). Due to the shortness of a tweet, a collective inference model incorporating global evidence from multiple mentions and concepts is more appropriate than a noncollecitve approach which links each mention at a time. In addition, it is challenging to generate sufficient high quality labeled data for supervised models with low cost. To tackle these challenges, we propose a novel semi-supervised graph regularization model to incorporate both local and global evidence from multiple tweets through three fine-grained relations. In order to identify semanticallyrelated mentions for collective inference, we detect meta path-based semantic relations through social networks. Compared to the state-of-the-art supervised model trained from 100% labeled data, our proposed approach achieves comparable performance with 31% labeled data and obtains 5% absolute F1 gain with 50% labeled data.", "title": "Collective Tweet Wikification based on Semi-supervised Graph Regularization", "venue": "P", "graph_vector": [0.171806, 0.0989333, -0.0311447, 0.393764, 0.52826, -0.272423, 0.189753, 0.128737, -1.47974, 0.672873, -0.216323, -0.330049, 0.718899, 0.193927, -0.416133, 0.382425, 0.353137, -0.511316, 0.100394, 0.446777, -0.434421, 0.671401, 0.263046, -0.103111, -0.222212, 0.00985102, 0.00212785, -0.00413265, 0.26557, 0.182085, -0.0556146, 0.0256658, -0.158712, -0.327957, -0.596357, 0.0219234, -0.376485, 1.06881, 0.086232, -0.375856, 0.0247529, -0.292769, -0.339824, 0.987964, 0.967377, -0.689541, 0.0587879, 0.421463, -0.131521, 0.0331497, 0.251942, -0.253486, 1.16354, 1.09395, -0.141841, 0.0743696, -0.300112, 0.148926, -0.172362, -0.0854819, -0.0249022, -0.0131329, 0.25227, -0.0365896, -0.172507, -0.629965, 0.163277, 0.0676178, 0.258333, -0.141487, 0.231199, -0.168547, -0.41542, -0.291187, -0.110513, -0.460532, -0.579547, -0.323978, 0.0068707, -0.092241, -0.197243, -0.200126, 0.218405, -0.0827652, 0.251184, -0.258506, 0.019836, -0.197862, -0.220768, -0.0150178, 0.328763, 0.0523876, -0.932022, 0.0135869, 0.00193272, 0.121988, 0.0249541, -0.145721, -0.169312, -0.198603, -0.225556, -0.100018, -0.0954608, -0.0629796, -0.142637, 0.0731956, -0.164795, -0.132002, -0.0990788, -0.227613, -0.365371, -0.387186, -0.221012, -0.0475259, 0.101644, 0.0742813, 0.203064, 0.304181, 0.000278056, 0.308074, 0.0743031, -0.0053045, -0.298541, 0.191151, 0.550555, 0.00375016, -0.0511918, 0.132869], "internal": 1}
{"paper_id": "P14-1012", "abstract": "In this paper, instead of designing new features based on intuition, linguistic knowledge and domain, we learn some new and effective features using the deep autoencoder (DAE) paradigm for phrase-based translation model. Using the unsupervised pre-trained deep belief net (DBN) to initialize DAE’s parameters and using the input original phrase features as a teacher for semi-supervised fine-tuning, we learn new semi-supervised DAE features, which are more effective and stable than the unsupervised DBN features. Moreover, to learn high dimensional feature representation, we introduce a natural horizontal composition of more DAEs for large hidden layers feature learning. On two ChineseEnglish tasks, our semi-supervised DAE features obtain statistically significant improvements of 1.34/2.45 (IWSLT) and 0.82/1.52 (NIST) BLEU points over the unsupervised DBN features and the baseline features, respectively.", "title": "Learning New Semi-Supervised Deep Auto-encoder Features for Statistical Machine Translation", "venue": "P", "graph_vector": [0.0817369, 0.00892623, 0.170698, 0.218631, 0.250866, -0.692857, 0.0586043, -0.122099, -1.58378, -0.325047, 0.0417462, -0.327172, 0.300459, 0.15382, -0.0574831, 0.0495938, 0.503715, -0.470115, 0.179909, 0.559162, -0.0456016, 0.994995, 0.317918, -0.52796, -0.145621, 0.208947, 0.239036, -0.0406673, -0.205929, -0.189346, -0.20223, -0.184298, 0.171164, -0.629598, -0.249119, 0.0934647, -0.415128, 0.538671, -0.143064, -0.604951, 0.133858, -0.36172, -0.144737, 0.458184, 1.39139, -1.09451, 0.298076, 0.223486, -0.126976, -0.213692, 0.119472, -0.423534, 0.919098, 0.443807, -0.191246, 0.543012, 0.121105, 0.244836, -0.0735308, 0.273154, 0.00490574, -0.336593, -0.140716, -0.026026, 0.132979, -0.251806, 0.429523, 0.121104, -0.0695303, 0.231628, -0.214981, 0.0493807, 0.312366, 0.127353, 0.187753, 0.0494194, -0.434963, -0.488139, -0.200429, -0.114144, -0.147712, 0.0847456, 0.582649, -0.249961, 0.375146, -0.679111, 0.0759139, 0.0684466, -0.450418, -0.544754, -0.00111096, 0.0218577, -0.641346, -0.0211749, -0.150283, 0.304007, 0.38474, 0.093434, -0.242713, -0.184916, -0.0735279, -0.523237, 0.153128, 0.0745991, 0.0669889, 0.0242339, -0.0726588, 0.144618, 0.0250158, 0.0279114, 0.0911072, -0.236501, -0.0619469, 0.261194, -0.0808286, -0.0667876, 0.33776, 0.0972123, 0.0334983, 0.126697, 0.107201, 0.0907677, -0.19669, -0.0847303, 0.15047, -0.0437255, 0.413578, 0.0253333], "internal": 1}
{"paper_id": "P14-1045", "abstract": "Using distributional analysis methods to compute semantic proximity links between words has become commonplace in NLP. The resulting relations are often noisy or difficult to interpret in general. This paper focuses on the issues of evaluating a distributional resource and filtering the relations it contains, but instead of considering it in abstracto, we focus on pairs of words in context. In a discourse, we are interested in knowing if the semantic link between two items is a byproduct of textual coherence or is irrelevant. We first set up a human annotation of semantic links with or without contextual information to show the importance of the textual context in evaluating the relevance of semantic similarity, and to assess the prevalence of actual semantic relations between word tokens. We then built an experiment to automatically predict this relevance, evaluated on the reliable reference data set which was the outcome of the first annotation. We show that in-document information greatly improve the prediction made by the similarity level alone.", "title": "Predicting the relevance of distributional semantic similarity with contextual information", "venue": "P", "graph_vector": [0.16272, 0.504949, 0.00125122, 0.0978359, 0.731094, -0.470642, 0.155996, -0.0642964, -1.61348, 0.21452, -0.116588, -0.252829, 0.688285, 0.0457959, -0.252422, -0.199693, 0.483649, -0.799553, 0.22604, 0.350229, -0.368055, 0.486448, 0.00905994, 0.51792, -0.677544, 0.116053, 0.0256618, 0.37596, -0.185996, 0.0116461, 0.19589, -0.293905, 0.342173, -0.108766, 0.0880695, -0.124301, -0.410746, 1.04082, -0.158283, -0.498964, -0.110347, -0.257367, -0.303554, 0.0691222, 1.15295, -0.384498, 0.264045, 0.0249266, -0.117108, 0.0804991, 0.195227, -0.057705, 0.799281, 0.597011, -0.304765, -0.365796, 0.308912, -0.0326113, 0.0457204, -0.00301962, -0.212443, -0.140152, 0.065038, -0.0704255, -0.182506, -0.15414, 0.175178, 0.0746147, -0.121114, -0.029474, -0.0595482, -0.0757288, 0.0226983, -0.378222, -0.0499763, -0.0712812, -0.480365, 0.0428208, -0.0914169, -0.252664, -0.465834, 0.0761777, -0.00528505, -0.0307244, 0.0836211, 0.0770787, -0.0554343, 0.108898, 0.505655, -0.338444, -0.270309, 0.0494209, -0.522625, -0.329283, -0.38245, 0.18457, 0.223015, -0.190727, 0.133315, 0.0971577, -0.373917, -0.0849052, 0.317695, -0.251984, 0.277907, 0.251092, -0.012533, -0.331869, -0.367961, -0.0246929, 0.114698, 0.12586, 0.131767, 0.0180819, -0.0178077, 0.269859, 0.063298, 0.288446, -0.137296, 0.594365, -0.276855, 0.0266033, 0.388959, 0.132838, 0.462932, 0.275712, -0.227718, -0.0121466], "internal": 1}
{"paper_id": "P14-1125", "abstract": "Recent work on Chinese analysis has led to large-scale annotations of the internal structures of words, enabling characterlevel analysis of Chinese syntactic structures. In this paper, we investigate the problem of character-level Chinese dependency parsing, building dependency trees over characters. Character-level information can benefit downstream applications by offering flexible granularities for word segmentation while improving wordlevel dependency parsing accuracies. We present novel adaptations of two major shift-reduce dependency parsing algorithms to character-level parsing. Experimental results on the Chinese Treebank demonstrate improved performances over word-based parsing methods.", "title": "Character-Level Chinese Dependency Parsing", "venue": "P", "graph_vector": [0.158457, 0.215564, -0.00645663, 0.137358, 0.8917, -0.849767, 0.0420042, -0.126602, -1.66399, -0.00185898, 0.0347978, -0.408402, 0.504844, 0.202541, -0.200063, -0.293098, 0.499621, -0.988252, -0.194479, 0.288378, -0.0974109, 0.678026, 0.404068, -0.198996, -0.115672, 0.045514, 0.252066, 0.126302, -0.0738802, -0.176711, -0.214165, -0.132466, 0.142384, -0.658383, -0.174405, 0.249473, -0.568983, 0.412851, 0.115944, -0.269414, 0.0597502, -0.412703, -0.134419, 0.310434, 0.655187, -0.69724, -0.146142, 0.0590168, -0.116553, 0.448473, 0.191566, -0.229092, 0.642274, 0.742896, -0.279728, 0.0336792, 0.150783, 0.369377, -0.140287, -0.0498367, -0.408594, 0.121157, -0.161013, 0.0549201, -0.469922, -0.143184, 0.115592, -0.121324, -0.0864558, 0.272092, 0.224224, 0.0433653, 0.0676959, 0.0743339, 0.487592, -0.136025, -0.560192, -0.330721, -0.427425, -0.208916, 0.0330541, 0.0234775, 0.197583, 0.0750364, 0.144791, -0.383286, -0.129856, -0.377548, 0.0669557, 0.0274142, 0.191848, 0.24774, -0.596537, -0.150734, 0.213103, -0.178466, -0.115354, -0.115788, -0.0911223, -0.301565, -0.0814874, -0.212281, 0.0374266, -0.0214449, -0.109244, 0.0376745, 0.0583701, -0.134221, 0.206532, -0.15298, 0.0255772, -0.255392, 0.025202, -0.199377, 0.182976, 0.0250076, 0.200259, 0.202467, -0.0867437, 0.347399, 0.11087, -0.211908, -0.130706, -0.116526, 0.438006, 0.166453, -0.202766, -0.18414], "internal": 1}
{"paper_id": "P14-6004", "abstract": "Contextual disambiguation and grounding of concepts and entities in natural language are essential to progress in many natural language understanding tasks and fundamental to many applications. Wikification aims at automatically identifying concept mentions in text and linking them to referents in a knowledge base (KB) (e.g., Wikipedia). Consider the sentence, &quot;The Times report on Blumenthal (D) has the potential to fundamentally reshape the contest in the Nutmeg State.&quot;. A Wikifier should identify the key entities and concepts and map them to an encyclopedic resource (e.g., “D” refers to Democratic Party, and “the Nutmeg State” refers to Connecticut. Wikification benefits end-users and Natural Language Processing (NLP) systems. Readers can better comprehend Wikified documents as information about related topics is readily accessible. For systems, a Wikified document elucidates concepts and entities by grounding them in an encyclopedic resource or an ontology. Wikification output has improved NLP down-stream tasks, including coreference resolution, user interest discovery , recommendation and search. This task has received increased attention in recent years from the NLP and Data Mining communities, partly fostered by the U.S. NIST Text Analysis Conference Knowledge Base Population (KBP) track, and several versions of it has been studied. These include Wikifying all concept mentions in a single text document; Wikifying a cluster of co-referential named entity mentions that appear across documents (Entity Linking), and Wikifying a whole document to a single concept. Other works relate this task to coreference resolution within and across documents and in the context of multiple text genres. 7", "title": "Wikification and Beyond: The Challenges of Entity and Concept Grounding", "venue": "P", "graph_vector": [], "internal": 1}
{"paper_id": "P14-1146", "abstract": "We present a method that learns word embedding for Twitter sentiment classification in this paper. Most existing algorithms for learning continuous word representations typically only model the syntactic context of words but ignore the sentiment of text. This is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity, such as good and bad, to neighboring word vectors. We address this issue by learning sentimentspecific word embedding (SSWE), which encodes sentiment information in the continuous representation of words. Specifically, we develop three neural networks to effectively incorporate the supervision from sentiment polarity of text (e.g. sentences or tweets) in their loss functions. To obtain large scale training corpora, we learn the sentiment-specific word embedding from massive distant-supervised tweets collected by positive and negative emoticons. Experiments on applying SSWE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show that (1) the SSWE feature performs comparably with hand-crafted features in the top-performed system; (2) the performance is further improved by concatenating SSWE with existing feature set.", "title": "Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification∗", "venue": "P", "graph_vector": [0.0435857, 0.360032, 0.0820545, 0.194406, 0.426814, -0.905139, 0.110883, -0.195521, -1.46227, 0.0554967, 0.132567, -0.373883, 0.44794, -0.0109008, 0.241829, -0.0395151, 0.47688, -0.376122, -0.159361, 0.0733946, -0.0148293, 0.684583, 0.226376, -0.185305, -0.293733, 0.0423841, 0.088422, -0.00750369, -0.0411648, -0.330726, -0.137623, 0.0411327, 0.0998131, -0.367242, -0.330214, 0.138148, -0.222534, 0.741015, 0.0217219, -0.188476, 0.00768382, -0.423079, -0.393807, 0.554114, 0.78167, -0.853418, -0.0636509, -0.147004, -0.204904, 0.0861575, 0.117934, -0.527793, 0.999972, 0.81367, 0.130727, 0.117126, 0.214843, 0.0597568, -0.135889, 0.196207, -0.0503169, 0.191987, -0.101666, 0.0273118, -0.0605697, 0.0403598, 0.178551, -0.232088, 0.117343, 0.00887189, 0.0862293, 0.142821, 0.122321, -0.190809, 0.0465233, -0.231937, -0.502002, -0.273688, 0.0370026, 0.0276872, -0.13806, 0.197223, 0.496185, -0.10708, 0.354522, -0.322659, 0.251544, 0.0377485, -0.264321, -0.0104066, 0.0150781, 0.344005, -0.56261, -0.0745435, 0.19887, -0.0892265, 0.24461, 0.163644, 0.101364, -0.0260597, 0.0186398, -0.274459, -0.107728, -0.105639, -0.178485, -0.0032505, -0.227252, -0.268848, 0.0207461, -0.269569, -0.0140937, -0.146213, -0.0472475, 0.0902863, -0.0667382, -0.0114851, 0.377552, 0.0888176, 0.245406, 0.16196, -0.251565, -0.0062846, -0.0680549, 0.184695, 0.31496, 0.139354, -0.0251529, 0.156826], "internal": 1}
{"paper_id": "P14-2125", "abstract": "In this paper we study the use of sentencelevel dialect identification in optimizing machine translation system selection when translating mixed dialect input. We test our approach on Arabic, a prototypical diglossic language; and we optimize the combination of four different machine translation systems. Our best result improves over the best single MT system baseline by 1.0% BLEU and over a strong system selection baseline by 0.6% BLEU on a blind test set.", "title": "Sentence Level Dialect Identification for Machine Translation System Selection", "venue": "P", "graph_vector": [-0.0573279, 0.0529516, -0.0351211, 0.232231, 0.311302, -0.853465, 0.120107, 0.0498503, -1.70223, 0.0974129, 0.263738, -0.18814, 0.555957, 0.454778, 0.0461056, -0.374956, 0.28756, -0.880372, -0.00272266, 0.20427, -0.427333, 0.746931, 0.528966, 0.157544, -0.387813, 0.0398787, 0.173911, -0.35826, -0.134087, -0.0429019, -0.488398, 0.158985, -0.111084, -0.421096, -0.40022, 0.270555, -0.145623, 0.308636, 0.155979, -0.16239, 0.119221, -0.505494, -0.357597, 0.613848, 1.13279, -0.519775, 0.249437, 0.0561008, 0.154088, 0.0571186, 0.199939, -0.207127, 0.521827, 0.763308, -0.0414959, -0.00975148, 0.32011, 0.0853573, 0.277211, -0.0467511, -0.108971, -0.16192, 0.11956, 0.487015, -0.240619, 0.355259, 0.382565, 0.0280678, 0.0937685, 0.115004, -0.393047, -0.014163, -0.185753, -0.0611134, -0.0119542, 0.1421, -0.433044, -0.560329, 0.190033, -0.157033, -0.0258103, 0.133699, 0.0239521, -0.213858, -0.241413, -0.457774, 0.147508, 0.079002, 0.44964, 0.0333813, 0.193343, -0.109926, -0.779092, 0.0584646, -0.201892, 0.125708, -0.00271242, 0.0509518, -0.10564, -0.00344831, -0.240028, -0.587891, 0.0937968, 0.356297, 0.185757, 0.055181, -0.0799062, -0.137424, 0.110526, -0.221165, 0.145791, -0.0810536, 0.141758, -0.144861, 0.0755611, 0.0100155, -0.0301808, -0.0966033, 0.13359, 0.218007, -0.056263, -0.13089, -0.33856, 0.246418, 0.268547, 0.476081, 0.0633067, -0.227008], "internal": 1}
{"paper_id": "P10-1025", "abstract": "Current Semantic Role Labeling technologies are based on inductive algorithms trained over large scale repositories of annotated examples. Frame-based systems currently make use of the FrameNet database but fail to show suitable generalization capabilities in out-of-domain scenarios. In this paper, a state-of-art system for frame-based SRL is extended through the encapsulation of a distributional model of semantic similarity. The resulting argument classification model promotes a simpler feature space that limits the potential overfitting effects. The large scale empirical study here discussed confirms that state-of-art accuracy can be obtained for out-of-domain evaluations.", "title": "Towards Open-Domain Semantic Role Labeling", "venue": "P", "graph_vector": [0.0212106, 0.223789, -0.25173, 0.098142, 0.176248, -0.684935, 0.0838587, -0.335816, -1.41699, 0.232029, -0.0024025, -0.514691, 0.696327, 0.273331, 0.0617188, -0.500064, 0.360919, -0.675076, -0.0516104, 0.141077, -0.336889, 0.938893, 0.050267, -0.0290155, -0.394342, 0.191189, 0.107436, 0.0711926, -0.271995, -0.0735386, 0.334118, -0.228607, 0.032126, -0.457121, -0.0495717, -0.0518352, -0.191426, 0.645083, 0.00272847, -0.177231, 0.34333, -0.42707, -0.0982913, 0.220012, 0.746935, -0.78732, -0.0345321, 0.564459, 0.297525, -0.0263751, 0.281283, -0.230437, 0.7026, 0.52355, 0.233686, -0.169756, 0.439443, 0.155311, 0.264341, -0.0399422, 0.0103535, -0.0278351, 0.37626, 0.194759, 0.195314, -0.0843194, -0.0305832, 0.37405, 0.210664, 0.290595, 0.191634, -0.118361, 0.0798003, -0.557207, -0.251249, -0.224459, -0.426413, -0.200976, 0.0384852, -0.152459, 0.525042, -0.135527, 0.141368, -0.328519, 0.182897, -0.130321, 0.111122, -0.399156, 0.532473, 0.34687, 0.135571, -0.0857585, -0.282606, -0.191877, -0.207744, 0.194368, -0.0719167, -0.206808, -0.0711583, -0.144638, 0.0656311, -0.397164, 0.0378178, -0.0292597, 0.427479, -0.0629546, 0.0794745, -0.15183, 0.208013, -0.0691825, 0.16524, -0.28449, -0.196941, 0.125692, -0.188364, -0.00417084, 0.628664, 0.0456616, 0.219507, 0.0764889, -0.100345, 0.224702, 0.118447, -0.308851, 0.533507, 0.126534, 0.0268845, -0.0971451], "internal": 1}
{"paper_id": "P10-1001", "abstract": "We present algorithms for higher-order dependency parsing that are “third-order” in the sense that they can evaluate substructures containing three dependencies, and “efficient” in the sense that they require only O(n4) time. Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions. We evaluate our parsers on the Penn Treebank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.", "title": "Efficient Third-order Dependency Parsers", "venue": "P", "graph_vector": [0.0813587, 0.158986, -0.00820541, 0.190584, 0.791584, -0.950347, -0.210116, -0.129846, -1.62802, 0.0354191, -0.0918677, -0.355181, 0.717469, 0.103043, -0.0545874, -0.416976, 0.497594, -0.277548, 0.15237, 0.17996, -0.646103, 0.552712, 0.260974, -0.0812664, -0.142798, 0.0592144, -0.0469725, 0.181242, -0.108324, -0.373208, -0.111531, -0.0909717, -0.0474407, -0.295692, -0.0926234, 0.114169, -0.331857, 0.383639, 0.177724, -0.0929061, 0.130227, -0.223307, 0.0254102, 0.344416, 0.72237, -0.804825, 0.25024, 0.337136, -0.0571687, 0.0850413, 0.139245, -0.36568, 0.656315, 0.474968, -0.00382201, -0.176015, -0.0944939, 0.34223, -0.184166, -0.0401359, -0.310855, 0.1583, -0.175093, -0.141381, -0.35043, -0.178674, 0.178973, 0.0503436, -0.140978, 0.272213, 0.0279539, -0.11443, -0.116544, 0.139748, 0.224037, -0.269504, -0.422126, -0.352599, -0.137743, -0.0988281, -0.0658623, 0.0222478, 0.319259, 0.116421, 0.184913, -0.369792, 0.0179904, -0.181754, 0.024667, -0.234009, 0.01204, -0.116645, -0.473185, -0.0630733, 0.173413, -0.133902, -0.158533, -0.142561, -0.0111283, 0.0153477, 0.0523438, -0.454024, 0.308081, 0.166792, -0.271381, 0.0760679, -0.245869, -0.179609, 0.269948, -0.272908, -0.155781, -0.0270126, -0.0587542, 0.0353285, 0.0279742, 0.0640762, 0.204751, 0.0728879, 0.13306, 0.0960127, 0.100762, -0.273883, -0.0443888, -0.00268919, 0.528612, 0.0281989, 0.0992765, 0.0284483], "internal": 1}
{"paper_id": "P10-2052", "abstract": "Building an accurate Named Entity Recognition (NER) system for languages with complex morphology is a challenging task. In this paper, we present research that explores the feature space using both gold and bootstrapped noisy features to build an improved highly accurate Arabic NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute).", "title": "Arabic Named Entity Recognition: Using Features Extracted from Noisy Data", "venue": "P", "graph_vector": [0.176016, -0.134415, -0.333625, 0.0502418, 0.440929, -0.708428, -0.0700557, 0.0834608, -1.39046, 0.65543, -0.126698, -0.400854, 0.393935, -0.217095, -0.285784, 0.0194933, 0.674159, -1.02191, 0.275048, 0.358959, -0.271946, 0.790347, 0.351937, 0.607868, -0.377017, 0.166038, -0.178332, 0.161305, 0.000626389, -0.270599, -0.247082, 0.137105, 0.184557, -0.496679, -0.0551791, 0.0582381, -0.38675, 0.503054, 0.323029, -0.408603, -0.115153, -0.812008, -0.643248, 0.58318, 0.963653, -0.404226, 0.286539, 0.346135, 0.227493, -0.0228415, -0.0488862, -0.0954973, 0.313014, 1.04863, 0.0563504, 0.384109, 0.302492, 0.0889967, 0.0957288, 0.111012, -0.621156, -0.331243, 0.374787, 0.0410084, -0.0675675, -0.355107, -0.0449095, -0.170092, -0.272316, 0.187953, 0.123802, 0.455375, -0.194697, 0.192638, -0.0716889, 0.214766, -0.442204, -0.242262, -0.295985, -0.220397, 0.0696319, 0.0784922, 0.165295, 0.20321, -0.0100901, -0.043163, -0.175525, -0.0903611, 0.165352, 0.225575, 0.384693, 0.0369331, -0.672315, -0.357968, -0.0815574, 0.0587622, -0.446784, -0.170474, 0.240149, -0.195175, -0.100352, -0.165427, -0.467759, 0.0470225, 0.0210162, 0.00101596, -0.125207, -0.225811, 0.0586447, -0.422917, -0.160188, 0.0646209, -0.414565, 0.00967097, -0.230767, 0.045064, 0.359953, -0.0660822, 0.184959, 0.166456, -0.303473, -0.159729, 0.0813025, 0.01187, 0.658526, 0.0478936, 0.200558, 0.0646622], "internal": 1}
{"paper_id": "P10-1099", "abstract": "Most supervised language processing systems show a significant drop-off in performance when they are tested on text that comes from a domain significantly different from the domain of the training data. Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text. We investigate techniques for building open-domain semantic role labeling systems that approach the ideal of a train-once, use-anywhere system. We leverage recently-developed techniques for learning representations of text using latent-variable language models, and extend these techniques to ones that provide the kinds of features that are useful for semantic role labeling. In experiments, our novel system reduces error by 16% relative to the previous state of the art on out-of-domain text.", "title": "Open-Domain Semantic Role Labeling by Modeling Word Spans", "venue": "P", "graph_vector": [-0.162743, -0.0506315, 0.0301117, 0.61772, 0.0326028, -0.529163, -0.11511, -0.0705321, -1.26592, 0.123128, 0.0356611, -0.357305, 0.670103, 0.0558502, 0.0552551, 0.031448, 0.662377, -0.618752, 0.0611381, 0.408064, -0.460102, 0.752871, 0.324073, -0.212245, -0.436421, 0.212869, 0.193607, -0.249158, -0.196048, -0.282621, 0.396228, -0.0043314, 0.222515, -0.637548, -0.412105, 0.193644, -0.445152, 0.458005, -0.302747, 0.0702707, 0.0753306, -0.723855, -0.170321, 0.313002, 0.69164, -1.19739, -0.0434534, 0.0303934, 0.420847, -0.129031, 0.325688, 0.0435918, 0.600094, 0.610463, -0.252939, -0.261802, 0.121867, 0.501754, 0.023414, -0.0141925, -0.196856, -0.0914671, 0.0201291, 0.279281, 0.300842, 0.135875, 0.339745, -0.100272, 0.0323893, 0.214538, -0.0923087, -0.293543, -0.166252, -0.218614, 0.0398915, -0.409261, -0.539882, -0.225712, 0.0903453, 0.149239, 0.0993956, 0.000439438, 0.350791, 0.0487744, -0.0335526, -0.153993, -0.0223597, -0.53803, -0.0764751, -0.120769, -0.0291549, -0.0750632, -0.236888, -0.200457, 0.185409, -0.153137, -0.481746, -0.189435, -0.219568, -0.324045, -0.0410322, -0.0972141, -0.0033575, 0.0465186, 0.0938119, 0.0380863, -0.0177217, -0.0993441, 0.164807, -0.0586805, -0.0760562, -0.331175, -0.209854, 0.279288, -0.366012, -0.171002, 0.442104, -0.292601, 0.0892587, -0.178817, -0.37057, 0.229223, -0.123014, -0.103828, 0.639317, -0.152747, 0.0040079, -0.0457405], "internal": 1}
{"paper_id": "P13-2027", "abstract": "The current topic modeling approaches for Information Retrieval do not allow to explicitly model query-oriented latent topics. More, the semantic coherence of the topics has never been considered in this field. We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics. We perform a first experimental evaluation using two major TREC test collections. Results show that retrieval performances tend to be better when using topics with higher semantic coherence.", "title": "Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?", "venue": "P", "graph_vector": [0.172316, 0.372972, 0.0486783, 0.275139, 0.395454, -0.672953, -0.0880191, 0.385978, -1.49459, -0.0608817, -0.167686, -0.0372077, 1.03804, 0.0879152, -0.0811354, 0.0750355, 0.631568, -0.520173, 0.121049, -0.349229, -0.243235, 0.455525, 0.168241, 0.133142, -0.372839, -0.29876, 0.0358194, 0.242114, -0.30622, -0.199502, -0.116196, -0.353623, 0.0412009, -0.15196, -0.237894, 0.178987, -0.543652, 0.473693, 0.277268, -0.185031, -0.425992, -0.0276521, -0.613544, 0.447387, 0.665116, -1.23566, 0.0158658, 0.0616131, -0.0259612, -0.095208, 0.386453, -0.0398186, 1.15314, 0.649572, -0.271872, 0.304633, 0.377015, 0.204099, -0.122499, 0.0895084, -0.11882, -0.358875, -0.0644144, -0.0270722, -0.291715, -0.051746, -0.0473905, -0.184586, -0.202678, -0.0240933, 0.279534, -0.0116798, 0.0908512, -0.434836, 0.170913, -0.39764, -0.283183, -0.300337, 0.160273, -0.381724, -0.220193, 0.15459, 0.222879, -0.0538563, 0.0635716, -0.177388, -0.104158, -0.216729, 0.234561, 0.0952193, 0.231602, -0.238602, -0.571023, -0.119766, -0.130765, 0.0233632, -0.249966, 0.00483978, 0.0893366, -0.0182862, 0.0498859, -0.425386, -0.256892, 0.0347091, 0.139392, 0.0272485, -0.0316571, -0.370116, -0.0979483, -0.429486, -0.456861, 0.0777874, -0.0688735, 0.109767, -0.24738, -0.447539, 0.153721, 0.231772, -0.284347, 0.079431, -0.362073, -0.188467, -0.552071, -0.208009, 0.00895679, 0.250171, -0.0107119, -0.238402], "internal": 1}
{"paper_id": "P13-1045", "abstract": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases or splitting categories only partly address the problem at the cost of huge feature spaces and sparseness. Instead, we introduce a Compositional Vector Grammar (CVG), which combines PCFGs with a syntactically untied recursive neural network that learns syntactico-semantic, compositional vector representations. The CVG improves the PCFG of the Stanford Parser by 3.8% to obtain an F1 score of 90.4%. It is fast to train and implemented approximately as an efficient reranker it is about 20% faster than the current Stanford factored parser. The CVG learns a soft notion of head words and improves performance on the types of ambiguities that require semantic information such as PP attachments.", "title": "Parsing with Compositional Vector Grammars", "venue": "P", "graph_vector": [0.0691003, -0.0555316, -0.104486, 0.312534, 0.530723, -0.661808, 0.0114075, 0.0296963, -1.44971, 0.29208, -0.229846, -0.592455, 0.437159, 0.0933242, 0.150516, -0.444672, 0.397121, -0.380495, -0.0460045, 0.152628, -0.389021, 0.558205, 0.230315, -0.0850025, -0.181268, 0.209421, -0.174541, 0.224264, -0.240445, -0.37276, 0.00178534, 0.0446221, 0.0128645, -0.50381, -0.368344, 0.0306599, -0.281311, 0.52412, -0.00487666, -0.237021, -0.153299, -0.563531, -0.297698, 0.281309, 0.794443, -0.596491, -0.162469, -0.0920618, 0.269663, -0.0776627, 0.431449, -0.246039, 0.678507, 0.549583, 0.364194, 0.0854989, 0.554319, 0.114333, 0.0964518, -0.167374, -0.508756, -0.208931, 0.015988, -0.0333094, -0.157507, -0.0387398, 0.148049, -0.0213856, -0.0518794, -0.098379, -0.0966892, -0.229643, 0.34223, -0.189402, 0.00111951, -0.0152358, -0.605315, -0.39963, 0.0139549, -0.400497, 0.0849173, 0.235906, 0.181586, -0.233848, 0.357736, -0.454297, 0.153321, 0.165681, -0.241309, -0.0552932, -0.198968, 0.172253, -0.407664, -0.141759, 0.181338, 0.169534, -0.0933751, 0.303241, 0.00451572, -0.124673, -0.0966089, -0.121011, 0.296553, -0.203702, -0.00176958, 0.0263715, 0.0214283, -0.484504, -0.162732, -0.122501, 0.141239, -0.212344, -0.0682024, 0.134283, -0.253758, -0.0015852, 0.369451, -0.0264398, 0.198931, 0.101946, -0.182159, -0.080751, 0.0801367, -0.290399, 0.32711, 0.328684, 0.0194232, -0.051335], "internal": 1}
{"paper_id": "P13-2078", "abstract": "Some words are more contentful than others: for instance, make is intuitively more general than produce and fifteen is more ‘precise’ than a group. In this paper, we propose to measure the ‘semantic content’ of lexical items, as modelled by distributional representations. We investigate the hypothesis that semantic content can be computed using the KullbackLeibler (KL) divergence, an informationtheoretic measure of the relative entropy of two distributions. In a task focusing on retrieving the correct ordering of hyponym-hypernym pairs, the KL divergence achieves close to 80% precision but does not outperform a simpler (linguistically unmotivated) frequency measure. We suggest that this result illustrates the rather ‘intensional’ aspect of distributions.", "title": "Measuring semantic content in distributional vectors", "venue": "P", "graph_vector": [-0.239749, 0.046115, 0.107794, 0.417891, 0.459753, -0.86785, -0.0433772, -0.306904, -1.51288, -0.0343447, 0.110039, -0.565512, 0.758688, 0.217208, -0.267057, 0.045361, 0.288101, -0.478132, -0.0259128, 0.493994, -0.452995, 0.519949, 0.251842, 0.122009, -0.682974, 0.0136972, -0.243317, 0.0805221, -0.140203, 0.279665, -0.610636, -0.550285, -0.0459492, 0.069215, -0.0404413, -0.104459, -0.0508695, 0.715639, 0.269642, -0.033659, -0.137734, -0.71741, 0.170644, -0.132742, 0.91302, -0.584093, -0.158282, -0.00061, 0.0106023, -0.00302163, 0.424204, -0.143254, 1.16087, 0.574916, 0.0499525, -0.20895, 0.518911, -0.097936, 0.159873, -0.340482, 0.0168292, -0.425367, 0.0283213, 0.123859, 0.0782193, -0.0905295, -0.157774, -0.179381, -0.237012, 0.0661373, -0.0497224, -0.129239, -0.0271635, 0.0845549, -0.054522, -0.445602, -0.465109, -0.291348, -0.112104, -0.0763251, -0.306991, -0.0983705, 0.206311, -0.354378, 0.101959, 0.00229209, 0.0675037, 0.0466301, 0.0308617, -0.171965, -0.195714, -0.0266907, -0.847494, -0.157199, -0.438585, -0.0778608, -0.296276, -0.000211969, 0.0975625, -0.175871, -0.305151, -0.120305, 0.00359541, -0.0157463, -0.0787408, 0.497133, -0.0488226, -0.165056, 0.386024, -0.414393, 0.0762878, 0.0473532, 0.0375776, -0.0767425, -0.0350961, -0.139642, -0.0343051, 0.0386601, 0.0563845, 0.330081, -0.373731, 0.00494342, 0.131089, -0.0654825, 0.02686, 0.0245476, -0.184538, 0.233239], "internal": 1}
{"paper_id": "P13-2122", "abstract": "We describe a translation model adaptation approach for conversational spoken language translation (CSLT), which encourages the use of contextually appropriate translation options from relevant training conversations. Our approach employs a monolingual LDA topic model to derive a similarity measure between the test conversation and the set of training conversations, which is used to bias translation choices towards the current context. A significant novelty of our adaptation technique is its incremental nature; we continuously update the topic distribution on the evolving test conversation as new utterances become available. Thus, our approach is well-suited to the causal constraint of spoken conversations. On an English-to-Iraqi CSLT task, the proposed approach gives significant improvements over a baseline system as measured by BLEU, TER, and NIST. Interestingly, the incremental approach outperforms a non-incremental oracle that has up-front knowledge of the whole conversation.", "title": "Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation", "venue": "P", "graph_vector": [-0.117841, 0.442188, 0.167504, 0.163107, 0.167074, -0.722939, 0.201705, -0.0198462, -1.58025, -0.236825, -0.0115685, -0.308714, 0.627589, 0.23412, -0.0213534, -0.163256, 0.574728, -0.484858, 0.0863834, 0.204579, -0.179914, 0.685052, 0.46821, 0.216763, -0.413278, 0.174396, 0.250834, -0.0586227, -0.185556, -0.38277, -0.104602, 0.126448, 0.0389859, -0.2487, -0.0312624, 0.158295, -0.321719, 0.653388, 0.229935, -0.36922, -0.29443, -0.324982, -0.513933, 0.298532, 1.00447, -0.770199, 0.168667, -0.182877, -0.208261, -0.344872, 0.317139, 0.252468, 0.565399, 0.828872, -0.465066, 0.416088, 0.0941691, 0.0912029, -0.230033, 0.0564448, 0.157766, -0.429874, 0.0800825, -0.177324, -0.202525, 0.137112, -0.0153134, -0.253027, -0.122964, -0.284616, 0.0327089, 0.10081, -0.0502875, -0.473904, 0.36908, -0.230313, -0.471352, -0.0622501, 0.0368803, 0.0760779, -0.250072, -0.164415, 0.103563, -0.256734, 0.159875, -0.0530937, 0.201032, -0.137017, 0.14754, -0.213179, 0.298108, -0.455223, -0.464235, 0.184667, 0.13349, 0.151406, -0.150315, -0.265275, 0.197935, -0.011858, 0.125901, -0.251488, -0.0495841, 0.256036, -0.0295486, -0.0620437, -0.0561038, -0.255245, 0.0254507, 0.00764523, 0.120609, 0.0101855, -0.0922957, 0.0143811, -0.252266, -0.0762511, 0.16607, 0.338352, 0.0784134, -0.113841, 0.217713, -0.1798, -0.145338, 0.0526952, 0.309429, 0.218547, 0.0365333, 0.0467176], "internal": 1}
{"paper_id": "P13-3016", "abstract": "There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our experimental results show that the proposed method outperforms analysis based only on opinion mining techniques.", "title": "Detecting Chronic Critics Based on Sentiment Polarity and User’s Behavior in Social Media", "venue": "P", "graph_vector": [-0.10213, 0.317553, 0.324311, 0.0533799, 0.550869, -0.806785, -0.0627998, -0.0772759, -1.80474, 0.495757, -0.0285719, -0.430421, 0.420864, 0.0157079, -0.440752, 0.0546553, 0.270094, -0.627272, -0.227294, 0.310193, 0.0397266, 0.524987, -0.154796, -0.154369, 0.0335325, 0.17306, -0.196074, -0.289906, 0.197233, -0.533766, -0.0750753, 0.285466, 0.130576, -0.527783, -0.280509, -0.0854049, -0.426741, 0.83114, 0.0631853, -0.286174, 0.118006, -0.72476, -0.233454, 0.807521, 0.975861, -0.911409, 0.241249, 0.0728924, 0.119797, 0.204122, 0.441186, -0.5713, 1.21555, 0.630016, -0.341652, 0.24751, 0.400098, 0.274661, -0.0965341, -0.0293179, -0.0710489, 0.145084, 0.104023, -0.145225, -0.346602, 0.0866438, 0.0823172, -0.187035, 0.23459, -0.0165538, -0.238993, -0.113114, -0.01137, -0.391678, 0.0525219, -0.360878, -0.670726, -0.505106, 0.0574525, 0.0348422, -0.165985, -0.355267, -0.0405413, 0.14217, 0.0845799, 0.0736829, 0.116401, 0.0570016, -0.134551, 0.0407261, 0.393017, 0.435038, -0.811211, -0.367625, 0.248081, -0.102304, 0.140225, 0.16226, 0.178187, 0.0193817, -0.334703, -0.152795, -0.271404, 0.260978, -0.0170492, -0.0844465, -0.220672, -0.355559, 0.287138, 0.326743, 0.231923, -0.0744618, 0.19681, 0.234672, 0.076428, -0.131326, 0.0898389, 0.0954906, 0.106143, 0.308982, -0.00147862, -0.142888, 0.176415, -0.16035, 0.886087, 0.254365, -0.219444, 0.15584], "internal": 1}
{"paper_id": "P13-1012", "abstract": "Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.", "title": "Decentralized Entity-Level Modeling for Coreference Resolution", "venue": "P", "graph_vector": [-0.00029504, 0.0900514, -0.0553984, 0.573202, 0.51238, -0.346524, 0.0643139, 0.0501509, -1.48694, 0.373459, -0.396873, -0.569192, 0.689137, 0.192934, 0.471337, -0.196926, -0.0387105, -0.817159, 0.126451, 0.200344, -0.538179, 0.433907, -0.125176, -0.361815, -0.349618, 0.187453, -0.0249204, 0.262258, 0.118349, -0.233568, -0.135089, -0.139175, 0.311612, -0.621814, -0.0498649, 0.282281, -0.271577, 0.620184, 0.105421, -0.0270852, 0.152447, -0.337565, -0.398207, 0.313005, 0.965631, -0.809579, 0.282555, 0.126368, -0.094441, -0.0710894, 0.050504, -0.00184571, 0.660191, 0.608391, -0.163815, -0.0477646, -0.125662, 0.0657852, -0.238031, 0.23389, -0.408316, -0.0120525, -0.035432, 0.0990078, -0.0410629, -0.113894, 0.110904, -0.181015, -0.177009, 0.192273, 0.309385, 0.129842, 0.000610213, -0.115067, 0.32252, -0.185768, -0.201917, -0.179635, 0.0662342, -0.0862361, 0.129228, 0.00328678, 0.0962253, -0.426613, 0.141318, -0.462141, 0.1009, -0.148136, -0.0173862, -0.156343, 0.244044, -0.0612984, -0.291926, -0.0367464, -0.275227, -0.308439, 0.104193, 0.197329, 0.135954, -0.253432, -0.047412, -0.350652, -0.047732, 0.486215, -0.465291, 0.061474, -0.212855, 0.0257193, 0.0748992, -0.0792033, -0.228618, -0.00456605, -0.16053, 0.0944602, 0.147138, -0.056763, 0.346391, 0.339534, -0.0694267, 0.320698, -0.0892356, 0.00422356, 0.18088, 0.133957, 0.454555, 0.203466, -0.0238519, -0.088414], "internal": 1}
{"paper_id": "P13-2109", "abstract": "We present fast, accurate, direct nonprojective dependency parsers with thirdorder features. Our approach uses AD3, an accelerated dual decomposition algorithm which we extend to handle specialized head automata and sequential head bigram models. Experiments in fourteen languages yield parsing speeds competitive to projective parsers, with state-ofthe-art accuracies for the largest datasets (English, Czech, and German).", "title": "Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers", "venue": "P", "graph_vector": [0.155075, 0.0528009, -0.0457627, 0.229845, 0.449905, -1.24401, 0.0697136, -0.0846489, -1.51589, 0.121303, -0.191073, -0.559874, 0.791858, -0.0101756, 0.100215, -0.177743, 0.345727, -0.589598, 0.0754042, 0.287073, -0.339332, 0.561108, 0.249348, -0.591508, -0.131981, 0.104498, -0.0387209, 0.218413, -0.349022, -0.292566, 0.12651, -0.129698, -0.0324288, -0.3182, -0.180742, 0.229851, -0.343506, 0.276661, 0.256345, 0.142898, 0.158917, -0.08125, -0.0766307, 0.348077, 0.920837, -0.590804, 0.282658, 0.097836, -0.179074, 0.111476, 0.133073, -0.428468, 0.702496, 0.571704, 0.281842, -0.1269, 0.136855, 0.173822, -0.110275, 0.211016, -0.310146, 0.377084, -0.0584382, 0.025985, -0.282737, -0.155512, 0.109889, -0.156715, 0.0338234, 0.465049, 0.0704931, 0.113917, -0.175959, -0.2351, -0.124927, -0.0243802, -0.701851, -0.209049, 0.0434709, -0.247175, -0.103045, -0.00267941, 0.347477, -0.191164, 0.00755399, -0.297828, 0.0989607, -0.240357, 0.0651047, -0.17569, -0.0668454, -0.0407275, -0.270973, -0.0514251, 0.0201114, -0.433529, -0.0384183, -0.106753, -0.0542173, -0.0891756, -0.0870965, -0.467096, 0.26312, 0.353452, -0.213738, 0.344506, -0.0234686, -0.0652779, 0.214844, -0.184978, -0.244644, -0.125473, -0.00754943, 0.17582, -0.0131537, -0.055177, 0.188132, 0.0662708, 0.00996855, 0.253401, 0.185252, -0.0657843, 0.310083, -0.00641212, 0.843045, 0.0686273, -0.354877, -0.0196041], "internal": 1}
{"paper_id": "P13-1128", "abstract": "We study the task of entity linking for tweets, which tries to associate each mention in a tweet with a knowledge base entry. Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations. To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions. Particularly, our model integrates three kinds of similarities, i.e., mention-entry similarity, entry-entry similarity, and mention-mention similarity, to enrich the context for entity linking, and to address irregular mentions that are not covered by the entity-variation dictionary. We evaluate our method on a publicly available data set and demonstrate the effectiveness of our method.", "title": "Entity Linking for Tweets", "venue": "P", "graph_vector": [0.349732, 0.128548, -0.0861538, 0.459598, 0.419193, -0.313789, -0.133923, 0.303979, -1.44725, 0.436318, -0.160335, -0.441685, 0.69257, 0.13445, 0.000858033, 0.0224006, 0.531545, -0.821699, 0.164779, 0.465304, -0.346545, 1.01883, 0.0120404, -0.215253, 0.412516, -0.164551, 0.0195464, 0.287713, 0.229374, -0.142949, -0.036922, 0.184647, -0.190523, -0.552151, -0.474592, 0.124326, -0.590898, 0.874259, 0.112652, -0.243077, 0.0656458, -0.683053, -0.157706, 0.851313, 0.697686, -0.823273, 0.366735, 0.445912, -0.129437, 0.0791699, 0.107439, -0.387695, 1.39351, 1.10137, 0.0669739, 0.0421653, 0.124141, 0.26868, -0.166589, -0.0896236, -0.335683, -0.232198, 0.1224, 0.0113138, -0.20476, -0.019152, 0.426209, 0.0391398, 0.0994083, -0.124316, 0.198138, -0.0581551, -0.189239, -0.299046, -0.07384, -0.302127, -0.703723, -0.0580528, -0.0149807, -0.0390916, 0.0364017, -0.265471, 0.0751024, -0.155089, 0.147884, -0.499764, -0.00855268, -0.0327218, -0.196275, 0.119068, 0.289121, 0.134255, -1.03933, -0.0380713, 0.0336788, 0.401116, 0.206931, -0.106665, -0.0952872, -0.0539607, -0.14945, -0.0200131, 0.0319668, 0.177678, 0.00691603, 0.0497209, -0.0554073, -0.218389, 0.126807, -0.27385, -0.418748, -0.139244, -0.173863, 0.10975, -0.0960361, -0.224793, 0.261463, 0.293781, -0.25919, 0.303946, -0.0395422, 0.173285, -0.179025, -0.0417895, 0.531289, -0.0415038, -0.15043, -0.123647], "internal": 1}
{"paper_id": "P13-2015", "abstract": "Most coreference resolvers rely heavily on string matching, syntactic properties, and semantic attributes of words, but they lack the ability to make decisions based on individual words. In this paper, we explore the benefits of lexicalized features in the setting of domain-specific coreference resolution. We show that adding lexicalized features to off-the-shelf coreference resolvers yields significant performance gains on four domain-specific data sets and with two types of coreference resolution architectures.", "title": "Domain-Specific Coreference Resolution with Lexicalized Features", "venue": "P", "graph_vector": [0.0542465, 0.237694, 0.166736, 0.611289, 0.400525, -0.470308, 0.237746, 0.0435585, -1.82035, 1.02077, 0.346943, -0.164259, 0.287158, 0.286817, 0.425303, 0.062635, 0.562855, -0.597286, -3.48247e-05, 0.223031, -0.839064, 0.476403, 0.254996, 0.374196, -0.155959, 0.2577, 0.0836729, 0.405536, -0.394522, -0.125789, 0.213747, 0.0604162, -0.198329, -0.566833, -0.271546, 0.486118, 0.235212, 0.377907, 0.133826, -0.275111, -0.0461897, -0.359582, -0.30976, 0.157056, 0.817719, -1.05659, 0.207688, -0.0176398, -0.182318, -0.123842, 0.10698, 0.0138841, 0.776772, 0.749747, -0.263539, 0.0468883, -0.389418, 0.302876, -0.0677084, -0.0483871, -0.323798, -0.0381569, 0.149776, 0.0577232, -0.110782, -0.155582, 0.269859, -0.0414903, 0.229785, 0.0446519, 0.119227, 0.066931, -0.220376, 0.0235329, -0.186685, -0.416565, -0.271805, -0.0310424, -0.441667, -0.142509, -0.226873, 0.236694, 0.169555, -0.194252, 0.126881, -0.293609, -0.3646, -0.135263, -0.07019, -0.129235, 0.2668, -0.342132, -0.654483, -0.294582, -0.178351, -0.163003, 0.199879, -0.0660166, -0.178499, 0.0754954, -0.225901, -0.209575, 0.174376, 0.179979, -0.380284, 0.0738717, -0.279939, 0.056703, -0.039434, -0.528138, -0.0521653, 0.0591354, -0.0787621, -0.156857, 0.0423908, 0.0557154, 0.365716, 0.0585764, -0.16449, 0.0691817, -0.114396, -0.170172, 0.625464, -0.295711, 0.29824, 0.214605, -0.00692674, -0.119781], "internal": 1}
{"paper_id": "P13-1046", "abstract": "In spoken dialog systems, statistical state tracking aims to improve robustness to speech recognition errors by tracking a posterior distribution over hidden dialog states. Current approaches based on generative or discriminative models have different but important shortcomings that limit their accuracy. In this paper we discuss these limitations and introduce a new approach for discriminative state tracking that overcomes them by leveraging the problem structure. An offline evaluation with dialog data collected from real users shows improvements in both state tracking accuracy and the quality of the posterior probabilities. Features that encode speech recognition error patterns are particularly helpful, and training requires relatively few dialogs.", "title": "Discriminative state tracking for spoken dialog systems", "venue": "P", "graph_vector": [-0.0661517, 0.192969, -0.163066, 0.238357, 0.276266, -0.539518, 0.372861, -0.398097, -1.62256, 0.246971, -0.243644, -0.00798567, 0.674288, -0.243757, -0.326318, -0.557439, 0.67347, -0.748189, 0.243864, 0.39932, -0.040048, 0.254615, 0.450631, -0.270169, -0.450241, 0.201472, -0.0790313, -0.179285, -0.991733, -0.0858073, 0.1411, -0.316698, 0.218411, -0.695712, -0.0475991, 0.092802, 0.148465, 1.42596, 0.106065, -0.108451, -0.113652, -0.193817, -0.389615, 0.57468, 0.959807, -0.972682, 0.236638, -0.231636, 0.529315, -0.183522, 0.586972, -0.0384248, 0.623622, 1.03453, 0.165528, -0.146085, 0.124772, 0.444364, -0.360323, 0.032565, -0.341596, -0.17338, 0.293997, 0.413021, -0.373133, 0.386387, 0.347298, 0.132661, -0.0422688, -0.207297, 0.372819, 0.114178, 0.165704, 0.253557, 0.483497, 0.0435208, -0.516877, -0.420449, -0.311957, 0.323659, -0.296357, -0.0411126, 0.260775, -0.11401, 0.369798, -0.631768, 0.0592005, 0.191758, -0.0389127, 0.460845, 0.242891, 0.0707518, -0.679692, -0.413993, 0.0277925, -0.107157, 0.214734, -0.0538111, -0.0560358, -0.1138, 0.162818, -0.644264, 0.222455, 0.00436479, -0.160087, 0.133309, -0.309672, 0.0688706, 0.330045, -0.120376, -0.0979428, -0.272209, -0.577344, -0.035365, -0.0885923, 0.166956, 0.056171, 0.308259, -0.479402, 0.0177601, -0.198584, 0.0105428, -0.347809, -0.0743855, 0.42399, 0.203798, -0.273925, -0.126817], "internal": 1}
{"paper_id": "P13-2083", "abstract": "In this paper we present a novel approach to modelling distributional semantics that represents meaning as distributions over relations in syntactic neighborhoods. We argue that our model approximates meaning in compositional configurations more effectively than standard distributional vectors or bag-of-words models. We test our hypothesis on the problem of judging event coreferentiality, which involves compositional interactions in the predicate-argument structure of sentences, and demonstrate that our model outperforms both state-of-the-art window-based word embeddings as well as simple approaches to compositional semantics previously employed in the literature.", "title": "A Structured Distributional Semantic Model for Event Co-reference", "venue": "P", "graph_vector": [0.0910794, 0.0257429, 0.100988, 0.410161, 0.607717, -0.483014, 0.0648683, -0.0854686, -1.3137, 0.565074, 0.252363, -0.30509, 0.664228, 0.0144888, 0.46547, -0.151889, 0.797209, -0.558692, 0.213609, 0.28282, -0.113785, 0.483618, -0.110167, 0.157199, -0.608082, -0.0798908, 0.0837661, 0.185976, 0.213459, -0.381669, 0.0280856, -0.116142, -0.0671135, -0.305384, -0.057862, 0.1987, -0.250165, 0.367546, -0.0812243, -0.203158, -0.12792, -0.0596062, -0.282895, 0.258425, 1.06962, -0.66874, 0.246374, 0.222488, -0.315984, -0.0245376, 0.226711, -0.168526, 0.963634, 0.719175, -0.106266, -0.192615, 0.0588016, 0.0674239, -0.231337, -0.12663, -0.197469, 0.0597922, -0.327052, 0.152927, -0.0516949, -0.269233, 0.00886934, -0.0505877, 0.122713, 0.0229997, 0.33569, 0.240507, 0.571805, -0.211432, -0.163146, -0.203748, -0.328366, -0.452807, 0.0607843, -0.0139605, 0.0488097, 0.183811, 0.046798, -0.188348, 0.452998, -0.472495, -0.0710705, -0.238437, 0.202009, -0.233646, -0.199573, 0.0250793, -0.393192, 0.0437652, 0.154613, -0.203741, 0.170566, 0.026479, -0.0740686, -0.163667, -0.0155855, -0.0196912, 0.0417491, 0.261597, 0.125674, 0.208085, -0.255631, 0.00540491, -0.0710964, -0.586843, -0.128846, -0.10501, -0.09024, 0.13955, 0.213787, -0.232548, 0.673111, 0.113676, 0.0213756, 0.322646, -0.345015, 0.0287309, 0.169595, -0.0673821, 0.117077, 0.075911, -0.0280645, -0.106638], "internal": 1}
{"paper_id": "P03-2041", "abstract": "Often one may wish to learn a tree-to-tree mapping, training it on unaligned pairs of trees, or on a mixture of trees and strings. Unlike previous statistical formalisms (limited to isomorphic trees), synchronous TSG allows local distortion of the tree topology. We reformulate it to permit dependency trees, and sketch EM/Viterbi algorithms for alignment, training, and decoding.", "title": "Learning Non-Isomorphic Tree Mappings for Machine Translation", "venue": "P", "graph_vector": [-0.0163425, -0.218699, -0.100572, 0.0465753, 0.246479, -1.00713, 0.231388, -0.128642, -1.52663, 0.158569, -0.037905, -0.4387, 0.647438, 0.0561263, -0.0977702, -0.375797, 0.623454, -0.414663, -0.162304, 0.165601, -0.195723, 0.538564, 0.425249, -0.166719, -0.373994, 0.334642, -0.0171414, -0.000344788, -0.279687, -0.339104, -0.127139, 0.476094, 0.22064, -0.405949, -0.178955, -0.0145609, -0.0993116, 0.535203, 0.325336, -0.451354, -0.156894, -0.311138, -0.0476299, 0.629618, 0.835965, -0.664634, 0.112747, 0.606462, 0.112899, -0.0878351, 0.113549, 0.0696879, 0.770229, 0.265, -0.0567277, 0.475165, -0.0256136, -0.101351, 0.0817676, 0.0273197, -0.510224, -0.179699, -0.188197, -0.0794073, -0.169171, -0.106517, 0.0637459, 0.122961, -0.317449, -0.0445996, 0.0826118, 0.0559892, 0.125981, -0.0911619, 0.175238, 0.00878735, -0.564792, -0.465826, -0.284692, -0.173027, -0.181184, 0.00928715, 0.179911, 0.155382, 0.189998, -0.17975, 0.100856, 0.0799294, 0.157895, -0.172204, -0.311913, -0.161088, -0.269088, 0.00379343, -0.235609, 0.174021, -0.00516156, -0.0940223, -0.193824, -0.172287, -0.330975, -0.555928, 0.0162446, 0.115901, 0.0707471, -0.0243958, -0.127894, 0.0450975, 0.401428, -0.0507541, 0.00373215, 0.236412, -0.0318473, -0.104393, 0.295059, -0.19159, 0.583133, 0.124258, -0.0364741, 0.11866, -0.00189518, 0.0775087, -0.0942672, 0.009113, 0.549098, 0.141637, 0.190947, -0.0997326], "internal": 1}
{"paper_id": "P15-1076", "abstract": "Language modeling (LM) involves determining the joint probability of words in a sentence. The conditional approach is dominant, representing the joint probability in terms of conditionals. Examples include n-gram LMs and neural network LMs. An alternative approach, called the random field (RF) approach, is used in whole-sentence maximum entropy (WSME) LMs. Although the RF approach has potential benefits, the empirical results of previous WSME models are not satisfactory. In this paper, we revisit the RF approach for language modeling, with a number of innovations. We propose a trans-dimensional RF (TDRF) model and develop a training algorithm using joint stochastic approximation and trans-dimensional mixture sampling. We perform speech recognition experiments on Wall Street Journal data, and find that our TDRF models lead to performances as good as the recurrent neural network LMs but are computationally more efficient in computing sentence probability.", "title": "Trans-dimensional Random Fields for Language Modeling", "venue": "P", "graph_vector": [-0.0317183, -0.0861417, 0.157257, 0.809345, 0.612218, -0.641095, 0.289604, -0.2069, -1.2698, 0.11786, -0.36201, -0.644791, 0.262091, 0.0190275, 0.220246, 0.204043, 0.467388, -0.558234, -0.0471221, 0.373695, -0.234441, 0.792733, 0.292077, 0.15265, -0.0771912, -0.0279472, 0.0699071, -0.193199, -0.388254, -0.173502, 0.317146, -0.29871, 0.255017, -0.872421, -0.489911, 0.41475, 0.0918445, 1.13292, 0.23807, -0.292973, -0.172772, -0.352525, -0.251771, 0.540516, 1.05845, -0.783778, 0.116533, -0.227446, -0.173453, -0.276668, 0.26832, 0.0885357, 0.861852, 0.396262, -0.0779753, 0.11207, 0.474784, 0.15152, -0.0212912, 0.0198948, -0.568106, -0.266857, -0.129749, 0.0482966, 0.0244964, 0.0151234, 0.08189, 0.0851873, 0.403162, 0.31925, -0.0914513, 0.454612, -0.186484, -0.46069, 0.135971, -0.114926, -0.570575, -0.119314, 0.0410862, -0.12514, -0.129785, 0.112919, 0.242075, -0.00174497, 0.0460452, -0.576212, 0.0469251, -0.0943603, -0.182254, -0.301365, 0.261389, 0.260454, -0.498283, -0.0755205, 0.0491053, -0.0567813, 0.122889, -0.302095, -0.0960588, 0.194547, -0.305886, -0.22147, 0.335523, 0.0421725, -0.0864808, 0.269051, 0.373724, -0.0391648, 0.286746, -0.223514, 0.183371, 0.0876528, -0.346209, 0.400444, 0.272213, -0.0329987, 0.132157, 0.0474371, 0.105243, 0.183152, 0.0869841, -0.227372, -0.179875, -0.00291118, 0.344486, 0.0795261, -0.0787511, -0.286929], "internal": 1}
{"paper_id": "P15-4015", "abstract": "Lexical Simplification consists in replacing complex words in a text with simpler alternatives. We introduce LEXenstein, the first open source framework for Lexical Simplification. It covers all major stages of the process and allows for easy benchmarking of various approaches. We test the tool’s performance and report comparisons on different datasets against the state of the art approaches. The results show that combining the novel Substitution Selection and Substitution Ranking approaches introduced in LEXenstein is the most effective approach to Lexical Simplification.", "title": "LEXenstein: A Framework for Lexical Simplification", "venue": "P", "graph_vector": [0.0612513, 0.010696, -0.196785, 0.793246, -0.0186305, -0.756371, 0.167766, -0.277897, -1.19927, 0.763213, -0.324935, -0.0759755, 0.786783, -0.194801, 0.136919, -0.129334, 0.725782, -0.952968, 0.500784, 0.152912, -0.23106, 0.17703, 0.0741871, 0.167307, 0.16199, 0.210098, 0.227457, -0.0148086, 0.30671, 0.0619522, 0.273105, 0.376049, -0.0238374, -0.299563, -0.0103198, -0.116603, -0.0905058, 0.73904, -0.0908902, 0.104751, 0.0798971, -0.0352255, -0.409526, 0.186807, 0.658582, -1.54223, 0.121766, 0.569571, -0.288582, -0.0970683, 0.224071, 0.0252833, 0.749789, 0.607754, -0.197975, 0.0998998, 0.70947, -0.250181, 0.134631, -0.0581162, -0.142224, -0.554034, -0.0874864, 0.076621, -0.15427, -0.0573498, -0.252202, 0.102688, 0.0839988, 0.112443, -0.0224042, -0.343854, -0.302335, -0.262915, 0.351767, -0.0461982, -0.810409, -0.382525, -0.387707, -0.268588, -0.195234, -0.224196, 0.223219, 0.109087, -0.0721787, -0.37696, 0.0652212, 0.415903, -0.0377691, 0.0612176, 0.0680239, 0.271814, -0.552008, -0.463, -0.0678713, 0.0265005, -0.0667394, -0.0152871, -0.247623, 0.138898, -0.271238, -0.0478468, 0.0603829, -0.100032, -0.174353, -0.030516, -0.218877, -0.196313, -0.0758475, -0.294563, 0.544271, -0.0464079, -0.281864, 0.157951, 0.183518, 0.0370312, 0.288567, 0.157221, 0.135723, 0.0499988, 0.00291199, -0.269866, -0.112153, 0.0566331, 0.321385, 0.0376721, -0.159215, 0.141151], "internal": 1}
{"paper_id": "P15-2118", "abstract": "We propose a simple yet effective approach to learning bilingual word embeddings (BWEs) from non-parallel document-aligned data (based on the omnipresent skip-gram model), and its application to bilingual lexicon induction (BLI). We demonstrate the utility of the induced BWEs in the BLI task by reporting on benchmarking BLI datasets for three language pairs: (1) We show that our BWE-based BLI models significantly outperform the MuPTM-based and context-counting models in this setting, and obtain the best reported BLI results for all three tested language pairs; (2) We also show that our BWE-based BLI models outperform other BLI models based on recently proposed BWEs that require parallel data for bilingual training.", "title": "Bilingual Word Embeddings from Non-Parallel Document-Aligned Data Applied to Bilingual Lexicon Induction", "venue": "P", "graph_vector": [0.0469054, 0.213234, 0.0633923, 0.330226, 0.379589, -0.713091, 0.144163, -0.643573, -1.53282, 0.258995, 0.0359773, -0.307908, 0.574333, -0.102772, -0.00492441, -0.117769, 0.313296, -0.428192, 0.0296064, 0.190957, 0.00934504, 0.827309, 0.36254, -0.112919, -0.441681, 0.16637, 0.113543, 0.213075, -0.126846, -0.0954333, -0.188258, -0.218777, 0.190637, -0.160201, -0.174355, 0.163537, -0.336352, 0.381473, 0.157463, -0.284641, -0.0840801, -0.224893, -0.391663, 0.461638, 0.919871, -0.725987, 0.278658, 0.06309, -0.0820412, -0.0280276, -0.0146933, -0.109991, 1.21599, 0.382075, -0.0304128, -0.264389, 0.309646, 0.343281, 0.0957342, -0.172193, -0.108235, -0.000356926, 0.118488, -0.149947, 0.0343183, 0.0431329, 0.128823, -0.143096, -0.22136, -0.227199, 0.280831, 0.289117, -0.289943, -0.23956, 0.00576682, -0.253208, -0.703927, -0.372768, -0.263242, -0.13998, -0.208021, 0.158897, -0.0514647, -0.312169, 0.102944, -0.177761, 0.121256, -0.175464, 0.0198564, -0.134391, 0.0948029, 0.249824, -0.692921, 0.0154332, -0.0910762, -0.015386, 0.0595726, -0.0377198, 0.0356191, -0.0959151, -0.00387111, -0.156591, -0.0913713, 0.0198334, 0.0802639, 0.565034, -0.348048, -0.396812, -0.0634338, 0.222895, -0.114108, -0.20297, -0.25865, 0.134095, -0.217431, 0.129514, 0.333465, -0.198147, -0.0228866, -0.0595471, -0.312477, 0.0042439, -0.0332948, -0.187033, 0.180522, 0.281339, 0.0610632, -0.0180618], "internal": 1}
{"paper_id": "P15-1044", "abstract": "We present a novel syntax-based natural language generation system that is trainable from unaligned pairs of input meaning representations and output sentences. It is divided into sentence planning, which incrementally builds deep-syntactic dependency trees, and surface realization. Sentence planner is based on A* search with a perceptron ranker that uses novel differing subtree updates and a simple future promise estimation; surface realization uses a rule-based pipeline from the Treex NLP toolkit. Our first results show that training from unaligned data is feasible, the outputs of our generator are mostly fluent and relevant.", "title": "Training a Natural Language Generator From Unaligned Data", "venue": "P", "graph_vector": [0.0340402, 0.101714, -0.238292, 0.200087, 0.334302, -0.608305, 0.183525, -0.295801, -1.61053, 0.221241, 0.0223645, -0.072297, 1.15633, 0.392512, -0.0873101, 0.0535438, 0.627182, -0.220716, 0.246078, 0.149161, -0.147206, 0.179993, 0.600677, 0.275338, -0.15968, 0.217506, -0.180056, 0.250815, -0.0461004, -0.414617, -0.0955303, 0.0461396, 0.218414, -0.684494, -0.169387, 0.199856, -0.334324, 0.464769, 0.0915657, 0.000844147, -0.137466, -0.291975, -0.306552, 0.17564, 0.812313, -0.344614, 0.0544252, 0.0661729, -0.186025, -0.325156, 0.172028, -0.1302, 0.81684, 0.432207, -0.459545, 0.128878, -0.154694, 0.271472, -0.0742991, -0.075639, 0.0361583, 0.0496934, 0.371664, -0.161683, 0.18274, 0.332452, 0.437538, 0.0105023, 0.0480225, -0.0273994, -0.0332083, 0.187749, -0.1515, -0.387196, 0.281658, -0.222446, -0.265897, -0.332542, -0.0919025, -0.00113694, 0.380697, 0.126557, 0.14894, -0.59066, 0.141101, -0.350775, 0.0868541, -0.371297, -0.0382827, -0.0529412, 0.00483952, -0.030888, -0.563319, -0.0441975, 0.00472877, 0.189935, -0.116474, -0.114688, -0.117407, -0.182603, 0.106539, -0.410461, 0.415791, 0.0394497, 0.0450162, -0.135746, 0.208206, 0.00387652, 0.228028, -0.291369, 0.0299244, -0.177362, 0.0374168, -0.261115, 0.301452, 0.131716, -0.0512365, 0.148863, -0.0708762, 0.111126, 0.346122, 0.0631448, -0.214272, -0.11055, 0.248619, 0.422191, -0.185627, 0.0835788], "internal": 1}
{"paper_id": "P15-1003", "abstract": "The recently proposed neural network joint model (NNJM) (Devlin et al., 2014) augments the n-gram target language model with a heuristically chosen source context window, achieving state-of-the-art performance in SMT. In this paper, we give a more systematic treatment by summarizing the relevant source information through a convolutional architecture guided by the target information. With different guiding signals during decoding, our specifically designed convolution+gating architectures can pinpoint the parts of a source sentence that are relevant to predicting a target word, and fuse them with the context of entire source sentence to form a unified representation. This representation, together with target language words, are fed to a deep neural network (DNN) to form a stronger NNJM. Experiments on two NIST Chinese-English translation tasks show that the proposed model can achieve significant improvements over the previous NNJM by up to +1.08 BLEU points on average.", "title": "Encoding Source Language with Convolutional Neural Network for Machine Translation", "venue": "P", "graph_vector": [], "internal": 1}
{"paper_id": "P15-1055", "abstract": "We study the problem of explaining relationships between pairs of knowledge graph entities with human-readable descriptions. Our method extracts and enriches sentences that refer to an entity pair from a corpus and ranks the sentences according to how well they describe the relationship between the entities. We model this task as a learning to rank problem for sentences and employ a rich set of features. When evaluated on a large set of manually annotated sentences, we find that our method significantly improves over state-of-the-art baseline models.", "title": "Learning to Explain Entity Relationships in Knowledge Graphs", "venue": "P", "graph_vector": [0.0222406, 0.00982471, 0.00593584, -0.0602939, 0.500722, -0.713338, 0.570996, 0.120466, -1.4257, 0.654987, 0.333572, -0.364066, 0.52611, 0.417299, -0.55848, 0.196166, 0.756348, -0.495579, -0.0178486, 0.304832, 0.00294783, 0.0332794, 0.130195, 0.105808, -0.461301, -0.126799, 0.416945, 0.27059, -0.462616, -0.201336, 0.187604, 0.231503, -0.164082, -0.624781, 0.00531449, -0.156143, -0.843678, 0.538226, 0.246814, -0.271557, -0.132423, -0.40619, -0.315732, 0.495823, 0.747692, -0.91735, 0.252763, 0.466243, -0.108895, -0.0757422, 0.0446486, 0.00324381, 1.06206, 0.583173, 0.137234, -0.221322, 0.0913725, -0.0162807, -0.225999, 0.149573, -0.567833, -0.273249, -0.144135, -0.200724, -0.347165, -0.291713, 0.275349, -0.0228625, 0.112291, 0.178086, 0.0407735, 0.0210898, -0.262046, -0.103268, 0.0598641, -0.292436, -0.783881, -0.358528, 0.105692, -0.164414, -0.188443, 0.367343, -0.0987678, -0.0360604, 0.273303, -0.322642, -0.27924, 0.187536, -0.184103, -0.34003, -0.0120507, 0.19314, -1.0713, -0.0974037, 0.0216784, -0.334019, -0.093135, 0.0821332, 0.305244, -0.232903, -0.111836, -0.364822, 0.151506, 0.257854, -0.0712134, 0.294127, -0.32424, 0.152863, 0.286454, -0.257517, -0.422195, 0.214579, -0.0338917, -0.242726, -0.421889, -0.090377, 0.280723, -0.216107, -0.0526448, 0.693773, -0.0731145, -0.0648511, 0.362722, 0.331714, 0.0547931, -0.202092, 0.423566, -0.172519], "internal": 1}
{"paper_id": "P15-2060", "abstract": "We study the event detection problem using convolutional neural networks (CNNs) that overcome the two fundamental limitations of the traditional feature-based approaches to this task: complicated feature engineering for rich feature sets and error propagation from the preceding stages which generate these features. The experimental results show that the CNNs outperform the best reported feature-based systems in the general setting as well as the domain adaptation setting without resorting to extensive external resources.", "title": "Event Detection and Domain Adaptation with Convolutional Neural Networks", "venue": "P", "graph_vector": [-0.025644, 0.136202, 0.161763, 0.00379507, 0.620437, -0.712751, -0.0426209, -0.0539334, -1.53241, 0.49656, 0.0784129, -0.150743, 0.312122, 0.359098, 0.330242, 0.0776479, 0.39386, -0.482187, 0.228325, 0.436306, -0.162457, 0.633904, 0.70137, -0.369634, -0.340397, 0.0538149, 0.122941, -0.00536672, -0.204241, -0.547001, -0.00157024, -0.19156, 0.225999, -0.782237, 0.00928463, 0.16218, 0.0931524, 0.384898, -0.242144, -0.0364477, -0.140192, -0.63993, -0.254636, 0.362536, 1.00055, -0.632791, -0.0872346, -0.00128012, -0.342093, 0.217407, 0.0188967, 0.0546604, 1.13175, 0.928203, 0.104922, 0.00137009, -0.0794498, 0.25462, -0.0653597, -0.299875, -0.0621775, -0.194407, 0.0103815, 0.0246077, 0.131231, -0.223606, 0.0923621, -0.365922, 0.182535, -0.0225231, -0.0774324, -0.00729603, 0.320678, -0.12262, 0.0576622, -0.317775, -0.396363, -0.375109, -0.0318757, -0.00166839, -0.382497, 0.162337, 0.456909, -0.0144159, 0.225612, -0.271835, 0.0712322, -0.124486, -0.0689887, -0.321107, 0.0800537, 0.237391, -0.62705, 0.0858371, -0.00312773, -0.0283791, -0.00984616, -0.276354, -0.417987, -0.0889736, 0.176271, -0.0723199, 0.101239, -0.147556, -0.0411476, 0.131189, 0.0784285, -0.212131, 0.436085, -0.178463, 0.194862, -0.542038, -0.497784, 0.105134, -0.27848, 0.105584, 0.346149, -0.182599, -0.0552896, 0.293958, -0.126825, -0.158015, -0.0913809, 0.0274089, 0.548723, -0.154309, 0.108274, 0.140526], "internal": 1}
{"paper_id": "P15-1165", "abstract": "We present a novel, count-based approach to obtaining inter-lingual word representations based on inverted indexing of Wikipedia. We present experiments applying these representations to 17 datasets in document classification, POS tagging, dependency parsing, and word alignment. Our approach has the advantage that it is simple, computationally efficient and almost parameter-free, and, more importantly, it enables multi-source crosslingual learning. In 14/17 cases, we improve over using state-of-the-art bilingual embeddings.", "title": "Inverted indexing for cross-lingual NLP Anders Søgaard* ˇZeljko Agi´c* H´ector Martinez Alonso*", "venue": "P", "graph_vector": [0.172221, 0.306745, -0.0225742, -0.04426, 0.310027, -0.96836, 0.203253, -0.197423, -1.45025, -0.123528, -0.0291663, -0.372231, 0.515834, -0.0385877, 0.0569375, -0.116904, 0.386849, -0.710023, -0.341349, 0.517011, -0.150358, 0.865542, 0.284737, -0.0310005, -0.265972, 0.0617834, -0.0562456, 0.383768, -0.0773304, -0.322524, -0.322213, -0.0633202, 0.32524, -0.130372, -0.486307, 0.289774, -0.366619, 0.443467, -0.236718, -0.191632, -0.00799361, -0.318545, -0.246428, 0.56367, 0.85912, -0.759299, -0.012802, 0.231394, -0.319282, -0.134479, 0.166553, -0.256603, 0.784997, 0.585523, -0.143601, -0.379612, -0.0756317, 0.33617, 0.269254, -0.325329, -0.0495101, -0.20355, -0.159782, -0.346481, 0.151936, 0.0178003, 0.417049, 0.0903882, 0.0979102, -0.07147, 0.0321209, 0.129399, -0.299851, -0.272642, 0.239288, -0.354138, -0.428231, -0.182079, -0.202823, -0.184846, -0.262897, -0.121918, -0.00509344, 0.100059, 0.111432, -0.508857, 0.0246837, -0.137922, -0.175806, -0.157731, -0.0543168, 0.0148241, -0.735105, -0.180265, -0.166484, -0.103128, -0.109698, -0.00259498, 0.182718, -0.109198, 0.0969643, -0.186748, -0.334232, 0.0689136, 0.0338752, 0.244466, -0.0105431, -0.173563, -0.0641034, -0.298655, -0.215757, -0.104969, -0.384455, 0.12258, -0.0573768, 0.0510888, 0.326332, -0.240637, -0.257625, 0.153459, -0.126468, -0.253084, -0.0462657, -0.0651791, 0.447512, 0.0240911, 0.311329, 0.00639972], "internal": 1}
{"paper_id": "P15-1166", "abstract": "In this paper, we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages. Our solution is inspired by the recently proposed neural machine translation model which generalizes machine translation as a sequence learning problem. We extend the neural machine translation to a multi-task learning framework which shares source language representation and separates the modeling of different target language translation. Our framework can be applied to situations where either large amounts of parallel data or limited parallel data is available. Experiments show that our multi-task learning model is able to achieve significantly higher translation quality over individually learned model in both situations on the data sets publicly available.", "title": "Multi-Task Learning for Multiple Language Translation", "venue": "P", "graph_vector": [0.110584, -0.0400846, 0.0312327, 0.232632, 0.488361, -0.52167, 0.363749, -0.285411, -1.35396, -0.293329, 0.294536, -0.258849, 0.537684, 0.0822299, -0.507214, 0.0874549, 0.432048, -0.566667, 0.0314855, 0.301012, -0.224494, 0.701921, 0.358572, -0.180768, -0.339721, 0.00732902, -0.080484, 0.09499, -0.0731531, -0.777654, 0.142087, -0.248379, 0.350543, -0.584015, -0.512603, 0.16936, -0.712445, 0.694949, 0.0604133, -0.310281, 0.0965232, -0.286115, -0.553143, 0.615869, 1.07445, -0.704455, 0.138317, -0.0809448, -0.314316, 0.0376641, 0.132466, -0.171811, 0.732144, 0.705779, -0.234482, 0.317435, 0.249099, 0.143984, 0.198286, 0.0992531, -0.151254, -0.0909208, -0.113134, 0.182771, 0.0132626, -0.234281, 0.269101, -0.156497, -0.0272263, -0.176433, 0.236733, -0.0795651, 0.421579, 0.0452308, 0.267775, -0.0939365, -0.683707, -0.18563, -0.0136795, -0.0381428, -0.00543182, 0.0508062, 0.13237, 0.0451932, 0.285587, -0.350441, 0.105053, -0.0978514, -0.0594299, -0.0970902, 0.504614, 0.4322, -0.666331, -0.160985, 0.0364605, -0.0762058, 0.121987, -0.122551, -0.162045, -0.331222, 0.158091, -0.42543, 0.108759, -0.0354979, 0.414224, 0.157003, -0.333684, 0.0121163, -0.0493366, 0.0544396, 0.428868, -0.275757, -0.454244, -0.135104, -0.25529, 0.291405, 0.475999, -0.130813, 0.0353372, 0.225083, -0.109074, -0.151687, -0.396462, -0.171852, 0.164494, 0.204499, -0.111168, 0.0447177], "internal": 1}
{"paper_id": "P15-4020", "abstract": "This paper presents QUEST++ , an open source tool for quality estimation which can predict quality for texts at word, sentence and document level. It also provides pipelined processing, whereby predictions made at a lower level (e.g. for words) can be used as input to build models for predictions at a higher level (e.g. sentences). QUEST++ allows the extraction of a variety of features, and provides machine learning algorithms to build and test quality estimation models. Results on recent datasets show that QUEST++ achieves state-of-the-art performance.", "title": "Multi-level Translation Quality Prediction with QUEST++", "venue": "P", "graph_vector": [-0.240117, 0.410512, 0.134059, 0.219697, 0.244181, -0.705118, 0.0441036, -0.11576, -1.52308, 0.092924, -0.216229, -0.290214, 0.39292, -0.39198, -0.36968, -0.155736, 0.411905, -1.02738, 0.0779346, 0.415406, -0.512214, 0.947492, 0.655786, 0.0553403, -0.481146, 0.191761, -0.375597, 0.190269, -0.180921, 0.0649469, -0.0989725, 0.0783729, 0.309686, 0.0617597, -0.345381, 0.213902, -0.23191, 0.798067, 0.051707, -0.0283721, -0.443996, -0.141326, -0.473015, 0.545073, 1.15737, -0.652926, -0.129965, 0.475571, -0.172557, -0.279415, 0.0957565, -0.0488379, 0.830148, 0.726403, -0.287742, 0.303581, 0.117115, -0.0904076, -0.463772, 0.199847, -0.325154, -0.310013, 0.153598, 0.224105, -0.315894, -0.0659866, 0.516802, -0.0327013, 0.413711, -0.322266, 0.173639, -0.13548, -0.512326, -0.201863, -0.100982, 0.213093, -0.0774137, -0.184242, -0.29465, -0.0696488, 0.0340308, 0.0597841, -0.0963231, -0.211695, 0.159519, -0.674458, 0.25158, -0.00427124, 0.20342, -0.0425946, 0.0108985, -0.315168, -0.704224, 0.225399, 0.0767904, -0.415591, -0.0269797, -0.0616743, 0.0836022, -0.00672278, -0.175773, -0.227149, 0.128416, -0.356283, 0.218931, 0.220304, -0.22521, 0.36068, 0.499934, -0.145107, 0.0890909, 0.130731, -0.192249, -0.0728467, -0.103699, 0.0614205, 0.35551, 0.487492, -0.0899939, -0.124435, -0.0491395, -0.175045, -0.00292994, 0.109951, 0.353427, 0.140099, 0.158918, 0.24805], "internal": 1}
{"paper_id": "P15-4025", "abstract": "We present a new toolkit - NiuParser for Chinese syntactic and semantic analysis. It can handle a wide range of Natural Language Processing (NLP) tasks in Chinese, including word segmentation, partof-speech tagging, named entity recognition, chunking, constituent parsing, dependency parsing, and semantic role labeling. The NiuParser system runs fast and shows state-of-the-art performance on several benchmarks. Moreover, it is very easy to use for both research and industrial purposes. Advanced features include the Software Development Kit (SDK) interfaces and a multi-thread implementation for system speed-up.", "title": "NiuParser: A Chinese Syntactic and Semantic Parsing Toolkit", "venue": "P", "graph_vector": [0.230826, 0.149142, -0.227037, 0.199996, 0.492786, -0.473488, 0.0400055, -0.120001, -1.44979, 0.120122, 0.182073, -0.449929, 0.506956, 0.0939682, -0.01412, -0.0201549, 0.82013, -0.652846, -0.226928, 0.350732, -0.282801, 0.519278, 0.430791, -0.0711783, -0.00655301, 0.0791717, 0.151768, 0.206184, -0.226641, -0.334803, 0.0384822, -0.280491, 0.247919, -0.620787, -0.160889, 0.207847, -0.438679, 0.601631, -0.110407, -0.144762, 0.0741546, -0.204717, -0.432721, 0.290519, 0.620742, -0.938234, -0.25764, 0.00759145, 0.151643, -0.134796, 0.137311, -0.0359229, 0.477652, 0.585192, -0.211739, 0.0231208, -0.0186687, 0.24981, -0.220674, 0.0725409, -0.243088, 0.094841, 0.0738284, 0.0107606, 0.0377455, -0.223268, 0.318109, -0.0534697, 0.0971043, 0.0104924, 0.00115476, -0.0811485, 0.280743, 0.153405, 0.284231, -0.262376, -0.401666, -0.485406, -0.0712151, 0.0230348, 0.0439251, -0.261474, 0.0416406, 0.345597, 0.347617, -0.0840933, 0.281257, -0.0410759, 0.30397, 0.179503, 0.465035, 0.173659, -0.632463, -0.339034, 0.295592, -0.359191, -0.405264, -0.142432, 0.0182154, -0.192112, 0.0777981, -0.116183, 0.28193, 0.254294, -0.670775, -0.0571154, -0.0325257, -0.134485, -0.135946, -0.340268, 0.0179323, 0.110349, 0.207946, 0.0496996, 0.187691, -0.018168, 0.204678, 0.19549, 0.0886621, -0.0179237, 0.231791, -0.0971191, 0.0784174, -0.445977, 0.254267, 0.312203, 0.0484566, -0.217667], "internal": 1}
{"paper_id": "P15-1125", "abstract": "Existing distributed representations are limited in utilizing structured knowledge to improve semantic relatedness modeling. We propose a principled framework of embedding entities that integrates hierarchical information from large-scale knowledge bases. The novel embedding model associates each category node of the hierarchy with a distance metric. To capture structured semantics, the entity similarity of context prediction are measured under the aggregated metrics of relevant categories along all inter-entity paths. We show that both the entity vectors and category distance metrics encode meaningful semantics. Experiments in entity linking and entity search show superiority of the proposed method.", "title": "Entity Hierarchy Embedding", "venue": "P", "graph_vector": [0.118538, 0.166633, -0.0507327, 0.690462, 0.362647, -0.859097, 0.0805766, -0.0219051, -1.41354, 0.24787, 0.129016, -0.747794, 0.703353, 0.38434, -0.247675, -0.238423, 0.172759, -0.45796, -0.110063, -0.0618242, -0.148135, 0.625307, 0.548823, -0.257496, -0.384366, 0.132695, -0.0423909, 0.397628, -0.0981403, 0.470544, -0.271808, -0.0193768, -0.00974427, -0.441814, -0.19278, -0.153847, -0.546099, 0.253101, 0.328463, -0.0400792, -0.116781, -0.703865, -0.238266, 0.620206, 0.977792, -1.00945, 0.265781, 0.0554673, -0.20652, -0.246374, 0.269997, -0.460912, 1.03089, 0.720492, -0.0116019, -0.278925, 0.207957, -0.0427477, -0.172689, 0.132703, -0.174602, -0.383507, -0.0661191, -0.305726, 0.0290102, 0.0521837, 0.4712, 0.0513982, 0.111642, 0.238382, -0.249979, 0.146437, -0.383479, -0.320076, 0.285252, -0.209648, -0.679565, -0.155113, 0.111989, 0.0271917, -0.0190387, -0.0275788, 0.211164, -0.121312, 0.175852, -0.336409, 0.377702, -0.308363, -0.194323, 0.217381, -0.11171, 0.404738, -0.620772, -0.0564526, -0.275665, -0.141959, 0.0564844, 0.0307671, 0.343194, -0.1672, -0.181873, -0.202238, 0.00367324, -0.193981, -0.213141, 0.240858, -0.0152394, -0.41626, -0.250515, -0.24538, -0.0861029, -0.130721, -0.276243, 0.12347, -0.0804113, -0.109772, 0.371704, 0.357707, -0.125718, 0.136743, -0.178241, 0.0772662, 0.101164, 0.253702, 0.2071, -0.046632, -0.0431679, 0.0355435], "internal": 1}
{"paper_id": "P15-1028", "abstract": "Over the last two decades, numerous algorithms have been developed that successfully capture something of the semantics of single words by looking at their distribution in text and comparing these distributions in a vector space model. However, it is not straightforward to construct meaning representations beyond the level of individual words – i.e. the combination of words into larger units – using distributional methods. Our contribution is twofold. First of all, we carry out a largescale evaluation, comparing different composition methods within the distributional framework for the cases of both adjectivenoun and noun-noun composition, making use of a newly developed dataset. Secondly, we propose a novel method for composition, which generalises the approach by Baroni and Zamparelli (2010). The performance of our novel method is also evaluated on our new dataset and proves competitive with the best methods.", "title": "A Generalisation of Lexical Functions for Composition in Distributional Semantics", "venue": "P", "graph_vector": [-0.050653, -0.0418146, 0.362334, 0.183385, 0.83821, -0.783533, 0.157495, -0.378207, -1.30136, 0.00874411, 0.0971821, -0.250206, 0.480001, 0.0433225, -0.216179, -0.0591348, 0.265813, -0.774214, 0.0997969, 0.322632, -0.254771, 0.629562, 0.2097, -0.238006, -0.336847, -0.00236913, -0.0927476, 0.309223, -0.247237, -0.0005105, -0.207722, -0.400965, 0.141048, -0.279976, -0.241011, -0.0358007, -0.206188, 0.833723, 0.0514386, -0.256919, 0.215474, -0.364995, 0.000377192, 0.229838, 1.11289, -0.857084, -0.213786, -0.0269763, -0.49378, 0.187912, 0.487622, -0.296807, 0.923268, 0.41101, -0.0408616, -0.41417, 0.39111, 0.112007, 0.0190852, 0.0428716, 0.224614, 0.140482, -0.290086, 0.0207474, 0.159587, 0.0996654, -0.0733371, 0.0987447, 0.104357, -0.190084, 0.254965, 0.204144, 0.138161, -0.0592381, 0.082784, -0.115982, -0.372959, -0.515282, -0.0180629, -0.281, -0.255015, -0.240481, 0.119535, -0.441332, 0.246972, -0.137537, -0.186911, 0.0664115, 0.11795, 0.0158385, 0.11462, -0.00215085, -0.388076, -0.121521, -0.162085, 0.157071, -0.238153, 0.0307138, 0.0847162, -0.156619, -0.170344, -0.146115, 0.0724265, 0.170794, 0.17453, 0.0240328, 0.217908, -0.176314, 0.144782, -0.320651, 0.0219313, 0.0315546, 0.144948, -0.195515, 0.386974, -0.207692, 0.279794, 0.552409, -0.0748187, 0.193882, -0.301314, 0.254758, -0.0842833, -0.0436627, 0.38894, -0.154553, -0.072548, 0.0740923], "internal": 1}
{"paper_id": "P15-1070", "abstract": "Traditional approaches to word sense disambiguation (WSD) rest on the assumption that there exists a single, unambiguous communicative intention underlying every word in a document. However, writers sometimes intend for a word to be interpreted as simultaneously carrying multiple distinct meanings. This deliberate use of lexical ambiguity—i.e., punning— is a particularly common source of humour. In this paper we describe how traditional, language-agnostic WSD approaches can be adapted to “disambiguate” puns, or rather to identify their double meanings. We evaluate several such approaches on a manually sense-annotated collection of English puns and observe performance exceeding that of some knowledge-based and supervised baselines.", "title": "Automatic disambiguation of English puns", "venue": "P", "graph_vector": [0.111959, 0.447759, -0.261671, -0.197004, 0.753636, -0.481092, 0.147911, -0.101649, -1.65002, 0.488159, -0.699277, -0.165198, 0.641871, 0.195193, -0.0569304, -0.154313, 0.81167, -0.80541, 0.164011, 0.471386, -0.453922, 0.280416, -0.0406488, -0.263313, -0.00593214, -0.317673, -0.274092, 0.611083, -0.183514, 0.0748283, -0.154119, -0.272052, -0.0213934, -0.43934, -0.182729, 0.343348, -0.708041, 0.632344, 0.19991, -0.2597, -0.306885, -0.319332, -0.382671, 0.0237346, 0.811011, -1.099, 0.176954, 0.280406, 0.0950663, -0.0934266, 0.495232, -0.410458, 0.998101, 0.876779, -0.0452677, -0.22272, 0.165025, -0.0369124, 0.19602, 0.5152, -0.298521, 0.223806, 0.0844662, -0.0352774, 0.657978, -0.244368, -0.31677, 0.239023, 0.186979, 0.364814, -0.296095, 0.37852, 0.0755871, -0.00668297, 0.16132, -0.177156, -0.408653, -0.129775, -0.283705, 0.189349, -0.279558, -0.283277, 0.0218465, 0.076064, 0.039592, -0.102781, 0.131596, 0.0112952, -7.34931e-05, 0.203671, -0.164337, -0.00854807, -0.733105, -0.369502, -0.00969322, 0.179123, 0.0660972, 0.231747, 0.117856, 0.0258213, 0.0434472, -0.082605, 0.154894, 0.235103, 0.0178202, 0.0780679, -0.124758, 0.208001, -0.229561, -0.688022, 0.308425, 0.189211, -0.0605544, 0.050244, -0.370254, 0.17652, 0.542957, 0.389136, -0.188188, 0.612249, -0.270356, 0.358214, -0.0395425, 0.247472, 0.450397, 0.00443731, 0.0127304, 0.248103], "internal": 1}
{"paper_id": "P15-1005", "abstract": "The Visual Dependency Representation (VDR) is an explicit model of the spatial relationships between objects in an image. In this paper we present an approach to training a VDR Parsing Model without the extensive human supervision used in previous work. Our approach is to find the objects mentioned in a given description using a state-of-the-art object detector, and to use successful detections to produce training data. The description of an unseen image is produced by first predicting its VDR over automatically detected objects, and then generating the text with a template-based generation model using the predicted VDR. The performance of our approach is comparable to a state-ofthe-art multimodal deep neural network in images depicting actions.", "title": "Describing Images using Inferred Visual Dependency Representations", "venue": "P", "graph_vector": [0.134094, 0.142782, -0.0168804, -0.066853, 0.668698, -0.96002, -0.0442662, -0.528523, -1.42344, 0.205616, 0.0135805, -0.445551, 0.683781, 0.309108, 0.0136357, 0.186094, 0.431519, -0.477038, 0.201359, 0.490922, -0.139669, 0.799745, 0.65579, -0.334257, -0.459078, -0.0881463, 0.209984, 0.0616698, -0.109108, -0.114709, -0.153239, 0.0488441, -0.00967894, -0.254866, -0.569992, 0.281113, -0.087628, 0.503163, 0.393807, -0.065688, 0.146041, -0.247947, -0.528336, 0.0125429, 1.19498, -0.992189, -0.00430957, -0.327129, -0.0148648, 0.0397977, 0.193246, 0.0651014, 0.987642, 0.630378, -0.0597193, -0.0838728, 0.211954, -0.0254349, -0.141367, 0.314059, 0.0685211, 0.16005, -0.183966, 0.384225, -0.247663, -0.238355, -0.0375681, -0.319768, 0.106508, 0.0620345, -0.194435, 0.283884, -0.170364, -0.0887926, 0.210029, 0.228822, -0.280416, -0.102952, -0.085607, -0.595411, -0.12744, 0.155019, 0.344992, -0.314894, -0.0982826, -0.0904395, 0.180969, -0.375064, 0.358344, -0.0106488, -0.137201, -0.505472, -0.742555, -0.189275, -0.060899, 0.0391061, 0.404474, 0.177733, -0.205392, -0.242547, -0.19804, -0.461395, 0.0869128, -0.0960055, 0.151647, 0.60055, -0.0993759, -0.0402064, 0.214618, -0.0220549, 0.0716088, -0.0836752, -0.130314, -0.0662734, 0.205931, -0.230989, 0.531703, 0.320398, 0.0369264, 0.450971, 0.379995, -0.0633737, -0.0344212, -0.0701917, 0.0941999, 0.072846, -0.572134, 0.330511], "internal": 1}
{"paper_id": "P15-1047", "abstract": "Spoken dialogue systems (SDS) typically require a predefined semantic ontology to train a spoken language understanding (SLU) module. In addition to the annotation cost, a key challenge for designing such an ontology is to define a coherent slot set while considering their complex relations. This paper introduces a novel matrix factorization (MF) approach to learn latent feature vectors for utterances and semantic elements without the need of corpus annotations. Specifically, our model learns the semantic slots for a domain-specific SDS in an unsupervised fashion, and carries out semantic parsing using latent MF techniques. To further consider the global semantic structure, such as inter-word and inter-slot relations, we augment the latent MF-based model with a knowledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner.", "title": "Matrix Factorization with Knowledge Graph Propagation for Unsupervised Spoken Language Understanding", "venue": "P", "graph_vector": [-0.140823, 0.0944339, 0.116982, 0.25389, 0.49095, -0.841224, 0.495974, -0.216857, -1.32445, 0.0424048, 0.154068, -0.195736, 0.891297, 0.183107, -0.556641, -0.10011, 0.830479, -0.421473, -0.32228, 0.125106, -0.300933, 0.237083, 0.851972, 0.166318, -0.513137, 0.210609, -0.27478, 0.0430203, -0.414699, 0.107554, 0.088239, -0.495251, 0.449003, -0.90419, -0.0624731, 0.295203, -0.356768, 0.741816, 0.220534, 0.0637463, -0.0874298, -0.410041, -0.348217, 0.672989, 0.857558, -0.678513, 0.0995474, 0.140368, 0.156395, 0.16298, 0.313024, 0.0182025, 0.986464, 0.603915, -0.00134643, 0.135001, 0.22482, 0.239912, -0.131439, 0.245613, -0.295872, -0.000931692, -0.111916, 0.0890667, -0.305488, 0.0596277, -0.0701042, -0.313224, 0.121779, 0.143669, 0.271504, -0.0905781, -0.288145, -0.225914, 0.179495, -0.226214, -0.0915382, -0.355912, 0.0588217, 0.374997, -0.169913, 0.371082, 0.326511, 0.116151, 0.1227, -0.544161, 0.304533, -0.170732, -0.0138963, 0.386836, 0.45551, 0.387672, -0.822838, -0.267252, -0.114528, 0.175327, -0.00686372, 0.311866, -0.018174, -0.0824538, -0.164517, -0.389193, -0.0270641, 0.130278, 0.155902, 0.546356, 0.435264, -0.396255, 0.0322927, 0.22461, -0.0115792, 0.058662, -0.308738, 0.35524, -0.127533, 0.0437284, 0.210081, 0.341287, 0.121762, 0.337005, -0.26488, -0.00931467, 0.176856, -0.517382, 0.18153, 0.319433, 0.0786173, -0.0361369], "internal": 1}
{"paper_id": "P15-2002", "abstract": "Computing pairwise word semantic similarity is widely used and serves as a building block in many tasks in NLP. In this paper, we explore the embedding of the shortest-path metrics from a knowledge base (Wordnet) into the Hamming hypercube, in order to enhance the computation performance. We show that, although an isometric embedding is untractable, it is possible to achieve good non-isometric embeddings. We report a speedup of three orders of magnitude for the task of computing Leacock and Chodorow (LCH) similarity while keeping strong correlations (r = .819, p = .826).", "title": "On metric embedding for boosting semantic similarity computations", "venue": "P", "graph_vector": [-0.130152, 0.128876, -0.151501, 0.538666, 0.286607, -0.558173, 0.243017, -0.408004, -1.46226, 0.296978, 0.0417234, -0.173224, 0.65261, 0.212368, -0.0788826, -0.228652, 0.535722, -0.555501, -0.133032, 0.26966, -0.272015, 0.685092, 0.288519, 0.0751794, -0.24386, 0.172083, -0.104787, 0.153086, 0.260695, 0.0442683, -0.44345, -0.168051, -0.286334, -0.264346, 0.0402743, 0.0970374, -0.267338, 0.351981, 0.171741, 0.026792, -0.022982, -0.674562, -0.373707, 0.0895143, 0.922916, -0.856224, 0.0410711, -0.197865, 0.00726351, -0.374925, 0.282593, -0.150657, 0.969956, 0.468527, -0.117172, -0.234748, 0.36188, 0.135826, -0.0780786, -0.108499, 0.229764, -0.324383, 0.0861947, -0.195202, 0.0827814, -0.0988903, -0.0290363, -0.0213271, 0.125936, 0.369272, -0.0284857, 0.169687, 0.505339, -0.353904, -0.0787593, -0.123651, -0.501557, -0.79483, 0.0284274, 0.0157317, 0.0666302, -0.161961, 0.29453, 0.178023, 0.193441, -0.372755, 0.088057, -0.162498, -0.0628874, -0.0228858, -0.0123645, 0.492854, -0.713165, -0.142052, -0.142908, 0.0269315, 0.0981085, -0.0800336, 0.162924, -0.110039, 0.0418178, 0.199361, 0.0760954, 0.121627, -0.150503, 0.410277, -0.102729, -0.270697, -0.149318, -0.274613, 0.236467, -0.164654, 0.0359994, 0.0507076, 0.0927606, 0.0707063, 0.0448997, 0.389866, -0.0649554, 0.214033, -0.359525, 0.0484462, 0.374672, -0.130558, 0.516362, 0.122427, -0.151984, 0.180434], "internal": 1}
{"paper_id": "P15-2003", "abstract": "In recent years, there has been an increasing interest in learning a distributed representation of word sense. Traditional context clustering based models usually require careful tuning of model parameters, and typically perform worse on infrequent word senses. This paper presents a novel approach which addresses these limitations by first initializing the word sense embeddings through learning sentencelevel embeddings from WordNet glosses using a convolutional neural networks. The initialized word sense embeddings are used by a context clustering based model to generate the distributed representations of word senses. Our learned representations outperform the publicly available embeddings on 2 out of 4 metrics in the word similarity task, and 6 out of 13 sub tasks in the analogical reasoning task.", "title": "Improving Distributed Representation of Word Sense via WordNet Gloss Composition and Context Clustering", "venue": "P", "graph_vector": [0.246356, 0.202857, 0.0444242, 0.108619, 0.372665, -0.731216, 0.262567, -0.172422, -1.66569, 0.197753, -0.0545039, -0.680702, 0.423653, -0.00104571, -0.0619125, -0.236728, 0.138374, -0.387123, 0.00883093, 0.321047, -0.219302, 0.599445, 0.188726, -0.102835, -0.320609, 0.259298, -0.164668, 0.171323, 0.0575111, -0.274517, -0.145006, -0.267226, 0.268954, -0.62303, -0.433771, 0.047623, -0.319105, 0.486978, 0.261, -0.0504926, -0.210692, -0.548765, -0.47768, 0.337957, 0.983973, -0.836235, 0.118385, -0.210841, -0.274311, -0.344494, 0.0616013, -0.241019, 0.946822, 0.543133, 0.0877657, -0.11206, 0.375853, 0.107348, 0.0629971, 0.0671508, -0.12366, -0.151353, -0.051857, 0.153935, -0.00131616, 0.0263476, 0.217417, -0.0673493, 0.324196, -0.168528, -0.12924, 0.214114, 0.27565, -0.118385, 0.167845, -0.120118, -0.460945, -0.439686, 0.14439, -0.110959, -0.0557007, 0.118809, 0.518127, 0.0853738, 0.339342, -0.327367, 0.137287, -0.133651, 0.0637863, -0.278483, 0.159452, 0.131347, -0.737009, -0.014192, -0.211746, -0.0299501, -0.0669751, 0.0653001, 0.113698, -0.142865, -0.383489, -0.235877, -0.00782773, -0.0458948, -0.204806, 0.256055, -0.0619233, -0.191216, 0.00397779, -0.138483, 0.207471, 0.0277442, -0.401707, 0.163881, 0.0332884, 0.351005, 0.582164, 0.116692, 0.0629622, 0.220637, -0.105443, 0.0640559, 0.198706, -0.0925077, 0.161478, -0.0915219, 0.232298, -0.108584], "internal": 1}
{"paper_id": "P15-1015", "abstract": "We present paired learning and inference algorithms for significantly reducing computation and increasing speed of the vector dot products in the classifiers that are at the heart of many NLP components. This is accomplished by partitioning the features into a sequence of templates which are ordered such that high confidence can often be reached using only a small fraction of all features. Parameter estimation is arranged to maximize accuracy and early confidence in this sequence. Our approach is simpler and better suited to NLP than other related cascade methods. We present experiments in left-to-right part-of-speech tagging, named entity recognition, and transition-based dependency parsing. On the typical benchmarking datasets we can preserve POS tagging accuracy above 97% and parsing LAS above 88.5% both with over a five-fold reduction in run-time, and NER F1 above 88 with more than 2x increase in speed.", "title": "Learning Dynamic Feature Selection for Fast Sequential Prediction", "venue": "P", "graph_vector": [-0.170806, 0.0930555, 0.133067, 0.677281, 0.491868, -0.967747, -0.261224, -0.215461, -1.58838, 0.119585, -0.101257, -0.218522, 0.784601, 0.212531, 0.0380265, -0.445126, 0.416685, -0.204974, 0.208592, 0.320447, -0.412069, 0.417096, -0.168536, -0.309936, -0.220456, 0.329897, -0.160118, 0.512564, -0.208326, -0.157851, -0.0206707, -0.00393826, -0.197958, -0.204097, -0.394722, 0.217326, -0.414809, 0.656406, 0.0893553, -0.436559, -0.0101572, -0.446597, -0.521486, 0.544819, 0.321223, -1.12695, 0.363632, 0.0514885, -0.169098, 0.0874949, 0.469751, -0.295051, 0.781624, 0.940145, 0.219737, 0.256009, -0.438151, 0.344727, -0.416795, -0.058486, 0.0625999, 0.147598, -0.347947, -0.145166, -0.389784, -0.145101, 0.246141, 0.00202786, -0.12836, 0.396968, -0.200275, -0.0722597, 0.188778, -0.180652, 0.230724, 0.23483, -0.415937, -0.627475, -0.562213, -0.173187, -0.278395, 0.278945, 0.0267679, -0.00280861, -0.12897, -0.276468, -0.167683, 0.0556417, -0.0173805, -0.0403224, -0.0224011, -0.279443, -0.677552, 0.254725, 0.00379641, -0.366468, -0.514452, -0.228524, 0.0704253, -0.000529819, -0.286967, -0.157125, 0.493095, 0.108689, 0.0490493, 0.0970558, -0.210002, 0.132529, 0.478453, 0.00199303, -0.091182, -0.315906, -0.175755, -0.386345, 0.246789, 0.266853, 0.364456, 0.425246, 0.245611, 0.68144, 0.0406552, -0.0132468, 0.369794, -0.538448, 0.604237, -0.0716021, 0.0746178, 0.0631819], "internal": 1}
{"paper_id": "P15-1045", "abstract": "We propose an event-driven model for headline generation. Given an input document, the system identifies a key event chain by extracting a set of structural events that describe them. Then a novel multi-sentence compression algorithm is used to fuse the extracted events, generating a headline for the document. Our model can be viewed as a novel combination of extractive and abstractive headline generation, combining the advantages of both methods using event structures. Standard evaluation shows that our model achieves the best performance compared with previous state-of-the-art systems.", "title": "Event-Driven Headline Generation", "venue": "P", "graph_vector": [-0.129113, 0.124845, -0.156425, 0.24412, 0.644588, -0.989927, -0.100856, -0.154708, -1.54242, 0.198389, -0.10923, -0.28789, 0.714903, 0.334886, -0.00229243, 0.215621, 0.382036, -0.762753, -0.583669, 0.310737, 0.0278807, 0.590757, 0.14763, -0.171937, -0.264563, -0.250356, 0.162861, 0.426145, 0.364138, -0.39563, 0.0435107, -0.127648, 0.332384, -0.530828, -0.132351, -0.0560982, -0.445385, 0.307838, 0.331308, -0.0671732, 0.0304996, -0.520333, 0.100461, 0.149016, 0.881856, -0.760247, -0.376825, 0.292935, -0.317918, -0.419646, 0.47876, -0.0220982, 0.447255, 0.506169, -0.185083, 0.216832, 0.0516706, 0.406183, 0.0246947, 0.330606, -0.413064, -0.567201, 0.0303734, 0.122097, -0.167478, -0.128426, 0.266103, -0.158973, 0.329585, -0.110646, -0.0537785, -0.134208, -0.0930864, 0.132292, 0.644426, -0.0890465, -0.322445, -0.0905097, -0.200225, -0.0245432, -0.0702481, -0.0373012, 0.0529231, 0.172062, 0.119347, -0.536687, -0.157663, 0.2661, 0.0899224, 0.0324926, -0.0630568, 0.26421, -1.04124, -0.43856, -0.164337, -0.105855, 0.0531245, -0.790546, -0.290131, 0.0533544, -0.22859, -0.389095, -0.0256933, -0.0842616, -0.0054346, 0.0699422, -0.199283, -0.380809, 0.222242, 0.0797088, 0.062068, -0.219565, 0.182917, -0.142989, 0.178151, -0.216527, 0.107271, 0.030401, -0.06152, 0.155999, 0.0133679, -0.0607788, 0.0802827, -0.238691, 0.340757, 0.0966824, -0.0182454, 0.0546261], "internal": 1}
{"paper_id": "P15-1072", "abstract": "Semantic representation lies at the core of several applications in Natural Language Processing. However, most existing semantic representation techniques cannot be used effectively for the representation of individual word senses. We put forward a novel multilingual concept representation, called MUFFIN, which not only enables accurate representation of word senses in different languages, but also provides multiple advantages over existing approaches. MUFFIN represents a given concept in a unified semantic space irrespective of the language of interest, enabling cross-lingual comparison of different concepts. We evaluate our approach in two different evaluation benchmarks, semantic similarity and Word Sense Disambiguation, reporting state-of-the-art performance on several standard datasets.", "title": "A Unified Multilingual Semantic Representation of Concepts", "venue": "P", "graph_vector": [-0.0255815, 0.0869876, 0.206414, 0.0295542, 0.41738, -0.811085, 0.271437, -0.245506, -1.38993, 0.260804, 0.0532377, -0.35364, 0.51289, 0.108704, -0.401388, -0.302381, 0.52987, -0.484948, -0.109042, 0.423118, -0.0734361, 0.517731, 0.157404, -0.0297901, -0.131981, 0.278434, -0.133308, 0.411213, -0.0834332, -0.0550883, 0.123866, -0.0883697, 0.0305643, -0.121488, -0.433196, -0.00944189, -0.580915, 0.490051, 0.06256, 0.0674411, -0.168419, -0.393867, -0.138647, 0.279249, 1.04393, -0.756877, 0.220688, -0.186738, -0.00286677, 0.00256541, 0.386601, 0.111336, 0.824251, 0.693269, -0.246903, -0.243031, 0.2733, 0.286443, -0.382135, -0.130002, -0.420824, -0.359725, 0.126767, -0.14596, 0.342194, 0.0765803, 0.249426, 0.029811, 0.00262294, 0.0319454, -0.152928, 0.0898332, 0.0225302, -0.499527, 0.0879719, -0.192916, -0.659484, -0.12554, -0.0255765, -0.195752, -0.0255887, -0.136102, 0.221517, 0.0918095, -0.159203, -0.23007, -0.0862327, -0.01608, 0.115843, -0.055225, 0.013137, 0.0997067, -0.83635, -0.333428, -0.451624, -0.0454289, -0.00016348, -0.244507, 0.170788, -0.0368406, -0.164803, -0.227341, -0.154729, 0.0882869, -0.122414, 0.122613, -0.498794, -0.0664686, 0.079249, 0.028796, -0.226569, 0.14114, -0.339833, 0.371093, 0.0995932, -0.00605317, 0.213232, 0.151789, -0.173954, 0.398318, -0.2178, -0.00339101, -0.318996, 0.0203789, 0.245577, 0.0362321, 0.218319, 0.285151], "internal": 1}
{"paper_id": "P15-1001", "abstract": "Neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrasebased statistical machine translation. Despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to match, and in some cases outperform, the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore, when we use an ensemble of a few models with very large target vocabularies, we achieve performance comparable to the state of the art (measured by BLEU) on both the English→German and English→French translation tasks of WMT’14.", "title": "On Using Very Large Target Vocabulary for Neural Machine Translation", "venue": "P", "graph_vector": [0.203311, 0.00506663, 0.106884, 0.147084, 0.476573, -0.809368, 0.20725, -0.275461, -1.40469, 0.0841915, 0.18687, -0.332193, 0.547003, 0.018399, 0.0645858, -0.257714, 0.509783, -0.339382, 0.0815192, 0.381941, -0.200368, 0.623491, 0.422042, -0.0279956, -0.685848, 0.0175925, -0.22631, 0.270671, -0.183235, -0.742792, 0.137824, -0.00221261, 0.0645065, -0.448902, -0.512435, 0.400161, -0.321645, 0.841049, 0.199523, -0.00847234, -0.162152, -0.298492, -0.214319, 0.601531, 1.22015, -1.16308, 0.256296, 0.228351, -0.132595, -0.22316, 0.436595, -0.212559, 0.643676, -0.0276974, -0.0932125, 0.176974, 0.254747, 0.289271, -0.128055, 0.214718, -0.142518, -0.191958, -0.272496, -0.154095, 0.00268666, -0.166191, 0.0947643, -0.138082, -0.380876, 0.216909, 0.328047, -0.155483, -0.0152028, -0.438821, 0.328435, 0.0541, -0.56659, -0.133115, 0.0981788, -0.324444, -0.178357, 0.129788, 0.232158, 0.100779, 0.242183, -0.526819, 0.15646, -0.170897, -0.134425, -0.136405, 0.363655, 0.335755, -0.739634, -0.0047004, -0.244882, 0.08783, 0.238485, 0.192072, -0.429997, 0.0476543, -0.118765, -0.468771, -0.164388, 0.10141, -0.214229, 0.20089, 0.170165, -0.00130784, -0.186747, 0.0252927, 0.483355, 0.0525959, -0.244311, 0.233232, -0.109761, 0.18534, 0.361331, 0.176209, -0.148909, 0.0424207, 0.00168541, 0.334234, 0.194777, -0.43518, 0.352523, 0.150334, 0.0928732, 0.271621], "internal": 1}
{"paper_id": "P15-1061", "abstract": "Relation classification is an important semantic processing task for which state-ofthe-art systems still rely on costly handcrafted features. In this work we tackle the relation classification task using a convolutional neural network that performs classification by ranking (CR-CNN). We propose a new pairwise ranking loss function that makes it easy to reduce the impact of artificial classes. We perform experiments using the the SemEval-2010 Task 8 dataset, which is designed for the task of classifying the relationship between two nominals marked in a sentence. Using CRCNN, we outperform the state-of-the-art for this dataset and achieve a F1 of 84.1 without using any costly handcrafted features. Additionally, our experimental results show that: (1) our approach is more effective than CNN followed by a softmax classifier; (2) omitting the representation of the artificial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals.", "title": "Classifying Relations by Ranking with Convolutional Neural Networks", "venue": "P", "graph_vector": [0.20467, 0.102, 0.382111, 0.173781, 0.628119, -0.368051, 0.0591112, -0.272296, -1.16662, 0.359114, -0.00290819, -0.099331, 0.437257, 0.109273, 0.0064023, -0.0277679, 0.421462, -0.508528, -0.0652633, 0.399488, -0.284778, 0.707628, 0.313397, -0.021051, -0.425442, 0.175987, -0.0141554, -0.00575257, -0.216212, -0.597789, -0.24478, -0.185313, 0.188461, -0.765673, -0.10293, 0.0535388, -0.389629, 0.938376, -0.0184597, -0.0871293, 0.0199349, -0.552189, -0.405443, 0.442716, 1.17805, -1.00334, -0.0190543, -0.224337, -0.297097, 0.0902294, 0.491798, -0.228711, 0.926521, 0.563515, 0.3744, -0.00873617, 0.186367, -0.0240037, -0.187088, 0.116692, 0.0870842, -0.13825, -0.269498, -0.069809, 0.235351, -0.213098, 0.00878364, -0.223435, 0.100388, -0.248692, -0.256931, 0.0308795, 0.254577, 0.177316, 0.416913, -0.246029, -0.603029, -0.291966, 0.120969, -0.342423, -0.197422, -0.0411637, 0.275525, 0.121016, 0.384459, -0.262254, 0.139491, -0.15304, -0.159652, -0.199744, 0.386762, 0.355772, -0.773859, -0.220046, 0.0633491, -0.145634, -0.0792637, -0.0852357, -0.635062, -0.445818, 0.113839, -0.00135583, -0.266896, -0.136792, 0.237369, -0.106007, 0.0844529, -0.290393, -0.0348812, -0.20222, -0.0185094, 0.0400856, -0.0359793, -0.0443893, -0.185217, 0.0437657, 0.383951, 0.127205, -0.0918876, 0.515143, 0.0616167, 0.110785, -0.0925811, 0.0557787, 0.426164, -0.250656, 0.165249, 0.209245], "internal": 1}
{"paper_id": "P15-1035", "abstract": "A standard pipeline for statistical relational learning involves two steps: one first constructs the knowledge base (KB) from text, and then performs the learning and reasoning tasks using probabilistic first-order logics. However, a key issue is that information extraction (IE) errors from text affect the quality of the KB, and propagate to the reasoning task. In this paper, we propose a statistical relational learning model for joint information extraction and reasoning. More specifically, we incorporate context-based entity extraction with structure learning (SL) in a scalable probabilistic logic framework. We then propose a latent context invention (LCI) approach to improve the performance. In experiments, we show that our approach outperforms state-of-the-art baselines over three real-world Wikipedia datasets from multiple domains; that joint learning and inference for IE and SL significantly improve both tasks; that latent context invention further improves the results.", "title": "Joint Information Extraction and Reasoning: A Scalable Statistical Relational Learning Approach", "venue": "P", "graph_vector": [-0.179861, 0.243026, 0.25928, 0.0452811, 0.463564, -0.676692, 0.196411, 0.0531684, -1.56285, 0.478833, 0.232481, -0.315393, 0.488512, 0.0894955, -0.180826, 0.312246, 0.789647, -0.658987, -0.167928, 0.492946, -0.319244, 0.349823, 0.472132, 0.032522, -0.150892, 0.361181, -0.247815, -0.0279955, 0.0482447, 0.0671976, -0.027377, -0.107603, 0.520386, -0.60524, 0.218805, 0.0711818, -0.749046, 0.865646, 0.419699, -0.0336288, 0.11342, -0.343366, -0.322401, 0.600641, 1.05699, -0.498415, 0.0588453, 0.0466057, 0.25781, 0.152723, 0.523341, -0.14781, 0.492613, 0.534954, -0.0627854, 0.19391, 0.111437, 0.485826, 0.0212175, 0.250174, -0.374959, -0.251176, -0.145185, -0.141484, -0.146026, 0.109885, 0.00122876, -0.452629, 0.000240805, 0.184437, 0.377842, 0.19264, -0.0905265, 0.130539, 0.27618, 0.186522, -0.447433, -0.233825, -0.131681, -0.21488, -0.0197748, 0.234722, -0.0679139, -0.717908, 0.136327, -0.580824, -0.197388, -0.116009, 0.349458, 0.638602, 0.457461, 0.207454, -0.810855, -0.00785769, -0.0269564, 0.00917404, -0.0670167, -0.141946, 0.0120046, -0.204404, -0.225512, -0.293546, 0.269648, 0.0149453, -0.0322306, 0.0223031, -0.178486, -0.179581, 0.0380923, -0.123993, -0.153078, -0.119874, -0.19799, 0.154355, -0.414863, -0.200198, -0.00549902, 0.168864, -0.0321246, 0.161986, -0.256476, -0.404581, 0.0327865, 0.153441, 0.307224, -0.0685133, 0.160522, 0.186971], "internal": 1}
{"paper_id": "P15-1123", "abstract": "This paper describes a novel sequence labeling method for identifying generic expressions, which refer to kinds or arbitrary members of a class, in discourse context. The automatic recognition of such expressions is important for any natural language processing task that requires text understanding. Prior work has focused on identifying generic noun phrases; we present a new corpus in which not only subjects but also clauses are annotated for genericity according to an annotation scheme motivated by semantic theory. Our contextaware approach for automatically identifying generic expressions uses conditional random fields and outperforms previous work based on local decisions when evaluated on this corpus and on related data sets (ACE-2 and ACE-2005).", "title": "Discourse-sensitive Automatic Identification of Generic Expressions", "venue": "P", "graph_vector": [-0.222337, 0.641287, 0.418498, 0.242252, 0.138037, -0.765643, -0.371965, -0.212796, -1.79669, 0.473581, -0.268866, -0.416961, 0.0888794, 0.209341, -0.133314, 0.281949, 0.351631, -0.55831, 0.249921, 0.222945, -0.55838, 0.580025, 0.0550238, 0.150998, -0.428055, -0.149659, 0.0961917, 0.138556, 0.0744585, -0.335031, -0.175851, 0.0806706, 0.0606253, -0.00538597, 0.0884602, 0.246395, -0.407924, 0.938638, 0.465453, -0.119208, -0.0285397, -0.174246, -0.4047, 0.132528, 0.526471, -0.57338, 0.183327, 0.0874309, 0.100401, -0.474852, 0.447573, 0.064453, 0.44521, 0.74249, -0.102361, 0.0647789, 0.114892, 0.114618, -0.0498629, 0.0484886, -0.0296597, 0.0271446, -0.0696187, -0.235457, 0.0711048, 0.216783, 0.411923, 0.0596109, -0.0432203, -0.294712, 0.0788697, -0.178878, 0.160258, -0.0733881, 0.0374985, -0.146938, -0.544736, -0.302438, -0.553301, 0.409965, -0.233732, -0.278686, 0.192291, -0.176643, 0.297371, -0.300181, 0.115365, 0.354124, 0.463951, 0.011645, 0.440425, -0.224675, -0.5862, -0.180212, -0.0629784, -0.24996, -0.119519, 0.20808, -0.0334822, -0.373344, -0.153222, 0.065529, -0.127771, 0.339154, -0.473912, 0.294308, 0.360417, 0.0467151, -0.140975, -0.0189795, 0.134505, 0.498169, -0.00681577, -0.168627, 0.0410887, 0.0793262, 0.488578, -0.228372, 0.105069, 0.18941, -0.257271, -0.163265, 0.0596133, -0.099843, 0.0809508, 0.281748, -0.200498, -0.742519], "internal": 1}
{"paper_id": "P15-1170", "abstract": "Tracking topics on social media streams is non-trivial as the number of topics mentioned grows without bound. This complexity is compounded when we want to track such topics against other fast moving streams. We go beyond traditional small scale topic tracking and consider a stream of topics against another document stream. We introduce two tracking approaches which are fully applicable to true streaming environments. When tracking 4.4 million topics against 52 million documents in constant time and space, we demonstrate that counter to expectations, simple single-pass clustering can outperform locality sensitive hashing for nearest neighbour search on streams.", "title": "Tracking unbounded Topic Streams", "venue": "P", "graph_vector": [0.336049, 0.328985, -0.158562, 0.353934, 0.935447, -0.609515, -0.302692, 0.301344, -1.89128, 0.00810895, -0.1664, -0.336597, 0.994006, -0.0352337, 0.361616, 0.263513, 0.71804, -0.819789, 0.19429, 0.341709, -0.0930686, 0.453839, 0.398612, 0.157755, -0.616829, -0.124699, 0.570619, 0.405104, 0.260748, 0.0225161, 0.281844, -0.227297, 0.311005, -0.748989, -0.524363, 0.0103691, -0.225885, 0.175118, 0.352377, -0.18549, 0.0307601, -0.722454, -0.481057, 0.568186, 0.959488, -0.923941, 0.0756789, 0.0535335, -0.130899, 0.153923, 0.1653, -0.237534, 1.07661, 1.01128, -0.18827, 0.341978, -0.407461, 0.120863, -0.00047582, -0.14202, -0.798794, 0.220731, -0.20256, -0.390945, -0.466426, -0.20306, 0.367311, -0.00233672, 0.253832, -0.0527805, 0.0821839, -0.267498, 0.215647, -0.468288, -0.255921, 0.24235, -0.417764, -0.47643, -0.0325425, -0.0442607, -0.180761, -0.0351805, 0.197905, -0.0608617, 0.0648641, -0.393021, -0.29418, -0.0252776, -0.0708455, 0.115355, 0.287588, 0.172482, -0.927996, -0.182049, -0.0075129, 0.462369, 0.118895, -0.35979, -0.189326, -0.429094, -0.154268, -0.193625, -0.00596916, -0.0646519, 0.114411, -0.363241, 0.0944542, -0.426609, -0.26184, -0.123224, -0.0691672, -0.158137, 0.346227, 0.374539, -0.592737, -0.527196, 0.122648, -0.142853, -0.225708, 0.46693, -0.432303, 0.131337, 0.21373, -0.00445841, 0.799588, 0.327542, -0.271867, 0.486668], "internal": 1}
{"paper_id": "P15-1104", "abstract": "We investigate a technique to adapt unsupervised word embeddings to specific applications, when only small and noisy labeled datasets are available. Current methods use pre-trained embeddings to initialize model parameters, and then use the labeled data to tailor them for the intended task. However, this approach is prone to overfitting when the training is performed with scarce and noisy data. To overcome this issue, we use the supervised data to find an embedding subspace that fits the task complexity. All the word representations are adapted through a projection into this task-specific subspace, even if they do not occur on the labeled dataset. This approach was recently used in the SemEval 2015 Twitter sentiment analysis challenge, attaining state-of-the-art results. Here we show results improving those of the challenge, as well as additional experiments in a Twitter Part-Of-Speech tagging task.", "title": "Learning Word Representations from Scarce and Noisy Data with Embedding Sub-spaces", "venue": "P", "graph_vector": [-0.0193269, 0.348026, 0.182041, 0.129933, 0.681593, -0.958445, 0.0776273, -0.109814, -1.40359, 0.0216464, 0.104635, -0.366823, 0.250344, -0.363817, 0.135654, 0.127164, 0.49519, -0.527817, -0.194769, 0.184648, -0.0329966, 0.621937, 0.0189717, -0.235365, -0.446328, 0.267149, 0.066691, 0.0463347, -0.0972588, -0.330438, 0.117643, -0.0986921, -0.00401901, -0.55234, -0.191031, 0.281014, -0.351547, 0.368035, 0.128468, -0.139754, -0.0192726, -0.428167, -0.461674, 0.389866, 0.72778, -0.943532, 0.0454815, -0.159462, -0.214711, -0.013486, 0.293607, -0.694913, 0.960574, 0.652259, 0.16307, 0.102541, 0.0151082, 0.281905, -0.410593, -0.0156469, -0.188466, 0.140116, -0.0815534, -0.281761, 0.151728, 0.186489, 0.194496, -0.251628, 0.175867, -0.00348881, 0.147324, 0.264371, -0.209507, -0.174822, 0.0884209, 0.0425495, -0.456507, -0.537418, 0.0461831, -0.0826744, -0.167393, 0.00395949, 0.234121, 0.282836, 0.266006, -0.532201, 0.0784038, -0.270053, -0.215223, -0.185119, 0.146051, 0.106613, -0.863558, -0.0864123, -0.0592982, 0.0378965, -0.0232444, 0.390941, -0.00643344, 0.206441, -0.0772861, -0.264918, 0.0312422, -0.231938, -0.199459, 0.100821, -0.0803261, -0.268673, -0.375572, -0.293796, 0.249137, -0.127012, -0.154741, 0.0285069, -0.212338, 0.21728, 0.223727, -0.0458592, 0.0420341, 0.234645, -0.0280176, -0.0152249, -0.11506, 0.191651, 0.204876, 0.108842, -0.0539024, 0.188403], "internal": 1}
{"paper_id": "P15-1002", "abstract": "Neural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement an effective technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT’14 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique. With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT’14 contest task.", "title": "Addressing the Rare Word Problem in Neural Machine Translation", "venue": "P", "graph_vector": [0.359968, -0.0677516, 0.0164627, 0.100551, 0.685538, -0.934787, 0.229283, -0.0286675, -1.71656, -0.0784572, 0.233669, -0.406929, 0.125852, 0.233931, 0.0144297, -0.246944, 0.447176, -0.104927, -0.186352, 0.456424, -0.208589, 0.508087, 0.322979, -0.216611, -0.451247, 0.367065, -0.0975895, 0.16829, -0.229796, -0.320705, -0.0138776, -0.0229009, -0.10615, -0.710742, -0.288561, 0.22949, -0.327746, 0.704817, 0.515955, -0.13035, -0.0975163, -0.273083, -0.515903, 0.668293, 1.04498, -0.933935, 0.0649323, -0.135073, -0.434995, -0.0245725, 0.154551, -2.96277e-05, 0.541896, 0.580236, 0.127767, 0.128791, 0.293492, 0.139351, 0.0867767, 0.0580119, 0.104253, -0.00377325, -0.0342751, 0.0587289, -0.115651, -0.208362, 0.242193, 0.181239, -0.124611, 0.0183464, 0.188104, -0.132794, 0.156663, -0.313988, 0.468129, -0.147004, -0.657542, -0.0968205, 0.0096906, 0.0133953, -0.129964, -0.018209, 0.155241, -0.114094, 0.00381171, -0.526945, -0.0201656, -0.160695, -0.166978, -0.0479915, 0.168378, 0.0569539, -0.712364, 0.126783, 0.0558574, 0.00398401, 0.0356945, 0.0868681, -0.301201, -0.0649135, -0.0992805, -0.281619, -0.0857323, 0.0343889, 0.0177217, 0.108483, 0.317609, -0.220364, -0.0407066, -0.0578312, 0.372678, 0.255524, -0.202548, 0.0215208, -0.38181, -0.0331913, 0.257115, 0.0828591, 0.0103633, 0.17364, 0.0449491, 0.262909, -0.214763, -0.127793, 0.271135, 0.296099, 0.0455074, 0.335412], "internal": 1}
{"paper_id": "P15-2125", "abstract": "Code-switching is commonly used in the free-form text environment, such as social media, and it is especially favored in emotion expressions. Emotions in codeswitching texts differ from monolingual texts in that they can be expressed in either monolingual or bilingual forms. In this paper, we first utilize two kinds of knowledge, i.e. bilingual and sentimental information to bridge the gap between different languages. Moreover, we use a term-document bipartite graph to incorporate both bilingual and sentimental information, and propose a label propagation based approach to learn and predict in the bipartite graph. Empirical studies demonstrate the effectiveness of our proposed approach in detecting emotion in code-switching texts.", "title": "Emotion Detection in Code-switching Texts via Bilingual and Sentimental Information", "venue": "P", "graph_vector": [0.137442, 0.227515, 0.124449, 0.292928, 0.567598, -1.06841, 0.125237, -0.260264, -1.69277, -0.23468, -0.381399, 0.332913, 0.489934, -0.108959, 0.132948, 0.394179, 0.424915, -0.947675, -0.107671, 0.541565, -0.418918, 0.449611, 0.568215, 0.395905, 0.00617867, 0.0855815, -0.0945419, -0.253921, -0.489005, -0.202424, -0.357502, -0.422994, -0.0791304, -0.348084, 0.00740238, 0.112784, -0.309042, 0.622299, 0.321794, -0.335883, 0.339802, -0.494462, 0.011763, 0.85444, 0.792406, -1.17073, -0.0863141, -0.0856501, 0.0367795, 0.127924, 0.0956692, -0.213692, 0.918949, 0.500779, -0.0223622, 0.0444044, 0.422767, 0.466447, 0.199997, -0.047447, -0.434763, 0.0608709, 0.0771892, 0.243894, -0.0909311, -0.0444114, -0.106308, -0.0804158, -0.135277, -0.0246981, -0.00136001, 0.246436, 0.103657, -0.129599, 0.209973, 0.107593, -0.460473, -0.501606, -0.0910166, 0.185052, -0.399575, -0.236114, 0.467161, 0.00344831, 0.293391, -0.217286, 0.315816, -0.113292, -0.329302, -0.354116, -0.284299, -0.0345279, -0.421018, 0.0491246, -0.197171, 0.207662, 0.175066, 0.104157, -0.135286, -0.130617, -0.335014, -0.751486, -0.511708, -0.0660043, 0.00909944, -0.0393909, -0.398652, 0.196729, 0.213015, -0.194927, -0.230459, -0.105087, 0.103499, -0.137674, -0.140854, -0.194593, 0.463221, -0.220295, 0.147911, 0.0727612, -0.289898, -0.768673, -0.687909, 0.000786571, 0.559173, -0.116789, 0.259406, -0.0717836], "internal": 1}
{"paper_id": "P15-1042", "abstract": "The sentiment classification performance relies on high-quality sentiment resources. However, these resources are imbalanced in different languages. Cross-language sentiment classification (CLSC) can leverage the rich resources in one language (source language) for sentiment classification in a resource-scarce language (target language). Bilingual embeddings could eliminate the semantic gap between two languages for CLSC, but ignore the sentiment information of text. This paper proposes an approach to learning bilingual sentiment word embeddings (BSWE) for English-Chinese CLSC. The proposed BSWE incorporate sentiment information of text into bilingual embeddings. Furthermore, we can learn high-quality BSWE by simply employing labeled corpora and their translations, without relying on largescale parallel corpora. Experiments on NLP&CC 2013 CLSC dataset show that our approach outperforms the state-of-theart systems.", "title": "Learning Bilingual Sentiment Word Embeddings for Cross-language Sentiment Classification", "venue": "P", "graph_vector": [0.133871, 0.162357, 0.108097, 0.220382, 0.38446, -0.907569, -0.120752, -0.130625, -1.42141, 0.191274, -0.0776047, -0.276333, 0.603364, -0.0731848, 0.127122, 0.0288657, 0.338997, -0.489958, 0.413368, 0.0993364, 0.160774, 0.844864, 0.541345, -0.1069, -0.258896, 0.226382, 0.253248, -0.0852191, -0.162743, -0.00818659, -0.185142, -0.105854, 0.25606, -0.770347, -0.624249, 0.0272181, -0.142229, 0.80986, -0.042333, -0.458646, -0.0969452, -0.328389, -0.363679, 0.528621, 1.00806, -0.852276, -0.191866, -0.0772516, -0.125179, 0.150344, 0.382843, -0.355783, 1.02243, 0.741705, 0.0884461, 0.0403103, 0.371303, 0.309084, -0.142918, -0.0484197, -0.232774, -0.140368, -0.015353, -0.0842474, 0.0120312, 0.0248085, 0.524966, -0.228851, -0.000970273, -0.124472, 0.192089, 0.265631, 0.194473, -0.133657, 0.0234408, -0.40201, -0.334198, -0.319514, -0.305728, 0.123167, 0.0723621, 0.192732, 0.119478, 0.111211, 0.249988, -0.637372, 0.250667, -0.133406, -0.42766, -0.145447, -0.100569, 0.25773, -0.728032, -0.0384771, 0.140548, 0.10748, 0.167391, -0.083347, -0.0198941, 0.247319, 0.340631, -0.503071, -0.154087, -0.221613, -0.0589573, 0.104317, -0.265137, -0.253867, 0.25501, -0.110594, 0.142699, -0.431634, -0.253547, -0.0344045, -0.100004, -0.270727, 0.582735, 0.251424, 0.0580637, 0.11481, -0.189012, -0.436381, -0.0453043, -0.135063, -0.0292783, 0.158302, 0.294361, 0.128729], "internal": 1}
{"paper_id": "P15-1169", "abstract": "Social media content can be used as a complementary source to the traditional methods for extracting and studying collective social attributes. This study focuses on the prediction of the occupational class for a public user profile. Our analysis is conducted on a new annotated corpus of Twitter users, their respective job titles, posted textual content and platform-related attributes. We frame our task as classification using latent feature representations such as word clusters and embeddings. The employed linear and, especially, non-linear methods can predict a user’s occupational class with strong accuracy for the coarsest level of a standard occupation taxonomy which includes nine classes. Combined with a qualitative assessment, the derived results confirm the feasibility of our approach in inferring a new user attribute that can be embedded in a multitude of downstream applications.", "title": "An analysis of the user occupational class through Twitter content", "venue": "P", "graph_vector": [-0.557912, 0.693906, 0.233443, 0.264777, 0.285561, -0.708884, 0.262641, -0.112805, -1.26327, 0.118112, -0.214542, -0.461471, 0.451783, -0.253559, -0.172583, -0.0808151, 0.384515, -0.856874, 0.206484, -0.173977, -0.0314476, 0.443577, 0.258787, 0.0380423, -0.20383, 0.192322, 0.195894, 0.103928, -0.274921, -0.71931, 0.0423262, 0.213993, 0.666345, -0.426999, -0.401158, 0.0725664, -0.390301, 0.932479, 0.637581, -0.515756, 0.0754066, -0.312999, -0.488072, 0.649617, 0.813152, -0.703469, 0.227639, 0.172476, -0.13569, 0.0427119, 0.153835, -0.181826, 1.27589, 0.854874, 0.0117655, 0.423729, -0.0194907, 0.396877, 0.0973827, 0.422831, -0.523488, -0.338369, -0.0224435, -0.0704464, -0.270176, -0.28489, 0.187636, -0.0627218, 0.233782, 0.129851, 0.300942, -0.0510358, -0.0637149, -0.220655, 0.0251412, 0.295707, -0.649984, -0.16868, -0.00861364, -0.295965, 0.337511, -0.519725, -0.0631046, -0.452299, 0.414235, -0.284793, 0.452671, -0.0777253, -0.224166, 0.0491896, 0.0407926, 0.010727, -0.69357, -0.171002, 0.0369767, -0.282012, -0.294506, 0.119091, 0.205081, -0.217012, -0.0573818, -0.0584083, 0.14067, -0.213458, 0.226653, 0.174438, -0.089319, -0.363987, -0.225163, -0.247108, 0.0593625, 0.0735639, -0.00403805, -0.0142195, -0.297055, -0.606652, 0.0181514, 0.453498, 0.0382408, 0.317171, -0.269946, 0.00411271, 0.253737, -0.19755, 0.505398, -0.162629, 0.0656249, 0.243591], "internal": 1}
{"paper_id": "P15-2040", "abstract": "We present KLcpos3, a language similarity measure based on Kullback-Leibler divergence of coarse part-of-speech tag trigram distributions in tagged corpora. It has been designed for multilingual delexicalized parsing, both for source treebank selection in single-source parser transfer, and for source treebank weighting in multi-source transfer. In the selection task, KLcpos3 identifies the best source treebank in 8 out of 18 cases. In the weighting task, it brings +4.5% UAS absolute, compared to unweighted parse tree combination.", "title": "KLcpos3 – a Language Similarity Measure for Delexicalized Parser Transfer", "venue": "P", "graph_vector": [-0.216243, 0.111479, -0.124051, 0.00545505, 0.513832, -0.911179, 0.142578, -0.0998034, -1.69034, 0.138073, -0.00584986, -0.0542633, 0.772873, -0.280712, 0.0821556, -0.0676847, 0.368583, -0.423377, -0.0368882, 0.575296, -0.45296, 0.715858, 0.520056, -0.286345, -0.117677, 0.311208, -0.166937, 0.278787, -0.11976, -0.0520661, -0.0778227, -0.218732, -0.109938, -0.158478, -0.509848, 0.449504, -0.155448, 0.757149, 0.0216878, -0.250389, -0.33331, -0.161516, 0.134039, 0.656869, 0.712722, -0.785366, -0.124014, 0.121375, -0.477738, 0.270643, 0.583461, -0.00446467, 0.629659, 0.40573, 0.0536215, -0.0219461, -0.172247, 0.572288, 0.440438, -0.247946, -0.281322, -0.0533015, -0.0758445, -0.237373, -0.602304, -0.456613, 0.16475, -0.238798, -0.0947773, 0.431075, 0.670032, 0.077028, -0.126941, 0.00393666, 0.23043, 0.138718, -0.3949, -0.142264, -0.295055, 0.0455935, 0.11646, -0.137885, -0.0858463, 0.205622, -0.141729, -0.608917, 0.170734, -0.276067, 0.0137093, -0.339541, -0.210061, 0.217045, -0.733844, -0.112483, -0.0796268, -0.4257, -0.141055, -0.148362, 0.119542, -0.192754, -0.223307, -0.335568, 0.0676236, 0.00943395, 0.00902713, 0.17983, -0.227958, -0.0463019, -0.375199, -0.259192, 0.0360322, 0.0983018, -0.019073, 0.143937, -0.24047, 0.151125, 0.415902, -0.129839, -0.169285, 0.0579277, -0.354445, -0.308697, 0.0328885, 0.084878, 0.383266, 0.17438, -0.300991, 0.0380611], "internal": 1}
{"paper_id": "P15-1173", "abstract": "We present AutoExtend, a system to learn embeddings for synsets and lexemes. It is flexible in that it can take any word embeddings as input and does not need an additional training corpus. The synset/lexeme embeddings obtained live in the same vector space as the word embeddings. A sparse tensor formalization guarantees efficiency and parallelizability. We use WordNet as a lexical resource, but AutoExtend can be easily applied to other resources like Freebase. AutoExtend achieves state-of-the-art performance on word similarity and word sense disambiguation tasks.", "title": "AutoExtend: Extending Word Embeddings to Embeddings for Synsets and Lexemes", "venue": "P", "graph_vector": [0.376793, 0.105096, 0.0333199, 0.455641, 0.377405, -0.755305, 0.41499, -0.147074, -1.2979, 0.35368, -0.0824394, -0.684784, 0.510819, 0.189126, -0.164827, -0.284562, 0.417364, -0.38777, -0.0699307, 0.194031, -0.0437586, 0.403983, 0.334418, 0.150725, -0.214382, 0.385519, 0.0234614, 0.204155, -0.177278, -0.135607, -0.12696, -0.125731, 0.305977, -0.603779, -0.382142, 0.0258347, -0.127141, 0.510201, 0.0765498, -0.100869, -0.209469, -0.671943, -0.224524, 0.283559, 0.99749, -0.984312, 0.333146, 0.163302, -0.322877, -0.268577, 0.112037, -0.322612, 0.98072, 0.459338, -0.00563745, -0.230931, 0.212546, 0.275571, -0.18817, -0.084947, -0.445474, -0.121863, -0.0890862, 0.259097, -0.0434862, 0.0016545, 0.243028, -0.350438, 0.228479, 0.175452, 0.113288, 0.149976, 0.163209, -0.110026, -0.0131205, 0.04211, -0.663503, -0.238856, 0.229263, -0.0425562, -0.0957622, -0.0888457, 0.209753, -0.0686796, 0.188862, -0.490958, 0.147807, -0.157418, 0.0353068, -0.129475, 0.145295, 0.206553, -0.759407, -0.149992, -0.100877, 0.0583811, -0.106613, 0.17158, 0.114399, -0.0543206, -0.399042, 0.0364964, 0.00708615, -0.0978521, 0.00747031, 0.228657, -0.275681, -0.169625, -0.0281143, -0.0575872, 0.170971, 0.0732274, -0.367294, 0.300959, -0.16566, 0.20837, 0.415813, 0.0655599, -0.149602, 0.0526971, -0.209398, 0.0725727, 0.0450554, -0.0960487, 0.226438, 0.0947717, 0.281467, 0.117025], "internal": 1}
{"paper_id": "P15-1080", "abstract": "Modern statistical machine translation (SMT) systems usually use a linear combination of features to model the quality of each translation hypothesis. The linear combination assumes that all the features are in a linear relationship and constrains that each feature interacts with the rest features in an linear manner, which might limit the expressive power of the model and lead to a under-fit model on the current data. In this paper, we propose a nonlinear modeling for the quality of translation hypotheses based on neural networks, which allows more complex interaction between features. A learning framework is presented for training the non-linear models. We also discuss possible heuristics in designing the network structure which may improve the non-linear learning performance. Experimental results show that with the basic features of a hierarchical phrase-based machine translation system, our method produce translations that are better than a linear model.", "title": "Non-linear Learning for Statistical Machine Translation", "venue": "P", "graph_vector": [0.180712, 0.10381, -0.0106056, 0.582855, 0.394129, -0.607027, 0.0167971, -0.105135, -1.43485, -0.186338, 0.137454, -0.536037, 0.384729, 0.533071, -0.102457, -0.172746, 0.395268, -0.440786, 0.326186, 0.242039, 0.0134159, 0.520682, 0.493116, -0.355955, -0.355241, -0.0776289, 0.236137, 0.160112, -0.276659, -0.197904, 0.320086, -0.0778052, 0.229377, -0.760901, -0.321642, 0.223632, -0.159927, 1.04664, 0.145212, -0.256353, 0.226595, -0.156206, -0.56056, 0.575101, 1.05005, -1.05148, 0.139902, 0.0755979, 0.0203103, -0.0219874, 0.00734491, -0.216838, 0.890314, 0.152943, -0.179453, 0.38775, 0.238453, 0.364328, 0.312943, 0.201595, 0.0219792, -0.13685, 0.0245978, -0.148247, 0.0894786, 0.0481038, 0.168102, 0.0252662, -0.183428, -0.208512, -0.0268922, 0.0406444, 0.0938925, -0.279547, 0.0962911, 0.227689, -0.502523, -0.539496, -0.231407, 0.0697643, -0.111166, 0.142766, 0.560106, -0.191077, -0.036759, -0.312125, -0.0335579, 0.157953, -0.0915612, -0.306303, 0.121516, -0.122782, -0.310543, -0.312276, -0.272436, -0.0906869, 0.0945621, 0.133194, -0.316447, -0.166407, -0.144373, -0.525887, 0.259748, -0.185513, -0.096903, 0.197712, -0.302347, -0.0116566, 0.18227, 0.0567617, 0.0451288, -0.404627, 0.157926, -0.121936, -0.0672614, -0.105614, 0.357423, 0.173781, -0.0220285, 0.212202, 0.0913563, -0.0313991, 0.05739, 0.046054, 0.232169, -0.048261, 0.199144, 0.0495896], "internal": 1}
{"paper_id": "P15-2104", "abstract": "We propose a label propagation approach to geolocation prediction based on Modified Adsorption, with two enhancements: (1) the removal of “celebrity” nodes to increase location homophily and boost tractability; and (2) the incorporation of text-based geolocation priors for test users. Experiments over three Twitter benchmark datasets achieve state-of-theart results, and demonstrate the effectiveness of the enhancements.", "title": "Twitter User Geolocation Using a Unified Text and Network Prediction Model", "venue": "P", "graph_vector": [-0.274088, 0.0830441, -0.0912808, 0.218114, 0.965222, -0.578181, -0.0467261, 0.0672142, -1.73151, 0.111121, -0.240852, -0.0135165, 0.438364, -0.191008, -0.164249, 0.361878, 0.375748, -0.743529, -0.00389956, 0.358787, -0.239794, 0.486262, 0.0993366, -0.138966, -0.185422, 0.490073, 0.220332, -0.0643262, -0.360675, 0.0594565, 0.0838705, 0.145915, -0.158198, -0.284412, -0.482012, -0.368065, -0.828513, 0.80224, 0.440994, -0.406652, 0.370027, -0.313235, -0.632298, 0.918508, 1.21766, -0.860304, -0.0164421, -0.339852, 0.438055, 0.333961, 0.0775793, -0.468227, 1.80331, 1.1874, -0.223821, 0.418548, -0.0645878, 0.484924, -0.0320241, -0.00120709, -0.348555, 0.00541554, 0.078901, 0.575632, -0.327173, -0.198161, -0.168328, -0.091728, -0.192791, 0.429073, 0.00511249, -0.0599912, -0.188561, 0.116568, 0.170656, -0.217932, -0.780849, -0.894218, 0.286582, -0.14056, -0.066198, -0.338622, 0.272181, -0.119482, -0.130812, -0.0996782, 0.197314, -0.188299, -0.0334483, 0.306693, 0.125345, 0.0690141, -0.571334, -0.196822, -0.166551, -0.26848, -0.354033, 0.294789, 0.180181, 0.00458931, -0.563676, -0.438276, -0.165316, 0.00431562, 0.466061, -0.0972875, -0.138353, -0.416345, -0.199361, -0.361976, -0.26709, -0.112116, -0.053781, -0.301358, 0.0759256, 0.0379143, 0.390075, -0.181571, 0.031501, 0.13783, -0.0108293, -0.0347472, 0.210708, -0.0967318, 0.456335, 0.15449, -0.0154357, 0.530823], "internal": 1}
{"paper_id": "P15-1056", "abstract": "An event chronicle provides people with an easy and fast access to learn the past. In this paper, we propose the first novel approach to automatically generate a topically relevant event chronicle during a certain period given a reference chronicle during another period. Our approach consists of two core components – a timeaware hierarchical Bayesian model for event detection, and a learning-to-rank model to select the salient events to construct the final chronicle. Experimental results demonstrate our approach is promising to tackle this new problem.", "title": "Bring you to the past: Automatic Generation of Topically Relevant Event Chronicles", "venue": "P", "graph_vector": [-0.160672, 0.364965, -0.0120497, -0.250613, 0.434564, -0.672162, -0.301506, -0.119231, -1.66342, 0.281207, -0.324627, -0.39953, 0.601775, 0.285573, -0.0874407, 0.251885, 0.339627, -0.692419, 0.606674, 0.420731, -0.111363, 0.344977, 0.37795, -0.191661, -0.43834, -0.391966, 0.348747, 0.118666, 0.19468, 0.0267651, 0.28727, -0.0709189, 0.307544, -0.470736, -0.158387, 0.0927349, -0.0669525, 0.646261, -0.00265912, -0.226331, 0.133163, -0.536195, -0.198407, 0.37093, 1.11889, -0.838355, -0.167776, 0.0905724, 0.117781, 0.0904037, 0.152403, -0.0236007, 1.00034, 0.995721, 0.210952, 0.249915, -0.112073, 0.0995905, -0.0876795, -0.0888101, -0.773698, -0.399247, 0.0350817, -0.389064, -0.321244, -0.30745, 0.0430813, -0.101856, 0.56853, -0.0590469, 0.20139, 0.189761, 0.326412, -0.110293, -0.161928, -0.0951152, -0.486868, -0.380295, -0.181922, -0.115104, -0.183605, 0.285091, 0.296644, -0.0107927, 0.0298495, -0.547099, -0.159277, 0.129718, 0.509693, -0.0797843, 0.244979, 0.300799, -0.83396, 0.0846054, 0.0777418, -0.113319, 0.441744, -0.194909, -0.731824, -0.213169, -0.142691, -0.113107, -0.0622393, 0.185936, 0.0283345, -0.187878, 0.0748856, -0.503027, 0.0655829, -0.419317, 0.160995, -0.522594, -0.0708096, 0.215304, -0.301611, 0.0248734, 0.209362, -0.313051, 0.0152273, 0.510666, -0.0420232, -0.223352, -0.0149166, 0.0607031, 0.407358, 0.171359, -0.23538, -0.100343], "internal": 1}
{"paper_id": "P15-1144", "abstract": "Current distributed representations of words show little resemblance to theories of lexical semantics. The former are dense and uninterpretable, the latter largely based on familiar, discrete classes (e.g., supersenses) and relations (e.g., synonymy and hypernymy). We propose methods that transform word vectors into sparse (and optionally binary) vectors. The resulting representations are more similar to the interpretable features typically used in NLP, though they are discovered automatically from raw corpora. Because the vectors are highly sparse, they are computationally easy to work with. Most importantly, we find that they outperform the original vectors on benchmark tasks.", "title": "Sparse Overcomplete Word Vector Representations", "venue": "P", "graph_vector": [-0.184597, 0.321576, 0.113413, 0.371402, 0.119861, -1.2179, 0.00949119, -0.0256858, -1.32393, -0.200026, -0.0571235, -0.346162, 0.581645, -0.35825, 0.254065, -0.142544, 0.472062, -0.241216, 0.314662, 0.485896, -0.258408, 0.469239, 0.0816407, 0.10481, -0.357944, -0.0798952, -0.0861777, 0.242219, 0.0880307, 0.0312803, -0.00186485, -0.0185228, 0.068356, -0.698021, -0.395345, 0.0179044, -0.474306, 0.534793, 0.0949836, 0.265285, -0.0808972, -0.529412, -0.186576, 0.199894, 1.07855, -0.554869, 0.137297, -0.544555, -0.0701065, 0.0102846, 0.230568, -0.436581, 0.925898, 0.591703, -0.0547768, -0.177665, 0.0844849, -0.0131864, -0.056066, 0.0125216, -0.444901, -0.157672, -0.106846, -0.0604629, 0.399274, 0.141333, 0.123405, -0.253991, -0.0532317, 0.198455, 0.2016, 0.0354136, -0.00978758, -0.117691, 0.304819, -0.379587, -0.496014, -0.386813, 0.125141, -0.138843, -0.0648301, 0.00863388, 0.0117853, -0.0391959, 0.276938, -0.370177, 0.299056, 0.107631, -0.136491, 0.116803, -0.161294, -0.278558, -0.774936, -0.213981, -0.343873, -0.153734, -0.0870772, -0.0277417, 0.351027, -0.0843182, 0.0841556, -0.483742, 0.280802, 0.18116, -0.360499, 0.094856, 0.363961, -0.180229, 0.402375, -0.027897, 0.0849701, -0.164317, -0.162484, -0.23197, -0.164911, 0.240462, 0.395357, 0.360156, -0.0433925, 0.059316, -0.130359, -0.102859, -0.119569, -0.0912897, 0.0660449, -0.0225287, 0.107929, -0.113875], "internal": 1}
{"paper_id": "P15-1065", "abstract": "The path ranking algorithm (PRA) has been recently proposed to address relational classification and retrieval tasks at large scale. We describe Cor-PRA, an enhanced system that can model a larger space of relational rules, including longer relational rules and a class of first order rules with constants, while maintaining scalability. We describe and test faster algorithms for searching for these features. A key contribution is to leverage backward random walks to efficiently discover these types of rules. An empirical study is conducted on the tasks of graph-based knowledge base inference, and person named entity extraction from parsed text. Our results show that learning paths with constants improves performance on both tasks, and that modeling longer paths dramatically improves performance for the named entity extraction task.", "title": "Learning Relational Features with Backward Random Walks", "venue": "P", "graph_vector": [0.279518, 0.177348, 0.0818297, 0.0910212, 0.571678, -0.554786, 0.37069, 0.084206, -1.69388, 0.458422, 0.183892, -0.254933, 0.657951, 0.49807, -0.148227, 0.055838, 0.530637, -0.575542, -0.217638, 0.709608, -0.308392, 0.028662, 0.189618, -0.0940893, 0.0195956, 0.379348, -0.30578, 0.249631, 0.0283151, -0.0956155, 0.0476095, -0.234586, 0.0874681, -0.751835, -0.0308114, -0.38555, -0.809109, 0.870036, 0.458591, 0.127496, 0.221431, -0.639414, -0.0270907, 0.670443, 0.974698, -0.715129, 0.288976, 0.0384892, 0.17502, -0.0720245, 0.619329, -0.0440059, 1.09072, 0.757754, 0.153288, 0.0393626, 0.211944, 0.388238, -0.179927, -0.0361143, -0.137509, -0.23701, -0.272846, -0.0507772, -0.124196, -0.277867, -0.145208, -0.275049, -0.208008, 0.0728327, 0.331447, 0.0777215, -0.109738, -0.15634, 0.0617155, -0.287039, -0.611924, -0.0830267, 0.318189, 0.130353, -0.143141, 0.186771, 0.153091, -0.423745, -0.126653, -0.384201, 0.0927636, -0.112241, 0.190876, 0.248363, 0.192932, 0.334855, -0.636397, -0.153204, 0.199533, -0.258178, -0.1444, -0.208553, -0.0194549, 0.0189124, -0.130642, -0.208437, -0.175129, 0.11192, 0.00323668, 0.224304, -0.246863, 0.179726, 0.33745, -0.0951955, 0.0397129, 0.125206, 0.16197, 0.0136927, -0.276648, -0.202254, 0.279328, 0.252717, -0.249254, 0.219782, -0.270134, -0.105368, -0.258757, 0.0749109, 0.495824, 0.192566, -0.191741, 0.370584], "internal": 1}
{"paper_id": "P15-1054", "abstract": "We study the problem of summarizing DAG-structured topic hierarchies over a given set of documents. Example applications include automatically generating Wikipedia disambiguation pages for a set of articles, and generating candidate multi-labels for preparing machine learning datasets (e.g., for text classification, functional genomics, and image classification). Unlike previous work, which focuses on clustering the set of documents using the topic hierarchy as features, we directly pose the problem as a submodular optimization problem on a topic hierarchy using the documents as features. Desirable properties of the chosen topics include document coverage, specificity, topic diversity, and topic homogeneity, each of which, we show, is naturally modeled by a submodular function. Other information, provided say by unsupervised approaches such as LDA and its variants, can also be utilized by defining a submodular function that expresses coherence between the chosen topics and this information. We use a large-margin framework to learn convex mixtures over the set of submodular components. We empirically evaluate our method on the problem of automatically generating Wikipedia disambiguation pages using human generated clusterings as ground truth. We find that our framework improves upon several baselines according to a variety of standard evaluation metrics including the Jaccard Index, F1 score and NMI, and moreover, can be scaled to extremely large scale problems.", "title": "Summarization of Multi-Document Topic Hierarchies using Submodular Mixtures", "venue": "P", "graph_vector": [0.0538951, 0.0204039, 0.176546, 0.280826, 0.513578, -1.0334, -0.290649, 0.428169, -1.37467, 0.21436, -0.530198, -0.457287, 0.798701, 0.504767, 0.273615, 0.393794, 0.718733, -0.414584, -0.190074, 0.239987, -0.0435094, 0.638301, 0.458645, -0.162684, -0.545685, 0.273174, 0.0137465, 0.392677, 0.294963, 0.0225099, 0.379412, 0.123782, -0.0128482, -0.159458, -0.507391, 0.0198128, -0.355535, 1.11879, 0.375485, -0.0642352, -0.331374, -0.311289, -0.243847, 0.688124, 0.728586, -0.891613, 0.201573, 0.370316, -0.442627, -0.126014, 0.41295, -0.233987, 1.123, 0.761826, -0.142527, -0.206601, -0.326299, 0.271743, 0.0211452, -0.140653, 0.00596976, -0.437345, -0.0680496, 0.0146927, -0.361515, -0.329111, 0.0597622, -0.426552, 0.118601, 0.244915, 0.0164765, 0.169668, -0.225416, -0.0815825, 0.196954, -0.51257, -1.01745, -0.229053, 0.00838752, -0.196269, -0.229879, -0.406973, 0.318621, -0.160307, 0.029911, -0.537203, 0.1977, -0.262749, 0.150035, -0.129619, 0.03212, 0.143432, -1.01652, -0.412533, -0.304352, 0.468463, 0.290758, 0.123579, 0.135427, -0.0661963, -0.0883114, -0.286718, 0.152119, 0.236417, -0.314296, -0.116775, 0.0612291, -0.206322, -0.0159601, 0.182312, -0.261368, 0.0462421, -0.337092, -0.279068, 0.0245084, -0.126833, 0.0398544, 0.163619, 0.0202887, 0.101417, -0.100789, -0.211483, -0.287879, -0.141588, 0.327859, 0.318568, -0.181182, -0.153842], "internal": 1}
{"paper_id": "P15-1058", "abstract": "In this paper, we present a novel approach to joint word sense disambiguation (WSD) and entity linking (EL) that combines a set of complementary objectives in an extensible multi-objective formalism. During disambiguation the system performs continuous optimization to find optimal probability distributions over candidate senses. The performance of our system on nominal WSD as well as EL improves state-ofthe-art results on several corpora. These improvements demonstrate the importance of combining complementary objectives in a joint model for robust disambiguation.", "title": "Multi-Objective Optimization for the Joint Disambiguation of Nouns and Named Entities", "venue": "P", "graph_vector": [], "internal": 1}
{"paper_id": "P15-1067", "abstract": "Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms stateof-the-art methods.", "title": "Knowledge Graph Embedding via Dynamic Mapping Matrix", "venue": "P", "graph_vector": [0.12705, 0.33799, -0.0165796, 0.145371, 0.449006, -0.618651, 0.31766, 0.0550828, -1.64589, 0.564409, 0.343948, -0.591033, 0.596109, 0.105644, -0.0391774, -0.306737, 0.300955, -0.560647, -0.0950071, 0.253236, -0.159615, 0.17243, 0.187115, 0.05266, -0.211984, 0.285701, -0.347403, 0.18146, 0.0746585, -0.0694919, -0.121531, -0.330769, 0.542893, -0.95167, -0.184918, 0.11811, -0.226793, 0.812016, 0.337765, -0.0381076, -0.148345, -0.664493, -0.23692, 0.610914, 0.90646, -0.817595, -0.21027, 0.307741, -0.121243, 0.084262, 0.354618, -0.101191, 0.873821, 0.757084, 0.0917082, 0.183997, 0.296131, 0.238358, -0.216954, 0.0724236, -0.141827, -0.169195, -0.171551, -0.00390344, -0.243118, 0.132159, 0.00420335, -0.485772, 0.145885, -0.0258892, 0.302168, -0.0839926, 0.0279992, 0.0946821, 0.252034, -0.236148, -0.625884, -0.188423, 0.239518, 0.0319922, -0.00037328, 0.0174918, 0.0643005, -0.376756, -0.0291341, -0.242576, -0.12392, -0.0689878, -0.157809, -0.298692, 0.251912, 0.270075, -0.960417, -0.00062649, -0.187152, 0.0940196, -0.177723, 0.417632, 0.368177, -0.191901, -0.385697, 0.0535444, 0.0907048, 0.139479, -0.421147, 0.434557, 0.0144913, 0.0747194, 0.277646, -0.1634, 0.395642, -0.0624036, -0.423496, -0.207288, -0.24326, -0.0286636, 0.805977, 0.102584, 0.148732, 0.136313, -0.329019, -0.0847019, -0.0127281, 0.0409944, 0.121983, 0.115195, -0.0725726, 0.152719], "internal": 1}
{"paper_id": "P15-2050", "abstract": "Semantic applications typically extract information from intermediate structures derived from sentences, such as dependency parse or semantic role labeling. In this paper, we study Open Information Extraction’s (Open IE) output as an additional intermediate structure and find that for tasks such as text comprehension, word similarity and word analogy it can be very effective. Specifically, for word analogy, Open IE-based embeddings surpass the state of the art. We suggest that semantic applications will likely benefit from adding Open IE format to their set of potential sentencelevel structures.", "title": "Open IE as an Intermediate Structure for Semantic Tasks", "venue": "P", "graph_vector": [0.101928, 0.193824, 0.052955, 0.363604, 0.4336, -0.866247, 0.347391, -0.364106, -1.38154, -0.135387, 0.431586, -0.702839, 0.55715, -0.130665, 0.0124603, -0.0891312, 0.351124, -0.432908, 0.177762, 0.309764, -0.308428, 0.343682, 0.365456, 0.0431492, -0.580819, 0.11575, -0.605569, 0.269739, -0.229262, 0.0687921, 0.341818, 0.0104403, 0.116014, -0.240537, -0.19956, -0.187948, -0.0392732, 0.728152, 0.417388, 0.115203, 0.248024, -0.533841, -0.0794213, 0.24991, 1.14486, -0.636578, 0.119455, 0.380054, -0.0789897, 0.118466, 0.303375, -0.229003, 0.830528, 0.700268, 0.189845, 0.19035, -0.292435, 0.0855099, -0.554784, -0.179502, -0.320033, -0.0604354, -0.243705, -0.199189, -0.137241, 0.264614, -0.0484674, -0.280913, 0.00708629, 0.069514, 0.0625825, 0.271019, -0.176925, -0.102101, -0.140025, -0.39184, -0.168748, -0.0482084, -0.106572, -0.298421, -0.0136157, -0.216706, 0.399541, 0.0230789, 0.169468, -0.111559, -0.0727729, -0.224776, 0.239642, -0.111877, -0.0107347, 0.220563, -1.05967, -0.109691, -0.000266589, 0.154385, 0.0461954, -0.129593, -0.292986, 0.424085, 0.000401608, -0.359634, -0.0804567, 0.278263, -0.0525169, 0.253831, -0.0286145, -0.442623, 0.398566, 0.117276, -0.0217813, -0.112073, 0.195032, 0.175729, -0.275006, 0.377037, 0.275495, 0.154947, -0.37446, 0.382506, -0.106291, 0.365525, 0.0584546, -0.12803, 0.342483, -0.252096, 0.130206, -0.153152], "internal": 1}
{"paper_id": "P15-1004", "abstract": "We present a three-pronged approach to improving Statistical Machine Translation (SMT), building on recent success in the application of neural networks to SMT. First, we propose new features based on neural networks to model various nonlocal translation phenomena. Second, we augment the architecture of the neural network with tensor layers that capture important higher-order interaction among the network units. Third, we apply multitask learning to estimate the neural network parameters jointly. Each of our proposed methods results in significant improvements that are complementary. The overall improvement is +2.7 and +1.8 BLEU points for Arabic-English and ChineseEnglish translation over a state-of-the-art system that already includes neural network features.", "title": "", "venue": "P", "graph_vector": [0.12843, 0.150295, 0.0552823, 0.226931, 0.606384, -0.691554, 0.251594, -0.0378661, -1.37151, 0.136258, 0.18456, -0.418402, 0.345026, 0.147969, 0.217106, 0.093264, 0.444227, -0.417562, -0.0767608, 0.126252, -0.309813, 0.481204, 0.39517, 0.0798539, -0.384663, 0.0485288, 0.0573134, 0.0815774, 0.0439473, -0.330265, -0.154466, -0.0596482, 0.0751081, -0.649841, -0.469403, 0.179375, -0.659839, 0.577113, 0.0786376, 0.108852, -0.137269, -0.587918, -0.240882, 0.494206, 1.42339, -0.772617, 0.340575, 0.00575692, 0.272853, -0.13696, 0.413607, -0.149715, 0.609998, 0.728065, -0.190111, 0.100493, 0.160948, 0.174223, 0.0455156, 0.395418, -0.380967, -0.0175567, 0.166286, 0.018589, 0.0987558, -0.0316051, -0.124155, 0.0878547, -0.12613, -0.0984989, 0.0618235, 0.0167097, 0.12936, -0.1148, 0.141283, 0.126165, -0.689844, -0.127788, 0.00162772, -0.106399, 0.0431866, 0.0160331, 0.220297, -0.279776, 0.135253, -0.714014, -0.00365179, -0.294984, 0.0197159, 0.107362, 0.335519, 0.326928, -0.511569, 0.156578, -0.449697, 0.19228, 0.117065, -0.00313021, -0.388766, -0.171112, 0.0191504, -0.257714, 0.00361662, 0.0537318, -0.0668719, -0.0270748, -0.397474, -0.518438, 0.0990696, -0.189634, 0.00263027, -0.0596046, -0.407434, -0.0626872, -0.227044, 0.270115, 0.518106, 0.189974, 0.148638, 0.349339, -0.0912013, -0.280819, -0.317383, 0.0204409, 0.0233507, 0.020245, 0.208161, 0.178455], "internal": 1}
{"paper_id": "P15-1145", "abstract": "In this paper, we propose a general framework to incorporate semantic knowledge into the popular data-driven learning process of word embeddings to improve the quality of them. Under this framework, we represent semantic knowledge as many ordinal ranking inequalities and formulate the learning of semantic word embeddings (SWE) as a constrained optimization problem, where the data-derived objective function is optimized subject to all ordinal knowledge inequality constraints extracted from available knowledge resources such as Thesaurus and WordNet. We have demonstrated that this constrained optimization problem can be efficiently solved by the stochastic gradient descent (SGD) algorithm, even for a large number of inequality constraints. Experimental results on four standard NLP tasks, including word similarity measure, sentence completion, name entity recognition, and the TOEFL synonym selection, have all demonstrated that the quality of learned word vectors can be significantly improved after semantic knowledge is incorporated as inequality constraints during the learning process of word embeddings.", "title": "Learning Semantic Word Embeddings based on Ordinal Knowledge Constraints", "venue": "P", "graph_vector": [0.177301, 0.378028, 0.0517347, 0.341665, 0.313064, -0.840691, 0.328803, -0.237899, -1.22752, 0.146063, -0.0134138, -0.607635, 0.424072, -0.301759, -0.136728, -0.326153, 0.535561, -0.275831, -0.0516076, 0.217049, -0.101743, 0.800467, 0.234098, 0.365591, -0.384284, 0.234777, -0.0472798, 0.0153477, 0.135353, -0.352076, 0.199159, -0.131411, 0.177251, -0.730676, -0.401232, 0.0667672, -0.155275, 0.657362, 0.165675, 0.184331, -0.357313, -0.202703, -0.288977, 0.364681, 0.944745, -0.827613, 0.171964, -0.0848465, -0.185071, -0.0917178, 0.247771, 0.0974263, 0.986389, 0.500478, -0.133989, -0.21721, 0.379871, 0.140194, -0.0752485, 0.00814082, -0.54669, -0.0647242, -0.0883934, 0.0539672, -0.0251399, -0.103552, 0.546494, -0.135918, 0.327167, -0.0837574, 0.0772435, 0.0396295, 0.176691, 0.0301824, -0.00251179, -0.120317, -0.91823, -0.211831, -0.000991123, -0.22824, 0.0080799, -0.229568, 0.125608, -0.0861202, -0.0118247, -0.482379, 0.168912, -0.303881, -0.0881982, -0.0243071, 0.138853, 0.00304072, -0.779802, 0.104549, -0.318803, 0.370939, 0.270195, -0.0400333, 0.207634, -0.245686, -0.339786, -0.0607233, 0.0082653, -0.142847, 0.113385, 0.419494, -0.198428, -0.325981, 0.175504, 0.0169196, 0.108475, -0.278846, -0.158827, 0.148752, -0.0210997, 0.245425, 0.256195, 0.110417, -0.0633345, 0.236265, 0.0485603, -0.0695209, -0.0259392, 0.0130271, 0.20336, 0.116318, 0.238396, 0.123258], "internal": 1}
{"paper_id": "P15-4014", "abstract": "In this paper, we present our Crossword Puzzle Resolution System (SACRY), which exploits syntactic structures for clue reranking and answer extraction. SACRY uses a database (DB) containing previously solved CPs in order to generate the list of candidate answers. Additionally, it uses innovative features, such as the answer position in the rank and aggregated information such as the min, max and average clue reranking scores. Our system is based on WebCrow, one of the most advanced systems for automatic crossword puzzle resolution. Our extensive experiments over our two million clue dataset show that our approach highly improves the quality of the answer list, enabling the achievement of unprecedented results on the complete CP resolution tasks, i.e., accuracy of 99.17%.", "title": "SACRY: Syntax-based Automatic Crossword puzzle Resolution sYstem", "venue": "P", "graph_vector": [0.289513, 0.147155, 0.180122, -0.245808, 0.2324, -0.758929, 0.323073, 0.00032413, -1.46128, 0.239551, -0.562539, -0.171075, 0.882019, -0.18599, 0.146825, 0.0526193, 0.27588, -0.927822, 0.21965, -0.0637482, -0.37211, 0.817421, 0.344024, -0.111752, -0.580749, -0.0738676, 0.273346, 0.286539, -0.0297941, 0.0420472, 0.170865, 0.331814, 0.0335941, -0.528221, -0.351018, 0.443601, -0.0490918, 0.369064, -0.0173435, 0.175272, 0.11097, -0.305645, -0.319974, 0.0672036, 0.741838, -1.0052, 0.0547082, 0.323615, 0.107098, -0.0196105, 0.289525, 0.127298, 1.2686, 0.153253, -0.00399319, 0.0380732, 0.491524, 0.149316, 0.0490828, -0.17597, -0.12789, -0.213169, 0.201115, 0.280335, 0.15286, 0.137443, 0.0983192, 9.85661e-05, 0.323554, -0.114494, -0.215654, 0.0133425, -0.247319, -0.396527, -0.241837, -0.497634, -0.537091, 0.169427, -0.0576458, -0.200013, -0.126168, 0.351659, 0.530616, 0.151129, 0.6484, -0.0622571, 0.183626, -0.369884, 0.0570826, -0.0517302, 0.186877, -0.0514944, -1.01609, 0.140551, -0.0287894, -0.0958314, -0.103874, 0.271816, -0.000777404, -0.102165, 0.0229071, -0.0517275, 0.350023, -0.239561, -0.108402, 0.243767, 0.000351235, -0.121927, 0.00307124, 0.0145946, 0.30701, -0.226052, 0.0199974, 0.0374905, 0.32766, 0.144644, 0.245528, 0.176444, -0.668377, 0.455407, -0.00782375, -0.0595872, -0.113891, -0.257432, 0.634629, 0.112593, 0.114757, 0.104341], "internal": 1}
{"paper_id": "P15-1051", "abstract": "Document enrichment focuses on retrieving relevant knowledge from external resources, which is essential because text is generally replete with gaps. Since conventional work primarily relies on special resources, we instead use triples of Subject, Predicate, Object as knowledge and incorporate distributional semantics to rank them. Our model first extracts these triples automatically from raw text and converts them into real-valued vectors based on the word semantics captured by Latent Dirichlet Allocation. We then represent these triples, together with the source document that is to be enriched, as a graph of triples, and adopt a global iterative algorithm to propagate relevance weight from source document to these triples so as to select the most relevant ones. Evaluated as a ranking problem, our model significantly outperforms multiple strong baselines. Moreover, we conduct a task-based evaluation by incorporating these triples as additional features into document classification and enhances the performance by 3.02%.", "title": "Encoding Distributional Semantics into Triple-Based Knowledge Ranking for Document Enrichment", "venue": "P", "graph_vector": [0.2167, 0.316966, -0.308668, 0.226177, 0.161053, -0.857964, -0.126959, 0.223182, -1.60009, 0.452755, 0.0717011, -0.21209, 0.6464, 0.22521, -0.324065, -0.00779158, 0.412268, -0.597181, -0.123048, 0.0189929, -0.235782, 0.652591, 0.0674995, -0.168182, -0.0549794, 0.140165, 0.42092, 0.0725842, -0.181843, 0.350532, 0.101733, -0.207801, 0.0944039, -0.601535, -0.249448, 0.0539771, -0.316906, 0.721678, 0.359635, -0.124729, -0.127034, -0.681352, -0.497487, 0.857758, 0.759057, -0.629898, -0.106875, 0.231733, -0.292905, 0.309648, 0.379889, 0.387005, 0.917088, 0.73737, -0.264547, 0.214367, -0.0215342, 0.068944, 0.0375405, 0.124081, 0.126263, -0.0290439, -0.317288, -0.10644, -0.122439, -0.028372, 0.385137, 0.116617, -0.191609, -0.00329017, -0.0968983, 0.19804, -0.253239, -0.203305, 0.444252, -0.608843, -0.487025, 0.0111436, -0.143958, -0.58351, -0.142604, 0.165884, 0.17806, 0.12664, 0.394754, -0.486901, 0.114719, 0.104267, 0.101471, 0.152043, -0.041125, 0.168456, -0.907342, -0.00401287, -0.096873, 0.250257, -0.243738, -0.140958, -0.17574, -0.13362, 0.203978, -0.242063, -0.327316, -0.0436359, -0.325106, -0.125756, -0.376024, 0.0301169, -0.0455533, -0.150818, -0.536152, -0.116701, 0.0849559, 0.333131, -0.113624, -0.324693, 0.486168, 0.563712, -0.322074, 0.445756, -0.0284045, 0.171863, 0.0650648, 0.206854, -0.0675406, -0.233992, -0.121027, 0.0747219], "internal": 1}
{"paper_id": "P05-1001", "abstract": "In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find “what good classifiers are like” by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL’00 syntactic chunking and CoNLL’03 named entity chunking (English and German).", "title": "A High-Performance Semi-Supervised Learning Method for Text Chunking", "venue": "P", "graph_vector": [0.252, 0.0621101, -0.196165, 0.317067, 0.0737479, -0.779958, -0.0674116, 0.101239, -1.3344, -0.137236, 0.0146101, -0.294943, 0.562165, -0.0815661, 0.173983, -0.412679, 0.239928, -0.709307, 0.13325, 0.619422, -0.537938, 0.737887, 0.106869, 0.00801524, -0.497314, 0.173095, -0.0314785, -0.0924916, -0.316765, -0.516885, 0.153601, -0.108027, 0.274044, -0.437182, 0.0464097, -0.000980361, -0.394188, 0.510411, -0.200706, -0.23576, -0.00444779, -0.487214, -0.342762, 0.568667, 0.761228, -0.766369, -0.219148, 0.182368, -0.0324309, 0.0277969, 0.400238, -0.322685, 0.84232, 0.646533, -0.261527, 0.181441, -0.0538092, 0.41272, -0.0183575, -0.0330971, -0.416077, -0.232318, 0.0282834, -0.289554, -0.0469083, -0.0501785, 0.449228, -0.129693, 0.00723404, 0.0782548, -0.102805, 0.303533, -0.00966287, -0.052122, 0.0706871, -0.101945, -0.193415, -0.301517, 0.106838, 0.00380968, 0.0432864, 0.00952277, 0.322345, 0.0662605, 0.160713, -0.0859934, -0.0389266, 0.0026414, -0.193933, -0.000392814, -0.0582, -0.314517, -0.553894, -0.0899948, -0.0891592, -0.105869, -0.417183, -0.193747, -0.136508, 0.127946, -0.0492482, -0.177389, -0.114399, -0.265491, 0.0504534, 0.22466, 0.015204, -0.0122645, -0.265758, -0.0187177, -0.0954238, -0.128988, -0.530054, 0.0131306, -0.247845, 0.0431458, 0.738594, -0.108872, -0.0917052, 0.208658, -0.139218, -0.0170856, 0.00489672, 0.0236604, 0.411486, 0.311, -0.0487402, 0.0384743], "internal": 1}
{"paper_id": "P01-1014", "abstract": "Educators are interested in essay evaluation systems that include feedback about writing features that can facilitate the essay revision process. For instance, if the thesis statement of a student’s essay could be automatically identified, the student could then use this information to reflect on the thesis statement with regard to its quality, and its relationship to other discourse elements in the essay. Using a relatively small corpus of manually annotated data, we use Bayesian classification to identify thesis statements. This method yields results that are much closer to human performance than the results produced by two baseline systems.", "title": "Towards Automatic Classification of Discourse Elements in Essays", "venue": "P", "graph_vector": [0.183822, 0.347841, -0.0319115, 0.3129, 0.263834, -0.933784, 0.257843, 0.209791, -1.63946, 0.202011, -0.259377, 0.0110596, 0.372243, 0.00312374, 0.122129, -0.497459, 0.605234, -1.02774, -0.190726, 0.0669964, -0.285988, 0.319936, -0.283415, -0.327876, -0.120865, 0.271199, -0.335648, -0.195486, -0.145902, 0.123702, 0.155045, 0.165457, -0.0457542, -0.307482, -0.0612079, 0.254831, -0.389965, 0.485117, 0.358762, -0.0642975, 0.0263996, 0.0474581, -0.234389, -0.0277702, 0.98199, -0.640575, -0.0930463, 0.0533609, -0.390279, -0.0424342, 0.357006, -0.0787898, 0.999897, 0.810528, -0.266166, -0.178189, 0.109272, -0.203737, 0.332325, 0.461364, -0.34434, -0.404033, -0.30419, 0.480784, -0.0227521, 0.576268, 0.546937, 0.267405, -0.0269588, 0.0108488, 0.366114, -0.0671494, 0.127564, -0.058448, -0.0557591, -0.0894214, -0.187482, -0.367697, 0.21123, -0.0851446, -0.0697925, 0.171242, 0.569543, 0.263489, -0.440794, 0.00606604, -0.276093, -0.28723, 0.0373021, -0.210498, -0.0654802, 0.128579, -0.478985, 0.0969197, 0.0451252, 0.258612, 0.35447, 0.0878636, 0.173095, 0.133925, 0.0967574, -0.329446, -0.264502, -0.383215, -0.0199832, -0.171037, -0.274526, -0.0743324, 0.0564227, 0.0230103, -0.133655, 0.203173, 0.374638, 0.109263, -0.188364, 0.192339, 0.546841, -0.227926, -0.0568843, 0.00947827, 0.0540946, 0.390231, 0.166964, -0.195184, 0.401422, -0.0346999, -0.0327474, -0.0694141], "internal": 1}
{"paper_id": "P97-1023", "abstract": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus.", "title": "Predicting the Semantic Orientation of Adjectives", "venue": "P", "graph_vector": [-0.138087, 0.152129, 0.460624, 0.531204, 0.450324, -1.06164, -0.333537, -0.201091, -1.59853, -0.0338788, -0.710351, -0.517959, 0.318894, 0.159984, 0.302714, 0.0639612, 0.0819031, -0.273647, 0.437041, 0.235272, 0.239308, 0.644817, -0.0977761, 0.129259, -0.32573, 0.0801615, 0.201233, 0.371464, -0.552388, 0.223159, 0.0211487, 0.133996, -0.176397, -0.278178, 0.253483, 0.278651, -0.11812, 0.972708, 0.439779, -0.185108, 0.192952, -0.191363, -0.118141, 0.528489, 1.0819, -0.661553, 0.0675689, 0.62264, -0.270784, 0.46145, 0.471947, -0.339173, 0.531656, 0.498764, 0.0316308, 0.116104, -0.0481152, 0.232308, 0.291148, 0.101669, -0.305678, -0.0120244, -0.0226117, -0.184471, 0.327565, -0.306428, 0.295191, 0.208677, -0.0271066, -0.16967, -0.182299, -0.00733761, 0.202635, -0.0825104, -0.0156821, -0.0367267, -0.201617, -0.218811, -0.00313372, 0.432199, -0.560068, -0.364032, 0.401597, -0.0710159, 0.155306, -0.113912, -0.234444, -0.0235236, -0.0199226, -0.039279, 0.231989, -0.139417, -0.447439, -0.573404, -0.186487, -0.195529, 0.206553, 0.111004, -0.242651, 0.4104, -0.322076, -0.386556, -0.00857254, -0.077994, -0.0500843, 0.161501, 0.0588539, 0.0987989, 0.304581, -0.106317, -0.0112843, 0.124476, -0.127782, 0.463863, 0.275386, 0.126635, 0.123206, 0.246741, 0.0812378, 0.164106, -0.328251, -0.0478195, -0.151727, 0.273448, 0.38387, 0.037854, -0.192483, -0.0744443], "internal": 1}
{"paper_id": "P97-1006", "abstract": "We propose a new method of classifying documents into categories. We define for each category a finite mixture model based on soft clustering of words. We treat the problem of classifying documents as that of conducting statistical hypothesis testing over finite mixture models, and employ the EM algorithm to efficiently estimate parameters in a finite mixture model. Experimental results indicate that our method outperforms existing methods.", "title": "Document Classification Using a Finite Mixture Model", "venue": "P", "graph_vector": [-0.0864378, 0.214287, -0.372147, 0.49062, 0.637887, -0.753868, 0.130631, 0.651264, -1.49448, 0.189415, -0.0248762, -0.489921, 0.546115, 0.0845297, 0.0823389, -0.216447, 0.417781, -0.601851, 0.253664, -0.366714, -0.0481002, 0.422148, -0.228595, -0.344815, -0.596189, -0.119016, 0.219876, 0.176948, -0.370048, -0.318299, 0.0890029, -0.363642, 0.0534918, -0.406406, -0.53575, 0.121792, 0.154509, 0.533091, 0.419435, -0.237149, -0.294114, -0.224185, -0.563219, 0.631292, 0.771966, -1.17003, -0.0940219, 0.234421, -0.118726, -0.167526, 0.483005, -0.0940608, 1.08257, 0.450524, -0.297965, -0.15501, 0.00209365, 0.0323667, 0.438193, 0.129426, -0.284373, -0.136976, -0.0761518, -0.0810368, -0.14587, -0.345305, -0.0143087, 0.255561, 0.237597, -0.506774, 0.0731637, -0.230251, -0.266091, -0.493172, 0.242149, -0.405869, -0.329765, -0.334402, 0.540855, 0.206934, 0.092097, 0.0938222, 0.034169, 0.27139, -0.0876495, -0.466742, 0.08107, -0.000732734, 0.181705, -0.00465577, 0.0112154, 0.215719, -0.623652, -0.207518, -0.180341, -0.16485, -0.331836, 0.0149023, -0.368539, -0.154845, -0.466263, -0.508378, -0.302143, 0.0900222, 0.0312197, 0.135106, -0.181328, 0.234218, 0.216259, -0.0136319, -0.321601, -0.311405, -0.307459, 0.186761, 0.0185002, -0.189449, 0.190658, 0.216325, -0.0573473, -0.103023, 0.0419864, 0.358825, -0.11375, 0.39404, 0.352357, 0.00754985, -0.0983787, -0.0199319], "internal": 1}
{"paper_id": "P79-1015", "abstract": "", "title": "Language and Perception>.", "venue": "P", "graph_vector": [0.148234, 0.683127, -0.144226, 0.391506, 0.738449, -1.04532, -0.283098, -0.024148, -1.79688, 0.168993, -0.255385, -0.276111, 0.357379, 0.580314, -0.155544, 0.0894893, 0.924469, -0.70688, 0.227293, 0.274862, -0.539906, 1.23639, 0.387437, -0.241115, -0.61737, -0.0349144, 0.373176, -0.100754, -0.270332, -0.322219, -0.00506391, 0.0295552, 0.238875, -0.189299, -0.07874, 0.251415, -0.318864, 0.823383, 0.331151, 0.145493, 0.257781, -0.387379, -0.511985, 0.247911, 1.05269, -0.644188, -0.217583, -0.161067, -0.290933, 0.118772, 0.347519, 0.0626111, 1.04884, 0.87537, -0.00834858, -0.181958, 0.224307, -0.0883442, -0.229688, 0.105687, -0.127756, -0.000162293, -0.430406, -0.118621, -0.0366182, -0.384314, 0.0690467, -0.283034, -0.17158, -0.0979248, 0.191639, -0.344005, 0.076558, 0.212406, -0.164136, 0.0464285, -0.533993, -0.526756, 0.0679792, -0.360064, -0.0200897, -0.134015, 0.315599, 0.150991, -0.142492, -0.110611, 0.296423, -0.219809, 0.0753736, -0.00858334, -0.0497597, -0.418228, -0.715831, -0.135087, -0.114454, 0.729688, 0.139788, 0.114264, -0.172522, 0.0482697, -0.212181, -0.304983, -0.0394609, 0.140293, 0.0439566, 0.380778, -0.0101287, -0.378223, 0.236361, -0.581504, -0.00780868, -0.0211593, -0.16459, -0.00100155, -0.110721, 0.0335492, 0.577867, -0.0957905, -0.327955, 0.0818261, -0.128361, 0.0323279, -0.180136, -0.212083, 0.556885, 0.0440709, -0.359366, -0.0549019], "internal": 1}
{"paper_id": "P79-1001", "abstract": "Bresnan, Joan (1978) &quot;A Realistic Transformational Grammar&quot; in Palle. &quot;roman and Piller (eds.) Linguistic Theory and Psychological Reality, The MIT Press.", "title": "", "venue": "P", "graph_vector": [], "internal": 1}
{"paper_id": "P98-2189", "abstract": "An efficient use of lexical cohesion is described for ranking text units according to their contribution in defining the meaning of a text (textual saliency), their ability to form a cohesive subtext (textual connectivity) and the extent and effectiveness to which they address the different topics which characterize the subject matter of the text (topic aptness). A specific application is also discussed where the method described is employed to build the indexing component of a summarization system to provide both generic and query-based indicative summaries.", "title": "Ranking Text Units According to Textual Saliency, Connectivity and Topic Aptness", "venue": "P", "graph_vector": [-0.0262064, 0.355559, -0.136256, 0.359282, 0.468226, -1.17811, 0.200886, -0.13769, -1.59278, 0.713335, -0.123461, -0.313649, 0.584932, 0.20787, 0.263563, -0.0987985, 0.366927, -0.222848, 0.148721, 0.288923, -0.194576, 0.282485, 0.37353, -0.139624, -0.373333, 0.325891, 0.297994, 0.0919891, -0.236283, 0.315052, 0.220086, -0.0820146, 0.356623, 0.0888226, 0.413362, -0.399213, -0.445743, 0.429415, 0.390456, -0.0993178, 0.000870879, -0.619278, -0.149683, 0.407234, 0.752581, -0.848007, -0.131939, -0.155812, -0.465821, -0.0767932, 0.449398, 0.121967, 0.879277, 0.966146, -0.15291, 0.244813, 0.291958, 0.304118, 0.421989, 0.101086, -0.0584967, -0.712645, 0.0861002, 0.0492657, -0.260989, -0.346099, 0.532994, 0.275169, -0.113794, 0.119382, 0.168722, -0.0686981, -0.048739, -0.0729604, 0.0478676, 0.158332, -0.62862, -0.358116, 0.00219002, 0.146521, -0.345039, -0.32788, 0.264187, 0.3254, 0.13164, -0.273023, -0.189104, -0.0767061, -0.226137, -0.157206, -0.0676537, 0.0740197, -0.49882, 0.00654703, 0.173898, 0.115776, 0.377513, -0.172386, -0.147878, 0.20759, -0.167902, -0.150218, -0.46198, -0.129681, -0.0788164, 0.0817702, 0.0556934, 0.160061, 0.3491, -0.0138385, 0.337439, 0.0910476, -0.00642141, 0.137631, 0.352307, -0.240834, 0.42131, 0.211133, -0.212178, 0.105567, 0.0133046, 0.455758, -0.128536, 0.173739, 0.296269, 0.0877991, -0.00671517, -0.199388], "internal": 1}
{"paper_id": "P98-1018", "abstract": "This paper examines the phenomenon of consonant spreading in Arabic sterns. Each spreading involves a local surface copying of an underlying consonant, and, in certain phonological contexts, spreading alternates productively with consonant lengthening (or gemination). The morphophonemic triggers of spreading lie in the patterns or even in the roots themselves, and the combination of a spreading root and a spreading pattern causes a consonant to be copied multiple times. The interdigitation of Arabic stems and the realization of consonant spreading are formalized using finite-state morphotactics and variation rules, and this approach has been successfully implemented in a large-scale Arabic morphological analyzer which is available for testing on the Internet.", "title": "Consonant Spreading in Arabic Stems", "venue": "P", "graph_vector": [-0.282166, 0.393136, -0.335306, 0.511938, 0.503118, -0.87194, -0.0110223, -0.156903, -2.22019, 0.209309, 0.205585, -0.330402, 0.529854, 0.0575603, -0.0228363, -0.244437, 0.402562, -0.440217, 0.637532, 0.196548, -0.260079, 0.765917, 0.0879964, 0.263745, -0.506537, 0.507375, -0.0230396, -0.143351, -0.54365, -0.258819, -0.243858, 0.427496, -0.113766, -0.286789, -0.319142, 0.499475, -0.189434, 0.323825, 0.0867099, -0.0373998, -0.029714, -0.496752, -0.664138, 0.550306, 1.28892, -0.518028, -0.0934853, -0.0696754, 0.124962, 0.0408503, 0.407572, -0.182188, 0.745691, 0.583259, -0.277277, 0.298777, -0.0698495, 0.179713, 0.00938573, 0.0917827, -0.197908, 0.183007, -0.0340524, -0.321369, -0.190744, 0.223674, 0.14373, 0.178287, -0.299586, 0.590165, -0.168121, 0.163568, -0.168569, 0.237694, -0.0202608, 0.131681, -0.742904, -0.587039, 0.0361186, -0.0694892, 0.00392428, 0.132936, 0.398955, -0.11408, 0.0108134, -0.058676, -0.0788888, 0.0366716, 0.374285, 0.147004, 0.295393, -0.148487, -0.583239, -0.348731, 0.214055, 0.011504, -0.0414047, -0.24872, -0.109688, 0.200545, 0.202307, -0.189558, -0.00775151, 0.10591, 0.0949864, 0.172949, -0.0251061, -0.329443, 0.0110207, -0.233607, -0.166452, 0.0610996, -0.29374, -0.102894, 0.281234, -0.109524, 0.116811, 0.295279, 0.173046, 0.774404, -0.337261, 0.276681, -0.0378476, 0.269895, 0.426815, 0.406684, 0.178591, -0.0482613], "internal": 1}
{"paper_id": "P08-2045", "abstract": "Finding temporal and causal relations is crucial to understanding the semantic structure of a text. Since existing corpora provide no parallel temporal and causal annotations, we annotated 1000 conjoined event pairs, achieving inter-annotator agreement of 81.2% on temporal relations and 77.8% on causal relations. We trained machine learning models using features derived from WordNet and the Google N-gram corpus, and they outperformed a variety of baselines, achieving an F-measure of 49.0 for temporals and 52.4 for causals. Analysis of these models suggests that additional data will improve performance, and that temporal information is crucial to causal relation identification.", "title": "Learning Semantic Links from a Corpus of Parallel Temporal and Causal Relations", "venue": "P", "graph_vector": [0.0600777, 0.124297, 0.135246, 0.132837, 0.50171, -0.929912, -0.441719, 0.108643, -1.18506, 0.444188, -0.280899, -0.533268, 0.70735, 0.51611, -0.182876, 0.221792, 0.144049, -0.838222, 0.517772, 0.374142, -0.499948, 0.415721, 0.288431, -0.263576, -0.485721, -0.158927, 0.156674, -0.413595, -0.553177, -0.393978, 0.103277, -0.573999, -0.17025, -0.54499, 0.211298, -0.402613, -0.374526, 0.582918, 0.278012, -0.0555906, -9.68617e-05, -0.0272641, -0.389005, 0.0800425, 0.849063, -0.944717, -0.25202, 0.258633, -0.099615, 0.0690055, 0.217008, -0.0942536, 0.716003, 0.914026, 0.172347, 0.0461772, -0.0965999, 0.276596, -0.19339, 0.0893626, -0.410316, -0.23451, -0.198084, -0.000327168, -0.0428263, -0.298165, 0.367698, -0.398526, 0.470431, 0.272553, 0.180243, -0.00038837, 0.105452, -0.248748, -0.229525, -0.210279, -0.270868, -0.198241, 0.0447955, 0.0825932, -0.365348, 0.0210193, -0.0216356, -0.227937, -0.281699, -0.197726, 0.255257, -0.362443, 0.345319, -0.546629, 0.0248055, -0.209492, -0.716428, -0.229866, 0.0544538, 0.172889, -0.185096, 0.237637, -0.281432, -0.202919, -0.05349, 0.0100147, 0.141606, -0.208745, -0.177113, -0.0443809, -0.0166615, -0.162631, 0.0525165, -0.0428965, 0.0253751, -0.168923, -0.153622, -0.171687, -0.259991, 0.0929072, 0.472971, 0.239957, 0.303864, 0.0617063, 0.0550703, 0.152298, -0.0428119, 0.0697925, 0.433403, 0.451596, 0.268834, -0.0725356], "internal": 1}
{"paper_id": "P08-1001", "abstract": "In this paper, we describe a system by which the multilingual characteristics of Wikipedia can be utilized to annotate a large corpus of text with Named Entity Recognition (NER) tags requiring minimal human intervention and no linguistic expertise. This process, though of value in languages for which resources exist, is particularly useful for less commonly taught languages. We show how the Wikipedia format can be used to identify possible named entities and discuss in detail the process by which we use the Category structure inherent to Wikipedia to determine the named entity type of a proposed entity. We further describe the methods by which English language data can be used to bootstrap the NER process in other languages. We demonstrate the system by using the generated corpus as training sets for a variant of BBN's Identifinder in French, Ukrainian, Spanish, Polish, Russian, and Portuguese, achieving overall F-scores as high as 84.7% on independent, human-annotated corpora, comparable to a system trained on up to 40,000 words of human-annotated newswire.", "title": "Mining Wiki Resources for Multilingual Named Entity Recognition", "venue": "P", "graph_vector": [-0.255685, -0.153645, 0.0544841, -0.100252, 0.0411044, -0.340753, 0.079128, 0.191368, -1.3586, 0.4949, -0.154249, -0.57297, 0.571367, -0.0247245, -0.143931, 0.375784, 0.692177, -0.421896, 0.197071, 0.612414, -0.834487, 0.692306, 0.362215, 0.0616402, -0.514083, 0.0770369, -0.172279, 0.0318246, -0.231919, 0.204295, -0.0331698, 0.177421, 0.302217, -0.508236, -0.32909, 0.107831, -0.202869, 0.458036, 0.342176, -0.171649, -0.452846, -0.558517, -0.475638, 0.592443, 1.2212, -0.617427, -0.13501, 0.583462, -0.0788053, -0.0799282, 0.436193, 0.122441, 0.40291, 1.05395, -0.526353, 0.214748, 0.175067, 0.408749, 0.0663111, -0.134375, -0.277557, -0.401963, -0.0403453, -0.0824403, -0.164414, -0.0781314, 0.271974, 0.0730709, -0.206791, 0.149374, 0.00914011, 0.339486, -0.123935, -0.0886467, -0.0878081, -0.176758, -0.583834, -0.260115, -0.349157, -0.312198, -0.0556087, -0.0540311, 0.269725, -0.146885, -0.0456021, -0.0541879, 0.118674, 0.127041, -0.0135386, 0.175631, -0.0563977, 0.0843291, -0.593488, -0.203775, -0.392567, -0.0529514, -0.25544, -0.305459, 0.495743, 0.00265224, 0.190288, -0.408726, -0.303413, -0.208371, -0.121837, -0.266786, -0.135819, 0.144028, 0.106427, -0.534122, -0.393683, 0.0804271, -0.638058, 0.179606, -0.387957, -0.12526, 0.571801, 0.149857, -0.0690803, 0.491713, 0.0638024, -0.0315425, -0.260504, 0.104175, 0.496408, 0.0616285, -0.0377403, -0.299494], "internal": 1}
{"paper_id": "P08-1068", "abstract": "We present a simple and effective semisupervised method for training dependency parsers. We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus. We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions. For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuracy of 92.02% to 93.16%, and in the case of Czech unlabeled second-order parsing, we improve from a baseline accuracy of 86.13% to 87.13%. In addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance.", "title": "Simple Semi-supervised Dependency Parsing", "venue": "P", "graph_vector": [-0.111693, 0.143274, -0.02307, 0.148458, 0.667691, -0.693535, 0.0213573, -0.143442, -1.43796, 0.163575, -0.070714, -0.389688, 0.529708, -0.0821863, -0.0682552, -0.237879, 0.439187, -0.52864, -0.0735823, 0.0765378, -0.53989, 0.609019, 0.144148, -0.0737995, -0.309193, 0.163185, -0.147996, 0.182596, -0.239222, -0.38834, -0.0694487, -0.198961, -0.00853952, -0.299858, -0.112738, 0.065245, -0.188917, 0.438535, 0.114575, -0.161088, 0.0572842, -0.561255, -0.184627, 0.225936, 0.729174, -0.820132, 0.0316255, -0.0779979, 0.0134427, 0.00401331, 0.114838, -0.312439, 0.753622, 0.468329, -0.171974, -0.043261, -0.304061, 0.265951, -0.0241597, -0.278951, -0.417508, 0.0524792, 0.0465494, -0.000451783, -0.108889, -0.170072, 0.110046, 0.0400904, -0.0538768, 0.0149847, 0.0324327, 0.147568, -0.105922, -0.184653, 0.484826, -0.214606, -0.335364, -0.411096, 0.00918753, -0.148647, 0.0346565, -0.19618, 0.410788, 0.17291, 0.0289684, -0.280765, 0.180204, -0.0802981, -0.0498088, -0.267566, -0.0820806, 0.137313, -0.242504, 0.00816606, -0.0286521, -0.0801212, -0.229334, 0.184653, 0.151169, 0.0179204, -0.0879403, -0.265232, 0.206681, -0.190452, -0.175934, -0.0294763, -0.171444, -0.315911, -0.0114505, -0.359337, -0.0657024, 0.0489343, -0.110229, -0.00140509, -0.186884, 0.0161038, 0.170383, -0.0840107, 0.217243, 0.0272944, -0.127275, -0.0536466, 0.251421, 0.0532331, 0.637486, -0.0476274, -0.111106, -0.297021], "internal": 1}
{"paper_id": "P08-1102", "abstract": "We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging. With a character-based perceptron as the core, combined with realvalued features such as language models, the cascaded model is able to efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly. Experiments show that the cascaded model achieves improved accuracies on both segmentation only and joint segmentation and part-of-speech tagging. On the Penn Chinese Treebank 5.0, we obtain an error reduction of 18.5% on segmentation and 12% on joint segmentation and part-of-speech tagging over the perceptron-only baseline.", "title": "A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging", "venue": "P", "graph_vector": [0.0804044, 0.114134, -0.197345, 0.688814, 0.627976, -0.694877, 0.0080708, -0.0623617, -1.58743, 0.040032, 0.189882, -0.172192, 0.578996, 0.392734, -0.12184, -0.0352806, 0.274042, -1.00552, -0.100637, 0.50726, -0.103373, 0.608287, 0.371172, 0.0370043, -0.045653, -0.320363, 0.0382113, 0.101218, -0.117661, -0.43849, -0.093893, -0.00832897, 0.1654, -0.57543, -0.520612, 0.21579, -0.32945, 0.606636, 0.101743, -0.0872352, -0.0133408, -0.315214, -0.124687, 0.409734, 0.919784, -0.624053, -0.193014, 0.0597212, 0.0316735, 0.149951, 0.474506, -0.129759, 0.781699, 0.421011, -0.755414, -0.0388468, 0.207129, 0.365206, -0.160469, 0.218402, -0.391014, 0.178527, 0.0858526, -0.254709, -0.184, 0.0149547, 0.191518, -0.0180086, 0.15785, -0.113052, 0.197174, 0.156371, 0.271528, -0.167062, 0.192741, -0.294751, -0.624749, -0.355242, -0.254502, 0.0633357, -0.26549, 0.00132789, 0.0668804, 0.0464711, 0.254876, -0.25093, 0.256757, -0.276186, 0.124209, 0.17139, 0.358578, 0.128901, -0.561993, -0.061324, 0.378147, -0.266462, 0.0817103, -0.299412, -0.184992, -0.369701, -0.0342013, -0.369784, 0.0455059, 0.0120107, 0.0929015, 0.0469297, 0.0748621, 0.261042, 0.21228, -0.270923, -0.00884137, -0.147174, -0.249531, -0.141773, 0.284089, 0.216071, 0.328144, 0.0526758, -0.048213, 0.118588, -0.0289642, -0.195911, -0.355068, 0.163513, 0.13025, 0.076293, 0.0113961, -0.123812], "internal": 1}
{"paper_id": "P08-2024", "abstract": "Chinese characters that are similar in their pronunciations or in their internal structures are useful for computer-assisted language learning and for psycholinguistic studies. Although it is possible for us to employ imagebased methods to identify visually similar characters, the resulting computational costs can be very high. We propose methods for identifying visually similar Chinese characters by adopting and extending the basic concepts of a proven Chinese input method--Cangjie. We present the methods, illustrate how they work, and discuss their weakness in this paper.", "title": "Using Structural Information for Identifying Similar Chinese Characters", "venue": "P", "graph_vector": [0.143153, 0.64437, 0.10992, 0.318492, 0.385342, -0.956021, -0.237872, -0.0413961, -2.52913, 0.202022, -0.197007, 0.333265, 1.39751, 0.0549392, -0.0902912, -0.00705378, 0.78197, -1.12854, 0.362156, 0.685302, -0.129492, 1.0844, 0.655854, -0.353947, -0.834336, 0.506846, 0.0709093, 0.236182, -0.353982, -0.0537769, 0.15332, 0.115927, 0.0906464, -0.16631, -0.468996, 0.409659, -0.37775, 0.961897, 0.492951, -0.572638, -0.150624, -0.248291, -0.223633, 0.40817, 0.913267, -0.940802, -0.481883, 0.398796, -0.186685, 0.155498, 0.268056, -0.44656, 1.36765, 0.692392, -0.12749, -0.0349534, 0.452579, 0.655818, 0.0300675, 0.316562, -0.14741, -0.00276345, 0.104417, -0.0582243, -0.128762, -0.183393, 0.400809, -0.281618, -0.344349, 0.0944006, 0.110597, 0.191216, 0.0374977, -0.0458322, -0.18032, -0.0735636, -0.636638, -0.444262, -0.310483, 0.299336, -0.0851267, 0.257596, -0.107152, 0.387147, 0.230945, -0.425698, 0.164898, -0.222524, -0.00337538, -0.316589, -0.352468, 0.109069, -0.710223, 0.207514, -0.334683, 0.531616, -0.163726, -0.0772004, -0.245942, -0.425743, -0.422672, -0.295933, -0.246405, 0.0243809, 0.0556781, -0.136889, -0.137443, -0.215637, 0.34465, 0.028428, 0.216557, -0.100243, 0.187201, 0.0208567, -0.0564963, -0.0350336, -0.0558489, 0.0432012, 0.155326, 0.435736, -0.103809, -0.240597, 0.032587, 0.0685277, 0.727974, 0.290335, -0.047999, -0.02455], "internal": 1}
{"paper_id": "P08-1006", "abstract": "This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks. Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers. We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data.", "title": "Task-oriented Evaluation of Syntactic Parsers and Their Representations", "venue": "P", "graph_vector": [-0.0239448, 0.0285297, 0.258444, 0.297079, 0.639254, -0.674708, 0.136759, -0.22074, -1.58448, 0.316833, -0.342245, -0.112221, 0.857253, 0.0567416, 0.335287, -0.231235, 0.402772, -0.643832, 0.200698, 0.325051, -0.272832, 0.220348, 0.47343, -0.155718, -0.211013, -0.0297856, -0.234905, -0.220208, -0.286697, 0.00562012, 0.240499, -0.130507, -0.0241467, -0.422939, -0.17021, 0.165117, -0.304199, 0.761745, 0.117189, -0.242928, 0.00548196, -0.00745008, -0.470766, -0.112038, 0.482995, -0.421381, 0.386688, 0.0103985, 0.101101, 0.359145, 0.228885, -0.151951, 0.814139, 0.440227, 0.118937, 0.0831061, 0.0742453, 0.0721207, 0.0129708, -0.385716, -0.211766, -0.171668, 0.247717, -0.031888, 0.0711124, -0.0742667, -0.114111, -0.0568529, 0.103528, 0.257943, 0.149058, -0.163502, 0.116389, 0.10193, 0.211915, -0.0870512, -0.278833, -0.176208, -0.396985, -0.306105, -0.243388, 0.109236, 0.135952, -0.0942614, 0.133709, 0.163877, 0.0492901, 0.142044, -0.0536254, 0.0274501, -0.037009, -0.00874359, -0.359879, -0.193042, 0.283772, 0.0841586, -0.185185, -0.0524731, -0.149594, 0.0462909, 0.143626, -0.113526, 0.0769914, -0.189099, -0.110686, -0.202898, 0.130974, 0.172388, 0.180645, -0.341706, 0.0927642, -0.035503, -0.0252855, 0.14954, -0.100853, -0.353463, 0.579379, -0.0755118, 0.0190658, -0.0108668, 0.0960874, 0.00944121, -0.384103, 0.0470238, 0.72233, 0.182483, -0.222321, 0.226027], "internal": 1}
{"paper_id": "P12-3019", "abstract": "Information extraction (IE) is becoming a critical building block in many enterprise applications. In order to satisfy the increasing text analytics demands of enterprise applications, it is crucial to enable developers with general computer science background to develop high quality IE extractors. In this demonstration, we present WizIE, an IE development environment intended to reduce the development life cycle and enable developers with little or no linguistic background to write high quality IE rules. WizIE provides an integrated wizard-like environment that guides IE developers step-by-step throughout the entire development process, based on best practices synthesized from the experience of expert developers. In addition, WizIE reduces the manual effort involved in performing key IE development tasks by offering automatic result explanation and rule discovery functionality. Preliminary results indicate that WizIE is a step forward towards enabling extractor development for novice IE developers.", "title": "WizIE: A Best Practices Guided Development Environment for Information Extraction", "venue": "P", "graph_vector": [0.571104, 0.479512, 0.200446, -0.368911, 0.380564, -0.445009, -0.051931, 0.225344, -1.95523, 0.319266, 0.338456, -0.628021, 0.508632, 0.200933, 0.00587687, 0.112464, 0.437721, -0.721125, -0.0199636, 0.44853, -0.52261, 0.954359, -0.0342547, -0.0691313, -0.0880154, 0.165476, 0.0593913, 0.689875, -0.355221, -0.27013, 0.561149, 0.0823247, -0.236322, -0.761344, -0.051204, 0.273999, -0.277453, 1.12752, 0.331487, -0.062303, -0.129221, -0.497784, 0.0453505, 0.224207, 1.184, -0.813436, 0.042136, 0.286092, -0.125688, 0.142174, 0.352552, 0.232851, 0.944319, 0.734259, 0.00266663, 0.322078, 0.337604, 0.105009, -0.138567, 0.110287, -0.610861, -0.233492, 0.26759, 0.186364, -0.318826, 0.435415, 0.175233, -0.189654, 0.134655, 0.330191, 0.219301, 0.205549, -0.415938, 0.0554209, 0.281286, -0.0974898, -0.777846, -0.459525, -0.349177, -0.253789, 0.183802, -0.0414102, 0.313934, -0.207155, 0.486254, 0.179466, -0.00669428, -0.0834744, -0.0671794, 0.166037, -0.363653, 0.139041, -0.835621, 0.0606448, 0.00289737, -0.115215, 0.0151886, -0.166733, -0.286706, -0.130125, -0.308529, -0.097235, -0.258062, -0.012124, 0.261455, 0.216105, 0.318625, -0.284952, 0.204027, 0.0545025, -0.0164269, -0.0805253, 0.0140573, -0.00294199, -0.368336, 0.0181618, 1.0178, -0.145763, -0.235191, 0.270491, -0.0541832, 0.120727, -0.0204569, 0.0210967, 0.126451, 0.414157, -0.396546, 0.0286565], "internal": 1}
{"paper_id": "P12-4004", "abstract": "Subjectivity and sentiment analysis focuses on the automatic identification of private states, such as opinions, emotions, sentiments, evaluations, beliefs, and speculations in natural language. While subjectivity classification labels text as either subjective or objective, sentiment classification adds an additional level of granularity, by further classifying subjective text as either positive, negative or neutral. While much of the research work in this area has been applied to English, research on other languages is growing, including Japanese, Chinese, German, Spanish, Romanian. While most of the researchers in the field are familiar with the methods applied on English, few of them have closely looked at the original research carried out in other languages. For example, in languages such as Chinese, researchers have been looking at the ability of characters to carry sentiment information (Ku et al., 2005; Xiang, 2011). In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (Banea et al., 2008). These additional sources of information may not be available across all languages, yet, various articles have pointed out that by investigating a synergistic approach for detecting subjectivity and sentiment in multiple languages at the same time, improvements can be achieved not only in other languages, but in English as well. The development and interest in these methods is also highly motivated by the fact that only 27% of Internet users speak English (www.internetworldstats.com/stats.htm, Oct 11, 2011), and that number diminishes further every year, as more people across the globe gain Internet access. The aim of this tutorial is to familiarize the attendees with the subjectivity and sentiment research carried out on languages other than English in order to enable and promote crossfertilization. Specifically, we will review work along three main directions. First, we will present methods where the resources and tools have been specifically developed for a given target language. In this category, we will also briefly overview the main methods that have been proposed for English, but which can be easily ported to other languages. Second, we will describe cross-lingual approaches, including several methods that have been proposed to leverage on the resources and tools available in English by using cross-lingual projections. Finally, third, we will show how the expression of opinions and polarity pervades language boundaries, and thus methods that holistically explore multiple languages at the same time can be effectively considered.", "title": "Multilingual Subjectivity and Sentiment Analysis", "venue": "P", "graph_vector": [-0.106054, 0.3643, 0.113913, 0.274166, 0.364086, -0.623212, -0.022499, -0.26131, -1.55342, 0.0918072, -0.230869, -0.331638, 0.573266, -0.0439965, -0.0157357, 0.105888, 0.577362, -0.433618, -0.059525, 0.180057, -0.0664534, 0.34988, 0.0673193, 0.108087, -0.448606, 0.155986, 0.056543, 0.163922, -0.261784, -0.171605, 0.0359929, 0.104942, -0.0478721, -0.383061, 0.0297628, -0.0344307, -0.431099, 0.582059, 0.165094, -0.0484597, 0.0651921, -0.271265, -0.243459, 0.484155, 0.715292, -0.670447, 0.0892784, -0.022883, 0.0133981, 0.00112337, -0.0370637, -0.176875, 0.480676, 0.52269, -0.115942, -0.127672, 0.194652, 0.211908, -0.106566, 0.0662516, -0.174853, 0.247947, 0.252187, -0.143891, -0.0217107, -0.0268454, 0.047945, 0.00386912, 0.0378515, 0.101686, 0.0314029, -0.00420405, 0.151006, -0.00834219, -0.155964, -0.0610354, -0.17192, -0.154193, -0.135138, 0.22757, -0.338956, -0.0949896, 0.202502, -0.0951009, 0.0202786, -0.0834698, 0.25781, -0.252648, -0.236603, -0.104179, -0.0992081, 0.0400025, -0.592363, -0.235923, -0.328931, -0.0143517, 0.0530575, 0.00833218, 0.0666265, 0.171895, -0.178391, -0.452946, -0.172654, 0.188919, 0.146847, 0.0864699, -0.139023, -0.128215, 0.32629, -0.287677, 0.0729734, -0.114506, 0.102231, 0.160599, 0.125517, -0.180156, 0.245654, 0.171708, 0.0119566, 0.0451336, 0.0136622, -0.0327415, 0.114073, 0.116675, 0.476306, 0.191979, 0.0514534, 0.0544111], "internal": 1}
{"paper_id": "P12-1072", "abstract": "We present a statistical model for canonicalizing named entity mentions into a table whose rows represent entities and whose columns are attributes (or parts of attributes). The model is novel in that it incorporates entity context, surface features, firstorder dependencies among attribute-parts, and a notion of noise. Transductive learning from a few seeds and a collection of mention tokens combines Bayesian inference and conditional estimation. We evaluate our model and its components on two datasets collected from political blogs and sports news, finding that it outperforms a simple agglomerative clustering approach and previous work.", "title": "A Probabilistic Model for Canonicalizing Named Entity Mentions", "venue": "P", "graph_vector": [-0.17421, 0.171027, -0.250389, 0.304049, 0.647315, -0.571379, -0.344625, 0.168324, -1.37309, 0.31415, -0.101018, -0.337028, 0.571557, -0.127646, -0.078893, 0.106438, 0.638901, -0.379155, 0.448765, 0.29562, -0.428678, 0.649503, 0.0260468, -0.131603, -0.0950436, 0.264173, 0.302622, 0.422684, -0.487809, -0.32484, 0.263609, -0.136631, 0.180228, -0.645827, -0.0693466, 0.319968, 0.0372722, 0.589881, -0.0291495, -0.0470675, 0.0079757, -0.669961, -0.377693, 0.480607, 1.01204, -0.861106, 0.167273, -0.064655, -0.236198, 0.101104, 0.168344, -0.205875, 0.77748, 0.77548, -0.0229528, -0.0541183, -0.00417733, 0.195793, -0.0225205, -0.10223, -0.355884, -0.00478276, 0.10633, 0.0783879, -0.393993, 0.0942042, 0.127068, -0.222435, 0.0363065, 0.489175, 0.343437, 0.107351, 0.320331, -0.406404, 0.161037, -0.296028, -0.392068, -0.165774, -0.299654, -0.198963, -0.346117, 0.109325, 0.174792, -0.344048, 0.014663, -0.538294, -0.0358871, -0.240419, -0.201994, -0.0959949, -0.193609, 0.179952, -0.63559, 0.0901836, -0.17832, -0.0771842, 0.127393, -0.0633776, 0.00898071, 0.120834, -0.045857, 0.0270457, -0.0589612, 0.635196, 0.402959, -0.158829, 0.352681, 0.0633854, 0.026639, -0.108668, -0.617633, 0.0185176, -0.212731, -0.448167, -0.143262, -0.0941743, 0.00681035, 0.61866, -0.281214, 0.016076, 0.00922958, 0.119424, -0.136217, 0.247903, 0.332507, -0.00650046, 0.236825, -0.138458], "internal": 1}
{"paper_id": "P12-3010", "abstract": "In this paper, we propose a web-based bilingual concordancer, DOMCAT 1 , for domain-specific computer assisted translation. Given a multi-word expression as a query, the system involves retrieving sentence pairs from a bilingual corpus, identifying translation equivalents of the query in the sentence pairs (translation spotting) and ranking the retrieved sentence pairs according to the relevance between the query and the translation equivalents. To provide high-precision translation spotting for domain-specific translation tasks, we exploited a normalized correlation method to spot the translation equivalents. To ranking the retrieved sentence pairs, we propose a correlation function modified from the Dice coefficient for assessing the correlation between the query and the translation equivalents. The performances of the translation spotting module and the ranking module are evaluated in terms of precision-recall measures and coverage rate respectively.", "title": "DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation", "venue": "P", "graph_vector": [-0.0713064, 0.507217, 0.0863532, 0.269049, 0.279657, -0.729323, 0.208155, -0.322512, -1.63701, 0.419748, -0.607345, 0.0838657, 0.829189, -0.015413, -0.23414, 0.015005, 0.289638, -0.817331, -0.175175, 0.594847, -0.18451, 0.114379, 0.0364956, -0.00120858, -0.376008, 0.187361, 0.154613, 0.254968, 0.145095, 0.245019, -0.116389, -0.468813, 0.572232, -0.210941, -0.491434, 0.464392, 0.0928279, 0.219609, -0.0365978, -0.062367, 0.0547331, 0.116415, -0.502094, 0.590343, 1.18289, -0.815643, 0.100921, 0.4698, -0.0141755, 0.178654, -0.104947, -0.285301, 0.883301, 0.694353, -0.610393, 0.352415, 0.660532, 0.0115381, 0.0896684, -0.22428, -0.514218, 0.0371519, -0.181804, -0.0965362, -0.198603, -0.307122, 0.339834, -0.12723, -0.337511, -0.0188574, -0.135102, 0.194712, -0.0462583, 0.083672, 0.133044, 0.0712203, -0.0825505, -0.348144, -0.333919, -0.147673, 0.306391, 0.175709, 0.11896, 0.0578596, 0.43923, -0.34108, 0.192035, 0.308828, -0.331061, 0.0883516, -0.390514, 0.110273, -0.871694, 0.0685146, 0.0810426, 0.527567, -0.516902, -0.0746764, -0.267604, 0.18727, -0.395862, -0.591931, -0.380747, -0.0338917, -0.194735, 0.0612342, -0.0548182, -0.497052, 0.169119, -0.485332, 0.0370867, -0.161129, 0.124799, -0.075329, -0.291314, -0.227576, -0.10916, -0.010364, -0.197652, 0.232641, -0.179217, -0.308411, 0.165348, 0.0509195, 0.310893, 0.211922, 0.00680787, -0.14536], "internal": 1}
{"paper_id": "P12-1073", "abstract": "In this paper we propose a method to automatically label multi-lingual data with named entity tags. We build on prior work utilizing Wikipedia metadata and show how to effectively combine the weak annotations stemming from Wikipedia metadata with information obtained through English-foreign language parallel Wikipedia sentences. The combination is achieved using a novel semi-CRF model for foreign sentence tagging in the context of a parallel English sentence. The model outperforms both standard annotation projection methods and methods based solely on Wikipedia metadata.", "title": "Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia", "venue": "P", "graph_vector": [0.16426, -0.122386, 0.0891616, 0.0904976, 0.133228, -0.674619, 0.0506133, -0.21647, -1.49218, 0.389362, -0.0721222, 0.0771474, 0.568044, -0.136854, -0.140569, -0.084538, 0.622544, -0.708723, 0.384369, 0.797902, -0.228393, 0.423707, 0.391816, -0.245235, -0.339535, 0.149564, -0.469195, 0.208946, -0.100939, -0.117175, -0.0962915, 0.062631, 0.326223, -0.115654, -0.0655948, 0.298812, 0.0246783, 0.580456, 0.102286, -0.562626, -0.0617297, -0.442329, -0.130352, 0.987797, 0.861012, -0.703481, 0.0785571, 0.490428, -0.267169, -0.0931807, 0.11573, -0.306329, 0.439284, 0.681427, -0.383653, -0.0840749, 0.319603, 0.0078232, -0.0845442, -0.186933, -0.429194, -0.278541, -0.0491009, 0.0582859, 0.0386029, -0.102269, -0.144271, -0.0816041, -0.223934, 0.171343, 0.427261, 0.525839, 0.0730419, -0.127365, 0.242954, -0.0373844, -0.351988, -0.345714, -0.00177253, -0.407558, 0.087505, -0.13494, -0.0296558, -0.120815, 0.0863402, -0.264355, 0.068529, -0.210348, -0.0678078, 0.0251813, -0.122821, 0.082061, -0.648793, -0.149592, -0.147441, -0.0735267, -0.334312, -0.201172, 0.196207, 0.0873797, -0.109594, -0.522246, -0.023189, -0.157922, -0.168371, -0.227868, -0.116743, -0.207759, 0.0921306, -0.479492, -0.211876, -0.291302, -0.35696, -0.00629899, -0.249438, -0.133179, 0.45568, -0.0722483, 0.0314407, 0.43455, 0.155761, 0.0579191, -0.0561895, 0.0120269, 0.224944, 0.274593, 0.209641, -0.0467748], "internal": 1}
{"paper_id": "P06-2110", "abstract": "This paper examines what kind of similarity between words can be represented by what kind of word vectors in the vector space model. Through two experiments, three methods for constructing word vectors, i.e., LSA-based, cooccurrence-based and dictionary-based methods, were compared in terms of the ability to represent two kinds of similarity, i.e., taxonomic similarity and associative similarity. The result of the comparison was that the dictionary-based word vectors better reflect taxonomic similarity, while the LSAbased and the cooccurrence-based word vectors better reflect associative similarity.", "title": "Word Vectors and Two Kinds of Similarity", "venue": "P", "graph_vector": [0.293285, 0.531478, -0.363612, 0.217687, 0.417555, -1.20137, -0.0308109, 0.0583946, -1.61688, 0.809373, 0.249436, -0.310723, 0.512401, -0.167403, 0.158543, -0.109388, 0.305313, -0.548065, 0.371682, 0.00339547, -0.181667, 0.719505, 0.30493, 0.139516, -0.453796, 0.299736, 0.183738, 0.242103, -0.165868, 0.0257666, 0.0429877, -0.408541, 0.33395, -0.250228, -0.168227, 0.426882, -0.331079, 0.939441, -0.107534, -0.274416, -0.385623, -0.214953, -0.380349, 0.347903, 0.909583, -0.666935, -0.0267609, -0.0105586, -0.590864, 0.404444, 0.228521, -0.248522, 1.20072, 0.547663, -0.481313, -0.150154, 0.564135, 0.00634209, 0.311217, -0.200214, -0.109892, -0.124195, -0.443454, -0.0477042, 0.0544072, 0.166825, 0.00549846, -0.108994, 0.280067, 0.0429485, 0.0351095, -0.115539, 0.0681373, -0.361099, 0.231874, -0.441221, -0.610409, -0.856783, 0.060279, -0.341615, -0.256846, 0.124939, -0.0716975, -0.232556, 0.0551232, -0.339676, -0.25477, -0.328989, -0.214371, 0.172627, -0.185193, -0.217748, -0.612051, -0.274782, -0.184985, 0.243591, -0.00830143, 0.247986, 0.122025, -0.124501, 0.000815819, -0.487409, 0.0346122, -0.0903297, 0.266792, -0.127219, -0.121833, -0.230065, 0.167289, -0.108134, 0.194291, 0.110699, -0.25712, 0.298601, -0.209625, 0.326393, 0.281576, 0.22571, -0.332169, -0.29564, -0.187346, 0.102371, -0.556252, -0.14665, 0.190342, -0.201848, -0.420724, 0.0649511], "internal": 1}
{"paper_id": "P06-1043", "abstract": "Statistical parsers trained and tested on the Penn Wall Street Journal (WSJ) treebank have shown vast improvements over the last 10 years. Much of this improvement, however, is based upon an ever-increasing number of features to be trained on (typically) the WSJ treebank data. This has led to concern that such parsers may be too finely tuned to this corpus at the expense of portability to other genres. Such worries have merit. The standard “Charniak parser” checks in at a labeled precisionrecall f-measure of 89.7% on the Penn WSJ test set, but only 82.9% on the test set from the Brown treebank corpus. This paper should allay these fears. In particular, we show that the reranking parser described in Charniak and Johnson (2005) improves performance of the parser on Brown to 85.2%. Furthermore, use of the self-training techniques described in (McClosky et al., 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data. This is remarkable since training the parser and reranker on labeled Brown data achieves only 88.4%.", "title": "Reranking and Self-Training for Parser Adaptation", "venue": "P", "graph_vector": [-0.0933632, -0.032884, 0.0416779, 0.174211, 0.759565, -0.842241, -0.198926, 0.0804839, -1.48377, 0.317821, -0.114259, -0.314594, 0.553288, -0.257544, -0.118335, 0.0189843, 0.59831, -0.610353, -0.124411, 0.364487, -0.3247, 0.663487, 0.443483, -0.105678, -0.24086, 0.411256, 0.031113, 0.0750241, -0.0354967, -0.205991, 0.384392, -0.114841, 0.198718, -0.446445, -0.543955, 0.0567277, -0.249536, 0.685234, 0.00901082, -0.397959, -0.0248578, -0.470552, -0.143805, 0.19436, 0.479475, -0.672708, -0.0769711, -0.0490826, 0.131515, -0.12419, 0.142377, -0.187563, 0.56169, 0.774568, -0.257146, -0.0561273, 0.101409, 0.293606, -0.11674, -0.0925004, -0.0235198, -0.193344, -0.224385, 0.0141146, -0.0486769, 0.0300476, 0.156786, -0.0364751, -0.111128, 0.0881987, -0.198187, -0.420818, -0.00482327, -0.100924, 0.298848, -0.0561254, -0.3495, -0.0554966, -0.323379, 0.0250748, -0.0884135, 0.16715, 0.375552, -0.104523, 0.293066, -0.142476, -0.0425962, -0.175915, -0.0821207, -0.23896, -0.297305, -0.251248, -0.253859, -0.0373404, 0.0995802, -0.342975, -0.306306, -0.0190217, -0.125342, -0.133328, -0.0186149, -0.186465, -0.0583879, -0.113665, -0.0427163, 0.145881, -0.267101, -0.118066, -0.225528, 0.0484094, -0.0951458, -0.259767, -0.0294899, 0.0780032, -0.519394, -0.0344401, 0.312875, -0.0911924, 0.120687, -0.186769, -0.126529, -0.120322, -0.235197, -0.125053, 0.806618, 0.387846, -0.146792, -0.0247447], "internal": 1}
{"paper_id": "P06-2018", "abstract": "Data-driven grammatical function tag assignment has been studied for English using the Penn-II Treebank data. In this paper we address the question of whether such methods can be applied successfully to other languages and treebank resources. In addition to tag assignment accuracy and f-scores we also present results of a task-based evaluation. We use three machine-learning methods to assign Cast3LB function tags to sentences parsed with Bikel’s parser trained on the Cast3LB treebank. The best performing method, SVM, achieves an f-score of 86.87% on gold-standard trees and 66.67% on parser output - a statistically significant improvement of 6.74% over the baseline. In a task-based evaluation we generate LFG functional-structures from the functiontag-enriched trees. On this task we achive an f-score of 75.67%, a statistically significant 3.4% improvement over the baseline.", "title": "Using Machine-Learning to Assign Function Labels to Parser Output for Spanish", "venue": "P", "graph_vector": [-0.0385627, 0.268721, -0.0168968, 0.303639, 0.425294, -1.22142, 0.39332, -0.17399, -1.54182, 0.274368, -0.13433, 0.0282106, 0.704283, -0.245545, -0.193095, -0.162058, 0.581565, -0.873979, 0.675628, 0.0802281, -0.239014, 0.652901, 0.431281, 0.0418093, -0.126174, 0.0258694, -0.262488, 0.0914662, -0.485322, -0.192014, -0.0134882, 0.0621793, -0.11536, -0.920177, 0.317151, -0.0697417, -0.362779, 0.429136, 0.356871, -0.0356176, 0.177986, -0.365825, -0.244095, 0.113445, 0.794375, -0.48959, 0.101004, -0.0773072, 0.115262, -0.148367, 0.350525, -0.100447, 0.390006, 0.69042, 0.0806956, 0.618974, 0.00377961, 0.0772774, 0.40874, -0.0191929, 0.131198, -0.289053, -0.36386, 0.0151961, -0.350202, -0.208074, 0.144336, -0.0647699, 0.100126, 0.0934681, 0.235551, 0.190288, -0.146319, -0.016251, 0.00910335, -0.0919925, -0.313905, -0.46638, 0.0529724, -0.521282, 0.137631, -0.050211, -0.0831966, 0.0982745, 0.278997, -0.0263028, 0.474209, 0.439076, 0.479206, -0.0655351, 0.326372, -0.389346, -0.348337, 0.0641163, -0.499526, 0.085327, -0.0988256, 0.108571, -0.224354, -0.0914736, 0.0656838, -0.0462269, 0.113086, 0.178451, -0.0649211, -0.0526922, 0.0482387, 0.28905, 0.0692175, -0.480031, 0.187946, 0.28052, 0.258823, 0.0293306, -0.0490703, -0.505409, 0.251319, 0.152527, 0.20274, -0.192693, 0.149603, -0.200398, 0.12951, -0.239944, 0.813883, 0.108592, -0.00481745, -0.096991], "internal": 1}
{"paper_id": "P06-1129", "abstract": "Investigations into query log data reveal that more than 10% of queries sent to search engines contain misspelled terms (Cucerzan and Brill, 2004). Such statistics indicate that a good query speller is crucial to search engine in improving web search relevance, because there is little opportunity that a search engine can retrieve many relevant contents with misspelled terms.", "title": "Exploring Distributional Similarity Based Models for Query Spelling Correction", "venue": "P", "graph_vector": [0.241395, 0.178362, 0.0255611, 0.6902, 0.293337, -0.337865, -0.052052, 0.137816, -1.77739, 0.32695, 0.16212, 0.15135, 0.626292, 0.06554, -0.0290621, -0.199301, 0.414565, -0.687305, 0.169178, 0.326196, -0.165292, 0.835317, 0.0815469, -0.341486, -0.601578, 0.181428, 0.35983, 0.322919, 0.0403512, -0.164254, -0.0736036, -0.262593, -0.263405, -0.0878828, -0.216903, 0.839794, 0.00992398, 0.771278, 0.547638, -0.350385, -0.0780371, -0.581818, -0.2542, 0.119823, 0.722768, -0.822861, -0.0090609, 0.116064, -0.371702, 0.137191, 0.244312, -0.425779, 0.683287, 0.464433, -0.414061, 0.141117, 0.075479, 0.352475, -0.0580863, 0.342382, -0.299115, 0.463637, 0.129156, 0.190911, -0.0488672, 0.079495, 0.0317893, -0.199335, -0.312297, 0.0620637, -0.0482812, -0.075746, -0.0384467, -0.239172, -0.110455, -0.0459409, -0.292517, -0.405583, 0.110745, 0.209141, -0.471506, -0.0906021, 0.278154, 0.179556, 0.168048, 0.0123644, 0.260539, -0.31894, 0.0843533, -0.0308156, 0.037126, 0.162359, -0.622833, -0.121015, 0.28733, 0.297857, -0.389498, -0.279513, -0.145205, -0.092356, -0.245209, -0.357252, 0.182465, 0.0662427, -0.0739109, 0.00519058, -0.10332, -0.109483, -0.102381, 0.0288709, 0.0302383, 0.0900173, 0.0206204, 0.0954537, 0.00704045, -0.0179838, 0.232472, 0.225672, -0.378745, 0.11052, -0.264601, 0.278948, -0.257253, 0.0514385, 0.352957, -0.205376, 0.0624298, -0.122083], "internal": 1}
{"paper_id": "P06-2096", "abstract": "Multiple sequence alignment techniques have recently gained popularity in the Natural Language community, especially for tasks such as machine translation, text generation, and paraphrase identification. Prior work falls into two categories, depending on the type of input used: (a) parallel corpora (e.g., multiple translations of the same text) or (b) comparable texts (non-parallel but on the same topic). So far, only techniques based on parallel texts have successfully used syntactic information to guide alignments. In this paper, we describe an algorithm for incorporating syntactic features in the alignment process for non-parallel texts with the goal of generating novel paraphrases of existing texts. Our method uses dynamic programming with alignment decision based on the local syntactic similarity between two sentences. Our results show that syntactic alignment outrivals syntax-free methods by 20% in both grammaticality and fidelity when computed over the novel sentences generated by alignment-induced finite state automata.", "title": "Adding Syntax to Dynamic Programming for Aligning Comparable Texts for the Generation of Paraphrases", "venue": "P", "graph_vector": [-0.315589, -0.0931192, -0.0622587, 0.471986, 0.189595, -0.476132, -0.00866081, 0.279651, -1.74733, 0.271724, -0.262566, -0.441267, 0.809065, 0.322549, -0.0632033, 0.0110009, 0.0125104, -0.497722, 0.37467, 0.157143, -0.254486, 0.812105, 0.00727067, 0.63781, -0.842766, 0.459194, -0.141431, 0.14475, -0.0347647, -0.433901, -0.346203, 0.0557763, 0.502252, -0.704507, -0.130122, 0.0123909, 0.0309232, 0.459632, 0.316888, -0.119741, 0.596278, -0.406119, -0.244572, 0.007396, 0.923139, -0.564043, 0.0807392, 0.154786, 0.0673785, -0.155629, 0.330768, -0.21107, 0.569269, 0.339141, 0.0402147, 0.18138, 0.35462, 0.0208657, 0.227625, 0.32581, -0.451446, 0.101158, 0.28234, 0.150759, 0.238332, 0.31489, -0.0207006, 0.00654956, -0.000100515, -0.0890117, -0.139447, 0.0116144, 0.282668, -0.485433, 0.335143, -0.0316751, -0.373249, -0.137854, 0.0810548, -0.111185, -0.217685, -9.54512e-05, 0.224848, 4.47947e-05, 0.112246, -0.412916, 0.113529, 0.249262, 0.243322, -0.108356, -0.227654, -0.00120576, -0.689076, 0.205347, 0.403759, 0.0319692, -0.148463, 0.0324872, 0.00888214, 0.261401, -0.232109, -0.145981, 0.209957, 0.380144, 0.210637, -0.290778, 0.105017, 0.0581425, -0.0688998, -0.0639987, 0.326021, 0.0256896, 0.0371982, -0.126414, 0.126417, -0.0999606, 0.349224, 0.369867, -0.00062326, 0.0575851, 0.350789, -0.0117077, -0.296774, -0.0514623, 0.169645, 0.197545, -0.15338, -0.0106502], "internal": 1}
{"paper_id": "P06-1086", "abstract": "We present MAGEAD, a morphological analyzer and generator for the Arabic language family. Our work is novel in that it explicitly addresses the need for processing the morphology of the dialects. MAGEAD performs an on-line analysis to or generation from a root+pattern+features representation, it has separate phonological and orthographic representations, and it allows for combining morphemes from different dialects. We present a detailed evaluation of MAGEAD.", "title": "A Morphological Analyzer and Generator for the Arabic Dialects", "venue": "P", "graph_vector": [-0.178757, 0.426809, -0.0953247, 0.334145, 0.530271, -0.893739, 0.0450631, 0.023405, -1.73981, 0.259262, 0.193297, -0.447523, 0.649617, 0.255148, -0.0164396, -0.197996, 0.566872, -0.76646, 0.590537, 0.275222, -0.471845, 0.91629, 0.413462, 0.208483, -0.233422, 0.0334693, -0.138852, -0.230353, -0.266577, -0.306052, -0.348291, 0.134421, -0.270311, -0.466217, -0.46874, 0.259562, -0.245098, 0.364149, 0.155317, -0.11515, -0.0462599, -0.418286, -0.75392, 0.719413, 1.23623, -0.411763, -0.0609896, 0.0988362, 0.145078, -0.040157, 0.365698, -0.281671, 0.324746, 0.835615, -0.0897764, 0.0872527, 0.227028, 0.0630768, 0.277663, -0.0353938, -0.298215, -0.194142, 0.0159288, 0.00680363, -0.163322, 0.161394, 0.162561, -0.149448, -0.074705, 0.339868, -0.21187, 0.0340057, -0.165643, 0.154812, -0.163311, -0.0164169, -0.78801, -0.588777, -0.105955, -0.195577, 0.0568006, 0.211689, 0.177585, -0.0237985, 0.157177, -0.0575271, 0.0320293, -0.297062, 0.262337, 0.118063, 0.351823, -0.289931, -0.69048, -0.212621, 0.09812, 0.328968, 0.122282, -0.134522, -0.0248881, 0.202233, 0.170733, -0.467359, -0.0360006, 0.26757, 0.389681, 0.0582125, -0.181794, -0.301113, -0.290124, -0.0844373, 0.0580977, 0.16293, 0.0338833, -0.290936, 0.123309, 0.0270058, 0.0384017, 0.257304, 0.107046, 0.473585, -0.182851, -0.0812332, -0.114874, 0.285048, 0.694914, 0.317073, -0.0271182, -0.170293], "internal": 1}
{"paper_id": "P06-1011", "abstract": "We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora. By analyzing potentially similar sentence pairs using a signal processinginspired approach, we detect which segments of the source sentence are translated into segments in the target sentence, and which are not. This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.", "title": "Extracting Parallel Sub-Sentential Fragments from Non-Parallel Corpora", "venue": "P", "graph_vector": [0.0744156, 0.251228, -0.174764, 0.414507, 0.0354089, -0.702192, 0.0203324, -0.108548, -1.64474, 0.53619, -0.0362994, -0.149006, 0.555095, 0.1775, 0.0318452, 0.0760284, 0.26206, -0.48645, 0.156862, 0.381093, -0.159675, 0.447633, 0.424288, -0.360576, -0.510066, 0.0696186, 0.26257, 0.352495, -0.242777, 0.0120147, -0.229997, -0.255331, 0.163957, -0.41198, -0.222488, -0.0865472, -0.258785, 0.100007, 0.140316, -0.193421, 0.275016, -0.315161, -0.408037, 0.577567, 1.05838, -1.00671, 0.143881, 0.373823, -0.0774132, -0.276833, -0.241896, -0.0613008, 0.758238, 0.619621, -0.383603, -0.148846, 0.258012, -0.038424, 0.053111, -0.0585713, -0.154545, 0.133193, -0.148882, -0.226155, -0.0935789, 0.154369, 0.0141261, 0.0987122, -0.304569, 0.136594, -0.0494168, -0.0804842, 0.172445, -0.336678, 0.123681, -0.273955, -0.496526, -0.135196, -0.0692361, -0.180217, -0.155192, 0.149121, 0.134974, -0.503621, -0.0246419, -0.112654, -0.0555866, -0.279064, -0.127723, 0.177533, 0.0960366, -0.181544, -0.777219, 0.163756, 0.290867, 0.1956, -0.150978, -0.113375, -0.0767881, 0.131265, -0.187023, -0.254772, -0.16734, 0.0282848, 0.294241, 0.286967, -0.425398, -0.28216, -0.0779658, -0.10029, 0.0217586, -0.19446, -0.0280664, -0.0507487, -0.289972, -0.117176, 0.378655, -0.0564632, -0.0191117, -0.0037668, 0.268632, 0.249437, -0.631192, 0.079136, 0.129963, 0.427804, -0.263317, -0.116707], "internal": 1}
{"paper_id": "P06-1095", "abstract": "This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts. To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data. This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.", "title": "Machine Learning of Temporal Relations", "venue": "P", "graph_vector": [-0.378803, 0.162736, 0.171328, 0.320685, 0.363177, -0.718155, -0.186271, 0.154683, -1.76496, 0.279548, -0.0602236, -0.262426, 0.685051, 0.328662, -0.0768126, 0.277689, 0.557517, -0.699649, 0.49032, 0.560855, -0.24182, 0.507323, 0.240826, -0.293727, -0.35161, 0.0442845, 0.339413, -0.399727, -0.0183099, 0.149783, 0.219052, -0.0526082, -0.105935, -0.557733, 0.0633643, -0.136799, -0.0369536, 0.51865, -0.142577, 0.333758, -0.0580921, -0.0677782, 0.00490736, 0.499486, 1.06966, -0.584265, -0.0279735, 0.41171, 0.0475923, -0.143269, 0.384698, 0.00814008, 0.868932, 0.427464, -0.0290381, 0.181537, 0.210912, 0.202666, -0.318635, 0.0214469, -0.636296, -0.262863, -0.00257725, 0.179116, -0.162358, -0.218305, 0.124055, -0.45319, 0.264741, -0.252765, 0.249263, -0.0534482, 0.100692, -0.193549, 0.155091, -0.480873, -0.134847, -0.0859029, -0.111511, 0.266715, -0.313956, 0.37734, 0.24539, -0.352901, -0.188821, -0.113336, 0.0344803, -0.137151, 0.519901, -0.130083, 0.143224, -0.0960822, -0.542154, 0.0996382, -0.212406, 0.15545, 0.262262, 0.241581, -0.26593, 0.0472682, -0.275386, -0.191154, 0.101288, 0.211905, -0.100243, 0.0461865, -0.16209, -0.018443, -0.0116299, -0.313331, -0.202458, -0.381226, 0.125733, -0.177204, -0.015399, 0.12437, 0.213652, 0.398851, -0.0705945, 0.273264, 0.0307243, -0.0844087, -0.172126, -0.104591, 0.413705, 0.131366, -0.0691194, 0.0621891], "internal": 1}
{"paper_id": "P11-5004", "abstract": "- [BLK+09] C.Bizer, J. Lehmann, G. Kobilarov, S. Auer et al. DBpedia - A Crystallization Point for the Web of Data. Journal of Web Semantics 2009. - community effort to convert Wikipedia articles into structured data - manually-created ontology, mappings from subset of Wikipedia infoboxes to ontology, mappings from Wikipedia articles fo WordNet concepts", "title": "", "venue": "P", "graph_vector": [], "internal": 1}
{"paper_id": "P11-1080", "abstract": "Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.", "title": "Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models", "venue": "P", "graph_vector": [0.0606703, 0.110552, 0.0560625, 0.85219, 0.445366, -0.646921, 0.128138, 0.245727, -1.50493, 0.317331, -0.177998, -0.208448, 0.769211, 0.134839, 0.0256593, -0.144162, 0.514974, -0.776643, 0.00974155, 0.274844, -0.45045, 0.895145, -0.374046, -0.2398, 0.155714, 0.145355, 0.180017, 0.159096, -0.193789, -0.483606, 0.167198, 0.0310053, -0.212886, -0.738419, -0.245406, 0.0971891, -0.190967, 0.454264, 0.209612, -0.0692792, 0.0734557, -0.398175, -0.10696, 0.609708, 0.840033, -0.644287, 0.46796, 0.203058, -0.448726, 0.245691, 0.176451, -0.0302243, 0.974146, 0.771012, -0.0531099, 0.201847, 0.11973, -0.199699, -0.399954, 0.0650045, -0.039435, -0.190374, -0.0130557, 0.145184, -0.414243, 0.153587, 0.295796, -0.260466, -0.145211, 0.400386, 0.421341, -0.0844305, -0.033156, -0.515111, 0.123331, -0.186225, -0.414543, -0.167288, -0.290672, 0.00129244, 0.0652084, -0.117456, 0.0526417, -0.195491, -0.0285739, -0.552664, -0.0577368, -0.065317, 0.229967, 0.0957674, 0.248837, 0.102574, -0.390085, -0.158203, -0.460047, -0.0412394, 0.0786127, 0.00600725, -0.27083, -0.0645817, -0.208422, -0.20877, -0.288238, 0.386246, 0.350334, 0.201661, 0.0922902, 0.138308, -0.000592875, -0.206393, -0.58937, 0.094807, -0.306919, -0.186608, -0.225292, -0.192752, 0.0548074, 0.491963, -0.265682, 0.0733924, 0.0481514, -0.317398, 0.0152075, 0.0521351, 0.437744, 0.0625732, 0.138614, -0.0523719], "internal": 1}
{"paper_id": "P11-1082", "abstract": "While world knowledge has been shown to improve learning-based coreference resolvers, the improvements were typically obtained by incorporating world knowledge into a fairly weak baseline resolver. Hence, it is not clear whether these benefits can carry over to a stronger baseline. Moreover, since there has been no attempt to apply different sources of world knowledge in combination to coreference resolution, it is not clear whether they offer complementary benefits to a resolver. We systematically compare commonly-used and under-investigated sources of world knowledge for coreference resolution by applying them to two learning-based coreference models and evaluating them on documents annotated with two different annotation schemes.", "title": "Coreference Resolution with World Knowledge", "venue": "P", "graph_vector": [0.101297, -0.130417, -0.220119, 0.517974, 0.568237, -0.373179, -0.0598424, 0.117254, -1.69114, 0.577861, 0.0941881, -0.293202, 0.626826, 0.243183, 0.0488433, 0.0225062, 0.554769, -0.774005, 0.206386, 0.336022, -0.608128, 0.270992, -0.00561317, -0.0245305, -0.405102, 0.09303, 0.0834893, 0.423475, -0.110309, -0.159367, 0.0373792, -0.00860932, 0.0900237, -0.367474, -0.176176, 0.321437, -0.157266, 0.468787, 0.390141, 0.140188, -0.31551, -0.344448, -0.24013, 0.356142, 0.760616, -0.917291, 0.0400345, 0.204766, -0.0233796, 0.00270974, 0.228965, 0.0587264, 0.665819, 0.999907, 0.00434135, 0.070292, -0.551822, 0.0733593, -0.152875, 0.0957962, -0.0836154, 0.0789657, 0.125068, -0.11851, -0.0765892, -0.246446, 0.629028, 0.0536648, 0.16687, -0.138297, 0.239142, 0.314664, -0.156089, -0.0400993, -0.160738, -0.413305, -0.53246, -0.0175113, -0.133677, -0.209442, 0.178815, 0.149719, 0.123056, -0.284341, 0.315171, -0.448004, 0.0439738, -0.25392, -0.087346, -0.140951, 0.181522, -0.263626, -0.457373, -0.149054, -0.104686, -0.0217383, 0.0801624, -0.0313401, 0.215971, -0.17636, 0.0352592, -0.441755, 0.0154583, 0.364578, -0.259237, 0.361578, -0.144031, 0.179557, 0.0866609, -0.227613, -0.244329, -0.142565, 0.0652733, 0.0185734, -0.0904692, 0.250717, 0.261529, 0.288827, 0.0633324, 0.146842, 0.032583, -0.0263191, 0.328716, -0.0157033, 0.4151, 0.149179, 0.0804115, -0.441251], "internal": 1}
{"paper_id": "P11-4019", "abstract": "Emerging text-intensive enterprise applications such as social analytics and semantic search pose new challenges of scalability and usability to Information Extraction (IE) systems. This paper presents SystemT, a declarative IE system that addresses these challenges and has been deployed in a wide range of enterprise applications. SystemT facilitates the development of high quality complex annotators by providing a highly expressive language and an advanced development environment. It also includes a cost-based optimizer and a high-performance, flexible runtime with minimum memory footprint. We present SystemT as a useful resource that is freely available, and as an opportunity to promote research in building scalable and usable IE systems.", "title": "SystemT: A Declarative Information Extraction System", "venue": "P", "graph_vector": [0.43673, 0.358485, -0.00789167, 0.0326769, 0.256078, -0.394779, 0.115202, 0.131831, -1.85155, 0.0768755, 0.439641, -0.812979, 0.515285, -0.10815, -0.0154134, 0.0169546, 0.568943, -0.756637, 0.143377, 0.401463, -0.457664, 0.869274, -0.123122, -0.115439, -0.0756035, 0.14078, -0.101058, 0.724464, -0.237741, -0.255813, 0.273171, 0.392741, -0.162346, -0.783137, -0.156055, 0.200588, -0.169645, 1.06547, 0.33325, -0.222563, -0.0410701, -0.224588, -0.146533, 0.318003, 1.38479, -1.17047, 0.185589, 0.17288, -0.099257, -0.244222, 0.207165, -0.141021, 1.02318, 0.815592, -0.00449858, 0.175518, 0.675247, 0.243682, 0.0833057, -0.177393, -0.712414, -0.324742, -0.0748735, 0.0323529, -0.173333, 0.562367, 0.314598, -0.578831, 0.0745675, 0.226388, -0.04761, 0.305969, -0.326039, -0.211441, 0.405291, -0.0877244, -0.653175, -0.675655, -0.433186, -0.27506, 0.321604, 0.489724, 0.149277, 0.0385758, 0.850393, -0.0250369, 0.0672981, 0.217184, 0.173325, 0.142896, -0.30315, 0.290491, -0.672614, 0.0640078, -0.295027, -0.200378, -0.030177, -0.319674, -0.407212, -0.303596, -0.369443, -0.0453107, -0.182957, -0.136482, 0.395979, 0.189851, 0.345492, -0.109637, 0.250586, -0.106294, -0.0250608, -0.0137577, -0.0114334, 0.0367735, -0.179923, -0.101934, 0.948127, -0.0579068, 0.026118, 0.232512, -0.410135, 0.105324, -0.0107645, -0.141535, 0.142874, 0.213861, -0.3453, 0.237678], "internal": 1}
{"paper_id": "P11-2090", "abstract": "This paper presents an original approach to semi-supervised learning of personal name ethnicity from typed graphs of morphophonemic features and first/last-name co-occurrence statistics. We frame this as a general solution to an inference problem over typed graphs where the edges represent labeled relations between features that are parameterized by the edge types. We propose a framework for parameter estimation on different constructions of typed graphs for this problem using a gradient-free optimization method based on grid search. Results on both in-domain and out-of-domain data show significant gains over 30% accuracy improvement using the techniques presented in the paper.", "title": "Typed Graph Models for Semi-Supervised Learning of Name Ethnicity", "venue": "P", "graph_vector": [0.160128, 0.27287, 0.0219759, 0.166742, 0.389135, -0.442052, 0.0067257, -0.304271, -1.39196, 0.397505, 0.05148, -0.254911, 0.466196, 0.0168117, -0.365571, 0.100528, 0.395374, -0.371538, -0.0683119, 0.545602, -0.244126, 0.28304, 0.0998182, -0.0681632, -0.27769, 0.390337, -0.238966, 0.0541378, -0.0661405, 0.0268489, -0.0694886, -0.0826086, -0.0517265, -0.229045, -0.145481, 0.139178, -0.756734, 1.05343, 0.260862, -0.326513, 0.0498784, -0.335196, -0.350725, 0.457634, 0.804364, -0.555414, -0.0572567, 0.0873227, 0.193974, 0.293695, 0.336888, -0.142816, 1.00857, 0.679667, -0.56996, -0.313341, 0.339987, 0.461971, 0.0962113, 0.0213974, -0.0887297, 0.16786, -0.0728852, 0.0844863, -0.00838628, -0.258953, 0.0203061, 0.0774313, -0.0979912, 0.055593, 0.637243, -0.425331, 0.0703771, -0.300839, -0.0726341, -0.647315, -0.495674, -0.392255, 0.0420451, 0.131369, 0.143422, -0.102216, 0.0467663, -0.031194, 0.0477701, 0.102822, 0.177424, -0.0343766, -0.161618, -0.124353, 0.00561765, 0.0413049, -0.548079, -0.327868, 0.0160624, -0.0161558, 0.14533, 0.0322232, -0.00344139, -0.227797, -0.0644681, -0.370069, -0.143827, -0.0240292, 0.293673, 0.16106, 0.0639846, 0.082508, -0.110774, -0.12382, -0.0162474, -0.259182, -0.06036, -0.127151, 0.179515, -0.0602632, 0.0146745, 0.121135, -0.0895071, 0.265826, 0.264474, -0.10858, 0.146253, -0.123643, 0.525641, 0.225321, -0.194549, 0.222957], "internal": 1}
{"paper_id": "P11-1128", "abstract": "We introduce synchronous tree adjoining grammars (TAG) into tree-to-string translation, which converts a source tree to a target string. Without reconstructing TAG derivations explicitly, our rule extraction algorithm directly learns tree-to-string rules from aligned Treebank-style trees. As tree-to-string translation casts decoding as a tree parsing problem rather than parsing, the decoder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets.", "title": "Adjoining Tree-to-String Translation", "venue": "P", "graph_vector": [0.0483827, 0.245887, 0.16928, 0.190106, 0.286296, -0.999845, 0.298344, 0.0428672, -1.70225, 0.171581, -0.177119, -0.531293, 0.601078, 0.236215, 0.165311, -0.0360794, 0.676467, -0.607378, -0.267956, -0.0220716, -0.3434, 0.555417, 0.64451, -0.244405, -0.517437, 0.305561, 0.140045, -0.0970302, -0.17329, -0.0845473, -0.0699922, 0.261869, 0.0893174, -0.473819, -0.34369, 0.396318, -0.501873, 0.388921, 0.3216, -0.216654, -0.107238, -0.447993, -0.184542, 0.39401, 1.03718, -0.447159, 0.302888, 0.279698, -0.177241, -0.029074, -0.0638273, -0.47895, 0.771358, 0.304817, -0.256829, 0.161006, 0.0219993, 0.308961, 0.331966, 0.0797782, -0.397309, -0.148887, -0.304489, 0.00724557, -0.319432, -0.138313, 0.049432, 0.188102, -0.203052, 0.0308582, 0.0779993, 0.191016, 0.115562, -0.283343, -0.111364, 0.0939346, -0.678025, -0.270716, -0.18544, -0.0893258, -0.0939701, 0.0933256, -0.113436, 0.00276179, 0.0284962, -0.341085, -0.213195, 0.237921, -0.12665, -0.087915, -0.00217097, 0.142977, -0.390951, -0.184095, -0.0600828, 0.315396, -0.176636, 0.0102881, -0.0778365, -0.214265, -0.314912, -0.229067, 0.179291, 0.254324, 0.204086, -0.143441, -0.109141, -0.140674, 0.373086, -0.197111, -0.119303, 0.0493655, -0.0261764, -0.385508, -0.0745264, 0.177162, 0.342883, 0.0122757, -0.125285, 0.0823443, 0.105327, 0.161543, -0.196261, 0.266186, 0.578592, 0.287065, 0.154474, -0.202488], "internal": 1}
{"paper_id": "P11-2017", "abstract": "Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines.", "title": "Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems", "venue": "P", "graph_vector": [0.254309, 0.190095, -0.18585, 0.299524, 0.337515, -1.05886, 0.39009, -0.058541, -1.97031, 0.042723, 0.147253, 0.0363918, 0.481025, 0.137257, 0.105706, -0.328325, 0.385048, -0.443613, 0.136099, 0.218539, -0.0741163, 0.598016, 0.0491416, -0.143149, -0.606407, -0.0186933, -0.196424, 0.0355371, -0.180009, -0.0726161, -0.209421, 0.111209, 0.0845275, -1.25077, -0.141447, 0.52294, -0.219132, 0.600338, 0.414992, 0.068445, 0.0109149, -0.0981006, -0.471777, 0.260315, 1.29753, -1.14443, 0.116995, -0.301699, 0.0145616, -0.314093, 0.174471, -0.189609, 0.501026, 1.10761, -0.262679, 0.0894676, 0.394888, 0.308798, 0.368826, 0.327017, -0.0849096, 0.0406612, -0.0625398, -0.106704, -0.263934, 0.0609276, 0.148042, 0.173544, -0.107965, 0.0135013, 0.33068, 0.145937, 0.213287, 0.104235, 0.0255155, -0.0425611, -0.147515, -0.535026, -0.159624, 0.173255, -0.27332, -0.123257, 0.218754, 0.0232032, 0.130755, 0.0287258, -0.132098, -0.028204, 0.324591, -0.214993, 0.242957, 0.0726537, -0.391719, 0.077789, 0.0667925, 0.111539, -0.239887, 0.362897, 0.399089, -0.0818431, -0.0270075, -0.424209, 0.0588124, 0.238518, -0.343659, -0.0938142, 0.247782, 0.00111114, 0.410479, -0.229189, -0.164618, -0.0634092, -0.287546, -0.00487181, -0.0707412, -0.635859, -0.00630678, -0.19806, 0.0665559, -0.481648, 0.561432, -0.102098, -0.161272, -0.159719, 0.374602, 0.336994, -0.458676, 0.151346], "internal": 1}
{"paper_id": "P11-1015", "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term–document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.", "title": "Learning Word Vectors for Sentiment Analysis", "venue": "P", "graph_vector": [-0.0418615, 0.0953395, -0.000450641, 0.220363, 0.374071, -0.94931, -0.0423102, -0.169144, -1.60868, 0.151473, -0.234252, -0.394165, 0.295845, -0.0656479, 0.216184, -0.0894176, 0.239503, -0.194795, 0.251342, 0.0596644, -0.217864, 0.654292, 0.19777, 0.169499, -0.145722, 0.105167, 0.0451805, -0.0957248, -0.17177, -0.388388, -0.190448, 0.194228, -0.0305884, -0.570699, -0.495535, -0.0645278, -0.307932, 0.404816, 0.115959, -0.234314, -0.0635208, -0.59789, -0.30353, 0.512108, 0.876099, -1.08543, -0.0732715, -0.259687, -0.28606, 0.23823, 0.191999, -0.132672, 0.718419, 0.624863, -0.162423, -0.142619, 0.262186, 0.198038, 0.0214621, 0.201004, 0.207684, 0.0993684, -0.188262, 0.146608, -0.0438664, 0.278974, 0.310245, -0.274213, 0.134021, 0.123107, 0.320059, -0.0346875, 0.117174, -0.406258, 0.0825127, -0.249084, -0.479204, -0.00177277, 0.199406, -0.121025, -0.343639, 0.23986, -0.00317136, 0.0113664, 0.274163, -0.299069, 0.13188, -0.161926, -0.0823199, -0.181498, 0.166016, 0.293879, -0.624328, -0.250055, -0.195951, -0.0657009, -0.0506506, 0.0344127, -0.0552758, 0.14539, -0.193131, -0.281862, -0.254694, -0.0772434, -0.112945, 0.0763175, -0.294963, -0.555445, 0.163045, -0.305911, -0.0827164, -0.058724, -0.0443172, 0.239844, -0.216201, 0.00205753, 0.299582, 0.0525835, -0.0156983, -0.0202114, -0.0968143, 0.0700405, 0.160533, -0.217245, 0.0852209, 0.290209, 0.165907, 0.308674], "internal": 1}
{"paper_id": "P04-1043", "abstract": "In this paper we have designed and experimented novel convolution kernels for automatic classification of predicate arguments. Their main property is the ability to process structured representations. Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify PropBank predicate arguments with accuracy higher than the current argument classification stateof-the-art. Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.", "title": "A Study on Convolution Kernels for Shallow Semantic Parsing", "venue": "P", "graph_vector": [-0.00376143, 0.278633, 0.423454, 0.177228, 0.202696, -0.808995, 0.149214, -0.085891, -1.49904, 0.267001, -0.0788844, -0.00760321, 0.696265, 0.166675, -0.0700508, -0.134237, 0.375673, -0.269791, 0.0802494, -0.202715, -0.474893, 0.51309, 0.106136, -0.06214, -0.778216, 0.0666675, 0.136867, -0.0640734, -0.31393, -0.0433878, 0.0292103, -0.110085, 0.387915, -0.715101, -0.069566, 0.300432, 0.0370694, 0.664254, 0.366421, 0.037707, 0.0259341, -0.378414, -0.308683, 0.0547128, 0.688818, -0.377935, 0.145099, 0.155976, 0.0276004, 0.228569, 0.29024, -0.238719, 0.743766, 0.652919, 0.0105966, 0.0376311, 0.324894, -0.0206047, -0.162687, -0.0166506, -0.307429, -0.116737, -0.0827892, -0.249607, -0.242183, -0.272576, 0.0489775, 0.0913264, -0.0397848, -0.253334, 0.033907, -0.15214, -0.282415, -0.306854, 0.0904925, 0.0125462, -0.49763, -0.415073, 0.130439, -0.184267, 0.397243, 0.00515818, 0.125011, 0.124819, -0.100358, 0.115599, 0.273264, -0.392122, 0.399189, 0.382404, -0.0657036, 0.063354, -0.547856, -0.191524, -0.186608, -0.0594349, -0.0415672, 0.197558, -0.365763, -0.117278, 0.342697, -0.0907605, 0.19862, -0.0795193, 0.0237314, -0.14527, -0.0628793, 0.147481, 0.192811, -0.276865, 0.0289213, -0.19869, -0.17314, -0.0652344, -0.0381833, 0.055775, 0.720892, 0.0460967, 0.103109, 0.069259, 0.0487859, 0.09199, -0.09928, -0.0192372, 0.396893, 0.169353, 0.196246, -0.176249], "internal": 1}
{"paper_id": "P04-1035", "abstract": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as “thumbs up” or “thumbs down”. To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.", "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts", "venue": "P", "graph_vector": [-0.0394737, 0.190408, 0.309933, 0.438776, 0.369937, -0.66305, -0.00899555, 0.234677, -1.71425, -0.130816, -0.202258, -0.616908, 0.751604, 0.143837, 0.000617446, -0.064239, 0.0525896, -0.491189, 0.108882, 0.0598907, -0.106119, 0.226684, 0.057356, -0.196085, -0.0673204, 0.331997, -0.0400879, 0.0610448, -0.326111, -0.33401, -0.266494, 0.115674, -0.133418, -0.60679, -0.262332, -0.105997, -0.238532, 0.625972, 0.132278, -0.36177, 0.0857788, -0.465473, -0.19007, 0.469683, 0.716156, -0.748147, 0.0973972, -0.0407647, -0.0332687, -0.0519188, 0.271111, -0.340913, 0.861427, 0.658173, 0.0317179, -0.0198935, 0.330235, 0.188306, -0.00422869, 0.172559, 0.235479, 0.0989769, 0.277185, -0.0337882, -0.0592646, 0.058951, 0.206493, -0.0560024, 0.125013, 0.0268386, 0.158686, 0.0909871, -0.00474866, -0.182379, 0.0468238, -0.386185, -0.185957, -0.250143, -0.10695, 0.218842, -0.228134, -0.0152067, -0.0653887, -0.0176455, 0.132485, -0.201971, -0.247692, -0.226945, 0.0680567, -0.0428217, -0.0392378, 0.181987, -0.693955, -0.238986, -0.182801, 0.00651913, 0.168082, -0.238323, 0.0241113, 0.316879, -0.0890759, -0.179731, -0.202081, -0.254859, -0.0835745, -0.0270444, -0.411325, -0.453163, 0.0500043, -0.271949, -0.061674, -0.161075, 0.111991, -0.0663729, 0.0966356, 0.000809839, 0.132653, -0.080763, -0.0623854, 0.203458, -0.283064, -0.0419884, 0.267205, -0.0274365, 0.449158, 0.286842, 0.333302, 0.109259], "internal": 1}
{"paper_id": "J07-2013", "abstract": "Understanding language is one of the great challenges of science, and languagerelated technology is one of the great opportunities of Information Technology. Consequently, many different kinds of researchers work on language issues. Within the computer science community, language is studied by the “ACL community,” by which I mean researchers who regularly publish in Association for Computational Linguistics (ACL) venues, such as the journal Computational Linguistics and ACL conferences. But language-related research is also carried out by researchers in other areas of computer science, including knowledge representation, cognitive modeling, vision and robotics, and human–computer interaction communities. Additionally, there are even more people outside computer science who study language, including linguists, psycholinguists, philosophers, and sociolinguists. This is fine; understanding language and developing language technology are huge problems, and it is very useful to have many research communities from diverse backgrounds working on language. This will be especially true if the different research communities are aware of each other, so they can share insights, observations, problems, and so forth. Unfortunately, my impression is that the ACL community is much less interested in research with other language-related research communities than it used to be. This impression is mostly based on discussions I have had with researchers who are on the border between ACL and another language-research community. Several such people have told me that whereas ten years ago they occasionally submitted papers to ACL venues and attended ACL conferences, now they do not bother, because they believe that the ACL community has no interest in their research. In attempt to quantify this insight, I have analyzed citations from papers published in Computational Linguistics in 1995 and in 2005. Specifically, I extracted all citations from Computational Linguistics (CL) articles (excluding book reviews) in these years to journal papers. I then classified the cited journal papers into one of the categories shown in Table 1; whenever possible this classification was based on the subject category assigned by ISI Journal Citation Reports (JCR) to the cited journal. For example, a citation of a paper in Cognitive Science would count as a psychology citation, since ISI JCR classifies Cognitive Science as “Psychology, Experimental.” I counted citations myself, rather than relying on ISI JCR’s count, as there were some mistakes in JCR’s counting. I also created my own “other NLP and speech” classification (that is, references to speech and NLP", "title": "Last Words The Shrinking Horizons of Computational Linguistics", "venue": "J", "graph_vector": [-0.0402202, 0.691853, -0.277185, 0.0628192, 0.36852, -0.842602, -0.0573519, -0.437021, -2.09632, 0.0968782, -0.160348, -0.0167387, 0.988363, 0.191706, -0.0482011, -0.0252618, 0.22153, -0.26132, 0.290623, 0.188886, -0.217194, 0.485123, 0.252147, -0.0350409, -0.233291, -0.143469, 0.0341695, 0.0160741, -0.0897648, -0.293184, -0.109941, 0.0520292, 0.247229, -0.572665, -0.205092, 0.32742, -0.17806, 0.868823, 0.664176, -0.147151, 0.185174, -0.623383, -0.511885, 0.52523, 1.17114, -1.11018, -0.39656, 0.0928398, -0.0321574, 0.136448, 0.160987, -0.137619, 0.862364, 0.485439, -0.178424, -0.153942, 0.157198, -0.101519, 0.049122, -0.207615, -0.357581, 0.0445951, -0.231899, 0.00804999, 0.112412, 0.267273, 0.186078, -0.21752, 0.135049, 0.19393, -0.0949957, 0.132556, 0.142226, 0.186056, 0.131471, 0.125033, -0.45311, -0.227414, -0.304021, 0.35898, -0.0808915, -0.0357197, 0.469762, -0.452562, -0.055773, -0.544702, 0.0489692, -0.160209, -0.0517358, -0.052167, -0.145301, 0.104518, -0.488067, -0.427356, 0.110987, 0.131199, -0.368869, -0.238858, -0.00551248, -0.270414, -0.165606, -0.270686, -0.030325, 0.230586, 0.0111507, 0.0274621, -0.0886794, -0.244363, 0.21503, -0.428045, -0.128568, 0.114501, -0.0241829, -0.100043, 0.120622, -0.077773, 0.53063, 0.135455, 0.344672, 0.2726, 0.00228875, 0.117627, 0.0863883, -0.200657, 0.720409, 0.207861, -0.216133, 0.284303], "internal": 1}
{"paper_id": "J08-1008", "abstract": "", "title": "The Trouble with Physics.", "venue": "J", "graph_vector": [0.183724, 0.220568, -0.0484683, 0.370688, 0.618708, -0.793508, -0.294846, 0.0254658, -1.41214, -0.132632, -0.128973, -0.200637, 0.706497, -0.181609, 0.273567, -0.0259421, 0.599669, -0.326337, 0.278445, -0.0395877, -0.612058, 0.24455, 0.446749, 0.00914029, -0.842838, 0.404616, -0.211429, 0.2545, -0.176617, -0.341401, 0.679193, -0.260932, 0.133232, -0.474377, -0.75662, 0.13047, -0.526546, 0.772307, 0.481773, -0.137992, -0.0832747, -0.303338, -0.458535, 0.657013, 1.0691, -1.08495, -0.113975, -0.183463, -0.201587, -0.211509, 0.0861856, -0.320579, 0.738115, 0.10814, -0.113637, 0.0351299, 0.236182, 0.430126, 0.0430617, 0.0780759, -0.455486, 0.0635218, -0.027552, -0.12401, 0.250678, -0.144845, 0.38911, 0.264627, 0.278386, 0.307424, 0.317247, -0.0712167, -0.155208, -0.160129, 0.0223955, -0.420748, -1.05518, -0.666722, -0.275086, 0.275272, -0.204182, -0.0130602, 0.412498, 0.314335, -0.0647961, -0.362505, 0.179963, -0.158506, -0.189779, -0.141003, 0.0615724, -0.175979, -0.438974, -0.138753, -0.100792, 0.571686, 0.0027512, -0.0353087, 0.130299, -0.555841, -0.417568, -0.340461, -0.0187325, -0.191181, 0.0407301, -0.18478, 0.192129, -0.140526, 0.129846, -0.205953, 0.0748609, 0.330586, 0.0313526, 0.336854, -0.0729376, -0.144184, 0.106158, 0.392997, 0.184106, 0.141742, -0.0549433, 0.270863, -0.23701, -0.401428, 0.714361, 0.285944, 0.0209755, -0.192097], "internal": 1}
{"paper_id": "J94-2002", "abstract": "Among formalisms for the computation of syntactic description of natural language sentences, Tree-Adjoining Grammars (TAG) play a major role. The class of TAG's was first introduced in Joshi, Levy, and Takahashi (1975) and Joshi (1985); since then, formal and computational properties of this class have been extensively investigated, and the linguistic relevance of TAGs has been discussed in the literature as well. The reader who is interested in these topics is referred to some of the most recent works, for example Schabes (1990) and Frank (1992), and to the references therein. Both in a theoretical vein and in view of possible natural language processing applications, the recognition and parsing problems for TAGs have been extensively studied and many algorithms have been proposed for their solution. On the basis of tabular techniques, the least time upper bound that has been attested is 0(1 G11w16) for the random-access model of computation, 1G1 being the size of the input grammar and 1w1 the length of the input string. In recent years, improvement of such a worst-case running time has been a common goal for many researchers, but up to the present time the TAG parsing problem has strongly resisted all such attempts. Because of the record of all these efforts, the task of improving the above upper bound is actually regarded as a difficult one by many researchers. In support of such a common feeling, in this paper we restate the TAG parsing problem as a search problem and relate it to the well-known computational problem of Boolean matrix multiplication. This is done in such a way that time upper bounds for TAG parsing can be transferred to time upper bounds for the latter problem. More precisely, we show that any algorithm for TAG parsing that improves the 0(1 G 11w 16) time upper bound can be converted into an algorithm for Boolean matrix multiplication running in less than 0(m3) time, m being the order of the input", "title": "Tree-Adjoining Grammar Parsing and Boolean Matrix Multiplication", "venue": "J", "graph_vector": [-0.00340856, 0.108742, 0.524568, 0.209479, 0.550372, -0.890008, 0.273525, -0.0462114, -1.89992, -0.358543, -0.453469, -0.488495, 0.599958, 0.327078, 0.0991722, 0.0287796, 0.53497, -0.630241, 0.204406, 0.147912, -0.417805, 0.695794, 0.521, -0.144102, -0.692468, 0.429729, 0.0854007, 0.260851, -0.264886, -0.615629, 0.0779738, 0.277482, 0.1209, -0.284745, -0.119444, 0.23528, -0.485361, 0.200342, 0.0795095, -0.172702, 0.145391, -0.137143, -0.138537, 0.613209, 1.20751, -0.850861, -0.254613, 0.0717846, -0.186394, 0.0374614, 0.225145, -0.347056, 0.902325, 0.294908, -0.351182, 0.338856, 0.190021, 0.0831833, 0.203385, -0.216779, -0.25896, -0.279191, -0.089712, 0.662028, -0.373979, -0.0413613, -0.0841188, 0.191278, 0.146975, -0.135746, 0.0964931, 0.242276, -0.136988, -0.282785, -0.00414684, 0.193673, -0.755246, -0.277834, 0.157272, -0.0208678, -0.299599, 0.0598667, -0.200762, -0.147626, 0.414449, -0.103206, 0.233751, 0.0953603, -0.00383798, -0.207419, -0.139508, -0.103634, -0.791022, -0.513345, -0.0497696, 0.354139, -0.342631, -0.0088894, 0.352512, -0.263489, 0.157448, -0.206413, 0.448556, 0.45753, -0.00228794, 0.0991344, -0.206124, -0.279261, 0.159071, -0.359528, -0.379751, 0.156192, -0.283364, -0.273359, -0.0843726, 0.097783, 0.497596, -0.084788, 0.14781, 0.159507, -0.0470594, 0.0165527, -0.363409, 0.354703, 0.280195, 0.250606, -0.146301, -0.104196], "internal": 1}
{"paper_id": "J15-2001", "abstract": "Statistical Machine Translation (SMT) advanced near the beginning of the century from word-based models (Brown et al. 1993) towards more advanced models that take contextual information into account. Phrase-based (Koehn, Och, and Marcu 2003; Och and Ney 2004) and N-gram-based (Casacuberta and Vidal 2004; Mari˜no et al. 2006) models are two instances of such frameworks. Although the two models have some common properties, they are substantially different. The present work is a step towards combining the benefits and remedying the flaws of these two frameworks. Phrase-based systems have a simple but effective mechanism that learns larger chunks of translation called bilingual phrases.1 Memorizing larger units enables the phrase-based model to learn local dependencies such as short-distance reorderings, idiomatic collocations, and insertions and deletions that are internal to the phrase pair. The model, however, has the following drawbacks: (i) it makes independence assumptions over phrases, ignoring the contextual information outside of phrases, (ii) the reordering model has difficulties in dealing with long-range reorderings, (iii) problems in both search and modeling require the use of a hard reordering limit, and (iv) it has the spurious phrasal segmentation problem, which allows multiple derivations of a bilingual sentence pair that have the same word alignment but different model scores. N-gram-based models are Markov models over sequences of tuples that are generated monotonically. Tuples are minimal translation units (MTUs) composed of source and target cepts.2 The N-gram-based model has the following drawbacks: (i) only precalculated orderings are hypothesized during decoding, (ii) it cannot memorize and use lexical reordering triggers, (iii) it cannot perform long distance reorderings, and (iv) using tuples presents a more difficult search problem than in phrase-based SMT. The Operation Sequence Model. In this article we present a novel model that tightly integrates translation and reordering into a single generative process. Our model explains the translation process as a linear sequence of operations that generates a source and target sentence in parallel, in a target left-to-right order. Possible operations are (i) generation of a sequence of source and target words, (ii) insertion of gaps as explicit target positions for reordering operations, and (iii) forward and backward jump operations that do the actual reordering. The probability of a sequence of operations is defined according to an N-gram model, that is, the probability of an operation depends on the n − 1 preceding operations. Because the translation (lexical generation) and reordering operations are coupled in a single generative story, the reordering decisions may depend on preceding translation decisions and translation decisions may depend", "title": "The Operation Sequence Model —Combining N-Gram-Based and Phrase-Based Statistical Machine Translation", "venue": "J", "graph_vector": [-0.0446533, 0.238363, -0.0429423, 0.252128, 0.626401, -0.486766, 0.039733, -0.162018, -1.65272, 0.0477071, -0.140731, -0.312052, 0.319399, 0.0720614, -0.0495745, -0.0461244, 0.68721, -0.552732, 0.0216165, 0.322153, -0.260531, 0.544085, 0.321961, 0.0204214, -0.456024, -0.0615724, 0.100306, 0.0691326, -0.221225, 0.0392164, 0.0712354, -0.0932283, 0.11872, -0.571149, -0.336602, 0.348267, -0.218624, 0.703441, 0.356416, -0.03832, 0.17099, -0.324015, -0.216848, 0.463863, 1.4037, -0.598149, 0.0801208, 0.187782, -0.0992743, -0.0401542, 0.549673, -0.243418, 0.683228, 0.385179, -0.365229, 0.55524, 0.0728924, 0.301841, -0.0628829, 0.254022, 0.008264, -0.18417, -0.140791, -0.00792112, 0.0590457, -0.182152, 0.194935, 0.299324, -0.328794, -0.0106061, 0.125443, -0.0292681, 0.0843583, -0.333584, 0.17768, 0.0758107, -0.466572, -0.31551, -0.0848945, -0.0153925, -0.148815, 0.146777, 0.109085, -0.0017251, -0.216524, -0.495287, 0.00868263, -0.430522, -0.236008, -0.0266279, 0.0722184, 0.119171, -0.512422, 0.223642, 0.0865551, 0.168641, 0.0301398, 0.240551, -0.0939042, -0.0259269, -0.375815, -0.0887979, 0.0463401, 0.588433, 0.152153, 0.157073, -0.0754958, 0.0316081, -0.103646, -0.156219, 0.205396, 0.0694062, -0.112217, 0.0739212, 0.239112, 0.0937829, 0.411854, -0.071829, 0.184033, -0.0203633, 0.10846, 0.0982825, -0.0561699, 0.13754, 0.438608, 0.274589, 0.157534, 0.0995667], "internal": 1}
{"paper_id": "J15-1005", "abstract": "Much of statistical NLP research relies on some sorts of manually annotated corpora to train models, but annotated resources are extremely expensive to build, especially on a large scale. The creation of treebanks is a prime example (Marcus, Santorini, and Marcinkiewicz 1993). However, the linguistic theories motivating these annotation efforts are often heavily debated, and as a result there often exist multiple corpora for the same task with vastly different and incompatible annotation philosophies. For example, there are several treebanks for English, including the Chomskian-style Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), the HPSG LinGo Redwoods Treebank (Oepen et al. 2002), and a smaller dependency treebank (Buchholz and Marsi 2006). From the perspective of resource accumulation, it seems a waste in human efforts.1 A second, related problem is that the raw texts are also drawn from different domains, which for the above example range from financial news (Penn Treebank/Wall Street Journal) to transcribed dialog (LinGo). It would be nice if a system could be automatically ported from one set of guidelines and/or domain to another, in order to exploit a much larger data set. The second problem, domain adaptation, is very well studied (e.g., Blitzer, McDonald, & Pereira 2006; Daum´e III 2007). This work focuses on the widely existing and equally important problem, annotation adaptation, in order to adapt the divergence between different annotation guidelines and integrate linguistic knowledge in corpora with incongruent annotation formats. In this article, we describe the problem of annotation adaptation and the intrinsic principles of the solutions, and present a series of successively improved concrete models, the goal being to transfer the annotations of a corpus (source corpus) to the annotation format of another corpus (target corpus). The transfer classifier is the fundamental component for annotation adaptation algorithms. It learns correspondence regularities between annotation guidelines from a parallel annotated corpus, which has two kinds of annotations for the same data. In the simplest model (Model 1), the source classifier trained on the source corpus gives its predications to the transfer classifier trained on the parallel annotated corpus, so as to integrate the knowledge in the two corpora. In a variant of the simplest model (Model 2), the transfer classifier is used to transform the annotations in the source corpus into the annotation format of the target corpus; then the transformed source corpus and the target corpus are merged in order to train a more accurate classifier. Based on the second model, we finally develop an optimized model (Model 3), where two optimization strategies, iterative training and predict-self re-estimation, are integrated to further improve the efficiency of annotation adaptation. We experiment on Chinese word segmentation and dependency parsing to test the efficacy of our methods. For word segmentation, the problem of incompatible annotation guidelines is one of the most glaring: No segmentation guideline has been widely accepted due to the lack of a clear definition of Chinese word morphology. For dependency parsing there also exist multiple disparate annotation guidelines. For", "title": "Automatic Adaptation of Annotations", "venue": "J", "graph_vector": [0.164835, 0.318798, 0.15173, 0.435152, 0.46562, -0.747418, -0.0529026, -0.236677, -1.53881, 0.334108, -0.203905, -0.355804, 0.702223, 0.131201, -0.300424, -0.134731, 0.175634, -0.681144, -0.049267, 0.52032, 0.145897, 0.870429, 0.423564, 0.126193, -0.152925, 0.259479, 0.282057, 0.0404334, -0.120302, -0.358726, -0.0788372, 0.156473, 0.0619082, -0.363434, -0.389523, 0.490709, -0.447339, 0.576088, 0.0907531, -0.27196, 0.0218829, -0.10507, 0.0317152, 0.302519, 0.68247, -0.678211, -0.154304, 0.0626409, 0.127123, 0.25659, 0.214306, -0.491466, 0.653439, 0.7042, -0.502575, 0.0510985, 0.0796314, 0.265896, 0.339546, 0.167726, -0.343455, -0.0683497, -0.208409, -0.00624071, -0.233253, -0.199528, 0.0330923, -0.150195, -0.0306974, 0.00399804, 0.426774, 0.191012, 0.0143569, 0.155594, 0.361075, -0.414293, -0.560517, -0.190127, -0.128036, -0.229343, -0.225927, 0.00150265, 0.270601, 0.231882, 0.462673, -0.141816, 0.00692894, -0.0801407, -0.078392, -0.0539652, 0.0393832, 0.0426678, -0.517706, -0.138199, 0.253559, -0.124452, -0.396655, -0.380467, -0.00424407, -0.0943203, 0.177275, -0.220602, 0.242815, 0.364379, -0.0532081, -0.161733, -0.0813466, 0.0981525, 0.0821255, -0.0831267, -0.163921, -0.0983736, -0.0807764, -0.00569753, -0.0155268, 0.12043, 0.43062, 0.150019, 0.0229465, 0.37105, -0.130697, -0.326393, -0.227477, -0.00425798, 0.132356, 0.167987, -0.175624, -0.154281], "internal": 1}
{"paper_id": "J15-2004", "abstract": "Sentiment analysis (Pang and Lee 2008; Liu 2012) has received much attention from both research and industry communities in recent years. Sentiment classification, which identifies sentiment polarity (positive or negative) from text (sentence or document), has been the most extensively studied task in sentiment analysis. Until now, there have been two mainstream approaches for sentiment classification. The lexicon-based approach (Turney 2002; Taboada et al. 2011) aims to aggregate the sentiment polarity of a sentence from the polarity of words or phrases found in the sentence, and the learning-based approach (Pang, Lee, and Vaithyanathan 2002) treats sentiment polarity identification as a special text classification task and focuses on building classifiers from a set of sentences (or documents) annotated with their corresponding sentiment polarity. The lexicon-based sentiment classification approach is simple and interpretable, but suffers from scalability and is inevitably limited by sentiment lexicons that are commonly created manually by experts. It has been widely recognized that sentiment expressions are colloquial and evolve over time very frequently. Taking tweets from Twitter1 and movie reviews on IMDb2 as examples, people use very casual language as well as informal and new vocabulary to comment on general topics and movies. In practice, it is not feasible to create and maintain sentiment lexicons to capture sentiment expressions with high coverage. On the other hand, the learning-based approach relies on large annotated samples to overcome the vocabulary coverage and deals with variations of words in sentences. Human ratings in reviews (Maas et al. 2011) and emoticons in tweets (Davidov, Tsur, and Rappoport 2010; Zhao et al. 2012) are extensively used to collect a large number of training corpora to train the sentiment classifier. However, it is usually not easy to design effective features to build the classifier. Among others, unigrams have been reported as the most effective features (Pang, Lee, and Vaithyanathan 2002) in sentiment classification. Handling complicated expressions delivering people’s opinions is one of the most challenging problems in sentiment analysis. Compositionalities such as negation, intensification, contrast, and their combinations are typical cases. We show some concrete examples here:", "title": "A Statistical Parsing Framework for Sentiment Classification", "venue": "J", "graph_vector": [-0.0915502, 0.0122877, 0.20713, 0.0788622, 0.604659, -0.612204, -0.180841, -0.486328, -1.83701, -0.0639343, -0.290436, -0.410049, 0.607304, 0.183444, 0.217601, -0.0208896, 0.47028, -0.178355, 0.144809, 0.40129, 0.0375452, 0.31739, 0.102188, -0.108425, -0.195383, 0.516712, -0.12104, 0.00686324, 0.138978, -0.096154, -0.299784, 0.41029, -0.0174379, -0.408524, -0.103926, -0.080968, -0.10004, 0.773771, -0.0425073, -0.0563609, 0.20315, -0.392639, -0.56239, 0.488848, 0.744783, -0.758768, -0.410568, 0.397206, 0.202114, -0.275842, 0.0429218, -0.266073, 0.482991, 0.625258, -0.213862, -0.0104491, 0.339055, 0.230342, 0.113474, 0.113572, 0.190276, 0.290339, -0.171909, 0.00147769, -0.481387, -0.000944078, 0.201438, 0.118853, -0.0203712, -0.0146224, -0.0174023, -0.0155687, -0.00730044, -0.0113691, -0.0955064, -0.324054, -0.740174, -0.0140755, 0.166863, 0.0442616, -0.198564, 0.463719, 0.309308, -0.412151, 0.345112, 0.160666, 0.103865, -0.121019, -0.0566039, -0.121101, 0.0207072, 0.277165, -0.530363, -0.0585971, -0.200054, 0.170137, -0.320936, 0.0358409, 0.0313446, 0.0474349, -0.143502, -0.468481, 0.158244, 0.121753, -0.169042, -0.0424169, 0.0257538, -0.288591, 0.391486, -0.361658, -0.018271, -0.131574, 0.138564, 0.314637, 0.0148668, -0.150568, 0.305776, -0.00523144, -0.00442574, -0.338113, -0.0783488, 0.0906069, 0.148175, 0.226757, 0.0876757, 0.202673, 0.332704, 0.0797377], "internal": 1}
{"paper_id": "J15-2003", "abstract": "Performing textual inference is at the heart of many semantic inference applications, such as Question Answering (QA) and Information Extraction (IE). A prominent generic", "title": "Efficient Global Learning of Entailment Graphs", "venue": "J", "graph_vector": [-0.208287, 0.267483, 0.0337264, 0.224376, 0.217584, -0.795413, 0.265877, -0.0377062, -1.85115, 0.455384, -0.26063, -0.560848, 0.517372, 0.196136, -0.0765419, 0.0793783, 0.521068, -0.428081, 0.280542, 0.543043, -0.244291, 0.489929, 0.224191, 0.346086, -0.658343, 0.0484631, -0.104576, 0.121851, -0.294759, 0.0734118, 0.167881, -0.000251194, -0.320821, -0.457221, -0.0583963, -0.108268, -0.11592, 0.649008, 0.140493, -0.209214, -0.286831, -0.394495, -0.0680371, 0.23306, 0.790329, -0.667532, 0.0619589, 0.264481, -0.129744, 0.0456999, -0.138481, -0.166691, 0.457608, 0.660784, -0.444132, -0.00835235, -0.0969238, -0.00175737, -0.264383, 0.177025, 0.0970731, -0.394227, -0.118578, -0.032938, -0.0863511, 0.0183, 0.248531, -0.241574, -0.0717714, 0.253344, 0.0504044, 0.0545022, 0.00906468, -0.248734, 0.358234, -0.324616, -0.594092, 0.0471715, 0.244916, 0.117416, -0.255727, -0.175774, -0.0518973, -0.206616, 0.145873, -0.364924, -0.170815, 0.0828442, 0.27974, -0.267768, -0.0571958, 0.23194, -0.446947, -0.055843, 0.199359, 0.0690538, -0.0558322, -0.270809, -0.347114, -0.30021, -0.181963, 0.147577, -0.0692103, 0.0886788, 0.236087, 0.269062, 0.0541399, -0.245348, 0.304495, 0.327771, -0.209533, -0.163439, 0.00464054, 0.204286, 0.119693, -0.346994, 0.500695, 0.168502, -0.0978744, 0.243091, -0.279509, -0.00770887, 0.127987, -0.049752, 0.471995, 0.346934, 0.0570814, 0.141825], "internal": 1}
{"paper_id": "J12-3009", "abstract": "", "title": "Chunshan Xu is an assistant professor at Anhui University of Architecture, China. His research interests include syntactic parsing, syntactic complexity, and quantitative syntactic study. Xu’s e-mail address is adinxu@yahoo.com.cn. Haitao Liu is a Qiushi distinguished professor of linguistics and applied linguistics at", "venue": "J", "graph_vector": [0.186923, 0.914314, 0.0844339, 0.297525, 0.902895, -0.778475, -0.225434, 0.509054, -2.13703, 0.277603, -0.00116728, -0.716994, 0.959529, -0.251498, 0.127849, -0.188543, 0.379434, -0.613606, -0.417218, 0.342689, -0.273618, 0.856983, 0.810483, -0.277132, -0.462768, 0.0978816, -0.0653453, 0.0327876, -0.337469, -0.318154, -0.204883, -0.244602, -0.0467615, -0.607959, -0.519135, 0.174726, -0.567761, 0.822391, 0.537172, -0.177064, -0.386547, -0.664484, -0.906817, 0.541815, 0.776868, -1.12241, -0.230443, 0.28313, -0.142696, 0.13677, 0.171185, -0.130159, 1.28595, 0.837561, -0.254938, 0.343189, 0.15363, -0.171213, 0.133145, 0.0833005, 0.0999762, -0.344079, -0.369067, 0.228299, -0.17896, 0.194665, 0.168024, -0.202158, 0.18573, 0.171432, -0.0914202, 0.143744, -0.00924993, -0.247355, 0.188508, 0.450378, -0.833771, -0.768022, -0.382332, -0.222087, -0.0571173, 0.0422247, 0.363431, 0.349908, 0.560646, -0.582934, 0.434286, -0.611425, 0.0863729, -0.122747, 0.0825477, -0.0817004, -0.638467, -0.267538, -0.471645, 0.223527, 0.161039, -0.293046, -0.11105, 0.121044, -0.299218, -0.301386, 0.23492, 0.177253, 0.171398, -0.0850799, -0.239251, -0.0853144, 0.474205, -0.498585, -0.0787311, 0.366317, -0.736072, -0.0275976, -0.254497, -0.329866, 0.898105, 0.223755, -0.0809575, 0.652006, -0.0418835, -0.246567, -0.455047, 0.355941, 1.10842, 0.67916, -0.412357, 0.421304], "internal": 1}
{"paper_id": "J14-1001", "abstract": "Boas, Hans Christian and Ivan A Sag. 2012. Sign-Based Construction Grammar. CSLI Publications, Stanford, CA. Bresnan, Joan and Ronald M. Kaplan. 1982. Lexical-Functional Grammar: A formal system for grammatical representation. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations, pp. 29–130, MIT Press, Cambridge, MA. Bresnan, Joan, Ronald M. Kaplan, Stanley Peters, and Annie Zaenen. 1982. Cross-serial dependencies in Dutch. Linguistic Inquiry, 13(4):613–635. Callmeier, Ulrich. 2002. Preprocessing and encoding techniques in PET. In Stephan Oepen, Daniel Flickinger, J. Tsujii, and Hans Uszkoreit, editors, Collaborative Language Engineering. A Case Study in Efficient Grammar-based Processing, pp. 127–140, CSLI Publications, Stanford, CA. Carpenter, Bob and Gerald Penn. 1994. ALE: The attribute logic engine user’s guide, version 2.0.1. Carnegie Mellon University, Department of Philosophy, Paper 526. Chomsky, Noam. 1981. Lectures on Government and Binding. Foris Publications, Dordrecht, Holland.", "title": "Obituary Ivan A. Sag", "venue": "J", "graph_vector": [0.140394, 0.294302, -0.0798216, 0.211526, 0.728278, -0.710103, -0.232957, -0.155194, -2.09964, 0.781353, -0.183547, -0.752373, 0.827575, 0.107266, 0.24158, -0.131205, 0.213648, -0.732923, 0.157242, 0.82868, -0.147868, 0.750519, -0.0995105, -0.292846, -0.217514, 0.289855, 0.387038, -0.462174, -0.414765, 0.197548, -0.160698, 0.143814, -0.155477, -0.511258, -0.0943308, 0.118753, -0.155229, 0.559066, 0.193707, 0.334954, 0.209564, -0.403883, 0.0972475, 0.817258, 0.320333, -0.3707, 0.142142, -0.0450559, -0.362173, -0.144451, 0.613227, -0.159663, 0.838484, 0.305556, -0.488358, 0.501563, 0.131648, -0.24766, -0.129851, -0.0748357, -0.275482, -0.0680847, -0.484662, -0.12293, -0.114005, 0.102874, -0.0440846, -0.0998489, 0.0712771, -0.0970444, -0.437698, -0.0737163, -0.297451, -0.222583, -0.00754487, -0.254179, -1.08368, -0.472811, -0.189068, 0.153456, -0.108998, 0.410733, -0.246054, 0.104822, 0.0890834, 0.0305846, 0.164874, -0.163545, -0.120226, -0.0454285, -0.183419, -0.161282, -0.742833, -0.267259, 0.201172, 0.262777, -0.384658, 0.0737762, 0.288769, -0.0166506, 0.174508, -0.364309, 0.102834, -0.0506001, -0.161557, 0.00599715, -0.142425, -0.153733, 0.303367, 0.0531471, 0.263465, -0.0990892, 0.087274, 0.155996, -0.339074, 0.210347, 0.287109, 0.0811905, -0.233754, 0.17913, 0.16778, 0.216805, -0.116452, -0.00319666, 0.682615, 0.0353623, -0.350987, 0.0684628], "internal": 1}
{"paper_id": "J14-4001", "abstract": "The authors of the article ”Frame-Semantic Parsing” and a graduate student discovered that in rows 7 and 8 of Table 8, at inference time for argument identification with gold frames, the described model included gold spans along with the candidate set of automatic spans (elaborated in Section 6.1), thus creating an oracle, and artificially bloating the precision, recall, and F1 metrics. The revised metrics are: Naive decoding: Precision=78.65 Recall=72.85 Fscore=75.64 (row 7) Beam search decoding: Precision=80.40 Recall=72.84 Fscore=76.43 (row 8) This unintended artifact also changes the interpretation of Table 9. The reported results there should be interpreted as an oracle comparison of various inference methods, that uses both automatically extracted candidate spans as well as gold spans for argument identification. None of the other results in the article are affected by this error.", "title": "", "venue": "J", "graph_vector": [], "internal": 1}
{"paper_id": "J80-2003", "abstract": "A truly natural language processing system does not have to have a perfect model of human language use, but it should have knowledge of whatever limitations its model has. Then, for a user who has exceeded these limitations, the system can interactively aid the user to rephrase the input in an acceptable way. This is a prerequisite to any practical application, whether it be natural language communication to a data base, a medical consultation system, or an office automation system. Users will not find such a system practical unless it gives helpful feedback when the system fails to understand an input. As an example of how a user's input can exceed the system's model, we repeat an anecdote of Woods (1973b) about his system for answering natural language queries about lunar rock samples. One question asked was, &quot;What is the average weight of all your samples?&quot; This overstepped the system's model in at least three ways.", "title": "Responding Intelligently to Unparsable Inputs'", "venue": "J", "graph_vector": [-0.0446568, 0.453329, -0.0680583, 0.645145, 0.49912, -0.590872, 0.123423, 0.081401, -2.18815, 0.552416, -0.12584, -0.468056, 0.534947, 0.0708524, -0.311013, 0.318665, 0.562555, -0.545944, 0.101848, 0.13848, -0.82424, 0.424927, -0.0568971, -0.144989, -0.992038, 0.101641, 0.281802, 0.0233538, -0.058058, -0.0968, -0.153896, 0.201572, 0.0966181, -0.778308, -0.268221, 0.599477, -0.629195, 0.465407, 0.139669, -0.210205, -0.257624, -0.485483, -0.333911, 0.232163, 1.16562, -0.649101, -0.107357, 0.183769, -0.10219, -0.167572, 0.0553389, -0.111972, 0.646675, 0.353174, -0.0529271, -0.260842, 0.044592, 0.28401, 0.372137, 0.257255, -0.162191, -0.259114, -0.277638, 0.112579, -0.0764884, 0.0658531, 0.425768, 0.14197, 0.206162, -0.247163, -0.209008, -0.231805, 0.013732, 0.400327, -0.356247, -0.0757938, -0.805762, -0.340345, -0.539416, -0.083476, 0.252703, 0.141556, 0.308201, -0.24215, 0.13933, -0.114093, -0.508621, -0.0186569, -0.177674, 0.228078, -0.101167, -0.523831, -0.405935, -0.384868, 0.342311, 0.188115, 0.00160389, 0.393848, -0.323598, -0.0512919, -0.192187, -0.183799, -0.348142, -0.0407119, -0.230492, 0.392565, -0.259416, 0.208007, 1.00359, 0.144216, -0.00367188, 0.267994, 0.0683476, 0.400686, -0.0113196, 0.318308, 0.39352, 0.287132, 0.0200102, 0.143397, -0.118545, 0.188713, -0.180524, -0.262248, 0.354652, 0.512174, -0.490917, 0.170395], "internal": 1}
{"paper_id": "J09-3005", "abstract": "", "title": "Natural Language Understanding. The Benjamin/Cummings Publishing Company, Inc.,", "venue": "J", "graph_vector": [], "internal": 1}
{"paper_id": "J13-4003", "abstract": "Coreference resolution is a natural language processing (NLP) task that consists of determining which mentions in a discourse refer to the same entity or event. A mention is a referring expression that has an entity or event as a referent. By referring expression we mean noun phrases (NP), named entities (NEs), embedded nouns, and pronouns (all but pleonastic and interrogative ones) whose meaning as a whole is a", "title": "A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution", "venue": "J", "graph_vector": [0.313837, 0.0704382, -0.0223589, 0.463787, 0.535149, -0.492167, 0.308594, -0.229759, -1.84907, 0.401132, 0.000243013, -0.145331, 0.336317, -0.027808, 0.0584645, -0.0833232, 0.479907, -0.69026, 0.0418185, 0.421281, -0.492008, 0.22678, 0.31822, -0.0487889, -0.172663, 0.138135, 0.268264, 0.681148, 0.110132, -0.201728, 0.192901, 0.23107, -0.022881, -0.828214, 0.1371, 0.34694, -0.37787, 0.496027, 0.118796, -0.0412725, 0.27374, -0.0288443, -0.407896, 0.481358, 0.802484, -0.776762, 0.328181, 0.0735923, 0.0990553, -0.0712306, 0.241164, 0.163466, 0.589121, 0.752219, 0.110931, -0.0882088, -0.425271, 0.018065, -0.152139, 0.382983, -0.170799, -0.312744, -0.105291, -0.159933, 0.102773, -0.328029, 0.421861, -0.0206262, 0.0199138, 0.063788, 0.304132, 0.304373, 0.135998, -0.31099, -0.079019, -0.205539, -0.314505, -0.314661, -0.059741, -0.373346, 0.0965346, 0.12055, -0.0434068, -0.0322351, 0.0624837, -0.246495, 0.153082, -0.0604497, 0.0995263, 0.188169, 0.382468, -0.0618043, -0.566576, -0.420523, -0.275062, -0.164572, 0.0373608, -0.0939324, 0.195491, -0.0610705, -0.0141143, -0.226041, -0.266961, 0.330727, -0.240536, 0.100331, -0.577533, 0.376336, -0.114978, -0.330265, -0.0328129, 0.225561, 0.0483573, -0.10676, 0.296843, -0.0309911, 0.215558, 0.147243, 0.190483, 0.132522, -0.105814, -0.0430143, 0.112486, 0.0189426, 0.502074, 0.135636, -0.0642418, -0.0172578], "internal": 1}
{"paper_id": "J87-1015", "abstract": "", "title": "Johan A Manual of Intensional Logic (CSLI lecture notes number 1) Center for the Study of Language and Information,", "venue": "J", "graph_vector": [], "internal": 1}
{"paper_id": "J87-1006", "abstract": "", "title": "NOTES", "venue": "J", "graph_vector": [], "internal": 1}
{"paper_id": "J87-1003", "abstract": "English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement. The agreement in question involves number in nouns and reflexive pronouns and is syntactic rather than semantic in nature because grammatical number in English, like grammatical gender in languages such as French, is partly arbitrary. The formal proof, which makes crucial use of the Interchange Lemma of Ogden et al., is so constructed as to be valid even if English is presumed to contain grammatical sentences in which respectively operates across a pair of coordinate phrases one of whose members has fewer conjuncts than the other; it thus goes through whatever the facts may be regarding constructions with unequal numbers of conjuncts in the scope of respectively, whereas other arguments have foundered on this problem. respective(Iy). Delight in these words is a widespread but depraved taste. Fowler (1937: 500)", "title": "Michael B. Kac Department of Linguistics University of Minnesota Minneapolis, Minnesota 55455", "venue": "J", "graph_vector": [-0.0371565, 0.71857, 0.0690422, 0.435511, 0.810475, -0.396715, 0.055299, -0.119708, -2.4754, 0.211788, -0.36085, -0.702105, 0.221841, 0.0240435, 0.0794604, -0.0102481, 0.95012, -0.964543, -0.0566593, 0.407778, -0.339142, 0.814687, 0.498974, 0.0655061, -0.274502, 0.503801, 0.733223, 0.323384, -0.0253685, -0.329717, -0.0202342, 0.0208524, -0.199129, -0.0934559, -0.635838, -0.0454153, -0.0683933, 0.322756, -0.217359, -0.0532408, -0.176315, -0.630227, -0.301329, 0.58211, 1.063, -0.794117, -0.194009, 0.0343901, -0.44216, -0.211151, 0.237728, -0.209811, 1.03832, 0.600365, -0.460845, 0.172526, 0.30689, 0.1153, 0.13337, 0.189952, -0.341695, -0.263617, -0.319153, 0.122344, -0.369519, -0.245367, -0.0860659, -0.161089, 0.360449, -0.0136035, 0.141217, -0.229824, -0.078179, -0.113009, 0.144271, -0.187757, -0.982239, -0.748366, 0.0773801, -0.178705, 0.0526029, 0.253991, -0.13507, -0.372768, 0.0496957, -0.182455, 0.166386, -0.324465, -0.309791, 0.243884, -0.10441, -0.344604, -0.739734, 0.0517328, -0.165599, 0.672123, -0.0979791, 0.087602, 0.0898152, -0.0156923, -0.231259, -0.232526, 0.165905, -0.132212, 0.0486639, -0.0306779, -0.00885156, -0.334466, 0.298419, -0.289367, -0.267459, -0.0188518, -0.430832, -0.185015, 0.089722, 0.152994, 0.474206, -0.324758, 0.199636, 0.364046, 0.205362, 0.459264, -0.223894, -0.114098, 0.989001, 0.230288, -0.253845, 0.00336409], "internal": 1}
{"paper_id": "J11-4003", "abstract": "There are around 7,000 languages spoken in the world today (Lewis 2009) that trace thousands of years of human cultural and linguistic evolution. Historical linguistics discovers the relationships between these languages using the comparative method to identify systematic sound correspondences between words in different languages. These correspondences distinguish the words that have descended from a common ancestor of the languages (i.e., are “cognate”), and are representative of the phonological or morphological innovations in the shared history of those languages (Durie and Ross 1996). Take, for example, the following words meaning “three”: Javanese telu, Mussau tolu, and Tongan tolu. One could therefore postulate that the two Oceanic languages, Mussau and Tongan, are more closely related to each other than to Javanese (in schematic form: Mussau,Tongan|Javanese) following a merger of Proto-MalayoPolynesian *e/-aw into Proto-Oceanic *o (Blust 2009). Correctly identifying the relationships between these languages is not an exercise in mere phylogenetic classification but a tool for investigating human prehistory. As an example, linguists have used the comparative method to trace the spread of the 1,200 or so Austronesian languages across the Pacific back to Taiwan (Blust 1999; Pawley 2002). Recently, computational phylogenetic methods from evolutionary biology have been", "title": "Levenshtein Distances Fail to Identify Language Relationships Accurately", "venue": "J", "graph_vector": [-0.105577, 0.43567, 0.0836027, -0.109233, 1.12189, -0.519169, -0.15073, -0.0932516, -2.18971, 0.175774, -0.0591384, -0.065561, 0.512195, 0.0103332, -0.100938, -0.0254393, 0.0619959, -1.01823, 0.484248, 0.515272, -0.257851, 0.929922, 0.208846, 0.552425, -0.779449, 0.52627, 0.471422, -0.128557, -0.50242, -0.0783513, -0.249335, 0.311771, -0.113006, -0.501897, -0.720251, 0.20912, -0.373873, 0.797195, 0.570499, -0.311302, -0.048231, -1.18071, -0.233845, 0.24988, 1.02056, -1.33793, 0.081351, 0.0187792, -0.503364, -0.33697, 0.302267, 0.0926417, 1.03428, 0.502699, -0.134384, 0.142885, -0.115459, 0.238895, 0.0632582, 0.0339842, -0.365278, -0.0694836, -0.0729569, -0.249644, -0.587183, 0.0419666, -0.151404, -0.306437, -0.718994, 0.266522, -0.207182, -0.0365392, 0.0098724, -0.335555, -0.187167, -0.1238, -0.680464, -0.906689, -0.300033, -0.0645182, 0.139967, -0.29808, 0.142701, 0.186241, 0.0257499, -0.265332, 0.188534, -0.618184, 0.518948, -0.254111, -0.199453, 0.125697, -1.07598, 0.0120967, -0.260673, -0.4477, -0.0556319, -0.0908118, -0.174814, -0.235567, -0.235144, -0.655074, 0.340214, 0.569129, 0.260172, -0.244362, -0.295494, -0.234067, -0.0199373, -0.166769, 0.0625652, 0.312378, -0.44326, -0.193652, 0.165905, 0.0284401, 0.062933, 0.193651, 0.302101, 0.0990047, -0.139663, 0.278476, -0.27082, 0.00256093, 0.30293, 0.188901, 0.0551281, 0.113895], "internal": 1}
{"paper_id": "Q13-1033", "abstract": "Greedy transition-based parsers are very fast but tend to suffer from error propagation. This problem is aggravated by the fact that they are normally trained using oracles that are deterministic and incomplete in the sense that they assume a unique canonical path through the transition system and are only valid as long as the parser does not stray from this path. In this paper, we give a general characterization of oracles that are nondeterministic and complete, present a method for deriving such oracles for transition systems that satisfy a property we call arc decomposition, and instantiate this method for three well-known transition systems from the literature. We say that these oracles are dynamic, because they allow us to dynamically explore alternative and nonoptimal paths during training – in contrast to oracles that statically assume a unique optimal path. Experimental evaluation on a wide range of data sets clearly shows that using dynamic oracles to train greedy parsers gives substantial improvements in accuracy. Moreover, this improvement comes at no cost in terms of efficiency, unlike other techniques like beam search.", "title": "Training Deterministic Parsers with Non-Deterministic Oracles", "venue": "Q", "graph_vector": [0.340642, 0.43352, 0.0335859, 0.349074, 0.826657, -0.800825, 0.133333, -0.500621, -1.69449, 0.260609, -0.0897652, 0.0311611, 0.461301, -0.0465149, 0.0344053, -0.315682, 0.295478, -0.544944, 0.0465372, 0.240595, -0.374743, 0.761765, 0.508796, -0.0166532, -0.159883, -0.00273672, -0.0985202, 0.0055778, -0.445554, -0.108514, -0.0533229, 0.0469753, 0.306769, -0.339377, -0.145208, 0.257373, -0.315025, 0.565882, -0.0103848, -0.165561, -0.0388882, -0.306226, -0.146788, 0.685571, 0.488206, -0.682387, 0.0799151, 0.0403384, -0.0612403, 0.324943, 0.342808, -0.242922, 0.486617, 0.924418, 0.0233548, 0.0146644, -0.31633, 0.246363, -0.211652, -0.147877, -0.217692, -0.0519797, -0.386548, -0.0446586, -0.25348, 0.0557927, 0.133864, -0.0320744, 0.043924, 0.2318, 0.342469, 0.0172933, -0.165393, 0.138217, 0.278639, 0.0143043, -0.641913, 0.0081197, -0.163854, -0.132582, 0.061143, 0.188903, 0.289768, 0.230817, -0.119225, -0.573653, 0.0137328, -0.194523, -0.0225716, -0.115589, 0.0525798, 0.0661651, -0.574842, 0.127459, 0.662467, 0.0142936, -0.141988, -0.00279238, -0.0151705, -0.0673144, -0.0875924, -0.342295, 0.0630402, 0.0029779, -0.127601, 0.197862, -0.229193, -0.00877466, 0.263248, -0.0777397, -0.122524, -0.0884782, -0.192417, 0.00558086, 0.541734, 0.130409, 0.403745, 0.401543, 0.147844, 0.63986, 0.19274, -0.405735, 0.0393741, -0.229133, 0.310991, 0.121961, -0.0405332, -0.11459], "internal": 1}
{"paper_id": "Q13-1003", "abstract": "Recent work has shown that the integration of visual information into text-based models can substantially improve model predictions, but so far only visual information extracted from static images has been used. In this paper, we consider the problem of grounding sentences describing actions in visual information extracted from videos. We present a general purpose corpus that aligns high quality videos with multiple natural language descriptions of the actions portrayed in the videos, together with an annotation of how similar the action descriptions are to each other. Experimental results demonstrate that a text-based model of similarity between actions improves substantially when combined with visual information from videos depicting the described actions.", "title": "Grounding Action Descriptions in Videos Michaela Regneri *, Marcus Rohrbach °, Dominikus Wetzel *,", "venue": "Q", "graph_vector": [0.0313975, -0.0992731, 0.265554, 0.416874, 0.768497, -1.03932, 0.172471, -0.287829, -1.31291, 0.309313, -0.145298, -0.456386, 0.673489, 0.0976999, -0.416619, 0.0863368, 0.234629, -0.714341, 0.363865, 0.528008, -0.20668, 0.340218, 0.360826, -0.11341, -0.361101, -0.115143, -0.0267445, 0.133943, 0.2849, 0.0410071, -0.228305, -0.0198318, 0.422383, -0.21908, 0.0946654, 0.00663942, -0.104756, 0.342027, 0.438028, -0.283961, -0.241348, -0.564336, -0.146889, 0.346048, 1.18322, -1.36926, -0.269184, -0.303219, 0.0938655, 0.229547, 0.31468, -0.203199, 0.93042, 0.912328, 0.00222229, 0.0644746, 0.216655, 0.00558184, 0.186666, -0.159754, -0.327814, 0.120234, 0.150879, 0.42538, -0.0714575, -0.193614, 0.0253712, -0.110388, 0.0418237, 0.0935126, 0.238455, 0.0847689, 0.213429, -0.0611909, 0.0728806, -0.296544, -0.605921, -0.101367, 0.0599643, -0.252812, -0.0879222, 0.191391, 0.314775, 0.0841593, 0.0672118, -0.309791, -0.0188488, -0.228394, 0.149597, 0.388049, -0.0953175, -0.44004, -0.00106601, -0.534749, 0.0413088, 0.0464162, 0.0463777, 0.0129165, -0.0376523, -0.446846, -0.442499, -0.142325, 0.0581658, 0.222338, 0.349419, 0.0927113, -0.37457, 0.132297, 0.379741, -0.193318, -0.0405878, 0.0705069, -0.0140946, 0.0813773, 0.113353, -0.425879, 0.598425, 0.153809, -0.238932, 0.175297, 0.0727219, -0.00708416, -0.195699, -0.304016, 0.175802, -0.0452578, -0.210654, 0.14504], "internal": 1}
{"paper_id": "Q14-1002", "abstract": "We present FLORS, a new part-of-speech tagger for domain adaptation. FLORS uses robust representations that work especially well for unknown words and for known words with unseen tags. FLORS is simpler and faster than previous domain adaptation methods, yet it has significantly better accuracy than several baselines.", "title": "FLORS: Fast and Simple Domain Adaptation for Part-of-Speech Tagging", "venue": "Q", "graph_vector": [-0.183471, 0.264393, -0.221224, 0.595343, 0.611076, -0.7775, -0.0369611, -0.0545927, -1.16634, 0.311894, -0.242649, -0.380414, 0.687938, 0.089151, 0.052484, 0.0346127, 0.181027, -0.347687, -0.0651382, 0.499826, -0.809662, 0.84053, 0.0953915, -0.0305444, -0.250895, 0.134093, 0.0299866, -0.0811161, -0.304659, -0.192849, 0.0721434, -0.245403, -0.00243805, -0.245316, -0.398704, 0.379108, -0.362275, 0.603572, -0.222148, -0.459697, -0.255644, -0.592524, -0.577989, 0.248749, 0.516098, -0.732942, 0.0757057, 0.21869, 0.123899, -0.11247, 0.306356, -0.189934, 0.809281, 0.769529, -0.189289, 0.295501, -0.0594581, 0.16065, -0.241406, -0.132844, -0.00894387, -0.314338, -0.300531, -0.00194406, 0.0840057, 0.101155, 0.290919, -0.0559314, -0.221669, 0.0161315, -0.122003, 0.252869, 0.0237965, -0.167215, 0.113288, -0.24212, -0.479426, -0.429487, -0.140036, 0.0588167, -0.358392, 0.048608, 0.236183, 0.325442, 0.252671, -0.0129625, -0.0927656, 0.263849, -0.0396073, -0.0770238, 0.123425, 0.301892, -0.229802, 0.0217009, 0.134339, -0.418414, -0.0315631, -0.160691, -0.310624, -0.304331, -0.586224, -0.387196, -0.021458, -0.32496, 0.25941, 0.167583, 0.0271794, 0.17203, 0.243334, -0.404279, 0.187583, -0.315753, -0.0959205, 0.176625, -0.244167, 0.0326429, 0.256117, -0.113611, -0.0315362, 0.320935, -0.00443931, 0.217415, 0.177202, -0.259431, 0.717324, 0.233042, -0.0646833, -0.0812952], "internal": 1}
{"paper_id": "Q14-1037", "abstract": "We present a joint model of three core tasks in the entity analysis stack: coreference resolution (within-document clustering), named entity recognition (coarse semantic typing), and entity linking (matching to Wikipedia entities). Our model is formally a structured conditional random field. Unary factors encode local features from strong baselines for each task. We then add binary and ternary factors to capture cross-task interactions, such as the constraint that coreferent mentions have the same semantic type. On the ACE 2005 and OntoNotes datasets, we achieve state-of-theart results for all three tasks. Moreover, joint modeling improves performance on each task over strong independent baselines.1", "title": "A Joint Model for Entity Analysis: Coreference, Typing, and Linking", "venue": "Q", "graph_vector": [-0.074001, -0.0262985, -0.113124, 0.430338, 0.547818, -0.231498, -0.107101, 0.171487, -1.39532, 0.641021, -0.102931, -0.483389, 0.635464, 0.173432, 0.126398, -0.00401386, 0.30088, -0.629418, 0.0236259, 0.298905, -0.748884, 0.501486, 0.0626995, -0.212518, -0.25414, 0.0793089, 0.149714, 0.408554, 0.0665081, -0.0292655, -0.0437768, 0.0918685, 0.0121066, -0.566558, -0.163408, 0.178262, -0.473731, 0.562907, 0.245489, -0.14217, 0.143146, -0.374248, -0.473701, 0.517533, 0.93178, -0.714989, 0.103182, 0.167, -0.0560166, 0.157421, 0.155794, 0.0434707, 0.730006, 0.716445, -0.142313, -0.0925371, -0.25613, 0.194183, 0.00504715, -0.111399, -0.437207, -0.0485308, 0.177736, 0.027649, -0.0132747, -0.137844, 0.345447, 0.146817, 0.0770663, 0.0984232, 0.31307, 0.142251, -0.168536, -0.102033, 0.0947388, -0.196271, -0.479944, -0.132248, -0.119716, -0.190567, -0.0290068, 0.116719, 0.215719, -0.315639, 0.105106, -0.441801, -0.0526907, -0.309428, -0.109037, -0.0146134, 0.255123, 0.0911513, -0.512611, -0.10867, -0.247277, -0.064328, -0.166853, 0.0364232, 0.268153, -0.0555571, 0.119031, -0.106114, 0.182015, 0.112857, -0.442391, 0.0935091, -0.396102, 0.173309, -0.0163472, -0.273104, -0.260816, -0.0370332, -0.141203, -0.0569066, -0.166353, -0.191747, 0.353866, 0.218677, 0.0984451, 0.187171, 0.0617047, -0.0169844, 0.176505, -0.114094, 0.433082, 0.112389, 0.0780694, -0.182518], "internal": 1}
{"paper_id": "S01-1005", "abstract": "We describe our experience in preparing the lexicon and sense-tagged corpora used in the English all-words and lexical sample tasks of SENSEVAL-2.", "title": "English Tasks: All-Words and Verb Lexical Sample", "venue": "S", "graph_vector": [-0.107188, -0.00700563, -0.280724, -0.0103874, 0.55159, -0.856968, 0.0978032, 0.012099, -1.18617, 0.646346, -0.126668, -0.301846, 0.79911, 0.280168, 0.0717342, -0.150865, 0.570891, -0.53064, 0.243586, 0.570151, -0.154891, 0.470662, 0.171093, 0.175247, -0.122724, 0.171676, 0.0988504, 0.27095, -0.157667, -0.10212, 0.107101, -0.116711, 0.191819, -0.356248, 0.0391155, 0.0355675, -0.365096, 0.681247, -0.0584732, -0.0375631, -0.0824009, -0.248109, -0.0914153, 0.170547, 0.780783, -0.496712, 0.188203, 0.233744, 0.224775, 0.186804, 0.411981, -0.211895, 0.901556, 0.676474, -0.0240926, -0.0580996, 0.221091, -0.0352845, -0.149873, 0.0980463, -0.218632, -0.0205405, 0.159694, 0.01842, 0.226071, -0.0215947, -0.0755697, -0.103674, -0.110364, 0.126422, 0.149781, 0.134785, 0.21817, -0.121731, 0.143541, 0.0837571, -0.636679, -0.527945, 0.0871548, 0.231376, 0.104098, 0.0109972, 0.102578, -0.0512949, -0.0585983, 0.071163, -0.11107, -0.310367, 0.0120493, 0.121207, 0.0996265, -0.26907, -0.346279, -0.329923, -0.199828, 0.118435, -0.021899, -0.0812196, -0.141862, -0.0838647, -0.227159, -0.193118, -0.0357412, 0.180779, -0.0219062, -0.0384554, -0.347636, -0.0405397, -0.107082, -0.14207, 0.276889, 0.159411, -0.00438715, 0.32907, 0.0272424, 0.0187709, 0.523568, 0.422492, 0.0803763, -0.114697, -0.26074, 0.27443, -0.268486, -0.197825, 0.254317, 0.406711, 0.0940812, 0.108763], "internal": 1}
{"paper_id": "S10-1082", "abstract": "We describe our language-independent unsupervised word sense induction system. This system only uses topic features to cluster different word senses in their global context topic space. Using unlabeled data, this system trains a latent Dirichlet allocation (LDA) topic model then uses it to infer the topics distribution of the test instances. By clustering these topics distributions in their topic space we cluster them into different senses. Our hypothesis is that closeness in topic space reflects similarity between different word senses. This system participated in SemEval-2 word sense induction and disambiguation task and achieved the second highest V-measure score among all other systems.", "title": "KSU KDD: Word Sense Induction by Clustering in Topic Space", "venue": "S", "graph_vector": [-0.0149313, 0.124792, 0.0162053, 0.139251, 0.464269, -0.871325, 0.172031, 0.103399, -1.39827, 0.273276, -0.488592, -0.207705, 0.853636, 0.139939, -0.13781, -0.387318, 0.390814, -0.788426, 0.0535225, 0.272564, -0.273015, 0.651209, 0.0409926, -0.149564, -0.295644, 0.200266, 0.0490407, 0.456418, -0.243932, -0.130863, -0.20059, 0.0064342, 0.170725, -0.230538, -0.239244, 0.112139, -0.380754, 0.547137, 0.0645456, -0.261657, -0.168989, -0.181324, -0.367911, 0.10802, 0.898485, -0.821903, 0.279992, -0.212357, -0.0537607, 0.0410926, 0.269262, 0.173492, 0.757384, 0.875835, -0.491992, 0.252913, -0.0641832, 0.101788, -0.283934, 0.225989, 0.0888525, -0.385509, 0.0178802, 0.153293, -0.0733271, -0.000270009, -0.0556161, -0.46844, 0.157997, 0.0783864, 0.014568, 0.149901, -0.0180635, -0.403672, 0.184332, -0.358787, -0.597135, -0.304926, -0.0478359, -0.232237, -0.358948, -0.231745, 0.106544, -0.230687, -0.206497, -0.24422, -0.00333949, -0.204175, 0.225761, -0.0370227, 0.0718289, -0.118998, -0.328274, 0.112806, -0.13235, 0.161436, 0.107548, 0.093676, 0.216189, 0.0336818, -0.187771, -0.258369, -0.310121, 0.198715, 0.00564892, -0.18054, 0.177451, -0.0362749, 0.0834339, -0.39685, -0.0889704, 0.165947, -0.158146, 0.0944665, -0.187714, -0.209936, 0.503646, -0.0106483, 0.00597264, 0.244493, -0.241136, 0.2143, -0.307772, -0.341361, 0.0806352, 0.256498, -0.0523453, 0.0442519], "internal": 1}
{"paper_id": "S10-1036", "abstract": "In this paper we present KX, a system for keyphrase extraction developed at FBK-IRST, which exploits basic linguistic annotation combined with simple statistical measures to select a list of weighted keywords from a document. The system is flexible in that it offers to the user the possibility of setting parameters such as frequency thresholds for collocation extraction and indicators for keyphrase relevance, as well as it allows for domain adaptation exploiting a corpus of documents in an unsupervised way. KX is also easily adaptable to new languages in that it requires only a PoS-Tagger to derive lexical patterns. In the SemEval task 5 “Automatic Keyphrase Extraction from Scientific Articles”, KX performance achieved satisfactory results both in finding reader-assigned keywords and in the combined keywords subtask.", "title": "KX: A flexible system for Keyphrase eXtraction", "venue": "S", "graph_vector": [-0.353924, 0.34339, 0.259934, 0.530261, 0.815658, -0.794952, -0.166342, -0.257021, -1.60718, 0.446727, -0.0816367, -0.249765, 0.791575, -0.131375, -0.221906, -0.149242, 0.465618, -0.88276, -0.0376779, 0.508264, -0.477383, 0.583555, 0.167881, 0.086757, -0.525523, 0.188681, 0.034534, -0.192898, -0.468325, -0.140201, 0.467513, -0.133226, -0.162449, 0.171491, 0.10017, -0.146513, 0.0518416, 0.793327, 0.101558, 0.0424773, 0.537412, -0.00320621, -0.344517, 0.139651, 1.34408, -1.44301, 0.0316295, -0.335992, -0.455209, -0.326868, -0.0864184, -0.247409, 0.734853, 0.694307, -0.286321, 0.104975, 0.0355751, 0.580425, -0.28166, -0.196223, -0.0590755, -0.312462, -0.194778, -0.122388, 0.00244888, -0.337746, 0.796246, 0.183788, 0.249882, -0.0258598, 0.217757, 0.00703734, -0.157049, -0.0545071, 0.093954, -0.429207, -0.666, -0.184581, -0.0557908, -0.278071, 0.236463, 0.383795, 0.0610801, -0.256603, -0.0019825, -0.227044, 0.249807, 0.299965, 0.311104, -0.0164047, -0.110041, 0.388102, -1.02589, 0.193301, -0.575546, -0.198033, -0.0638446, -0.217838, -0.0959792, -0.0906303, -0.216765, -0.775258, -0.108693, 0.53589, 0.00594628, -0.161173, -0.0419152, 0.183944, 0.0793055, -0.185575, 0.0251971, 0.0389522, -0.0534975, -0.341359, 0.060297, 0.249461, 0.192581, -0.317685, 0.0532754, 0.263485, -0.399527, 0.663238, -0.236931, -0.0440888, 0.484159, 0.234112, 0.108378, 0.200423], "internal": 1}
{"paper_id": "S14-2038", "abstract": "This paper describes our system used in the Aspect Based Sentiment Analysis Task 4 at the SemEval-2014. Our system consists of two components to address two of the subtasks respectively: a Conditional Random Field (CRF) based classifier for Aspect Term Extraction (ATE) and a linear classifier for Aspect Term Polarity Classification (ATP). For the ATE subtask, we implement a variety of lexicon, syntactic and semantic features, as well as cluster features induced from unlabeled data. Our system achieves state-of-the-art performances in ATE, ranking 1st (among 28 submissions) and 2rd (among 27 submissions) for the restaurant and laptop domain respectively.", "title": "DLIREC: Aspect Term Extraction and Term Polarity Classification System", "venue": "S", "graph_vector": [-0.24881, 0.189675, 0.0805568, 0.372491, 0.174733, -0.751095, 0.0998389, -0.0584737, -1.76293, -0.00765757, -0.176853, -0.383236, 0.599745, -0.311651, -0.194062, -0.243637, 0.459088, -0.42053, -0.0632001, 0.246464, -0.507655, 0.955131, 0.201546, 0.11622, -0.251335, 0.210462, -0.239911, 0.140316, -0.367754, 0.0563216, -0.247964, -0.0542509, 0.471456, -0.329179, -0.117766, 0.291642, -0.286784, 0.696098, -0.195276, -0.19699, -0.23366, -0.295996, -0.461863, 0.523998, 0.560142, -0.982496, -0.323897, 0.26108, -0.102018, -0.0720314, 0.200657, 0.286264, 0.537741, 0.739825, 0.185892, 0.0135514, 0.255359, 0.278024, -0.262414, 0.146101, -0.408336, 0.0593448, 0.0619354, -0.0126731, -0.0959795, 0.187876, 0.33526, -0.265942, 0.224382, -0.0418229, 7.87226e-05, 0.067559, -0.153376, -0.334198, -0.0725913, -0.160921, -0.114724, -0.283988, -0.0901569, -0.127017, -0.162492, 0.195444, 0.461947, -0.282102, 0.197167, -0.238045, 0.38328, 0.0325669, -0.127569, -0.16057, 0.137555, -0.129407, -0.822415, 0.0742191, 0.0105991, -0.102794, -0.167515, -0.0965436, 0.0257808, 0.0309092, -0.18844, -0.282199, -0.185704, 0.0446722, 0.0548922, 0.245101, -0.11641, 0.0470336, 0.481682, -0.509592, 0.48359, -0.040024, -0.230568, -0.0392954, -0.0766253, -0.238738, 0.318197, 0.147853, 0.301335, 0.285092, -0.415456, -0.309643, 0.309783, -0.0795006, -0.00289473, 0.203015, 0.039405, -0.00860715], "internal": 1}
{"paper_id": "S14-2029", "abstract": "In this paper, we describe our system for the Sentiment Analysis of Twitter shared task in SemEval 2014. Our system uses an SVM classifier along with rich set of lexical features to detect the sentiment of a phrase within a tweet (Task-A) and also the sentiment of the whole tweet (TaskB). We start from the lexical features that were used in the 2013 shared tasks, we enhance the underlying lexicon and also introduce new features. We focus our feature engineering effort mainly on TaskA. Moreover, we adapt our initial framework and introduce new features for TaskB. Our system reaches weighted score of 87.11% in Task-A and 64.52% in Task-B. This places us in the 4th rank in the TaskA and 15th in the Task-B.", "title": "CMUQ@Qatar:Using Rich Lexical Features for Sentiment Analysis on Twitter", "venue": "S", "graph_vector": [0.181758, 0.681409, 0.28316, 0.167834, 0.56989, -0.831357, -0.0038784, -0.204761, -1.69865, 0.228149, 0.0323944, -0.0952267, 0.479888, 0.00734655, 0.0253652, 0.104324, 0.45952, -0.430001, 0.0394981, -0.0317123, 0.106129, 0.665391, 0.0770271, -0.221317, -0.269355, 0.0455541, 0.14353, 0.185127, -0.299623, -0.235589, -0.259057, 0.203659, 0.313529, -0.134395, 0.0152827, -0.0550312, -0.199187, 0.857575, 0.0618233, 0.174572, 0.208515, -0.548999, -0.201323, 0.699633, 0.806242, -0.964122, 0.145605, 0.233303, -0.0891579, -0.0845992, 0.138314, -0.518954, 0.879912, 0.922913, -0.114125, 0.179611, 0.0217945, -0.0010564, -0.302428, 0.22427, -0.141015, -0.0111781, 0.0941785, -0.0604131, -0.147152, -0.108035, 0.0953956, 0.262445, 0.373508, -0.176959, -0.110007, 0.0899304, -0.0312842, -0.364397, 0.032502, -0.296916, -0.179711, -0.29803, 0.0186102, -0.0775517, -0.376607, 0.270151, 0.395642, 0.0125456, 0.442732, -0.313283, 0.135291, 0.133885, -0.220857, 0.045043, 0.117112, 0.277085, -0.691374, -0.196592, -0.11512, -0.287652, 0.141393, -0.106683, 0.352745, 0.00915096, -0.279027, -0.24366, -0.0381417, -0.00911762, 0.020386, 0.014357, -0.195847, -0.130363, 0.0885789, -0.314845, 0.279922, 0.168654, 0.0326182, 0.136992, -0.0775352, 0.0604724, 0.0837974, 0.0483364, 0.221502, 0.297364, -0.164264, 0.00657666, -0.360057, 0.143732, 0.565737, 0.245196, -0.060514, 0.147206], "internal": 1}
{"paper_id": "S14-2072", "abstract": "We describe UMBC’s systems developed for the SemEval 2014 tasks on Multilingual Semantic Textual Similarity (Task 10) and Cross-Level Semantic Similarity (Task 3). Our best submission in the Multilingual task ranked second in both English and Spanish subtasks using an unsupervised approach. Our best systems for Cross-Level task ranked second in Paragraph-Sentence and first in both Sentence-Phrase and Word-Sense subtask. The system ranked first for the PhraseWord subtask but was not included in the official results due to a late submission.", "title": "Meerkat Mafia: Multilingual and Cross-Level Semantic Textual Similarity Systems", "venue": "S", "graph_vector": [0.107414, 0.105498, 0.0659691, 0.178062, 0.3184, -0.544501, 0.459141, -0.249742, -1.21591, 0.237217, -0.35382, -0.064819, 0.787847, 0.279393, 0.178258, 0.20496, 0.590248, -0.730868, 0.275619, 0.680881, -0.575228, 0.276625, 0.267379, 0.231211, -0.127121, 0.387051, -0.127446, 0.311462, -0.632474, 0.316224, 0.0284381, -0.0603543, 0.083595, -0.137906, 0.0920837, 0.0367134, -0.0400591, 0.525459, 0.0247405, -0.339636, 0.381826, -0.180188, 0.00467441, 0.564495, 1.20599, -1.01347, -0.0770149, 0.0135196, -0.0305155, -0.0542449, 0.181342, 0.301019, 0.913952, 0.707256, -0.0809877, -0.190815, 0.412703, 0.0764831, -0.128106, 0.104135, -0.226863, 0.249592, -0.134004, -0.164115, -0.0873193, -0.049613, 0.0675951, -0.135184, 0.332828, 0.255299, 0.303638, 0.180718, -0.130906, -0.433951, 0.172919, 0.0534274, -0.748803, -0.483244, -0.108484, -0.251256, -0.364955, -0.283521, 0.099731, -0.144664, 0.390617, -0.228579, -0.0368403, 0.317056, 0.172554, -0.152953, -0.381609, 0.145883, -0.4758, -0.230796, -0.308928, 0.0678597, -0.236872, 0.400677, 0.242981, 0.0884805, -0.302038, -0.0857283, 0.192053, -0.103316, -0.175889, 0.0933382, 0.185791, -0.303741, 0.551326, 0.0229674, 0.0895082, -0.2463, 0.0661893, 0.0391741, 0.0759955, -0.808235, 0.585726, -0.136903, -0.369134, 0.225451, 0.0411306, 0.29383, -0.445085, 0.460053, 0.259852, -0.100373, -0.0757575, 0.37708], "internal": 1}
{"paper_id": "S14-2039", "abstract": "We present an algorithm for computing the semantic similarity between two sentences. It adopts the hypothesis that semantic similarity is a monotonically increasing function of the degree to which (1) the two sentences contain similar semantic units, and (2) such units occur in similar semantic contexts. With a simplistic operationalization of the notion of semantic units with individual words, we experimentally show that this hypothesis can lead to state-of-the-art results for sentencelevel semantic similarity. At the SemEval 2014 STS task (task 10), our system demonstrated the best performance (measured by correlation with human annotations) among 38 system runs.", "title": "DLS@CU: Sentence Similarity from Word Alignment", "venue": "S", "graph_vector": [0.0124166, 0.131961, 0.12867, 0.111801, 0.37452, -0.580672, 0.464044, -0.194853, -1.50202, 0.447533, -0.269036, -0.347569, 0.815847, 0.0539336, -0.274813, -0.224402, 0.469145, -0.617539, 0.193386, 0.43244, -0.319658, 0.929417, 0.256816, 0.141131, -0.57366, 0.206088, -0.250024, 0.306206, -0.201561, 0.328479, -0.0936114, 0.0297652, 0.173732, -0.124263, 0.217509, 0.0346217, 0.035002, 0.619343, -0.0252124, -0.39278, 0.0500471, 0.050761, -0.445944, -0.133252, 0.916379, -1.07254, -0.00822049, 0.0528946, 0.144116, 0.0123234, 0.406352, 0.223166, 0.925176, 0.513323, -0.262401, -0.257494, 0.565958, -0.135709, -0.141161, 0.15327, -0.268858, 0.0224723, -0.0522524, -0.0278761, -0.333196, 0.337751, 0.405823, -0.184739, 0.175047, 0.0113768, 0.0188035, -0.0793348, 0.0380696, -0.317937, -0.13656, -0.00603361, -0.573264, -0.408804, 0.0719802, -0.374025, -0.185266, -0.252091, 0.175262, -0.264819, -0.0754467, -0.574205, -0.143445, 0.0573326, -0.175778, 0.100458, -0.0345704, -0.0381067, -0.490005, -0.254147, -0.118655, 0.0297347, -0.189929, 0.347287, 0.102824, -0.0496992, -0.104511, -0.0515171, 0.121251, 0.160095, -0.182017, -0.16955, 0.0530461, -0.26628, -0.0135411, 0.096519, 0.0945479, 0.0418293, 0.0045761, 0.0162956, 0.17325, -0.38384, 0.23808, 0.0283346, -0.29895, 0.173269, -0.267947, 0.199312, -0.0377878, -0.0135325, 0.542428, 0.408622, -0.235722, 0.0325964], "internal": 1}
{"paper_id": "S14-2083", "abstract": "We refined the performance of Cocoa/Peaberry, a linguistically motivated system, on extracting disease entities from clinical notes in the training and development sets for Task 7. Entities were identified in noun chunks by use of dictionaries, and events (‘The left atrium is dilated’) through our own parser and predicate-argument structures. We also developed a module to map the extracted entities to the SNOMED subset of UMLS. The module is based on direct matching against UMLS entries through regular expressions derived from a small set of morphological transformations, along with priority rules when multiple UMLS entries were matched. The performance on training and development sets was 81.0% and 83.3% respectively (Task A), and the UMLS matching scores were respectively 75.3% and 78.2% (Task B). However, the performance against the test set was low by comparison, 72.0% for Task A and 63.9% for Task B, even while the pure UMLS mapping score was reasonably high (relaxed score in Task B = 91.2%). We speculate that our moderate performance on the test set derives primarily from chunking/parsing errors.", "title": "RelAgent: Entity Detection and Normalization for Diseases in Clinical Records: a Linguistically Driven Approach", "venue": "S", "graph_vector": [-0.0705001, 0.549663, 0.122755, 0.0249539, 0.795619, -0.457767, 0.146889, 0.48251, -1.45725, 0.600506, 0.373118, -0.405893, 0.799254, -0.193122, 0.0327491, 0.321175, 0.366431, -0.786064, 0.160186, 0.348166, -0.429943, 0.709438, 0.106694, -0.255552, -0.0406493, 0.35806, 0.358781, 0.0703896, -0.0393886, -0.170991, -0.105804, 0.435844, -0.127254, -0.326112, -0.0500768, 0.250547, -0.195639, 0.757212, -0.0698815, -0.186205, -0.0995871, -0.401477, -0.651574, 0.259572, 1.07657, -1.18675, 0.218322, 0.269112, 0.105141, -0.360617, 0.275881, -0.200249, 1.18356, 1.18189, -0.188949, -0.0964807, 0.150498, 0.339422, 0.175598, -0.136912, -0.529833, -0.19042, 0.20515, -0.00835744, -0.280442, -0.0817443, 0.173013, -0.0297665, 0.0993199, -0.0170326, 0.100442, 0.0645148, -0.254482, 0.157651, 0.0103368, 0.441645, -0.831908, -0.335088, -0.546174, -0.02332, 0.0500549, -0.151996, 0.35161, 0.137116, -0.050334, -0.792606, 0.236145, 0.163282, 0.609459, 0.161211, -0.201105, -0.288881, -0.535818, -0.00031212, 0.342219, -0.216112, 0.00152246, -0.259996, 0.0013648, -0.0794776, -0.262986, -0.351594, -0.152791, 0.0245539, 0.233779, 0.146578, 0.235303, -0.198261, -0.0131135, -0.437038, -0.283755, -0.154322, -0.295773, 0.00291355, -0.0941189, -0.268168, 0.701703, 0.280791, 0.141031, 0.386599, 0.0812249, -0.239107, 0.12521, -0.116573, 0.517062, -0.23346, -0.101033, 0.360351], "internal": 1}
{"paper_id": "S14-1010", "abstract": "Sentence Connectivity is a textual characteristic that may be incorporated intelligently for the selection of sentences of a well meaning summary. However, the existing summarization methods do not utilize its potential fully. The present paper introduces a novel method for singledocument text summarization. It poses the text summarization task as an optimization problem, and attempts to solve it using Weighted Minimum Vertex Cover (WMVC), a graph-based algorithm. Textual entailment, an established indicator of semantic relationships between text units, is used to measure sentence connectivity and construct the graph on which WMVC operates. Experiments on a standard summarization dataset show that the suggested algorithm outperforms related methods.", "title": "Text Summarization through Entailment-based Minimum Vertex Cover", "venue": "S", "graph_vector": [-0.377246, 0.631705, -0.195935, 0.278587, 0.690631, -1.10345, 0.0911922, 0.0317288, -1.75798, 0.079454, -0.412617, -0.323209, 0.519435, 0.387249, 0.218519, 0.000923333, 0.389768, -0.429124, -0.00297795, 0.280952, -0.365092, 0.625281, 0.243507, -0.141508, -0.51316, 0.129717, -0.0815056, -0.101064, -0.201194, 0.0960142, 0.192224, -0.0448325, -0.061267, -0.338739, 0.0419969, -0.0885925, -0.208866, 0.718407, 0.393488, -0.28771, -0.235277, -0.0561923, -0.373246, 0.248925, 0.822014, -0.387454, 0.019867, 0.365612, -0.283667, -0.157588, -0.0235696, 0.243767, 0.710512, 0.493488, -0.0628175, 0.129503, 0.239281, 0.118645, -0.120537, -0.065419, -0.0909562, -0.408544, -0.146787, 0.0994661, -0.149823, -0.263296, 0.42493, 0.217203, 0.214085, -0.0435327, -0.104196, 0.0233821, -0.208083, 0.119589, -0.133183, -0.137575, -0.610597, 0.333697, 0.251921, -0.358589, -0.160882, -0.579377, 0.100106, -0.255464, 0.334754, -0.327681, -0.759988, -0.34255, -0.134462, 0.155354, 0.0854537, 0.198482, -0.756729, -0.568981, 0.139941, 0.123122, 0.337697, -0.126738, -0.286224, 0.323002, -0.0124547, -0.082379, -0.0621613, 0.0948248, 0.213608, 0.146134, -0.412214, -0.18685, 0.289339, 0.221838, 0.0398712, 0.151326, -0.310261, 0.0271807, -0.0567305, -0.495773, 0.412956, 0.084657, -0.437939, 0.492452, -0.0888348, -0.0102121, 0.192944, 0.309044, 0.526845, 0.0582635, -0.181962, -0.0419345], "internal": 1}
{"paper_id": "S14-2004", "abstract": "Sentiment analysis is increasingly viewed as a vital task both from an academic and a commercial standpoint. The majority of current approaches, however, attempt to detect the overall polarity of a sentence, paragraph, or text span, irrespective of the entities mentioned (e.g., laptops) and their aspects (e.g., battery, screen). SemEval2014 Task 4 aimed to foster research in the field of aspect-based sentiment analysis, where the goal is to identify the aspects of given target entities and the sentiment expressed for each aspect. The task provided datasets containing manually annotated reviews of restaurants and laptops, as well as a common evaluation procedure. It attracted 163 submissions from 32 teams.", "title": "SemEval-2014 Task 4: Aspect Based Sentiment Analysis", "venue": "S", "graph_vector": [0.113746, 0.3361, 0.392911, 0.0902724, 0.245747, -0.771405, 0.192024, 0.119031, -1.76299, 0.160849, -0.370895, -0.18499, 0.60236, -0.231762, -0.128351, -0.239184, 0.225549, -0.455674, -0.063973, 0.167546, -0.257089, 0.81295, 0.260657, 0.0974593, -0.527455, -0.103491, 0.0396579, -0.0585194, -0.234123, -0.132053, -0.140077, 0.0116282, 0.391468, -0.200605, -0.113083, 0.203661, -0.300653, 0.633168, 0.0420913, 0.301088, 0.167489, -0.399165, -0.464033, 0.623696, 0.595085, -1.02276, -0.0322663, 0.234972, 0.0949355, -0.0357639, 0.140284, 0.203039, 0.694653, 0.870672, 0.255387, -0.0733403, 0.330255, 0.14873, 0.0250197, 0.24011, -0.196603, 0.106037, 0.163971, -0.236823, -0.0956322, 0.166621, -0.0461546, -0.184233, 0.447183, 0.018529, -0.139405, 0.269732, -0.242851, -0.474416, -0.0628197, -0.267904, -0.285573, -0.312749, -0.391239, -0.0869191, -0.372693, 0.0366882, 0.357096, -0.199278, -0.176845, -0.32434, 0.182284, -0.0779694, -0.0848624, -0.0304202, 0.10281, 0.0636169, -0.627301, -0.18676, 0.0532247, 0.0727737, -0.151222, -0.192193, 0.259525, -0.0753891, 0.0190848, -0.551406, -0.00451058, 0.0937171, -0.0746607, 0.0854978, -0.205304, 0.160231, 0.409929, -0.264415, 0.310369, 0.141579, -0.046826, -0.371381, 0.161121, -0.122326, 0.524291, 0.130609, 0.416047, 0.189391, -0.588752, -0.16068, 0.189649, 0.022525, 0.13648, 0.272542, 0.107503, 0.165751], "internal": 1}
{"paper_id": "S14-2147", "abstract": "This paper describes Team UWM’s system for the Task 7 of SemEval 2014 that does disorder mention extraction and normalization from clinical text. For the disorder mention extraction (Task A), the system was trained using Conditional Random Fields with features based on words, their POS tags and semantic types, as well as features based on MetaMap matches. For the disorder mention normalization (Task B), variations of disorder mentions were considered whenever exact matches were not found in the training data or in the UMLS. Suitable types of variations for disorder mentions were automatically learned using a new method based on edit distance patterns. Among nineteen participating teams, UWM ranked third in Task A with 0.755 strict F-measure and second in Task B with 0.66 strict accuracy.", "title": "UWM: Disorder Mention Extraction from Clinical Text Using CRFs and Normalization Using Learned Edit Distance Patterns", "venue": "S", "graph_vector": [0.10073, 0.198535, 0.1226, 0.475851, 0.372993, -0.227855, -0.0512431, 0.0797738, -1.55206, 0.504158, 0.266574, 0.101628, 0.770953, -0.257511, -0.03285, -0.0383234, 0.687352, -0.572844, 0.19038, 0.578945, -0.449544, 0.594251, 0.316842, 0.0836827, -0.278086, 0.455735, 0.133968, 0.277017, 0.017919, -0.0730423, -0.25353, -0.177647, 0.124927, -0.0759654, 0.0798079, 0.484799, -0.212229, 0.683077, 0.147215, -0.333507, 0.230272, -0.725431, -0.82203, -0.14245, 0.753967, -1.01444, 0.085364, 0.425657, 0.142552, -0.278011, -0.00295798, -0.386546, 0.896444, 0.661632, -0.161936, 0.138878, 0.258266, -0.130895, -0.109159, 0.418122, -0.487428, 0.346576, 0.179796, 0.0589879, 0.0434468, -0.0314902, 0.196031, -0.155491, 0.0598301, -0.137387, 0.113544, 0.0687707, -0.259469, 0.320074, -0.461115, -0.156117, -0.297344, -0.161155, -0.159237, -0.214938, -0.277773, 0.159594, 0.411406, -0.0192885, -0.225795, -0.709623, 0.296211, -0.198324, 0.350081, -0.291348, -0.280055, 0.0974177, -0.601887, -0.152285, 0.0903338, -0.39377, -0.263018, 0.0499789, 0.0705533, 0.0847346, -0.252932, -0.292246, 0.283383, 0.131225, -0.225489, 0.157958, -0.113002, 0.381571, -0.00762054, -0.443756, -0.223995, 0.376507, -0.391084, -0.269712, -0.155449, -0.208453, 0.268327, 0.331958, -0.0942558, 0.155224, 0.0203487, 0.243192, 0.0665759, -0.118251, 0.358281, -0.0925209, 0.207103, 0.0519745], "internal": 1}
{"paper_id": "S14-2020", "abstract": "The article describes our system submitted to the SemEval-2014 task on Aspect-Based Sentiment Analysis. The methods based on distributed representations of words for the aspect term extraction and aspect term polarity detection tasks are presented. The methods for the aspect category detection and category polarity detection tasks are presented as well. Well-known skip-gram model for constructing the distributed representations is briefly described. The results of our methods are shown in comparison with the baseline and the best result.", "title": "Blinov: Distributed Representations of Words for Aspect-Based Sentiment Analysis at SemEval 2014", "venue": "S", "graph_vector": [0.0889699, 0.311453, 0.333377, 0.466501, 0.381037, -0.56215, 0.178912, -0.0420657, -1.7059, 0.0518201, -0.421807, -0.503344, 0.540684, 0.0404834, 0.159239, -0.250594, 0.418305, -0.385683, -0.00966968, 0.308176, -0.206182, 0.929322, 0.091986, 0.384458, -0.299689, 0.154772, -0.144806, 0.3278, -0.340797, -0.18241, -0.23135, 0.0746992, 0.216988, -0.385576, -0.121846, 0.394658, -0.426561, 0.378303, 0.214467, -0.15998, -0.403165, -0.432712, 0.0385826, 0.141048, 1.05184, -0.965152, 0.0278571, -0.00400818, -0.0250029, 0.209097, 0.356879, -0.0719338, 0.725504, 0.511206, 0.125895, -0.18419, 0.252373, -0.273635, -0.017277, 0.372963, 0.051616, 0.168634, 0.203144, 0.0917979, -0.188895, 0.166544, 0.613749, -0.380304, -0.107846, 0.270758, -0.321654, 0.0890179, 0.164887, -0.100486, 0.243922, -0.111298, -0.363295, -0.496584, -0.265865, -0.118266, -0.0152761, 0.171674, 0.175264, 0.142732, 0.276865, -0.030736, 0.19099, 0.0460832, -0.450428, -0.163223, 0.0127688, 0.398969, -0.739309, -0.198596, -0.169458, -0.215259, 0.0542882, -0.158828, -0.113179, 0.294964, -0.633548, -0.332296, 0.0539048, -0.183237, -0.0391346, 0.115207, -0.244232, -0.388628, 0.544054, 0.0361398, 0.328951, -0.132379, 0.104779, 0.170631, -0.216017, 0.134134, 0.332347, -0.0538272, 0.160401, 0.248352, -0.225158, -0.161205, -0.0946335, -0.043955, 0.20677, 0.169905, 0.130019, 0.27333], "internal": 1}
{"paper_id": "S14-2045", "abstract": "This paper describes the system used in Task-7 (Analysis of Clinical Text) of SemEval-2014 for detecting disorder mentions and associating them with their related CUI of UMLS1. For Task-A, a CRF based sequencing algorithm was used to find different medical entities and a binary SVM classifier was used to find relationship between entities. For Task-B, a dictionary look-up algorithm on a customized UMLS-2012 dictionary was used to find relative CUI for a given disorder mention. The system achieved F-score of 0.714 for Task A & accuracy of 0.599 for Task B when trained only on training data set, and it achieved F-score of 0.755 for Task A & accuracy of 0.646 for Task B when trained on both training as well as development data set. Our system was placed 3rd for both task A and B.", "title": "ezDI: A Hybrid CRF and SVM based Model for Detecting and Encoding Disorder Mentions in Clinical Notes", "venue": "S", "graph_vector": [-0.0586443, 0.277314, 0.390615, 0.503851, 0.732523, -0.634651, 0.324474, 0.0943792, -1.77202, 0.197646, 0.0386204, -0.402085, 0.718898, 0.109111, 0.317704, -0.090961, 0.563342, -0.642469, 0.0736859, 0.392837, -0.0183111, 0.567308, 0.32138, 0.0910532, -0.487706, 0.357856, 0.0148862, 0.189027, -0.299322, -0.113715, 0.33669, 0.081558, -0.120975, -0.212306, 0.122174, 0.137328, -0.501914, 0.644492, 0.140533, -0.0816412, -0.127343, -0.404886, -0.625172, -0.163312, 0.618662, -0.896968, 0.130326, 0.38982, 0.248143, -0.00669207, 0.357704, -0.114006, 0.756338, 0.609623, -0.22633, 0.16824, 0.363678, 0.103128, -0.203639, 0.0278383, -0.128014, -0.0212808, -0.149446, -0.0684576, -0.0999845, -0.106947, -0.0829005, 0.189039, 0.133466, 0.00521363, 0.16546, -0.252747, -0.142994, 0.220649, 0.00548595, 0.0508218, -0.726738, -0.393741, -0.197178, 0.027507, -0.381136, -0.043943, 0.266719, 0.161479, -0.160973, -0.777599, 0.287291, -0.162036, -0.0497699, 0.0910627, 0.112757, 0.143524, -1.08905, 0.00273908, 0.105269, -0.00457919, 0.0439853, -0.350941, -0.232661, 0.284763, -0.348866, -0.211675, -0.158734, -0.17167, -0.127732, -0.0263646, -0.0137106, 0.123699, 0.14364, -0.834931, -0.0854042, -0.011611, -0.269854, 0.18747, -0.348477, -0.26752, 0.485175, 0.359991, -0.0522021, 0.346349, 0.335219, -0.284777, 0.00318426, -0.285118, 0.419782, -0.0922532, -0.117456, 0.215681], "internal": 1}
{"paper_id": "S14-2119", "abstract": "We describe the grammar induction system for Spoken Dialogue Systems (SDS) submitted to SemEval’14: Task 2. A statistical model is trained with a rich feature set and used for the selection of candidate rule fragments. Posterior probabilities produced by the fragment selection model are fused with estimates of phraselevel similarity based on lexical and contextual information. Domain and language portability are among the advantages of the proposed system that was experimentally validated for three thematically different domains in two languages.", "title": "tucSage: Grammar Rule Induction for Spoken Dialogue Systems via Probabilistic Candidate Selection", "venue": "S", "graph_vector": [-0.0199194, 0.311106, -0.0427297, 0.607477, 0.136821, -0.993077, 0.364092, -0.119373, -1.49937, 0.503534, -0.177529, -0.26597, 0.325108, 0.0425457, -0.427976, -0.221867, 0.495251, -0.589682, 0.182857, 0.232319, -0.12823, 0.649896, 0.109813, -0.161057, -0.452082, -0.180096, -0.0476403, 0.306292, -0.193132, 0.0120578, 0.162617, 0.0711386, -0.045637, -0.0703402, 0.306925, 0.227679, -0.143453, 0.440845, 0.0341318, -0.438631, 0.0868961, -0.189954, -0.3575, 0.228611, 0.855057, -0.918323, 0.162549, 0.421406, -0.111459, 0.113074, 0.273187, 0.210024, 0.790337, 0.390163, -0.345257, -0.300785, 0.395484, -0.323255, -0.324647, 0.428708, -0.363085, 0.0454915, 0.000188003, -0.000258928, -0.411983, 0.0212069, 0.284836, 0.130236, 0.230407, -0.24113, 0.138347, -0.31827, -0.0979685, 0.141895, -0.120057, 0.226705, -0.527153, -0.124686, -0.0418021, -0.211116, -0.413516, 0.128652, -0.0586674, -0.201731, -0.0428791, -0.258607, 0.000110977, -0.0210063, 0.41838, -0.20905, -0.0777178, 0.123722, -0.4556, -0.296816, -0.23169, -0.0611842, -0.200821, -0.0301393, 0.264472, -0.173947, -0.439957, -0.269259, 0.195283, 0.260957, -0.0905597, -0.0547081, 0.0835131, 0.0700903, -0.252695, 0.070968, -0.0277703, 0.532628, 0.238088, 0.135473, -0.155501, 0.249967, -0.572316, -0.201339, -0.035932, 0.175423, -0.070408, -0.38619, -0.204591, 0.340414, 0.793485, 0.0057366, 0.427181, 0.0664245], "internal": 1}
{"paper_id": "S14-2095", "abstract": "This document describes the senti.ue system and how it was used for participation in SemEval-2014 Task 9 challenge. Our system is an evolution of our prior work, also used in last year’s edition of Sentiment Analysis in Twitter. This system maintains a supervised machine learning approach to classify the tweet overall sentiment, but with a change in the used features and the algorithm. We use a restricted set of 47 features in subtask B and 31 features in subtask A. In the constrained mode, and for the five data sources, senti.ue achieved a score between 78,72 and 84,05 in subtask A, and a score between 55,31 and 71,39 in subtask B. For the unconstrained mode, our score was slightly below, except for one case in subtask A.", "title": "Senti.ue: Tweet Overall Sentiment Classification Approach for SemEval-2014 Task 9", "venue": "S", "graph_vector": [0.209568, 0.168369, 0.621439, 0.0324608, 0.490571, -0.804231, 0.151992, 0.0637999, -1.54844, 0.37929, -0.0353605, -0.432527, 0.405915, 0.127028, 0.161518, 0.0112895, 0.651944, -0.621153, 0.140427, 0.142219, -0.359289, 0.721678, 0.0668789, -0.00916411, -0.378952, -0.166681, 0.276307, -0.147269, -0.40582, 0.202913, 0.0643936, 0.348386, 0.289751, -0.143599, -0.46093, 0.149088, -0.236255, 0.848258, -0.0350063, 0.0285324, 0.00732307, -0.429596, -0.159851, 0.712256, 0.897163, -0.818777, -0.0774645, 0.181301, -0.140141, -0.205707, 0.0149229, -0.163012, 0.687281, 0.937342, -0.122843, 0.207929, 0.0430421, 0.0282032, -0.0901658, 0.211247, 0.203199, 0.355722, 0.221669, -0.0893844, -0.41939, -0.0733387, 0.0149626, 0.133085, 0.344299, 0.0104134, -0.24998, 0.00709132, -0.196714, -0.464736, -0.33669, -0.114057, -0.195963, -0.242906, -0.306641, 0.0110174, -0.335759, -0.00229175, 0.354021, -0.145029, 0.00570692, -0.00781712, 0.117139, 0.12264, 0.0135137, 0.154789, 0.0186461, 0.187791, -0.943075, -0.350554, -0.294729, -0.121927, -0.238067, 0.0331438, 0.406778, 0.0920888, -0.118832, -0.426484, -0.33465, -0.0868969, 0.0151181, 0.168275, -0.252864, 0.151195, 0.133695, 0.00923226, 0.0851638, 0.133904, 0.0186912, -0.0823004, -0.0694299, 0.00116738, 0.239722, -0.0720938, -0.0367371, 0.323426, -0.135797, -0.19824, -0.111014, 0.0505172, 0.470075, 0.485148, 0.144332, 0.424732], "internal": 1}
{"paper_id": "S14-2019", "abstract": "Clinical texts, such as discharge summaries or test reports, contain a valuable amount of information that, if efficiently and effectively mined, could be used to infer new knowledge, possibly leading to better diagnosis and therapeutics. With this in mind, the SemEval-2014 Analysis of Clinical Text task aimed at assessing and improving current methods for identification and normalization of concepts occurring in clinical narrative. This paper describes our approach in this task, which was based on a fully modular architecture for text mining. We followed a pure dictionary-based approach, after performing error analysis to refine our dictionaries. We obtained an F-measure of 69.4% in the entity recognition task, achieving the second best precision over all submitted runs (81.3%), with above average recall (60.5%). In the normalization task, we achieved a strict accuracy of 53.1% and a relaxed accuracy of 87.0%.", "title": "BioinformaticsUA: Concept Recognition in Clinical Narratives Using a Modular and Highly Efficient Text Processing Framework", "venue": "S", "graph_vector": [-0.0679723, 0.0477833, 0.278813, 0.158282, 0.862596, -0.618551, 0.333255, 0.0293139, -1.79952, 0.433657, 0.200561, -0.124811, 0.620128, -0.27507, 0.0672426, 0.13842, 0.77235, -0.92699, 0.0435406, 0.680426, -0.668705, 0.792701, 0.378154, 0.173225, -0.0539979, 0.275731, 0.397525, -0.028234, -0.0734787, -0.0481165, 0.142413, -0.0950309, -0.278212, -0.0878513, 0.0224633, 0.195854, -0.123298, 0.742795, -0.169894, -0.243219, -0.0641025, -0.216942, -0.491224, -0.0126891, 0.931736, -0.874574, 0.454141, 0.173014, 0.0367933, -0.245529, 0.0989041, -0.0924017, 1.03258, 0.90429, -0.0864025, -0.279105, -0.0909545, 0.370056, 0.220433, 0.0910523, -0.470618, -0.143344, -0.159057, 0.110247, -0.0411127, 0.037721, 0.0869673, -0.141382, -0.0780395, -0.122847, 0.158917, -0.00438916, -0.277972, -0.0125002, -0.0388352, -0.242944, -0.642886, -0.273911, -0.205111, -0.209965, -0.327969, 0.234957, 0.462023, 0.00327377, 0.0237895, -0.433697, 0.282674, -0.373494, 0.348261, -0.117618, 0.0837102, -0.148734, -0.343081, -0.144501, 0.0508986, -0.299879, -0.390511, -0.30367, 0.137763, -0.249866, -0.211264, -0.570812, 0.165604, 0.104255, 0.015681, 0.172, 0.0272306, -0.0017699, -0.185603, -0.106302, -0.0423634, 0.218794, -0.265521, -0.125798, -0.462354, -0.0337402, 0.472343, 0.190202, 0.177294, 0.327786, 0.183208, -0.26982, 0.0314653, -0.21505, 0.426077, -0.0952171, 0.00794105, 0.198755], "internal": 1}
{"paper_id": "S14-2118", "abstract": "We present our participation in Task 7 of SemEval shared task 2014. The goal of this particular task includes the identification of disorder named entities and the mapping of each disorder to a unique Unified Medical Language System concept identifier, which were referred to as Task A and Task B respectively. We participated in both of these subtasks and used YTEX as a baseline system. We further developed a supervised linear chain Conditional Random Field model based on sets of features to predict disorder mentions. To take benefit of results from both systems we merged these results. Under strict condition our best run evaluated at 0.549 F-measure for Task A and an accuracy of 0.489 for Task B on test dataset. Based on our error analysis we conclude that recall of our system can be significantly increased by adding more features to the Conditional Random Field model and by using another type of tag representation or frame matching algorithm to deal with the disjoint entity mentions.", "title": "TMUNSW: Disorder Concept Recognition and Normalization in Clinical Notes for SemEval-2014 Task 7 Jitendra Jonnagaddala", "venue": "S", "graph_vector": [0.104444, 0.108197, -0.190345, 0.422998, 0.202983, -0.904292, 0.19895, 0.42905, -1.73323, 0.348207, -0.129308, -0.350042, 0.674367, -0.0907327, -0.101544, -0.397224, 0.469706, -0.558707, 0.171405, 0.197017, -0.392147, 0.50552, 0.144262, -0.0214863, -0.126869, 0.414573, 0.188375, -0.172629, 0.132334, 0.0444007, 0.190528, 0.119246, -0.0255777, -0.121832, -0.0276103, 0.0378932, -0.288603, 0.73395, -0.413962, 0.056388, 0.228396, -0.618045, -0.358244, 0.548888, 0.675477, -0.545454, 0.246719, 0.185912, -0.053337, -0.197507, 0.275908, -0.200066, 0.688514, 0.898187, -0.159997, -0.333902, 0.131922, 0.265418, -0.25423, 0.152956, -0.00968272, -0.467799, 0.12582, -0.0319199, 0.218425, 0.135723, 0.229386, -0.127629, 0.174549, -0.111844, 0.258996, -0.416311, -0.485331, 0.249603, 0.228568, 0.0712373, -0.67037, -0.384106, 0.0615832, -0.122945, -0.555496, 0.157373, 0.596835, 0.262175, -0.227217, -0.511413, 0.395414, -0.216865, 0.439181, -0.187949, 0.352282, -0.0210014, -0.6842, -0.0467241, 0.0615948, -0.213951, -0.189338, -0.356113, -0.118302, 0.326751, -0.609238, -0.339278, 0.182434, 0.351802, -0.0299188, -0.155667, 0.236375, 0.336331, -0.0838189, -0.462192, 0.0342633, 0.0200104, 0.0801811, -0.341882, -0.011371, -0.441777, 0.117512, 0.0339165, 0.40467, 0.552401, 0.533473, -0.261851, -0.199387, -0.147041, 0.164384, -0.0106767, 0.0757971, 0.184788], "internal": 1}
{"paper_id": "S14-2061", "abstract": "This paper presents the results of the IxaMed team at the SemEval-2014 Shared Task 7 on Analyzing Clinical Texts. We have developed three different systems based on: a) exact match, b) a general-purpose morphosyntactic analyzer enriched with the SNOMED CT terminology content, and c) a perceptron sequential tagger based on a Global Linear Model. The three individual systems result in similar f-score while they vary in their precision and recall. We have also tried direct combinations of the individual systems, obtaining considerable improvements in performance.", "title": "IxaMed: Applying Freeling and a Perceptron Sequential Tagger at the Shared Task on Analyzing Clinical Texts", "venue": "S", "graph_vector": [0.301645, 0.550439, -0.0590556, 0.175406, 0.73391, -0.697924, 0.00958018, 0.199089, -1.86436, 0.137749, 0.629004, -0.403725, 1.01332, 0.0740611, -0.155171, -0.173176, 0.619149, -0.653585, 0.114026, 0.588638, -0.318308, 0.785257, 0.236321, 0.198986, -0.18431, -0.0013532, -0.103359, 0.370427, 0.135589, -0.331608, 0.131003, 0.325413, 0.199738, 0.275853, 0.0770085, 0.0480882, -0.432497, 1.07082, -0.320408, 0.221185, 0.078905, -0.585636, -0.387447, 0.243863, 0.821594, -0.431892, 0.209614, 0.303381, 0.302879, 0.0312897, 0.178405, 0.112388, 1.21796, 0.784703, -0.299925, 0.104851, 0.0939888, 0.247597, -0.160892, -0.102316, -0.413026, 0.0206678, -0.286863, 0.0211471, -0.0513927, 0.017974, 0.211045, -0.299365, 0.0874419, -0.123602, 0.0510369, 0.159016, 0.157599, 0.0853059, 0.367021, -0.0814785, -0.575475, 0.0194638, -0.307545, 0.0911332, -0.260959, 0.157938, 0.544367, -0.0966123, -0.266294, -0.512314, 0.0646431, -0.152593, 0.309392, 0.361997, 0.145238, -0.0514789, -0.757543, 0.326087, -0.231784, -0.524949, -0.284379, 0.0158326, -0.183536, 0.18754, -0.325952, 0.260023, 0.160718, 0.121583, 0.116928, 0.164087, -0.130453, 0.292792, 0.0565903, -0.723149, 0.324021, 0.0167578, -0.641655, -0.100484, -0.125905, -0.534996, 0.131053, 0.0992416, 0.381264, 0.425676, 0.512566, -0.502214, -0.238527, 0.0402026, 0.640595, 0.0600153, -0.0473254, 0.229024], "internal": 1}
{"paper_id": "S14-2134", "abstract": "The paper describes our experiments addressing the SemEval 2014 task on the Analysis of Clinical text. Our approach consists in extending the techniques of NE recognition, based on sequence labelling, to address the special issues of this task, i.e. the presence of overlapping and discontiguous mentions and the requirement to map the mentions to unique identifiers. We explored using supervised methods in combination with word embeddings generated from unannotated data.", "title": "UniPi: Recognition of Mentions of Disorders in Clinical Text", "venue": "S", "graph_vector": [0.208183, 0.355606, 0.416546, 0.674253, 0.513182, -0.612202, 0.21891, -0.188945, -1.70552, 0.424641, -0.00169088, -0.135073, 0.466557, -0.0531165, 0.562793, -0.389148, 0.564079, -0.79333, 0.328886, 0.0675705, -0.216477, 0.897715, 0.591453, 0.231857, -0.160972, 0.756008, 0.175883, 0.143594, 0.531888, 0.241543, -0.00795353, 0.0644749, 0.0773062, -0.843187, -0.00415966, 0.019076, 0.428029, 0.636359, -0.141946, 0.066595, 0.415408, -0.340198, -0.36458, 0.0868904, 1.12033, -0.989205, 0.438736, 0.198844, 0.0755894, -0.0983952, 0.131515, -0.345794, 0.363697, 1.06147, -0.121024, 0.122853, 0.177355, -0.0310298, -0.259457, -0.0125884, -0.497047, -0.0752772, -0.292119, -0.0334113, -0.270175, -0.253522, 0.0890478, -0.0137524, 0.110929, 0.184609, 0.0951585, 0.334537, -0.199912, -0.0543899, 0.0692736, -0.274243, -0.877298, -0.185597, -0.355168, -0.273956, -0.136611, 0.412632, 0.461227, 0.192118, -0.0269677, -0.302192, -0.106936, -0.231431, 0.0451883, 0.00591407, 0.120404, -0.0395804, -0.500221, -0.248303, 0.317913, -0.288903, -0.0340189, -0.214225, -0.0280344, -0.0724786, -0.265993, -0.224948, -0.196855, 0.162106, 0.0357361, 0.50937, 0.121521, 0.0635619, -0.280225, -0.555833, -0.0335351, 0.199681, -0.434136, -0.207672, -0.00135967, 0.301765, 0.696338, 0.0671948, 0.0162817, 0.252886, 0.181527, -0.188127, -0.291721, -0.140025, 0.462983, -0.182957, 0.0954057, 0.548676], "internal": 1}
{"paper_id": "S14-2055", "abstract": "This paper describes and analyzes our SemEval 2014 Task 1 system. Its features are based on distributional and denotational similarities; word alignment; negation; and hypernym/hyponym, synonym, and antonym relations.", "title": "Illinois-LH: A Denotational and Distributional Approach to Semantics", "venue": "S", "graph_vector": [-0.570811, 0.253476, 0.17687, 0.328205, 0.293991, -0.856156, 0.448979, -0.25699, -1.49367, 0.145958, 0.500701, -0.430464, 0.280175, 0.254013, 0.0894264, -0.0212509, 0.207343, -0.702052, 0.168987, 0.558109, 0.0017214, 1.09867, 0.143846, -0.0913653, -0.387574, 0.0624786, -0.0674178, 0.0130995, -0.283561, -0.349354, -0.251996, -0.0729848, -0.19615, -0.139446, -0.0881527, 0.196372, -0.0586417, 0.963573, 0.257159, -0.0547903, -0.0678553, -0.028709, -0.199139, 0.0854247, 0.736147, -1.0107, 0.204226, -0.0977463, 0.061114, -0.141506, 0.290321, -0.0596452, 0.410901, 0.538764, -0.0951677, -0.225501, 0.247641, -0.0590222, -0.329474, 0.0961696, 0.0685405, 0.199445, -0.133295, 0.266878, -0.170952, 0.174165, -0.0799757, 0.211721, 0.15259, -0.299287, -0.098509, 0.141155, 0.0492707, -0.100047, -0.0219083, -0.110646, -0.499374, -0.182422, 0.0908817, -0.204118, -0.198182, -0.147925, 0.124456, -0.408256, 0.270531, -0.322821, -0.278106, 0.193857, 0.128784, -0.0400531, -0.021384, -0.116264, -0.413308, 0.110059, -0.0173365, 0.129269, -0.211366, -0.0726857, -0.179301, -0.316868, 0.153063, -0.215397, 0.0615956, 0.296478, 0.222991, 0.0349855, 0.28111, -0.174801, -0.0355435, -0.0471897, 0.0931683, 0.089507, 0.246879, -0.0478869, 0.0108797, -0.262694, 0.359332, 0.0905655, -0.0321724, 0.490029, -0.309331, 0.0120107, 0.191642, -0.183869, 0.547187, 0.115709, -0.138188, 0.391171], "internal": 1}
{"paper_id": "S14-2028", "abstract": "This paper describes the system we submitted to the SemEval-2014 shared task on sentiment analysis in Twitter. Our system is a hybrid combination of two system developed for a course project at CMUQatar. We use an SVM classifier and couple a set of features from one system with feature and parameter optimization framework from the second system. Most of the tuning and feature selection efforts were originally aimed at task-A of the shared task. We achieve an F-score of 84.4% for task-A and 62.71% for task-B and the systems are ranked 3rd and 29th respectively.", "title": "CMUQ-Hybrid: Sentiment Classification By Feature Engineering and Parameter Tuning", "venue": "S", "graph_vector": [-0.0152328, 0.569103, 0.158357, 0.268147, 0.465117, -0.842514, 0.219658, -0.149278, -1.57442, 0.238656, 0.153585, -0.319638, 0.388072, 0.0577949, 0.0987918, 0.0143717, 0.656096, -0.442606, 0.303273, 0.0242156, -0.0678341, 0.547942, 0.278978, -0.164116, -0.238195, -0.0101653, 0.268971, -0.185289, -0.243411, -0.247133, -0.425802, 0.0910831, 0.209439, -0.0660094, -0.136826, -0.0387492, -0.268388, 0.829182, 0.343525, 0.0126708, 0.159061, -0.424862, -0.341239, 0.53013, 0.723753, -1.03456, 0.0202662, 0.0342937, -0.0489744, -0.0302747, -0.020517, -0.593072, 0.886212, 0.787034, 0.203069, 0.310037, 0.206417, 0.049777, -0.0310031, 0.118825, 0.0787493, 0.124421, 0.00184215, 0.0311101, -0.342569, -0.117711, 0.0932451, -0.0449232, 0.312638, -0.136726, -0.190729, -0.0318272, -0.019481, -0.233524, -0.0878783, -0.417297, -0.357249, -0.306028, 0.0491716, -0.0330191, -0.25916, 0.102744, 0.312724, 0.00622101, 0.255166, -0.442208, 0.172072, 0.206249, -0.0871667, 0.0721438, -0.0133626, 0.305981, -0.722597, -0.340707, -0.0851335, -0.273449, -0.0556902, -0.123598, 0.337455, 0.173143, -0.29903, -0.176026, -0.16659, -0.0699586, -0.189026, -0.237894, -0.157629, -0.0339177, 0.246261, -0.250992, 0.129764, -0.0987714, 0.0525507, -0.0145933, -0.0993352, 0.139703, 0.054665, -0.0984632, 0.206955, 0.187187, -0.250042, -0.219999, -0.0847447, 0.243033, 0.53247, 0.216844, 0.0247264, 0.0906408], "internal": 1}
{"paper_id": "S14-2111", "abstract": "This paper describes the system that has been used by TeamX in SemEval-2014 Task 9 Subtask B. The system is a sentiment analyzer based on a supervised text categorization approach designed with following two concepts. Firstly, since lexicon features were shown to be effective in SemEval-2013 Task 2, various lexicons and pre-processors for them are introduced to enhance lexical information. Secondly, since a distribution of sentiment on tweets is known to be unbalanced, an weighting scheme is introduced to bias an output of a machine learner. For the test run, the system was tuned towards Twitter texts and successfully achieved high scoring results on Twitter data, average F1 70.96 on Twitter2014 and average F1 56.50 on Twitter2014Sarcasm.", "title": "TeamX: A Sentiment Analyzer with Enhanced Lexicon Mapping and Weighting Scheme for Unbalanced Data", "venue": "S", "graph_vector": [-0.0825681, 0.403523, 0.324864, 0.209736, 0.596847, -0.78758, 0.0689336, -0.228718, -1.51228, 0.371606, -0.123305, -0.303557, 0.535741, -0.0817682, -0.00765453, 0.151021, 0.699273, -0.607634, -0.018441, 0.342122, -0.200333, 0.747959, 0.189386, -0.224279, -0.248391, -0.0886742, 0.123588, 0.0951076, -0.104524, -0.0105678, -0.121832, 0.156388, 0.280414, -0.0715275, -0.205779, 0.12218, -0.39853, 0.53321, 0.206264, 0.0277, -0.114897, -0.275898, -0.125709, 0.355324, 0.732088, -0.926966, 0.338494, -0.0314969, -0.0759456, -0.0954934, 0.26893, -0.49448, 0.693464, 0.674446, 0.104443, 0.188232, 0.0171888, 0.245149, -0.458806, 0.262937, 0.187061, 0.105539, -0.102319, -0.114017, -0.0372279, -0.0634365, 0.152243, -0.150649, 0.276931, -0.262405, -0.128011, 0.526304, -0.0563354, -0.47438, -0.21933, -0.161126, -0.411351, -0.527898, 0.100243, -0.0597435, -0.256186, -0.0344107, 0.099844, 0.0417309, -0.0205266, -0.643009, 0.434873, -0.293415, -0.21498, -0.00809599, -0.022531, -0.00976691, -0.757798, -0.166493, 0.0537472, -0.235527, -0.347296, -0.136171, 0.00208408, 0.538735, -0.101984, -0.304003, 0.00501839, -0.22372, -0.0281132, -0.125845, -0.0753481, 0.0010981, 0.202216, -0.318653, 0.141249, 0.0606166, -0.0951351, -0.0895291, -0.118842, -0.0695604, 0.235688, 0.102469, 0.299689, 0.27582, -0.137157, 0.150824, -0.210474, 0.554997, 0.601161, 0.0600369, 0.128204, 0.362677], "internal": 1}
{"paper_id": "S14-2035", "abstract": "This paper describes our participation at SemEval2014 sentiment analysis task, in both contextual and message polarity classification. Our idea was to compare two different techniques for sentiment analysis. First, a machine learning classifier specifically built for the task using the provided training corpus. On the other hand, a lexicon-based approach using natural language processing techniques, developed for a generic sentiment analysis task with no adaptation to the provided training corpus. Results, though far from the best runs, prove that the generic model is more robust as it achieves a more balanced evaluation for message polarity along the different test sets.", "title": "DAEDALUS at SemEval-2014 Task 9: Comparing Approaches for Sentiment Analysis in Twitter", "venue": "S", "graph_vector": [-0.140759, 0.542834, 0.327833, 0.469477, 0.309449, -0.768178, -0.0713849, 0.0719668, -1.60354, 0.388329, -0.228853, -0.509433, 1.02758, 0.240757, -0.400441, 0.0663328, 0.371711, -0.705843, 0.0258761, 0.624084, 0.0993849, 0.837309, 0.0866961, -0.257829, -0.768588, -0.0112252, -0.221834, 0.137623, -0.162297, -0.119511, 0.0349788, -0.0161504, -0.233613, -0.520705, -0.287591, 0.0404938, 0.01378, 0.742706, 0.17975, -0.000960326, 0.296414, -0.374747, -0.336251, 0.584553, 0.998362, -0.897123, 0.0480491, -0.142675, -0.354751, 0.261104, 0.47613, 0.341699, 1.23422, 0.961015, 0.0279402, -0.00436297, 0.610587, 0.153063, -0.237828, 0.190461, -0.059429, -0.527687, 0.0253002, -0.309627, 0.0283173, -0.0846849, 0.377253, 0.572516, 0.37324, 0.115294, 0.254961, -0.307932, -0.285911, -0.226085, 0.0288258, -0.141, -1.11681, -0.730783, -0.184564, -0.324981, -0.229647, -0.0523932, 0.123599, 0.014436, -0.220525, -0.342548, 0.171059, 0.167727, -0.365721, -0.442614, -0.229131, -0.170612, -1.28808, -0.167395, -0.130168, -0.143699, 0.354394, -0.0456954, -0.0150898, -0.157942, -0.14074, -0.194596, 0.217491, 0.106323, -0.156114, -0.117366, -0.179606, -0.0732213, 0.404951, -0.225941, -0.0490665, 0.416806, -0.114618, -0.0811961, 0.106492, 0.309142, 0.0538592, -0.165635, 0.255513, 0.193677, -0.0662638, -0.0981293, -0.367534, -0.260294, 0.275248, -0.0570458, 0.0660097, 0.292823], "internal": 1}
{"paper_id": "S14-2009", "abstract": "We describe the Sentiment Analysis in Twitter task, ran as part of SemEval-2014. It is a continuation of the last year’s task that ran successfully as part of SemEval2013. As in 2013, this was the most popular SemEval task; a total of 46 teams contributed 27 submissions for subtask A (21 teams) and 50 submissions for subtask B (44 teams). This year, we introduced three new test sets: (i) regular tweets, (ii) sarcastic tweets, and (iii) LiveJournal sentences. We further tested on (iv) 2013 tweets, and (v) 2013 SMS messages. The highest F1score on (i) was achieved by NRC-Canada at 86.63 for subtask A and by TeamX at 70.96 for subtask B.", "title": "SemEval-2014 Task 9: Sentiment Analysis in Twitter", "venue": "S", "graph_vector": [-0.0272224, 0.479563, 0.260082, 0.134483, 0.436712, -0.727417, 0.473287, 0.320709, -1.60097, 0.0731476, -0.199888, -0.299578, 0.270565, 0.109214, 0.328055, 0.0086866, 0.569106, -0.467451, 0.0911154, 0.211249, -0.250269, 0.752735, 0.0273996, -0.00327399, -0.162216, -0.0815198, 0.0550434, 0.098555, -0.322113, -0.160037, -0.0605124, 0.251006, 0.340694, -0.139478, -0.280843, 0.324166, -0.197618, 0.539584, 0.126917, -0.0386987, 0.143292, -0.671672, -0.341767, 0.735266, 0.774477, -0.984819, -0.0331394, 0.139163, 0.116897, -0.00251232, -0.146291, -0.347212, 0.748447, 0.982466, -0.106594, 0.10008, -0.0487542, 0.0328133, -0.129057, -0.0186397, -0.160261, 0.0737334, 0.102781, -0.213059, -0.298541, -0.0542796, 0.181882, 0.0122297, 0.421744, 0.0822388, -0.112925, 0.0758943, -0.0542602, -0.289829, -0.15611, -0.081143, -0.308365, -0.387769, -0.228591, 0.0226962, -0.207954, -0.137092, 0.536087, 0.0418294, -0.156676, -0.017275, 0.397605, -0.0890222, 0.0104705, 0.374544, 0.0594325, 0.284687, -0.749568, -0.285629, 0.11175, 0.258578, -0.194576, -0.0492575, 0.353957, 0.163161, -0.0348708, -0.414704, -0.156465, 0.105332, -0.0105769, -0.0493593, -0.450605, 0.0540918, 0.273986, -0.279456, 0.213938, 0.137869, -0.098735, 0.0817803, -0.283939, -0.0265247, 0.0762144, 0.142752, 0.0905164, 0.185448, -0.235711, 0.0661675, 0.207313, 0.186445, 0.566635, 0.273721, 0.0933503, 0.111292], "internal": 1}
{"paper_id": "S13-2005", "abstract": "This paper presents the second round of the task on Cross-lingual Textual Entailment for Content Synchronization, organized within SemEval-2013. The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (six teams, 61 runs), the approaches adopted and the results achieved.", "title": "Semeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization", "venue": "S", "graph_vector": [-0.279993, 0.482146, 0.286211, 0.337916, 0.780239, -0.980342, 0.172056, -0.390841, -1.52292, 0.453186, 0.126673, -0.185926, 0.551952, -0.383701, -0.0926588, -0.048698, 0.554305, -0.845012, 0.330863, 0.424856, -0.0926301, 0.59334, 0.537446, 0.0494602, -0.320271, -0.0841894, 0.46914, 0.115151, -0.199745, 0.293335, 0.134848, 0.269742, 0.531994, -0.274701, -0.0413536, -0.0914758, 0.177545, 0.778922, 0.154733, -0.251666, -0.449011, -0.752207, -0.282688, 0.507775, 1.17333, -0.849988, 0.147335, 0.437527, -0.0214246, -0.0922147, 0.240211, 0.188145, 0.465309, 0.639311, -0.268838, -0.0490636, 0.0568073, -0.0521008, -0.496184, -0.408163, -0.171504, -0.261025, 0.00769469, 0.295957, -0.0147529, -0.181828, -0.0251, -0.0364903, 0.208239, -0.199385, -0.156271, -0.582529, -0.123309, -0.202598, -0.00837547, 0.266086, -0.0657925, -0.196051, 0.134891, -0.243645, 0.0192546, -0.303714, 0.063441, -0.0496105, 0.167493, -0.593432, -0.144006, -0.0402987, -0.407655, -0.184827, 0.0783647, 0.0672926, -0.641487, -0.328944, 0.0965779, -0.0413939, -0.133534, 0.0350383, -0.0138098, -0.111105, -0.302608, -0.566258, -0.0416165, 0.10997, -0.232735, -0.31751, 0.178347, -0.0655177, 0.0949087, 0.547726, 0.139431, -0.018881, -0.0389192, -0.0952228, 0.260816, -0.394426, 0.0905854, 0.265399, 0.186316, 0.173746, -0.224665, -0.182046, -0.306657, 0.066776, 0.863845, 0.488728, -0.179331, 0.237103], "internal": 1}
{"paper_id": "S13-1009", "abstract": "This paper describes our system submitted to *SEM 2013 Semantic Textual Similarity (STS) core task which aims to measure semantic similarity of two given text snippets. In this shared task, we propose an interpolation STS model named Model_LIM integrating FrameNet parsing information, which has a good performance with low time complexity compared with former submissions.", "title": "SXUCFN-Core: STS Models Integrating FrameNet Parsing Information", "venue": "S", "graph_vector": [-0.0379763, 0.280945, 0.437491, 0.396157, 0.298091, -0.700696, 0.0463189, -0.177251, -1.20762, 0.642038, 0.0562951, -0.238282, 1.05971, 0.0982292, -0.29168, 0.131356, 0.256329, -0.753544, 0.0543548, 0.437578, -0.497879, 0.664793, -0.156929, 0.0767663, -0.152671, 0.0110366, -0.0636935, -0.0742232, 0.0425632, 0.0729316, 0.0783418, 0.230824, -0.0542751, -0.427175, 0.104339, 0.151166, -0.0534095, 0.622416, -0.00284852, -0.451964, 0.21158, -0.172968, -0.291096, 0.3083, 0.561615, -0.930093, -0.207647, 0.105307, -0.277246, 0.234943, 0.144339, 0.117673, 0.884637, 0.454611, -0.270183, -0.146655, 0.537723, 0.107352, -0.155732, -0.0753691, -0.0995384, 0.115422, 0.0262613, 0.254941, -0.170588, 0.19288, 0.169917, 0.516937, -0.08992, 0.223857, 0.134253, -0.354823, 0.107765, -0.272948, 0.171218, -0.17098, -0.433927, -0.390283, -0.0320533, 0.0297726, -0.228092, -0.274711, 0.32839, 0.166322, -0.130479, -0.179948, -0.392739, 0.184607, 0.297858, -0.0952829, -0.144214, 0.123271, -0.728411, -0.244555, -0.381308, -0.120963, 0.194827, 0.154059, -0.183766, -0.311024, 0.00705594, 0.145783, 0.00288724, 0.132245, 0.187667, -0.104694, -0.0356798, -0.278066, 0.00926027, 0.238173, 0.134599, 0.0631842, -0.114606, 0.148156, 0.131161, 0.166355, -0.0351919, 0.292679, -0.0060944, -0.000838769, -0.104773, 0.119289, 0.159974, -0.0940655, 0.484309, 0.262737, 0.13489, 0.0792353], "internal": 1}
{"paper_id": "S13-2091", "abstract": "This paper describes the system developed by the Serendio team for the SemEval-2013 Task 2 competition (Task A). We use a lexicon based approach for discovering sentiments. Our lexicon is built from the Serendio taxonomy. The Serendio taxonomy consists of positive, negative, negation, stop words and phrases. A typical tweet contains word variations, emoticons, hashtags etc. We use preprocessing steps such as stemming, emoticon detection and normalization, exaggerated word shortening and hashtag detection. After the preprocessing, the lexicon-based system classifies the tweets as positive or negative based on the contextual sentiment orientation of the words. Our system yields an F-score of 0.8004 on the test dataset.", "title": "Serendio: Simple and Practical lexicon based approach to Sentiment Analysis", "venue": "S", "graph_vector": [0.255602, 0.105491, 0.608544, 0.12633, 0.256969, -0.701148, 0.125795, 0.00884447, -1.6219, 0.361001, -0.140937, -0.236826, 0.487879, -0.122114, 0.236841, 0.111448, 0.409675, -0.755794, 0.0210992, 0.40178, -0.0405114, 0.603299, -0.0500616, -0.172556, -0.350377, 0.00630273, 0.43133, -0.0689226, -0.143594, -0.43629, -0.00695408, -0.0160317, -0.225446, -0.423083, -0.15209, 0.0805816, -0.223508, 0.479973, 0.153848, -0.0548318, -0.00363583, -0.429968, -0.246629, 0.548234, 0.766281, -0.631473, -0.0976423, 0.182763, 0.0818994, 0.0405076, 0.414516, -0.520659, 0.731252, 0.680193, 0.144611, 0.202629, 0.189217, 0.0630153, -0.0656493, 0.491443, -0.0309085, 0.365947, 0.00299841, -0.0913937, 0.00321442, 0.222888, 0.287216, 0.069439, 0.332676, 0.164539, -0.155987, -0.164139, 0.0229721, -0.239511, -0.307631, 0.0547727, -0.752476, -0.253546, -0.272227, 0.193213, -0.0702265, -0.226832, 0.245175, -0.288736, 0.496574, -0.0459107, 0.281968, -0.0975898, -0.0518521, 0.229986, -0.106606, 0.320566, -0.945636, -0.229824, 0.0143423, 0.104667, -0.136866, 0.10327, 0.0251343, 0.171142, -0.263687, -0.303228, -0.227284, -0.144719, 0.0131224, 0.0197265, -0.244714, -0.271015, 0.137162, -0.152732, 0.218486, 0.158731, 0.0628956, 0.136312, -0.0899042, -0.143502, 0.0192447, -0.0265568, -0.201537, 0.0572855, -0.0887241, 0.0388906, -0.00219483, 0.108702, 0.55217, 0.285536, -0.0806763, 0.00962269], "internal": 1}
{"paper_id": "S13-2035", "abstract": "In this paper we describe our Semeval-2013 task on Word Sense Induction and Disambiguation within an end-user application, namely Web search result clustering and diversification. Given a target query, induction and disambiguation systems are requested to cluster and diversify the search results returned by a search engine for that query. The task enables the end-to-end evaluation and comparison of systems.", "title": "SemEval-2013 Task 11: Word Sense Induction & Disambiguation within an End-User Application", "venue": "S", "graph_vector": [-0.198012, 0.116802, 0.0384805, -0.213181, 0.473653, -0.789647, -0.206391, -0.246817, -1.17212, 0.441194, -0.401976, -0.158517, 0.899518, 0.0736986, -0.180813, -0.0905905, 0.17656, -0.53345, -0.0114864, 0.566752, -0.180887, 0.156913, 0.133536, 0.0352965, -0.448281, -0.0892132, 0.219976, 0.364385, -0.113213, 0.0756254, -0.179723, 0.172841, 0.173845, -0.518325, -0.459947, -0.100866, -0.375666, 0.521809, -0.0879628, -0.12535, 0.0520678, -0.702856, -0.297052, 0.20518, 1.21756, -0.630547, 0.240291, -0.0797863, -0.258209, -0.215565, 0.259875, 0.233608, 0.875094, 0.798746, -0.0629319, -0.18683, -0.0929942, 0.147599, -0.00181565, 0.112597, -0.448831, -0.032847, -0.138018, -0.0182228, 0.198279, -0.251425, 0.0411772, -0.193274, -0.0362816, 0.176837, -0.113566, -0.0266564, -0.2975, -0.28498, -0.127309, -0.375159, -0.721081, -0.274329, -0.273511, 0.0728849, -0.223983, -0.299156, 0.203611, 0.0870363, 0.093782, -0.60109, -0.154833, -0.453288, 0.510759, 0.158261, 0.326831, -0.0897127, -0.441401, 0.0849485, -0.137405, 0.148379, -0.329139, 0.417602, -0.0223714, 0.0443868, -0.391992, -0.162467, -0.409371, 0.0962129, -0.224685, -0.26939, 0.360938, -0.190608, -0.179417, -0.127675, -0.125599, 0.434678, 0.320152, 0.145671, 0.275222, -0.025737, 0.580817, 0.0227751, 0.0282313, 0.268842, -0.561404, 0.0340859, -0.350641, -0.0192285, 0.462308, -0.0820567, -0.00877062, 0.394114], "internal": 1}
{"paper_id": "S13-2021", "abstract": "This paper presents our approach used for cross-lingual textual entailment task (task 8) organized within SemEval 2013. Crosslingual textual entailment (CLTE) tries to detect the entailment relationship between two text fragments in different languages. We solved this problem in three steps. Firstly, we use a off-the-shelf machine translation (MT) tool to convert the two input texts into the same language. Then after performing a text preprocessing, we extract multiple feature types with respect to surface text and grammar. We also propose novel feature types regarding to sentence difference and semantic similarity based on our observations in the preliminary experiments. Finally, we adopt a multiclass SVM algorithm for classification. The results on the cross-lingual data collections provided by SemEval 2013 show that (1) we can build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG.", "title": "ECNUCS: Recognizing Cross-lingual Textual Entailment Using Multiple Text Similarity and Text Difference Measures", "venue": "S", "graph_vector": [-0.168457, 0.0849934, 0.345077, 0.23272, 0.663195, -0.619369, 0.113641, -0.270686, -1.63581, 0.241792, 0.182138, -0.14567, 0.739599, -0.0427205, -0.110535, 0.0994642, 0.304353, -0.814405, 0.359051, 0.161785, -0.471033, 0.765279, 0.290656, 0.0925568, -0.272724, 0.0650007, 0.536788, 0.33913, -0.098491, -0.0858896, -0.00668093, -0.0171255, 0.391672, -0.233957, 0.151946, -0.0991193, 0.00976261, 0.433728, 0.167735, -0.624251, -0.481256, -0.483511, -0.19264, 0.379528, 0.96048, -0.924177, -0.0843307, 0.181269, 0.134479, 0.0272341, 0.321443, -0.111906, 0.537095, 0.393535, -0.00552239, 0.313242, 0.185249, -0.156319, -0.371573, -0.141005, 0.233171, -0.309064, -0.135774, 0.322697, -0.113241, 0.0923156, 0.289399, -0.0416186, 0.252922, 0.0227047, -0.273659, -0.168569, 0.090319, -0.087139, 0.31257, 0.149357, -0.220524, -0.317973, 0.369317, -0.364255, 0.143982, -0.29589, 0.125882, -0.187696, 0.187739, -0.544895, -0.0155757, 0.100415, -0.0598962, 0.162527, 0.065462, -0.054165, -0.932581, -0.604243, 0.137455, -0.0137143, -0.438081, -0.228745, 0.0859326, -0.259865, -0.190756, -0.279638, 0.311571, -0.148682, 0.0939701, -0.577255, -0.0198851, 0.00964884, 0.0644321, 0.302795, 0.11885, -0.299005, -0.0231421, 0.0147226, 0.243545, -0.341441, 0.234742, 0.436493, 0.282065, 0.353381, -0.403024, -0.00770163, 0.0662128, -0.0430945, 0.54673, 0.417115, -0.050048, 0.165345], "internal": 1}
{"paper_id": "S13-2006", "abstract": "In this paper we describe our system submitted for evaluation in the CLTE-SemEval-2013 task, which achieved the best results in two of the four data sets, and finished third in average. This system consists of a SVM classifier with features extracted from texts (and their translations SMT) based on a cardinality function. Such function was the soft cardinality. Furthermore, this system was simplified by providing a single model for the 4 pairs of languages obtaining better (unofficial) results than separate models for each language pair. We also evaluated the use of additional circular-pivoting translations achieving results 6.14% above the best official results.", "title": "SOFTCARDINALITY: Learning to Identify Directional Cross-Lingual Entailment from Cardinalities and SMT", "venue": "S", "graph_vector": [-0.175008, 0.145275, 0.21096, 0.367691, 0.263903, -0.91631, 0.0640974, 0.0931106, -1.39063, 0.553887, -0.0826197, -0.0481861, 0.801909, -0.40825, -0.350192, -0.271846, 0.520051, -0.973839, 0.373529, 0.157484, -0.209713, 0.591313, 0.349943, -0.30614, -0.478689, 0.0312851, 0.3664, 0.190574, 0.00222958, 0.221011, 0.300828, 0.00291476, 0.0928981, -0.108485, -1.25139e-05, 0.00401327, 0.419186, 0.608506, 0.127159, -0.240247, -0.29629, -0.615996, -0.178516, 0.584667, 0.742569, -0.632512, -0.25196, 0.169262, -0.19506, -0.0294271, 0.335957, 0.16574, 0.708791, 0.599527, -0.0745648, -0.184573, 0.0436936, -0.271866, -0.693254, 0.133519, -0.255492, -0.0303679, 0.208106, -0.247007, -0.172892, -0.0414919, 0.242984, 0.00678991, 0.00826127, 0.306442, -0.231743, -0.392423, -0.0152742, -0.0848788, 0.0955555, 0.195272, -0.47815, -0.473064, -0.0334376, -0.355892, -0.227255, 0.0423754, 0.418756, 0.0559305, 0.0874004, -0.748072, 0.246992, -0.21022, -0.0420522, -0.217266, -0.18295, 0.149018, -0.907199, -0.382347, -0.218468, 0.239197, -0.437823, -0.401768, 0.00752382, 0.0261896, -0.116798, -0.362803, -0.200303, 0.432924, -0.179939, -0.507188, -0.220905, 0.0499554, 0.027869, 0.645086, 0.0448769, 0.135696, 0.109495, -0.0440544, 0.189396, -0.102064, -0.0692509, 0.285033, -0.0615837, 0.23835, -0.145896, 0.128483, 0.167028, -0.194061, 0.506212, 0.332096, -0.213613, 0.346315], "internal": 1}
{"paper_id": "S13-2023", "abstract": "We present a supervised learning approach to cross-lingual textual entailment that explores statistical word alignment models to predict entailment relations between sentences written in different languages. Our approach is language independent, and was used to participate in the CLTE task (Task#8) organized within Semeval 2013 (Negri et al., 2013). The four runs submitted, one for each language combination covered by the test data (i.e. Spanish/English, German/English, French/English and Italian/English), achieved encouraging results. In terms of accuracy, performance ranges from 38.8% (for German/English) to 43.2% (for Italian/English). On the Italian/English and Spanish/English test sets our systems ranked second among five participants, close to the top results (respectively 43.4% and 45.4%).", "title": "ALTN: Word Alignment Features for Cross-lingual Textual Entailment", "venue": "S", "graph_vector": [-0.0427258, 0.571883, -0.0553674, 0.151092, 0.511676, -0.833215, -0.193315, -0.431055, -1.79118, 0.256155, 0.054476, -0.220164, 0.524694, -0.135007, -0.0448259, -0.106429, 0.309448, -0.838219, 0.440054, 0.263928, -0.122033, 0.625099, 0.507844, 0.111034, -0.330231, -0.170861, 0.217797, 0.169814, -0.170421, 0.188929, -0.00225566, -0.00846023, 0.12641, -0.327723, -0.0934952, -0.000154388, 0.0638928, 0.400239, 0.221977, -0.194568, -0.362264, -0.57218, -0.42279, 0.364509, 1.13867, -0.941183, 0.210606, 0.398202, -0.00165182, 0.00757973, 0.194351, 0.221942, 0.505406, 0.488519, -0.359261, 0.00348408, 0.0344867, 0.0784781, -0.15306, -0.0183693, 0.00861882, -0.537967, -0.0716372, 0.106966, 0.0175658, -0.130709, 0.0717027, 0.125664, -0.0132774, 0.160931, -0.0298709, -0.0489768, -0.104274, -0.0251921, 0.0140137, 0.0808, -0.221101, -0.0803192, 0.0702617, -0.0810254, -0.189387, -0.353776, 0.237796, -0.143114, 0.0154058, -0.770554, 0.12564, 0.078731, -0.411442, -0.222713, 0.0276594, 0.0664067, -0.736654, -0.279789, 0.122182, 0.0110823, 0.00661716, 0.208533, -0.263518, 0.0778961, -0.174372, -0.532057, -0.00531613, 0.26278, -0.0659787, -0.467889, 0.228491, -0.19011, 0.0925063, 0.420976, -0.00952443, 0.228117, 0.145822, -0.133372, 0.211684, -0.281107, 0.197326, 0.113145, 0.0829982, 0.00957805, -0.0941503, -0.137985, 0.0103836, 0.142582, 0.657014, 0.705359, 0.0498626, 0.271276], "internal": 1}
{"paper_id": "S13-2085", "abstract": "For SemEval-2013 Task 2, A and B (Sentiment Analysis in Twitter), we use a rulebased pattern matching system that is based on an existing ‘Domain Independent’ sentiment taxonomy for English, essentially a highly phrasal sentiment lexicon. We have made some modifications to our set of rules, based on what we found in the annotated training data that was made available for the task. The resulting system scores competitively, especially on task B.", "title": "teragram: Rule-based detection of sentiment phrases using SAS Sentiment Analysis", "venue": "S", "graph_vector": [0.12236, 0.222015, 0.236801, 0.18689, 0.245009, -0.930639, -0.00847728, 0.0267492, -2.06616, 0.216335, 0.134409, -0.145186, 0.504969, 0.0247641, 0.14082, 0.18296, 0.343827, -0.4072, 0.0604982, 0.378544, -0.210583, 0.667277, 0.193561, -0.222762, -0.347778, 0.115437, 0.164595, 0.263742, -0.178541, -0.128192, -0.0396383, -0.0388788, 0.127809, -0.221909, -0.133693, 0.129625, -0.477408, 0.732878, -0.271298, -0.110162, -0.243296, -0.484322, -0.320855, 0.44921, 0.773033, -0.705401, -0.00670286, 0.211923, 0.151515, 0.00256917, 0.529995, -0.348648, 0.709398, 0.903412, 0.0745523, -0.0351759, 0.216518, 0.0825001, -0.116848, 0.179853, -0.104159, 0.28028, -0.0407534, 0.0873422, -0.275147, 0.29488, 0.273333, 0.0795727, 0.337938, 0.389425, 0.249194, -0.164698, 0.323076, 0.0222726, -0.286877, -0.071737, -0.259385, 0.0205677, -0.121275, -0.0583293, -0.29892, -0.0955919, 0.183342, -0.34198, 0.452726, -0.197842, 0.298036, -0.268582, -0.316624, -0.0178113, 0.0864248, 0.353995, -0.688963, -0.0469682, 0.126969, 0.0782128, 0.177154, 0.196627, 0.174231, 0.135002, -0.183094, -0.335827, -0.340055, 0.0896601, -0.024377, -0.0219951, -0.14519, -0.557141, 0.369301, -0.452068, 0.0568253, 0.103019, 0.212626, -0.0705008, 0.192035, -0.341117, 0.0935746, -0.0143331, -0.146357, 0.1022, -0.0794928, 0.0392403, 0.133039, 0.246136, 0.684714, 0.0930265, -0.0714229, -0.06354], "internal": 1}
{"paper_id": "S15-2068", "abstract": "Unstructured clinical notes are rich sources for valuable patient information. Information extraction techniques can be employed to extract this valuable information, which in turn can be used to discover new knowledge. Named entity recognition and normalization are the basic tasks involved in information extraction. In this paper, identification of disorder named entities and the mapping of identified disorder entities to SNOMED-CT terminology using UMLS Metathesaurus is presented. A supervised linear chain conditional random field model based on sets of features to predict disorder mentions is used in conjunction with MetaMap to identify and normalize disorders. Error analysis conclude that recall of the developed system can be significantly increased by adding more features during model development and also by using a frame based approach for handling disjoint entities.", "title": "TMUNSW: Identification of disorders and normalization to SNOMED-CT terminology in unstructured clinical notes", "venue": "S", "graph_vector": [0.186005, 0.338444, 0.0616261, 0.376337, 0.298454, -0.915012, 0.227131, 0.106948, -1.82284, 0.211271, 0.19093, -0.0723919, 0.835873, -0.0787624, 0.0563636, -0.0241649, 0.651623, -0.810234, 0.220118, 0.440044, -0.141323, 0.63844, -0.0351811, 0.259996, 0.0226957, 0.473335, 0.0378167, -0.224054, 0.12355, -0.0123282, 0.0133799, 0.224489, -0.144834, 0.0462239, -0.00650062, 0.0553597, -0.149041, 0.81913, -0.145357, 0.181264, 0.202122, -0.305374, -0.700729, 0.155535, 0.801019, -0.694216, 0.313835, 0.0995613, 0.0980556, -0.262277, 0.526764, -0.0828189, 0.592626, 1.05523, -0.205411, -0.300264, 0.12838, 0.396299, -0.0599725, 0.224312, -0.14488, -0.337058, -0.064352, 0.292185, -0.0705704, 0.176195, 0.18447, -0.0129228, 0.150937, -0.290987, 0.240116, -0.0753578, -0.176599, -0.0575616, 0.0963106, -0.331623, -0.891898, -0.134834, -0.0713489, -0.242142, -0.632444, 0.00811282, 0.52124, 0.117708, 0.114237, -0.325393, 0.275315, -0.330999, 0.328039, -0.115659, 0.338496, -0.0975784, -0.685205, -0.276064, 0.12156, -0.0845933, -0.229992, -0.227894, -0.0237093, -0.0704919, -0.443377, -0.172539, 0.047953, 0.269444, 0.0601095, 0.445093, 0.444795, 0.164874, 0.0566927, -0.221056, 0.0740635, 0.0378259, -0.261697, -0.427892, -0.249048, -0.360834, 0.384503, 0.0610905, 0.375558, 0.373046, 0.271674, -0.389095, -0.0611764, -0.250113, 0.186931, -0.0475502, 0.100507, 0.138137], "internal": 1}
{"paper_id": "S15-2010", "abstract": "We use referential translation machines (RTMs) for predicting the semantic similarity of text. RTMs are a computational model effectively judging monolingual and bilingual similarity while identifying translation acts between any two data sets with respect to interpretants. RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource. RTMs become the 2nd system out of 13 systems participating in Paraphrase and Semantic Similarity in Twitter, 6th out of 16 submissions in Semantic Textual Similarity Spanish, and 50th out of 73 submissions in Semantic Textual Similarity English.", "title": "RTM-DCU: Predicting Semantic Similarity with Referential Translation Machines", "venue": "S", "graph_vector": [-0.0268714, 0.0858829, 0.11642, 0.269015, 0.445047, -0.608404, 0.249097, -0.12933, -1.26204, -0.106256, -0.355399, -0.4367, 0.306398, 0.147013, 0.094682, -0.146999, 0.671415, -1.11604, 0.141858, 0.389423, -0.475005, 0.630897, 0.345301, -0.104622, -0.714406, 0.115461, -0.355263, 0.368911, -0.171424, -0.0874804, -0.208643, -0.0155628, 0.052488, -0.262249, -0.300981, 0.192954, -0.0861732, 1.02587, -0.101204, -0.593236, -0.20535, -0.138128, -0.248551, 0.396766, 1.20632, -1.01975, -0.322466, 0.0381674, 0.168913, -0.32183, 0.0427702, -0.00414673, 0.84069, 0.60134, -0.277894, -0.238321, -0.0173348, -0.140787, -0.677557, -0.161745, -0.0919707, -0.0449133, 0.0567351, -0.0562756, -0.136547, 0.0386136, 0.441594, 0.0228764, 0.271654, -0.491799, 0.138414, 0.203487, -0.166706, -0.199676, -0.226253, -0.00201079, -0.456534, -0.25891, -0.196622, 0.028179, 0.0606206, -0.420973, -0.0938175, -0.20569, 0.290865, -0.310422, -0.0316152, 0.271811, -0.214207, -0.00379263, -0.0920506, 0.0983987, -0.58707, 0.299631, -0.153119, -0.110738, -0.200049, -0.109308, -0.122026, -0.322678, -0.396238, 0.141037, 0.192522, 0.189725, 0.113138, 0.246545, 0.108584, 0.0674202, 0.153837, 0.0853202, 0.409516, 0.102927, 0.282163, -0.0281774, 0.0181858, -0.386011, 0.318694, 0.268088, 0.0699966, 0.555548, -0.0944485, 0.222744, -0.107031, 0.334183, 0.669887, 0.222866, -0.236138, 0.520014], "internal": 1}
{"paper_id": "S15-2075", "abstract": "We describe a system for semantic role labeling adapted to a dependency parsing framework. Verb arguments are predicted over nodes in a dependency parse tree instead of nodes in a phrase-structure parse tree. Our system participated in SemEval-2015 shared Task 15, Subtask 1: CPA parsing and achieved an Fscore of 0.516. We adapted features from prior semantic role labeling work to the dependency parsing paradigm, using a series of supervised classifiers to identify arguments of a verb and then assigning syntactic and semantic labels. We found that careful feature selection had a major impact on system performance. However, sparse training data still led rule-based systems like the baseline to be more effective than learning-based approaches.", "title": "CMILLS: Adapting Semantic Role Labeling Features to Dependency Parsing", "venue": "S", "graph_vector": [0.0690413, 0.341616, 0.155794, -0.094563, 0.253713, -0.704882, 0.227862, -0.430106, -1.53426, 0.0298457, -0.0198513, -0.683356, 0.614711, 0.0956787, 0.0876224, 0.0241243, 0.680443, -0.599677, 0.593834, 0.181722, -0.562132, 0.716192, 0.333151, 0.189599, -0.258909, 0.079497, -0.0935769, -0.0581446, -0.283182, -0.26357, 0.427762, 0.260128, 0.0846828, -0.447962, -0.19883, 0.223622, -0.275599, 0.432064, 0.161961, 0.0109718, 0.257229, -0.480386, -0.291852, 0.330224, 0.714707, -0.897633, 0.150492, 0.16576, 0.717308, -0.111984, 0.389265, -0.00078438, 0.678812, 0.862921, -0.131663, 0.0885578, 0.191865, 0.207246, -0.0123386, 0.0119755, -0.2003, -0.146496, -0.337703, -0.0294708, -0.164422, -0.282643, -0.138126, -0.301647, 0.298146, -0.0153867, 0.0818393, 0.404443, -0.225696, -0.280798, -0.239976, 0.195739, -0.519838, -0.414584, -0.0238874, -0.270645, 0.211942, 0.0175742, 0.125782, 0.0782145, 0.133507, -0.566315, 0.329703, -0.241005, 0.392163, 0.169331, -0.0705988, 0.0831195, -0.646706, -0.316851, 0.0553449, -0.122439, 0.134158, 0.14807, -0.136474, 0.0370118, -0.0817267, -0.297595, -0.062693, 0.235234, -0.229829, 0.191944, 0.0647487, -0.421341, 0.233677, -0.0919354, 0.291426, -0.200336, -0.14161, 0.270339, -0.0211466, 0.164491, 0.611916, -0.101663, 0.199456, 0.199477, -0.429849, 0.190377, 0.135462, -0.249557, 0.422991, 0.250155, 0.212283, -0.236033], "internal": 1}
{"paper_id": "S07-1065", "abstract": "This article describes the implementation of Word Sense Disambiguation system that participated in the SemEval-2007 multilingual Chinese-English lexical sample task. We adopted a supervised learning approach with Maximum Entropy classifier. The features used were neighboring words and their part-of-speech, as well as single words in the context, and other syntactic features based on shallow parsing. In addition, we used word category information of a Chinese thesaurus as features for verb disambiguation. For the task we participated in, we obtained precision of 0.716 in micro-average, which is the best among all participated systems.", "title": "SRCB-WSD: Supervised Chinese Word Sense Disambiguation with Key Features", "venue": "S", "graph_vector": [0.0556169, 0.0993491, -0.495944, 0.298907, 0.35383, -0.424199, 0.219035, -0.109473, -1.48128, 0.360129, -0.32325, -0.0589707, 0.602713, 0.557975, -0.0356147, -0.0778574, 0.389474, -0.676978, 0.144889, 0.29455, -0.106696, 0.479343, 0.0975313, 0.0715609, -0.146854, 0.295179, 0.146052, 0.0805373, 0.0697451, -0.26432, -0.0985712, -0.085726, 0.314194, -0.641371, -0.0578617, 0.0710461, -0.397235, 0.747266, 0.0797084, -0.0393843, -0.0594735, -0.264967, -0.0237195, 0.218763, 1.11565, -0.611699, 0.135269, -0.0800302, 0.0846362, -0.144286, 0.643933, -0.203683, 0.642673, 0.705098, -0.415019, 0.130809, 0.075661, 0.376561, -0.0948791, 0.582133, -0.401229, 0.106221, 0.265866, 0.120436, -0.108044, -0.121223, -0.261317, 0.281639, -0.087255, -0.0186624, 0.0214228, 0.210019, -0.0349016, -0.0597218, -0.171557, -0.029827, -0.333456, -0.543402, 0.0453711, 0.499762, -0.184836, -0.316649, 0.186306, 0.0435884, 0.0689741, 0.0490811, -0.272947, -0.0848982, 0.15083, 0.19381, 0.0150335, -0.336767, -0.504127, 0.0997687, -0.0603786, 0.202134, -0.0354891, 0.144734, -0.112142, 0.0730097, -0.156898, 0.115295, -0.10138, 0.307107, 0.123077, 0.111794, -0.174533, -0.217876, -0.14375, -0.600937, 0.337019, -0.0470071, -0.227105, 0.232387, 0.0844299, 0.299679, 0.443039, 0.322735, 0.189545, 0.0589382, -0.159664, -0.29396, -0.272446, -0.231363, 0.101127, 0.33029, -0.123445, -0.0109646], "internal": 1}
{"paper_id": "S07-1054", "abstract": "We participated in the SemEval-2007 coarse-grained English all-words task and fine-grained English all-words task. We used a supervised learning approach with SVM as the learning algorithm. The knowledge sources used include local collocations, parts-of-speech, and surrounding words. We gathered training examples from English-Chinese parallel corpora, SEMCOR, and DSO corpus. While the fine-grained sense inventory of WordNet was used to train our system employed for the fine-grained English all-words task, our system employed for the coarse-grained English all-words task was trained with the coarse-grained sense inventory released by the task organizers. Our scores (for both recall and precision) are 0.825 and 0.587 for the coarse-grained English all-words task and fine-grained English all-words task respectively. These scores put our systems in the first place for the coarse-grained English all-words task' and the second place for the fine-grained English all-words task.", "title": "NUS-PT: Exploiting Parallel Texts for Word Sense Disambiguation in the English All-Words Tasks", "venue": "S", "graph_vector": [0.185072, 0.163377, -0.253511, 0.60148, 0.30746, -0.544086, 0.146053, -0.132367, -1.5336, 0.509331, -0.110399, -0.382615, 0.486956, 0.483945, -0.154749, -0.159865, 0.457029, -0.846843, -0.0520149, 0.542037, 0.261875, 0.501031, 0.0116117, 0.100147, -0.0275375, 0.124043, 0.153587, 0.1907, 0.024381, -0.0847596, -0.105216, 0.379635, 0.144868, -0.0938955, -0.156233, -0.024156, -0.126335, 0.731331, 0.163744, -0.159609, 0.170946, -0.117733, -0.231836, 0.430126, 0.85189, -0.601498, 0.363866, -0.0257237, -0.0485569, -0.165083, 0.434823, -0.244174, 0.774025, 0.865361, -0.319427, 0.018309, 0.139687, 0.31792, -0.209315, 0.195027, -0.430184, 0.150266, 0.104307, 0.209002, 0.00911847, -0.27648, 0.0751849, -0.0931946, 0.0265488, 0.136225, 0.115802, 0.0761589, 0.139719, -0.357079, 0.0114547, 0.0672215, -0.507438, -0.292505, -0.229264, 0.244041, 0.219355, -0.128352, 0.149951, 0.513573, 0.107768, -0.213685, 0.0254341, -0.0105969, -0.226397, -0.0151643, 0.0368076, 0.019557, -0.498496, -0.376053, 0.00739756, -0.289336, -0.201325, 0.0031783, -0.0252909, 0.0992526, -0.040408, -0.279616, -0.125006, 0.0988803, 0.227311, -0.158346, -0.368424, -0.144211, 0.00473014, -0.658844, 0.412222, -0.189395, -0.164539, 0.00998023, 0.0674198, 0.207639, 0.415504, 0.387566, -0.0424127, 0.0760691, -0.276865, -0.39198, -0.404715, -0.0103337, 0.104802, 0.252432, -0.0153646, -0.0170771], "internal": 1}
{"paper_id": "S12-1024", "abstract": "We present a rule-based method to automatically create a large-coverage semantic lexicon of French adjectives by extracting paradigmatic relations from lexicographic definitions. Formalized adjectival resources are, indeed, scarce for French and they mostly focus on morphological and syntactic information. Our objective is, therefore, to contribute enriching the available set of resources by taking advantage of reliable lexicographic data and formalizing it with the well-established lexical functions formalism. The resulting semantic lexicon of French adjectives can be used in NLP tasks such as word sense disambiguation or machine translation. After presenting related work, we describe the extraction method and the formalization procedure of the data. Our method is then quantitatively and qualitatively evaluated. We discuss the results of the evaluation and conclude on some perspectives.", "title": "Extracting a Semantic Lexicon of French Adjectives from a Large Lexicographic Dictionary", "venue": "S", "graph_vector": [0.517851, 0.264144, -0.00525158, 0.510304, 0.648836, -0.990095, 0.569744, -0.182108, -2.08307, 0.206031, -0.030781, -0.44245, 0.813207, 0.512948, 0.185348, 0.0617687, 0.210446, -0.53747, 0.00113998, 0.421496, -0.508778, 0.864486, 0.608227, 0.0202944, -0.585633, -0.0450307, 0.514348, 0.707223, -0.742949, -0.307703, 0.125106, 0.0866477, -0.0527167, -0.389429, 0.128333, -0.125033, -0.347352, 0.987563, 0.230007, -0.0157279, -0.140973, -0.592666, -0.0342384, 0.137116, 0.891567, -0.845879, -0.217427, 0.126606, 0.314188, 0.415833, 0.139046, 0.283401, 0.826944, 0.628595, -0.334098, 0.0333639, -0.0806447, 0.27601, -0.252179, -0.197753, -0.224568, 0.126246, -0.263049, 0.122231, 0.292159, -0.0680829, 0.291887, 0.261972, -0.18544, -0.197293, -0.15246, 0.033752, 0.58972, -0.0244418, 0.129277, -0.181064, -0.578201, -0.735564, 0.0326193, 0.288761, -0.43607, -0.531827, -0.0718983, 0.0586374, 0.240315, -0.160765, 0.231414, -0.0269985, -0.184126, 0.047046, 0.36313, -0.330561, -0.932758, -0.722686, 0.184107, -0.0162094, -0.113868, -0.115746, -0.0115625, -0.176694, -0.230376, -0.577077, -0.00211001, -0.316238, 0.237478, -0.185117, -0.676311, -0.46747, 0.226268, -0.162771, -0.178634, 0.116776, -0.152334, -0.226692, 0.091613, 0.0652402, 0.382737, 0.204897, 0.323683, 0.127835, -0.334223, -0.0574002, 0.0961962, 0.0758381, 0.209937, 0.312284, -0.171403, 0.258295], "internal": 1}
{"paper_id": "S12-1079", "abstract": "This paper describes investigations into using syntactic chunk information as the basis for determining the similarity of candidate texts at the semantic level. Two approaches were considered. The first was a corpus-based method that extracted lexical and semantic features from pairs of chunks from each sentence that were associated through a chunk alignment algorithm. The features were used as input to a classifier trained on the same features extracted from a corpus of gold standard training data. The second approach involved breadthfirst chunk association and the application of a rule-based scoring algorithm. Both approaches were evaluated against the test data for the SemEval 2012 Semantic Text Similarity task. The results show that the rule-based chunk approach is superior.", "title": "ATA-Sem: Chunk-based Determination of Semantic Text Similarity", "venue": "S", "graph_vector": [0.0664291, 0.203972, -0.094458, -0.0104995, 0.637715, -0.4583, 0.165748, -0.0927329, -1.46607, 0.541547, -0.204842, -0.150968, 1.12947, 0.0216993, 0.449818, 0.212117, 0.763835, -0.828756, 0.307037, 0.556559, -0.0815417, 0.575969, 0.4577, 0.281481, -0.53972, 0.252217, 0.208411, 0.111644, -0.0655993, 0.176884, -0.199994, 0.150212, 0.225694, -0.183856, -0.105199, -0.0138624, -0.0567892, 0.311918, -0.0704857, -0.0763128, -0.201803, -0.353053, -0.360189, 0.193394, 1.09202, -1.06265, 0.0462237, -0.249837, 0.0789598, 0.146064, 0.0814375, -0.0868687, 0.724512, 0.453064, -0.263304, -0.131531, 0.1128, 0.27512, -0.1884, -0.0432405, -0.406998, 0.2971, -0.133396, 0.0946909, -0.189211, 0.0603608, 0.0329095, -0.0821666, 0.213464, 0.108193, 0.341015, 0.199225, 0.499645, -0.124435, -0.0360207, -0.143621, -0.477601, -0.681889, -0.240957, -0.0230545, -0.165434, 0.00241446, 0.282369, -0.127506, -0.176749, -0.494124, -0.282621, 0.0527381, 0.216853, -0.386466, 0.0710373, -0.278981, -0.751539, -0.490443, -0.092639, 0.151361, 0.124175, 0.092492, -0.338022, -0.312619, -0.165259, 0.0564937, 0.252549, 0.0446472, 0.116048, -0.00728258, 0.137221, 0.000596241, -0.413033, 0.214778, 0.0863257, -0.0487458, 0.126068, 0.362706, -0.167388, -0.203931, 0.131424, 0.236109, 0.0735833, 0.373817, -0.318833, 0.280955, 0.0144408, 0.370135, 0.418168, 0.623179, -0.124749, 0.0865445], "internal": 1}
{"paper_id": "D07-1072", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.117285, -0.128485, -0.0973981, 0.143652, 0.47479, -0.658674, -0.0929162, -0.074237, -1.49422, 0.399188, -0.237736, -0.797831, 0.318379, 0.0824046, 0.0724997, -0.398463, 0.640965, -0.405808, -0.1065, 0.24235, -0.148352, 0.642425, 0.308631, -0.0176977, -0.0658317, 0.0955081, 0.080375, 0.206176, -0.0821706, -0.430855, 0.506036, -0.113611, 0.171444, -0.477644, 0.158322, 0.527957, -0.178832, 0.44324, -0.0906781, -0.472598, 0.232669, -0.0365509, -0.415645, 0.421062, 1.06375, -1.04183, -0.040687, 0.207891, 0.0736484, -0.0966597, 0.246704, -0.221889, 0.783904, 0.563039, -0.111608, 0.0599019, -0.225789, 0.0727116, 0.284722, 0.123226, -0.399765, -0.228944, 0.0553506, 0.260127, -0.208721, 0.065114, -0.0201256, -0.0862235, -0.0413292, -0.117867, 0.197046, -0.237883, -0.0218744, -0.0408867, 0.0595361, -0.191902, -0.422556, -0.302738, -0.0873455, -0.220365, 0.0075084, -0.101678, 0.0741937, -0.397845, 0.00817963, -0.18586, -0.0563155, -0.256417, 0.225921, 0.134595, -0.425523, 0.11859, -0.343089, -0.604281, 0.0542128, -0.195188, 0.00101506, 0.160065, -0.254717, -0.101309, -0.333347, -0.175285, 0.0348691, 0.414, 0.22594, -0.0703452, 0.276754, -0.0512919, -0.0669912, -0.132623, -0.456227, 0.428992, -0.119672, -0.0562427, -0.0473972, 0.149037, 0.162408, -0.0919759, 0.0622751, 0.230378, -0.358656, -0.204545, -0.0646822, 0.236916, 0.385519, 0.128229, 0.0851341, -0.00939534], "internal": 0}
{"paper_id": "N13-1073", "abstract": "", "title": "", "venue": "", "graph_vector": [0.164855, 0.152405, 0.0970277, 0.343758, 0.555256, -0.642378, 0.0216641, -0.449766, -1.54903, 0.297582, -0.279693, -0.164259, 0.419977, -0.0203875, 0.400857, -0.115711, 0.497068, -0.666112, -0.135418, 0.435051, 0.149093, 0.630629, 0.481927, -0.139443, -0.44167, -0.133712, -0.314124, 0.313873, -0.154924, -0.725875, -0.0340632, -0.104419, -0.0607157, -0.409905, -0.177091, 0.347002, 0.030259, 0.372358, 0.168994, 0.102317, 0.0350936, -0.364256, -0.604769, 0.71291, 1.20434, -0.952483, 0.381733, 0.179392, -0.237271, -0.188441, 0.38831, 0.0267378, 0.879464, 0.0823111, -0.292617, -0.140366, 0.224443, -0.0302553, -0.0163424, -0.339696, -0.252362, 0.19129, -0.121184, 0.137416, -0.0972165, 0.0530617, 0.219897, 0.0574719, -0.325802, 0.0645705, 0.36579, -0.115215, -0.29473, -0.347822, 0.223799, 0.315211, -0.630524, -0.201789, 0.191721, -0.0163951, -0.304868, 0.172699, 0.0171105, 0.00318672, -0.0927319, -0.285892, 0.302453, -0.204753, -0.14972, -0.453982, 0.230815, -0.0721417, -0.591244, -0.115591, -0.161005, -0.0867436, -0.0314927, -0.124328, -0.289809, 0.124242, -0.355802, -0.285451, 0.0486249, 0.0806372, -0.108165, 0.13256, 0.288814, 0.0781132, 0.256272, -0.22293, 0.262656, 0.286733, -0.185215, -0.134406, -0.236466, 0.23858, 0.334934, 0.117612, -0.0916938, 0.586369, 0.0190669, 0.0995431, 0.132054, -0.0429901, 0.45338, 0.125139, -0.0332289, -0.080199], "internal": 0}
{"paper_id": "C10-1037", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.313272, 0.223922, -0.264953, 0.027124, 0.49452, -0.906411, -0.339556, -0.114621, -1.49025, 0.0534357, -0.294997, -0.283847, 0.812383, 0.288961, 0.25051, -0.0594953, 0.300521, -0.654513, -0.349394, 0.206621, 0.0518625, 0.47173, 0.312253, -0.0240984, -0.474363, 0.161162, 0.115996, 0.196914, 0.150809, -0.22744, 0.290016, 0.00366314, 0.154403, -0.611319, -0.292126, -0.0874183, -0.145193, 0.705317, 0.409571, 0.0634267, -0.034283, -0.537189, 0.263474, 0.100937, 0.764742, -0.827495, 0.0824224, 0.467153, -0.236391, -0.141898, 0.240286, 0.0813609, 0.634575, 0.651107, -0.107856, -0.0349295, 0.00226864, 0.284693, -0.261779, -0.0225165, -0.576586, -0.535185, 0.0748409, 0.299023, -0.264994, -0.121896, 0.462283, 0.140576, 0.321954, -0.0767831, -0.199658, -0.173226, 0.0082106, -0.0202267, 0.328405, -0.220325, -0.358121, -0.23125, -0.13494, -0.332126, -0.198419, -0.191639, 0.0887649, -0.00562696, 0.416506, -0.56008, -0.107728, 0.0938619, 0.032929, 0.00138941, -0.0296344, -0.0132536, -0.832507, -0.369275, 0.121033, 0.148877, 0.208547, -0.528636, -0.377245, -0.0124445, -0.0225725, -0.493446, -0.166495, 0.184097, -0.276981, 0.230014, -0.285225, -0.153165, -0.00717884, -0.0447346, 0.083227, -0.104975, 0.335053, -0.13476, 0.253985, -0.249956, 0.157385, 0.0521872, -0.187033, 0.0856481, -0.378172, 0.121496, 0.205285, -0.254256, 0.510766, 0.383281, -0.264827, 0.118325], "internal": 0}
{"paper_id": "L08-1017", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.308736, 0.592828, 0.183801, 0.281606, 0.567597, -0.833627, -0.312168, 0.090742, -1.49317, 0.53071, 0.360084, -0.252612, 1.16459, 0.344623, -0.359858, -0.074521, 0.296259, -0.564053, 0.335682, 0.0876876, -0.640926, 0.651501, 0.623224, -0.357747, -0.312477, -0.396035, 0.134594, 0.0700733, 0.0844272, 0.109058, 0.114246, -0.0175313, 0.290036, -0.59153, -0.134204, 0.0503623, -0.358344, 1.08234, 0.178087, 0.164068, 0.41345, -0.375718, -0.414427, 0.239088, 1.19477, -1.2322, -0.124957, -0.0598039, 0.496326, -0.0948206, 0.23983, -0.48969, 1.20319, 0.822845, 0.266401, 0.27281, 0.298364, 0.445099, 0.0169986, -0.0910865, -0.351228, -0.322042, -0.224339, -0.0745892, 0.107906, -0.062667, 0.617511, -0.00921848, 0.179822, -0.134934, 0.346307, 0.255349, 0.2035, -0.0927103, -0.205772, 0.114127, -0.615986, -0.633568, -0.180117, -0.161843, 0.132694, -0.0574514, 0.105541, -0.104348, -0.0148503, -0.222067, 0.627419, -0.437418, 0.429035, -0.0451392, 0.0257961, -0.169826, -0.247595, -0.244968, 0.0989687, 0.224537, -0.0454313, -0.212509, -0.14315, -0.208169, -0.185574, -0.258436, -0.157856, -0.177024, 0.101844, 0.640352, -0.023333, 0.290887, -0.242689, -0.0723393, 0.178873, -0.335335, -0.115625, -0.267862, -0.0756485, 0.0116146, 0.683539, 0.364194, -0.0561532, 0.0631573, 0.131258, -0.0140955, 0.258906, -0.00968773, 0.599473, 0.547568, 0.0857736, 0.115976], "internal": 0}
{"paper_id": "I05-3017", "abstract": "", "title": "", "venue": "", "graph_vector": [0.219798, 0.297494, -0.24701, 0.478589, 0.473412, -0.998782, -0.131544, 0.0430731, -1.59329, 0.0391252, -0.13701, -0.203262, 0.610616, 0.355326, -0.165596, -0.46245, 0.481189, -0.541558, -0.129546, 0.386634, -0.121664, 0.634117, 0.571893, 0.128647, -0.0604155, 0.209699, 0.182042, -0.138665, 0.010045, -0.115635, -0.0175364, -0.190982, 0.345389, -0.526325, -0.00422743, 0.256752, -0.13308, 0.677152, 0.309656, 0.0767319, 0.0942251, -0.380552, -0.294295, 0.543416, 0.94375, -0.639229, -0.329846, -0.0191256, -0.340399, 0.370452, 0.0399423, -0.347125, 0.870187, 0.520591, -0.569023, -0.0476666, 0.377471, 0.390288, -0.245505, 0.144393, -0.337245, 0.303315, 0.13924, 0.0170814, -0.304401, -0.266013, -0.0412418, 0.0374657, -0.262412, 0.113519, 0.396754, 0.117087, 0.106609, -0.257698, 0.239376, -0.149864, -0.648589, -0.318914, -0.258359, -0.159695, -0.216634, 0.116346, 0.295681, 0.250516, 0.308586, -0.564954, -0.432393, -0.441717, -0.0552042, 0.0325665, 0.16911, 0.255059, -0.697093, -0.277769, 0.129016, 0.0353037, -0.0719024, 0.00722844, -0.226569, -0.333168, -0.0139867, -0.383797, -0.139145, 0.181634, -0.267668, 0.0387415, 0.363311, 0.146566, -0.0307479, -0.487994, -0.0601406, -0.223262, -0.172561, -0.0968937, -0.0648628, -0.0184362, 0.153625, 0.348689, -0.109241, 0.338969, 0.133081, -0.181317, -0.0227354, 0.18856, 0.0528929, 0.0938818, 0.135174, -0.0380219], "internal": 0}
{"paper_id": "C04-1081", "abstract": "", "title": "", "venue": "", "graph_vector": [0.221593, 0.12915, 0.0786487, 0.431561, 0.313605, -0.929827, -0.270311, -0.00940508, -1.29636, 0.191028, 0.251218, -0.406386, 0.796074, 0.226224, -0.273107, -0.294848, 0.241822, -0.780316, -0.160501, 0.442653, -0.0440046, 0.759548, 0.20956, -0.105475, -0.152103, -0.0248054, 0.0757183, -0.290789, -0.312898, 0.0112772, 0.146931, 0.0360341, 0.159151, -0.300044, -0.0148833, 0.384686, -0.0646418, 0.485374, 0.193591, -0.0703015, -0.0905906, -0.581184, -0.131214, 0.329691, 1.05338, -0.926021, -0.279751, -0.111018, -0.0396607, 0.206845, 0.312319, -0.340605, 0.621111, 0.845032, -0.589222, -0.0905109, 0.282987, 0.396621, 0.0385997, 0.276576, -0.557972, 0.0888034, 0.0520649, -0.367509, -0.394653, -0.367869, 0.183813, -0.0626903, -0.117314, 0.0962549, 0.0034734, -0.187247, 0.227488, -0.243585, 0.00521496, -0.331256, -0.417665, -0.319256, -0.12621, -0.177444, -0.215672, 0.0915752, 0.349426, 0.333587, 0.243771, -0.650472, 0.0725551, -0.368129, -0.186869, -0.0454578, 0.1996, 0.222137, -0.426425, -0.223531, 0.359704, -0.106754, 0.0166095, -0.0538681, 0.0629492, -0.0791004, -0.13786, -0.0974447, -0.0225939, 0.0552915, 0.116922, 0.178659, 0.0709462, 0.143175, 0.241711, -0.353833, 0.242072, 0.0600351, -0.371322, -0.264966, 0.0381379, -0.0563114, 0.112503, 0.106391, -0.0531937, 0.248094, 0.154211, -0.0457209, -0.0590009, 0.163705, 0.255437, 0.400976, -0.217327, -0.0801907], "internal": 0}
{"paper_id": "C08-1067", "abstract": "", "title": "", "venue": "", "graph_vector": [0.0667623, 0.383785, 0.188769, 0.138202, 0.291818, -0.472126, 0.0413942, 0.102544, -1.23825, 0.319541, 0.00359567, -0.313829, 0.592919, 0.0174873, 0.00906317, -0.235121, 0.471012, -0.401575, 0.0191663, 0.356468, -0.0260362, 0.272549, 0.253598, 0.0781858, -0.223645, 0.155081, 0.0343983, 0.0829765, -0.297464, -0.0333187, 0.290918, -0.0996647, 0.0820553, 0.105089, -0.13402, 0.0789608, 0.0405955, 0.212286, 0.247645, -0.207473, 0.0221522, -0.145844, -0.395838, 0.254703, 0.944437, -0.574093, 0.40125, 0.152871, -0.129818, -0.274128, 0.130529, 0.0657926, 0.6787, 0.581092, -0.34857, 0.179905, 0.225303, 0.364266, -0.078802, -0.14964, -0.0787785, -0.240672, 0.0331978, -0.118316, 0.00509291, -0.247827, 0.236528, 0.0633511, -0.290047, -0.0157573, 0.0750156, 0.127525, -0.0178992, -0.188504, 0.213472, -0.0432733, -0.46915, -0.110431, 0.061754, -0.0243352, -0.0204229, 0.0505715, 0.15813, -0.179883, 0.013725, -0.084114, 0.288441, -0.0115145, -0.0893194, -0.215274, 0.139497, 0.114404, -0.664496, 0.150816, 0.0354719, 0.0103467, -0.151273, -0.0362281, -0.0760931, -0.0831924, -0.283075, -0.247399, -0.0449516, 0.13708, -0.0691837, 0.0501095, -0.0238835, -0.0346966, 0.132912, -0.233724, -0.0130932, 0.151416, 0.0288855, -0.224292, -0.155942, -0.163841, 0.324074, 0.232446, 0.112786, 0.11647, -0.195546, 0.0268814, -0.180525, -0.113145, 0.350826, 0.145225, -0.0747625, -0.0443411], "internal": 0}
{"paper_id": "P14-2133", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.250951, 0.190375, 0.119876, 0.701711, 0.60363, -0.83304, 0.146789, -0.227351, -1.51516, 0.190538, -0.108409, -0.475066, 0.740274, -0.121897, 0.015248, -0.150823, 0.497742, -0.559414, -0.235574, 0.336027, -0.537361, 0.866058, 0.34935, 0.0601207, -0.640435, -0.00232714, -0.0907175, -0.0190271, 0.0243788, -0.227238, -0.0574576, -0.0985179, -0.127877, -0.357346, -0.138067, 0.149312, -0.18736, 0.503519, 0.13116, -0.350421, -0.0948744, -0.419454, -0.341379, 0.118259, 0.983058, -0.863593, 0.261537, -0.249212, -0.047321, -0.31637, 0.305391, -0.292551, 0.717329, 0.199464, 0.0104629, -0.0729921, -0.149619, 0.119564, -0.131419, -0.0458397, -0.184382, -0.218496, 0.0485868, -0.140002, 0.039708, -0.0790761, 0.0263666, -0.114602, 0.234369, -0.0468741, -0.0456623, 0.222389, -0.132895, -0.3579, 0.0576428, -0.241105, -0.261686, -0.559917, -0.0720985, -0.207278, -0.219838, 0.0444237, 0.293791, 0.211939, 0.240231, -0.281794, 0.0970042, 0.0542331, -0.0726382, -0.128604, 0.160005, 0.508515, -0.772478, -0.289518, 0.056571, -0.209306, -0.0327821, 0.115559, 0.354573, -0.17413, -0.161068, -0.259977, 0.000379419, -0.126345, -0.145555, 0.452877, 0.184467, -0.405086, -0.0759835, -0.348347, 0.140951, -0.303835, -0.204696, 0.0448691, -0.143703, 0.259434, 0.306079, 0.0506101, 0.020213, 0.336157, -0.0617423, 0.0157091, 0.241659, 0.0664064, 0.351919, 0.312996, -0.149387, 0.143494], "internal": 0}
{"paper_id": "C14-1008", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.0338857, 0.365865, 0.210277, 0.503856, 0.612658, -0.791773, 0.079291, -0.127647, -1.30367, 0.0102263, 0.0671371, -0.492439, 0.482125, 0.0972518, 0.0873876, 0.0567702, 0.326075, -0.60114, -0.168626, 0.384249, 0.0909595, 0.633518, 0.302872, -0.082888, -0.468238, 0.122695, 0.313095, 0.0797324, 0.031245, -0.393769, -0.280316, 0.0916544, 0.0892858, -0.789625, -0.210005, 0.270274, -0.288211, 0.70475, -0.00310771, -0.133258, 0.239835, -0.352907, -0.461319, 0.561902, 1.00319, -1.11106, -0.232213, -0.157696, -0.422512, 0.174919, 0.227544, -0.43414, 0.888183, 0.598779, 0.155906, -0.100388, 0.108492, -0.0707258, -0.304652, 0.171729, -0.136247, 0.277868, -0.0841431, 0.0494579, 0.0554804, -0.0189225, 0.154586, -0.0850962, 0.20598, -0.180228, -0.0663174, -0.0322636, 0.0682168, -0.414343, 0.261378, -0.275439, -0.478591, -0.372573, -0.128448, -0.260644, -0.37206, 0.162619, 0.532035, 0.581671, 0.506748, -0.665532, -0.0966292, -0.1788, -0.193249, -0.0171954, 0.420766, 0.282228, -0.790799, -0.35955, -0.150128, 0.0485692, -0.120415, 0.239359, -0.283743, -0.279792, -0.164265, -0.0874297, -0.053965, -0.150846, -0.053147, 0.133621, 0.0201552, -0.144293, 0.0152489, -0.271187, 0.174305, -0.0933186, -0.112274, -0.0488226, -0.210882, -0.0357122, 0.212541, -0.107527, -0.089117, 0.34049, -0.106842, 0.0060687, 0.0683272, 0.260706, 0.412527, 0.158629, -0.213619, 0.230958], "internal": 0}
{"paper_id": "C14-1206", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.194333, 0.201199, 0.333519, 0.0887765, 0.0573815, -0.525428, -0.183827, -0.101232, -1.32008, 0.199884, 0.0292294, -0.447283, 0.739481, 0.086192, 0.0172352, 0.0216705, 0.677171, -0.710706, 0.271483, 0.371507, -0.291229, 0.670194, 0.138475, -0.0735124, -0.277402, -0.0415145, -0.0183326, -0.0900334, -0.335863, -0.113684, 0.0580769, -0.0902721, 0.21334, -0.358931, 0.0674223, -0.0203557, -0.422832, 0.620572, -0.0516457, 0.0213911, -0.021362, -0.261713, 0.00810839, 0.193379, 0.704978, -0.821641, -0.0324721, 0.0279673, -0.108875, -0.0988594, 0.0480761, 0.176908, 0.651134, 0.463167, -0.0693528, 0.16622, 0.0677137, -0.071971, -0.274138, -0.0531754, -0.191364, -0.114446, 0.0877424, 0.0561622, -0.123019, -0.119085, 0.240955, -0.152536, 0.15451, 0.0454417, 0.160767, -0.102001, 0.0319782, -0.200469, 0.152125, -0.0384567, -0.193823, -0.217801, -0.0556695, -0.0562475, 0.143403, 0.00976403, -0.0563958, -0.0583938, -0.233796, -0.264076, 0.14565, -0.0697824, 0.356479, -0.126181, -0.217497, -0.0632518, -0.628962, -0.235455, 0.0119538, -0.084159, -0.100307, 0.283826, -0.100374, -0.1033, -0.114672, -0.133299, 0.174705, 0.0133594, 0.157049, -0.0361434, -0.0136472, -0.152555, -0.126154, 0.109785, 0.107102, -0.0160991, 0.0503488, -0.154138, -0.157747, 0.204433, 0.425234, 0.344203, -0.0115405, 0.159825, 0.0543381, 0.11549, -0.190012, -0.0354202, 0.403603, 0.0450141, 0.221402, 0.00996569], "internal": 0}
{"paper_id": "C14-1003", "abstract": "", "title": "", "venue": "", "graph_vector": [0.186663, 0.0690197, 0.0583851, 0.0925565, 0.181903, -0.566626, 0.1422, -0.216728, -1.11649, 0.358448, 0.010193, -0.325125, 0.615784, -0.0202804, -0.135164, 0.050274, 0.262554, -0.47063, -0.0429771, 0.282887, -0.0825996, 0.354352, 0.226501, -0.0123948, -0.19743, 0.143801, -8.65785e-05, 0.149974, -0.196609, -0.0503738, -0.177709, -0.107364, -0.11504, -0.140851, -0.135422, 0.044385, -0.338179, 0.400556, -0.0577062, -0.0408561, -0.0125062, -0.342445, -0.083092, 0.364014, 0.650987, -0.626018, 0.278472, 0.116972, 0.0492101, -0.168705, 0.0902581, -0.0909553, 0.487436, 0.66681, -0.0593272, 0.221732, 0.11793, 0.158507, -0.0859032, -0.0444024, -0.123234, -0.186446, 0.142139, 0.090842, 0.119919, -0.0571098, -0.0936383, 0.0380573, -0.146525, 0.0723205, 0.134933, 0.16252, 0.125771, 0.0157256, 0.0590847, -0.000955062, -0.362882, -0.169209, 0.0860083, 0.0853269, 0.12927, -0.120707, -0.0578452, 0.0649664, -0.0986954, -0.193768, 0.141866, -0.279051, -0.0117327, 0.103024, -0.136637, -0.125039, -0.55037, -0.10133, 0.0395396, -0.122532, -0.142641, 0.0533298, -0.133683, -0.102896, -0.291812, -0.326151, 0.0107951, 0.1335, -0.139586, -0.035163, -0.156073, -0.132028, 0.0354911, -0.307879, 0.191792, -0.0893487, 0.042282, 0.198807, -0.176234, 0.20891, 0.353292, 0.103335, -0.0247118, 0.132216, 0.056352, -0.0453169, -0.0405103, 0.129809, 0.367961, 0.380819, 0.0866465, 0.038021], "internal": 0}
{"paper_id": "C02-1025", "abstract": "", "title": "", "venue": "", "graph_vector": [0.260621, 0.162661, 0.0166133, 0.0468783, 0.401355, -0.798317, -0.212822, 0.106038, -1.46773, 0.45566, -0.120674, -0.379702, -0.0410188, 0.0812553, 0.141478, -0.0407102, 0.258519, -0.264897, 0.399695, 0.583902, -0.466771, 0.606634, 0.117997, -0.14505, -0.380481, -0.0819573, 0.030155, 0.177919, -0.406802, -0.326242, 0.228916, -0.0140943, 0.465698, -0.766045, 0.428975, 0.246696, -0.160616, 0.873586, 0.00870369, -0.368513, -0.0731548, -0.548678, -0.357634, 0.411774, 1.01175, -0.675593, -0.0740537, 0.0705734, 0.128948, 0.0114797, 0.257141, -0.157787, 0.886444, 0.943051, -0.636375, -0.0904737, 0.151212, -0.127274, -0.287615, 0.192294, -0.418176, -0.187214, -0.155728, -0.0571095, -0.264539, -0.0101447, 0.117163, -0.0160807, -0.0318378, -0.0785441, 0.323373, 0.315839, -0.230424, -0.236001, -0.0784405, 0.0222368, -0.220353, -0.656361, -0.00434461, -0.416147, 0.0752052, -0.0760493, 0.192448, 0.168098, 0.311129, -0.0292154, -0.0153403, 0.129452, 0.0598326, -0.19717, 0.287668, 0.194618, -0.392685, 0.109766, -0.0117436, -0.28479, -0.0463899, -0.0199503, 0.244916, -0.109153, -0.141719, -0.191655, 0.257267, 0.283911, 0.477485, 0.0556529, 0.0038503, -0.149848, 0.377141, 0.0574474, 0.160934, -0.1334, 0.0332165, -0.0352443, 0.0249782, -0.626351, 0.354155, -0.152373, 0.329909, 0.212641, 0.366988, 0.084756, -0.297605, 0.0168355, 0.258868, 0.27246, -0.268614, 0.0108146], "internal": 0}
{"paper_id": "I08-1012", "abstract": "", "title": "", "venue": "", "graph_vector": [0.177428, 0.295828, 0.234352, 0.231343, 0.477122, -1.07668, 0.0725916, -0.318332, -1.80096, -0.122479, -0.00197016, -0.203799, 0.697551, -0.0382559, -0.111483, -0.11297, 0.557621, -0.832861, 0.0385321, 0.310078, -0.515657, 0.694565, 0.452454, -0.124255, -0.231684, 0.271097, 0.185039, 0.20375, -0.409638, -0.255956, 0.12134, -0.324366, 0.155917, -0.512107, -0.194417, 0.0442881, -0.450146, 0.594183, -0.00127531, 0.0620606, 0.128153, -0.275315, -0.078574, 0.231806, 0.643767, -0.800323, -0.116513, -0.0284482, 0.0241053, 0.144545, 0.216777, -0.320475, 0.635554, 0.741823, -0.418979, 0.0148862, 0.052193, 0.515458, 0.166886, -0.266142, -0.387335, 0.195646, -0.0582621, -0.188555, -0.127986, -0.221093, -0.0581344, -0.0411653, -0.295162, 0.0563825, -0.00239741, -0.16552, -0.157493, 0.0177464, 0.383188, -0.197917, -0.399105, -0.0380782, 0.00743703, 0.063286, -0.0607841, -0.132653, 0.170393, 0.299163, 0.0551961, -0.278855, 0.223567, -0.13669, 0.122019, -0.26758, -0.273894, -0.0862693, -0.436656, -0.097936, 0.179231, -0.217849, -0.178122, -0.106419, -0.0904898, -0.105844, -0.0376506, -0.376282, 0.0651677, -0.0848124, -0.192631, -0.140298, -0.0541193, -0.301362, -0.241782, -0.163159, -0.162372, -0.317934, -0.1389, 0.100826, -0.226357, 0.221721, 0.647665, 0.27541, 0.0795581, 0.391772, 0.105933, -0.233232, -0.0571499, -0.259224, 0.538173, 0.117608, -0.073468, -0.174161], "internal": 0}
{"paper_id": "W09-1324", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.0783549, 0.283285, 0.261586, 0.0144167, 0.428124, -0.60824, 0.0284961, 0.260502, -1.3432, 0.0527697, 0.115509, 0.00349043, 0.581423, 0.100015, 0.117177, -0.107381, 0.391131, -0.637019, 0.186934, 0.321216, -0.22314, 0.49013, 0.169839, 0.0494944, -0.259091, 0.0791662, 0.175726, -0.0239694, -0.089344, -0.0183236, 0.211604, 0.00544209, -0.100544, -0.0937222, -0.152919, 0.222068, -0.162901, 0.592436, 0.0822862, -0.0740729, -0.081046, -0.280055, -0.546502, -0.161376, 0.616093, -0.800902, 0.0600444, 0.233101, 0.04867, 0.0419345, 0.184365, 0.0128436, 0.741323, 0.422041, -0.0877662, 0.150685, 0.24565, 0.0816759, -0.179663, -0.00118189, -0.215167, -0.105919, -0.234437, 0.116373, -0.0830578, -0.123061, 0.0398494, 0.0648288, 0.174961, -0.147984, 0.0451077, -0.0295121, -0.255518, 0.170773, 0.140796, -0.016996, -0.545133, -0.230415, -0.0950516, 0.0681575, -0.230635, 0.00940461, 0.131088, -0.184376, 0.0485426, -0.427355, 0.234376, 0.00226756, 0.228919, 0.132885, -0.000700275, 0.0858411, -0.764944, 0.016966, 0.10498, 0.00375648, 0.0147476, -0.217173, -0.240578, 0.0866655, -0.326002, -0.161397, -0.00393885, -0.0977665, -0.000239593, -0.0624845, 0.0985229, 0.0176836, 0.0909521, -0.373526, 0.0757726, 0.0160359, -0.150157, -0.0911911, -0.230359, -0.25108, 0.319368, 0.124234, 0.108767, 0.185616, 0.271412, -0.239008, 0.0377886, -0.115671, 0.377702, 0.139758, 0.0101444, 0.225035], "internal": 0}
{"paper_id": "I08-7006", "abstract": "", "title": "", "venue": "", "graph_vector": [0.124154, 0.377434, -0.0306856, 0.37214, 0.376973, -0.882379, -0.110085, -0.074348, -1.22443, 0.24943, -0.156369, -0.352455, 0.43136, 0.29692, -0.0105346, -0.237984, 0.294043, -0.322561, -0.0692827, 0.515011, -0.0312286, 0.595436, 0.289679, -0.0173365, -0.471874, -0.0483129, 0.0192202, -0.0960328, -0.243582, -0.297827, 0.243289, -0.0375161, 0.239669, -0.215684, -0.290174, 0.408237, -0.24783, 0.488422, 0.173047, -0.0679136, -0.0479252, -0.0752582, -0.349312, 0.115766, 0.858193, -0.742661, -0.206312, 0.0869047, -0.0812033, 0.0326035, -0.00493274, -0.158667, 0.995591, 0.555678, -0.439062, 0.111696, 0.21901, 0.0752804, 0.180316, 0.142584, -0.354711, 0.0661868, -0.0463694, -0.0428924, -0.43399, 0.00370443, 0.282157, -0.00283553, -0.215503, 0.259999, 0.0877013, -8.20347e-05, 0.0112554, -0.0515473, 0.314578, -0.275806, -0.621509, -0.240692, -0.295293, 0.0590285, -0.037856, 0.0538733, 0.248955, -0.0409943, 0.411519, -0.294826, 0.0115129, -0.375343, -0.129046, 0.0191884, 0.24232, 0.0905024, -0.445529, -0.115998, 0.051284, 0.212017, 0.126316, -0.231481, -0.0384425, -0.221817, -0.126448, -0.17312, -0.216574, 0.256625, 0.234552, -0.064673, 0.259423, 0.148222, -0.0180634, -0.332383, -0.0162444, 0.163063, -0.0547351, -0.140706, 0.0207085, -0.153105, -0.151247, 0.0905519, -0.0179936, 0.216976, -0.156487, -0.135738, -0.223001, 0.11068, 0.412528, 0.370818, 0.0851393, -0.017334], "internal": 0}
{"paper_id": "I08-1053", "abstract": "", "title": "", "venue": "", "graph_vector": [0.069094, 0.262878, -0.176857, 0.19704, 0.396365, -0.709486, -0.102518, -0.416373, -1.31255, 0.279692, -0.272814, -0.381822, 0.514947, 0.0351673, 0.0367861, -0.0301154, 0.660971, -0.532724, 0.274953, 0.201649, -0.0116699, 0.580952, 0.365493, -0.176484, -0.507467, -0.0837197, 0.104756, 0.169212, -0.373381, -0.123621, 0.192192, 0.0626541, -0.0287964, 0.0181165, -0.31583, 0.236343, -0.0642711, 0.242696, 0.165585, 0.139726, -0.0376504, -0.471279, -0.520832, 0.790783, 1.15823, -0.719824, 0.16788, 0.144149, -0.0172561, -0.039303, -0.0344255, -0.0481761, 0.795025, 0.423927, -0.00604332, 0.0526956, 0.35237, 0.259578, 0.0487233, -0.16785, -0.0374465, -0.250247, 0.00205938, 0.131617, -0.164059, -0.0409068, 0.140568, 0.000911194, -0.259331, 0.0306138, 0.21227, 0.0288255, -0.117997, -0.11899, 0.111629, -0.322098, -0.69458, -0.306753, -0.0787629, 0.0663445, -0.146879, 0.0737503, 0.167952, -0.309192, -0.0595478, -0.188244, 0.0465543, -0.0940278, 0.0578668, -0.263728, 0.337515, -0.0969724, -0.497108, -0.00354062, 0.267581, 0.0762188, -0.0180115, -0.270757, -0.0419927, 0.117786, -0.332139, -0.0522902, -0.11826, 0.173301, 0.0933646, 0.14531, -0.0255942, 0.11196, 0.0366371, -0.137834, -0.0577261, 0.202836, -0.0761795, -0.228733, -0.136648, -0.205737, 0.318181, -0.077653, 0.137072, 0.0203057, 0.324513, -0.0923257, -0.207078, 0.0125498, 0.426753, 0.307989, -0.222643, 0.035083], "internal": 0}
{"paper_id": "C14-1018", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.0178663, 0.541174, 0.0997569, 0.183726, 0.668375, -1.02167, 0.130842, -0.0943869, -1.57961, -0.0497343, 0.0604709, -0.366121, 0.577552, -0.286851, 0.305299, 0.24256, 0.661868, -0.257378, 0.135056, 0.220961, 0.0151625, 0.722717, 0.0564851, -0.10554, -0.275472, 0.261981, 0.013276, 0.0701693, -0.262819, -0.386261, -0.345829, 0.172695, 0.171535, -0.363579, -0.175132, 0.0382067, -0.462643, 0.71716, 0.157114, -0.199561, -0.230179, -0.398961, -0.274348, 0.510397, 0.762123, -0.837821, 0.0696756, -0.0420812, -0.0387949, -0.162198, 0.379859, -0.412785, 0.788248, 0.675377, -0.0693922, 0.0997964, 0.242971, 0.158203, 0.0151885, 0.204745, 0.0451176, 0.0792634, -0.107408, -0.21652, -0.151556, -0.0280725, 0.283999, -0.173262, 0.311937, -0.0138533, -0.00412569, -0.046036, -0.139803, -0.173287, -0.0841982, -0.305755, -0.355275, -0.422357, -0.101505, -0.0664368, -0.292793, -0.0181436, 0.340767, 0.0903029, 0.111346, -0.66041, 0.132197, -0.0414369, -0.258546, -0.0181528, 0.235017, 0.275831, -0.680538, -0.272221, -0.136687, -0.136172, -0.00243949, 0.117449, 0.162063, -0.186525, -0.208278, -0.302697, -0.0231068, -0.106932, 0.106947, 0.175912, -0.294571, -0.275765, 0.241307, -0.325126, 0.199334, 0.0391034, -0.183859, 0.0986228, -0.092235, -0.0816537, 0.176232, 0.373408, -0.121272, 0.229629, -0.276613, 0.190866, -0.0121141, 0.111803, 0.382796, 0.0654885, -0.0235307, 0.306392], "internal": 0}
{"paper_id": "C14-1015", "abstract": "", "title": "", "venue": "", "graph_vector": [0.0890426, -0.162074, 0.150424, 0.145472, 0.383919, -0.559706, 0.00514315, -0.0797939, -1.23088, 0.0562546, 0.235371, -0.230006, 0.414663, 0.171953, -0.024554, 0.00441942, 0.372657, -0.476827, -0.0820953, 0.454921, -0.647198, 0.613697, 0.000343914, -0.0791119, -0.170055, 0.05082, -0.0989434, -0.0476926, 0.0792276, -0.106977, -0.261917, 0.0175606, 0.0516677, -0.528802, -0.111685, 0.136593, -0.0618062, 0.536505, 0.216365, -0.127432, 0.24628, -0.536158, -0.170579, 0.46547, 0.949744, -0.59363, -0.146042, 0.0164919, -0.226646, 0.0303721, 0.137613, -0.0908735, 0.870383, 0.613017, -0.0319157, -0.213937, 0.373866, 0.282496, -0.138224, -0.0705533, -0.521798, 0.0605787, 0.084306, -0.0469578, -0.106886, 0.00140597, 0.217645, -0.0205719, 0.0680775, 0.0717581, 0.196106, 0.090396, -0.018665, -0.0017351, 0.0786707, -0.0910225, -0.409217, -0.337852, -0.0945159, -0.27412, -0.216038, -0.103021, 0.216535, -0.0648743, 0.307964, -0.194354, 0.110949, -0.058836, -0.150688, 0.0837804, 0.244873, 0.360165, -0.490499, -0.0266781, 0.0368742, 0.00842074, -0.20532, -0.0831415, 0.0872799, -0.158785, -0.00209485, -0.229209, 0.0189842, -0.0923683, 0.0164156, 0.252143, 0.090272, -0.0152767, 0.00654255, -0.0292135, -0.0399426, -0.130897, -0.151868, -0.0720491, -0.207125, -0.0807536, 0.274887, -0.0539522, -0.128756, 0.254971, 0.00870542, 0.0162578, -0.0794111, -0.151762, 0.227818, 0.156843, -0.0626065, -0.144537], "internal": 0}
{"paper_id": "C14-1083", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.10356, 0.398016, -0.0145516, 0.129487, 0.584977, -0.752071, -0.238946, 0.0822696, -1.37874, 0.0810867, -0.168632, -0.376643, 0.645189, 0.0963137, -0.0244523, 0.0796021, 0.380752, -0.294445, 0.0193939, 0.30024, -0.310659, 0.41492, 0.185926, -0.0779224, -0.27528, 0.168583, 0.0954607, 0.263431, -0.0214321, -0.217098, 0.190028, 0.162482, 0.18053, -0.2562, -0.302504, 0.338636, -0.288411, 0.522325, 0.361566, 0.119568, 0.0704457, -0.153951, -0.189265, 0.350852, 0.559459, -0.637478, -0.137302, 0.0678201, 0.0801381, -0.0318532, 0.0260665, 0.00311157, 0.727308, 0.693208, 0.0606408, 0.207755, 0.0283431, 0.123636, -0.0212313, 0.205972, -0.184288, -0.0831745, 0.126355, 0.01721, -0.129221, -0.00810434, 0.311653, -0.219243, 0.228943, -0.0565471, 0.124399, -0.0956074, 0.0701461, -0.0422397, 0.182574, -0.177195, -0.205207, -0.369025, -0.137128, -0.118608, -0.121599, -0.0333321, 0.201627, 0.0625673, 0.168379, -0.284546, 0.0337586, 0.00813392, 0.0372024, 0.0843526, 0.0165329, -0.0394789, -0.834741, -0.129109, 0.131405, 0.0260313, 0.132065, -0.0753792, -0.0345154, -0.0092622, -0.0326728, -0.259413, -0.0321667, 0.226458, 0.131799, 0.0154588, 0.106272, -0.28226, -0.10951, -0.0456385, -0.00543333, 0.0258906, 0.0586585, 0.0606785, 0.00635501, -0.327616, 0.0340748, -0.115599, -0.0878778, 0.126948, -0.0127788, 0.208125, 0.133862, -0.161528, 0.677484, -0.0674334, -0.252909, -0.108064], "internal": 0}
{"paper_id": "C96-2212", "abstract": "", "title": "", "venue": "", "graph_vector": [-0.000814022, 0.44401, 0.0880407, 0.176482, 0.260164, -0.520283, -0.000244449, -0.0564273, -1.13296, 0.424638, -0.14028, -0.442995, 0.615849, -0.0239152, -0.0591698, -0.286847, 0.319471, -0.382223, 0.0518691, 0.281432, -0.367598, 0.538573, 0.148488, -0.0399942, -0.525807, 0.166301, 0.251478, 0.238086, -0.168805, 0.0252552, 0.0212068, 0.0271786, 0.29078, -0.57665, -0.100545, 0.285601, -0.303826, 0.533021, 0.0145585, 0.0134838, 0.0809213, -0.317643, -0.0517999, 0.378132, 0.69802, -0.606147, 0.166171, 0.0817982, -0.0301762, 0.107088, 0.26663, 0.0944618, 0.837761, 0.418218, -0.203418, 0.155797, -0.0622675, 0.0709322, 0.0652307, 0.0460662, 0.0864725, -0.324788, 0.0222036, 0.0654168, 0.0506766, -0.278251, -0.0793379, -0.0654512, -0.127762, 0.0720548, 0.136455, -0.155121, -0.0385287, -0.213013, 0.137001, -0.123745, -0.515919, 0.0205238, -0.0792596, 0.259751, 0.074185, -0.288089, -0.0239067, -0.0850323, 0.0297137, -0.303238, 0.21572, -0.331052, 0.1436, -0.278963, -0.210599, -0.101857, -0.445953, -0.29766, -0.154332, -0.0770799, -0.0382842, 0.0534556, 0.0732282, 0.0759693, -0.278613, -0.104896, -0.15444, 0.0345815, 0.332112, -0.0664649, 0.160893, -0.151467, 0.0306793, -0.208833, 0.235021, -0.00151374, 0.0766921, 0.171791, 0.0102697, -0.0703357, 0.333522, -0.0237843, 0.138887, 0.0767632, -0.339119, 0.165423, -0.270473, -0.0360272, 0.00967023, 0.023904, -0.00896926, 0.0890465], "internal": 0}
{"paper_id": "I08-7010", "abstract": "", "title": "", "venue": "", "graph_vector": [0.071949, 0.220237, 0.122903, 0.130854, 0.349394, -0.678504, -0.0715525, -0.320265, -1.74797, 0.0645935, -0.197387, -0.416744, 0.459261, -0.00914, -0.0321356, 0.0586792, 0.365798, -0.467072, 0.337156, 0.297738, -0.286342, 0.481752, 0.0983044, 0.0268627, -0.353383, 0.2849, 0.0314041, -0.105221, -0.360101, -0.292851, -0.102484, -0.0145138, -0.0556028, -0.339924, -0.103771, -0.0692476, -0.334732, 0.385052, 0.0501413, -0.0116152, -0.160504, -0.222603, -0.0953621, 0.236604, 0.813013, -0.505219, -0.344302, -0.0714735, -0.177615, 0.0921435, 0.140944, -0.202907, 0.661988, 0.64222, -0.227198, 0.249828, 0.127847, 0.0117222, 0.173424, -0.0267527, -0.294758, -0.224743, -0.105722, -0.079697, -0.127807, -0.191597, 0.165795, -0.285432, 0.18164, 0.0828038, 0.151014, -0.00120756, -0.00868309, -0.297278, -0.0244693, -0.00972317, -0.276099, -0.136617, -0.0800933, 0.113273, -0.0501607, 0.088959, 0.0804924, -0.138843, -0.181993, -0.213639, -0.130811, 0.0347538, 0.2371, -0.00901153, 0.0541636, 0.438732, -0.307134, 0.0694353, -0.0461356, 0.0767245, -0.0669049, 0.0392946, 0.160949, -0.0217934, 0.00298479, -0.415145, 0.0232561, -0.101451, -0.0877156, -0.0730367, -0.269989, 0.246768, -0.238367, 0.0419641, 0.00585157, 0.160036, 0.329284, -0.173555, 0.0237724, 0.122189, 0.618609, -0.031075, -0.0988203, 0.204046, -0.0445873, 0.132767, -0.02678, -0.127984, 0.348937, 0.108843, 0.238726, -0.335081], "internal": 0}
{"paper_id": "S14-2108", "abstract": "", "title": "", "venue": "", "graph_vector": [0.108233, 0.210505, 0.160937, 0.224392, 0.421211, -0.478129, 0.0546678, 0.18048, -1.25455, 0.366159, 0.183763, -0.161517, 0.565056, -0.0992256, 0.0344687, -0.0466921, 0.479712, -0.66705, 0.177119, 0.404137, -0.368625, 0.631029, 0.283604, 0.138826, -0.0986367, 0.114843, 0.229564, 0.0897887, 0.0300011, 0.0346959, -0.0335256, 0.103597, -0.0524457, -0.142548, -0.0568581, 0.0118359, -0.0773887, 0.562636, -0.0566186, -0.124766, -0.0155131, -0.401814, -0.481642, -0.0741752, 0.851035, -0.727181, 0.253264, 0.29136, 0.00545644, -0.114662, 0.0474994, -0.108049, 0.753288, 0.692275, -0.121657, -0.112094, 0.0775929, 0.146869, 0.0189071, 0.0800212, -0.321293, 0.02509, 0.0943938, 0.0525984, -0.0255731, -0.171381, 0.119938, -0.0281631, -0.0121023, -0.185318, 0.12421, 0.255374, -0.188161, 0.0135392, -0.0804652, -0.0759786, -0.617901, -0.303184, -0.199017, -0.0694983, -0.22386, 0.250485, 0.275959, -0.0259138, 0.0237737, -0.503283, 0.284588, -0.34874, 0.266774, -0.0572712, 0.0416548, 0.046489, -0.449361, -0.0405386, -0.028983, -0.157147, -0.228188, -0.178007, 0.00327613, -0.166937, -0.341843, -0.215346, 0.104903, -0.00253677, -0.143479, 0.10683, 0.0562791, -0.0102806, -0.0951438, -0.329279, -0.118793, 0.0655975, -0.211384, -0.118428, -0.256611, -0.0350793, 0.492708, 0.257321, 0.0928037, 0.359289, 0.30372, -0.178237, 0.0305437, -0.17045, 0.225997, 0.0864891, 0.0726909, 0.25456], "internal": 0}
